<phrase>OQL</phrase>[<phrase>C++</phrase>]: <phrase>Extending</phrase> <phrase>C++</phrase> with an Object Query Capability.
<phrase>Transaction Management</phrase> in <phrase>Multidatabase Systems</phrase>.
<phrase>Overview</phrase> of the ADDS System.
<phrase>Multimedia</phrase> <phrase>Information</phrase> Systems: Issues and Approaches.
<phrase>Active</phrase> <phrase>Database Systems</phrase>.
Where <phrase>Object-Oriented</phrase> <phrase>DBMSs</phrase> Should Do Better: A Critique Based on <phrase>Early Experiences</phrase>.
<phrase>Distributed Databases</phrase>.
<phrase>An Object-Oriented</phrase> <phrase>DBMS</phrase> <phrase>War</phrase> <phrase>Story</phrase>: <phrase>Developing</phrase> a <phrase>Genome</phrase> Mapping <phrase>Database</phrase> in <phrase>C++</phrase>.
<phrase>Cooperative</phrase> Transactions for <phrase>Multiuser</phrase> Environments.
Schema <phrase>Architecture</phrase> of the UniSQL/<phrase>M</phrase> <phrase>Multidatabase</phrase> System
<phrase>Physical Object</phrase> <phrase>Management</phrase>.
<phrase>Introduction</phrase> to Part 1: <phrase>Next</phrase>-Generation <phrase>Database</phrase> <phrase>Technology</phrase>.
<phrase>Object-Oriented</phrase> <phrase>Database Systems</phrase>: Promises, <phrase>Reality</phrase>, and Future.
<phrase>Introduction</phrase> to Part 2: <phrase>Technology</phrase> for <phrase>Interoperating</phrase> <phrase>Legacy Databases</phrase>.
On <phrase>Resolving</phrase> <phrase>Schematic</phrase> Heterogeneity in <phrase>Multidatabase Systems</phrase>.
Requirements for a <phrase>Performance Benchmark</phrase> for <phrase>Object-Oriented</phrase> <phrase>Database Systems</phrase>.
On View Support in <phrase>Object-Oriented</phrase> <phrase>Databases</phrase> Systems.
The POSC <phrase>Solution</phrase> to <phrase>Managing</phrase> <phrase>E</phrase>&<phrase>P</phrase> <phrase>Data</phrase>.
<phrase>C++</phrase> Bindings to an <phrase>Object Database</phrase>.
<phrase>Authorization</phrase> in <phrase>Object-Oriented</phrase> <phrase>Databases</phrase>.
<phrase>Query Processing</phrase> in <phrase>Multidatabase Systems</phrase>.
<phrase>Management</phrase> of Uncerainty in <phrase>database Systems</phrase>.
<phrase>Parallel</phrase> <phrase>Relational Database</phrase> Systems.
<phrase>Query Processing</phrase> in <phrase>Object-Oriented</phrase> <phrase>Database Systems</phrase>.
Specification and Execution of <phrase>Transactional Workflows</phrase>.
<phrase>Spatial Data</phrase> Structures.
<phrase>An overview</phrase> is presented of the use of <phrase>spatial data</phrase> structures in <phrase>spatial databases</phrase>. The focus is on <phrase>hierarchical</phrase> <phrase>data</phrase> structures, including a number of variants of <phrase>quadtrees</phrase>, which <phrase>sort</phrase> the <phrase>data</phrase> with respect to the space occupied by it. Such techniques are known as <phrase>spatial indexing</phrase> methods. <phrase>Hierarchical</phrase> <phrase>data</phrase> structures are based on the principle of <phrase>recursive</phrase> decomposition. They are attractive because they are <phrase>compact</phrase> and depending on the <phrase>nature</phrase> of the <phrase>data</phrase> they save space as well as time and also facilitate operations such as search. Examples are given of the use of these <phrase>data</phrase> structures in the representation of different <phrase>data</phrase> types such as regions, points, rectangles, lines, and <phrase>volumes</phrase>.
<phrase>Spatial Data</phrase> Models and <phrase>Query Processing</phrase>.
<phrase>Pegasus</phrase>: A <phrase>Heterogeneous Information</phrase> <phrase>Management</phrase> System.
<phrase>Temporal Object-Oriented Databases</phrase>: A Critical Comparison.
The <phrase>OMG</phrase> <phrase>Object Model</phrase>.
<phrase>EDA</phrase>/<phrase>SQL</phrase>.
The Changing <phrase>Database</phrase> Standards <phrase>Landscape</phrase>.
Modern <phrase>Database Systems</phrase>: The <phrase>Object Model</phrase>, <phrase>Interoperability</phrase>, and Beyond.
Inequalities: Theory of <phrase>Majorization</phrase> and Its Application.
<phrase>Version Control</phrase> in <phrase>an Object-Oriented</phrase> <phrase>Architecture</phrase>.
The <phrase>GemStone</phrase> <phrase>Data Management</phrase> System.
<phrase>Storage Management</phrase> in <phrase>EXODUS</phrase>.
A <phrase>Distributed Object</phrase> <phrase>Manager</phrase> for the <phrase>Smalltalk</phrase>-80 System.
Objects, Messages, and Rules in <phrase>Database Design</phrase>.
<phrase>Active</phrase> Objects: Ealities and Possibilities.
<phrase>Overview</phrase> of the <phrase>Iris</phrase> <phrase>DBMS</phrase>.
Features of the <phrase>ORION</phrase> <phrase>Object-Oriented</phrase> <phrase>Database</phrase> System.
<phrase>Indexing</phrase> Techniques for <phrase>Object-Oriented</phrase> <phrase>Databases</phrase>.
My <phrase>Cat</phrase> Is <phrase>Object-Oriented</phrase>.
Making <phrase>Database Systems</phrase> <phrase>Fast</phrase> Enough for <phrase>CAD</phrase> Applications.
<phrase>Optimizing</phrase> <phrase>Smalltalk</phrase> Message Performance.
The Common List <phrase>Object-Oriented Programming Language</phrase> Standard.
<phrase>Object Orientation</phrase> as <phrase>Catalyst</phrase> for <phrase>Language</phrase>-<phrase>Database</phrase> Inegration.
<phrase>A Survey</phrase> of <phrase>Object-Oriented</phrase> Concepts.
Integrated <phrase>Office</phrase> Systems.
<phrase>Proteus</phrase>: A <phrase>Frame-Based</phrase> <phrase>Nonmonotonic</phrase> Inference System.
<phrase>Concurrency Control</phrase> and <phrase>Object-Oriented</phrase> <phrase>Databases</phrase>.
A Shared View of Sharing: The <phrase>Treaty</phrase> of <phrase>Orlando</phrase>.
Pogo: A <phrase>Declarative</phrase> Representation System for Graphics.
<phrase>Concurrent Object-Oriented Programming Languages</phrase>.
Directions in <phrase>Object-Oriented</phrase> <phrase>Research</phrase>.
A Proposal for a <phrase>Formal Model</phrase> of Objects.
<phrase>OZ</phrase>+: <phrase>An Object-Oriented Database</phrase> System.
The Commercial <phrase>INGRES</phrase> Epilogue.
<phrase>Design</phrase> of <phrase>Relational</phrase> Systems (<phrase>Introduction</phrase> to Section 1).
<phrase>Supporting</phrase> Studies on <phrase>Relational</phrase> Systems (<phrase>Introduction</phrase> to Section 2).
<phrase>Distributed Database</phrase> Systems (<phrase>Introduction</phrase> to Section 3).
The <phrase>Design</phrase> and Implementation of Distributed <phrase>INGRES</phrase>.
<phrase>User Interfaces</phrase> for <phrase>Database Systems</phrase> (<phrase>Introduction</phrase> to <phrase>Section 4</phrase>).
Extended <phrase>Semantics</phrase> for the <phrase>Relational Model</phrase> (<phrase>Introduction</phrase> to Section 5).
<phrase>Database Design</phrase> (<phrase>Introduction</phrase> to Section 6).
<phrase>Title</phrase>, <phrase>Preface</phrase>, Contents.
References.
<phrase>TeX</phrase>: The Program
Foundations of <phrase>Databases</phrase>.
<phrase>LaTeX</phrase>: <phrase>User's Guide</phrase> & <phrase>Reference Manual</phrase>
The <phrase>Design</phrase> and Analysis of Computer <phrase>Algorithms</phrase>.
Specifying Systems, The <phrase>TLA+</phrase> <phrase>Language</phrase> and Tools for Hardware and <phrase>Software</phrase> Engineers
From the <phrase>Book</phrase>: This <phrase>book</phrase> will teach you how to write specifications of <phrase>computer systems</phrase>, using the <phrase>language</phrase> <phrase>TLA+</phrase>. <phrase>It's</phrase> rather <phrase>long</phrase>, but most people will <phrase>read only</phrase> <phrase>Part I</phrase>, which comprises the first 83 pages. That part contains all that most engineers need to know about <phrase>writing specifications</phrase>; it assumes only the <phrase>basic</phrase> background in <phrase>computing</phrase> and <phrase>knowledge</phrase> of <phrase>mathematics</phrase> expected of an <phrase>undergraduate</phrase> studying <phrase>engineering</phrase> or <phrase>computer science</phrase>. <phrase>Part II</phrase> contains more <phrase>advanced</phrase> material for more sophisticated readers. The remainder of the <phrase>book</phrase> is a <phrase>reference manual</phrase><phrase>Part III</phrase> for the <phrase>TLA+</phrase> tools and <phrase>Part IV</phrase> for the <phrase>language</phrase> itself. The <phrase>TLA</phrase> <phrase>World Wide Web</phrase> page contains material to accompany the <phrase>book</phrase>, including the <phrase>TLA+</phrase> tools, exercises, references to the <phrase>literature</phrase>, and a list of corrections. There is a link to the <phrase>TLA</phrase> <phrase>Web</phrase> page on <phrase>http</phrase>://lamport.org.What Is a Specification?Writing is <phrase>nature's</phrase> way of letting you know how sloppy your <phrase>thinking</phrase> is.-GuindonA specification is a written description of what a system is supposed to do. Specifying a system helps us understand it. <phrase>It's</phrase> a good idea to understand a system before <phrase>building</phrase> it, so <phrase>it's</phrase> a good idea to write a specification of a system before <phrase>implementing</phrase> it.This <phrase>book</phrase> is about specifying the <phrase>behavioral</phrase> properties of a systemalso called its <phrase>functional</phrase> or <phrase>logical</phrase> properties. These are the properties that specify what the system is supposed to do. There are other important kinds of properties that we <phrase>don't</phrase> consider, including <phrase>performance properties</phrase>. <phrase>Worst-case</phrase> performance can often be expressed as a <phrase>behavioral</phrase> <phrase>property</phrase>forexample, <phrase>Chapter</phrase> 9 explains how to specify that a system must react within a certain length of time. However, specifying <phrase>average</phrase> performance is beyond the scope of the methods described here.Our <phrase>basic</phrase> tool for <phrase>writing specifications</phrase> is <phrase>mathematics</phrase>. <phrase>Mathematics</phrase> is <phrase>nature's</phrase> way of letting you know how sloppy your writing is. <phrase>It's</phrase> hard to be precise in an imprecise <phrase>language</phrase> like <phrase>English</phrase> or <phrase>Chinese</phrase>. In <phrase>engineering</phrase>, imprecision can <phrase>lead</phrase> to errors. To avoid errors, <phrase>science</phrase> and <phrase>engineering</phrase> have adopted <phrase>mathematics</phrase> as their language.The <phrase>mathematics</phrase> we use is more formal than the <phrase>math</phrase> <phrase>you've</phrase> grown up with. <phrase>Formal mathematics</phrase> is <phrase>nature's</phrase> way of letting you know how sloppy your <phrase>mathematics</phrase> is. The <phrase>mathematics</phrase> written by most <phrase>mathematicians</phrase> and scientists is not really precise. <phrase>It's</phrase> precise in the small, but imprecise in the large. Each equation is a precise <phrase>assertion</phrase>, but you have to read the accompanying words to understand how the equations relate to one another and exactly what the theorems mean. Logicians have developed ways of <phrase>eliminating</phrase> those words and making the <phrase>mathematics</phrase> completely formal, and <phrase>hence</phrase> completely precise.Most <phrase>mathematicians</phrase> and scientists think that <phrase>formal mathematics</phrase>, without words, is <phrase>long</phrase> and tiresome. They're wrong. Ordinary <phrase>mathematics</phrase> can be expressed compactly in a precise, completely <phrase>formal language</phrase>. It takes only about two dozen lines to define the <phrase>solution</phrase> to an arbitrary <phrase>differential equation</phrase> in the <phrase>Differential Equations</phrase> module of <phrase>Chapter</phrase> 11. But few specifications need such sophisticated <phrase>mathematics</phrase>. Most require only simple application of a few standard <phrase>mathematical</phrase> concepts.Why <phrase>TLA+</phrase>?We specify a system by describing its allowed behaviorswhat it may do in the course of an execution. In 1977, <phrase>Amir Pnueli</phrase> introduced the use of <phrase>temporal logic</phrase> for describing system behaviors. In principle, a system could be described by a <phrase>single</phrase> <phrase>temporal logic</phrase> formula. In practice, it couldn't. Pnueli's <phrase>temporal logic</phrase> was ideal for describing some properties of systems, but awkward for others. So, it was usually combined with a more traditional way of describing systems.In the <phrase>late 1980s</phrase>, <phrase>I</phrase> invented <phrase>TLA</phrase>, the <phrase>Temporal Logic</phrase> of Actionsa simple variant of Pnueli's original <phrase>logic</phrase>. <phrase>TLA</phrase> makes it practical to describe a system by a <phrase>single</phrase> formula. Most of a <phrase>TLA</phrase> specification consists of ordinary, nontemporal <phrase>mathematics</phrase>. <phrase>Temporal logic</phrase> plays a significant role only in describing those properties that <phrase>it's</phrase> good at describing. <phrase>TLA</phrase> also provides a <phrase>nice</phrase> way to formalize the style of <phrase>reasoning about</phrase> systems that has proved to be most effective in practicea style known as <phrase>assertional reasoning</phrase>. However, this <phrase>book</phrase> is about specification; it says almost nothing about proofs.Temporal <phrase>logic</phrase> assumes an underlying <phrase>logic</phrase> for expressing ordinary <phrase>mathematics</phrase>. There are many ways to formalize ordinary <phrase>math</phrase>. Most <phrase>computer scientists</phrase> prefer one that resembles their favorite <phrase>programming language</phrase>. <phrase>I</phrase> chose <phrase>instead</phrase> the one that most <phrase>mathematicians</phrase> preferthe one logicians call <phrase>first-order logic</phrase> and set theory.TLA provides a <phrase>mathematical foundation</phrase> for describing systems. To write specifications, we need a complete <phrase>language</phrase> <phrase>built atop</phrase> that <phrase>foundation</phrase>. <phrase>I</phrase> initially thought that this <phrase>language</phrase> should be some <phrase>sort</phrase> of <phrase>abstract</phrase> <phrase>programming language</phrase> whose <phrase>semantics</phrase> would be based on <phrase>TLA</phrase>. <phrase>I</phrase> <phrase>didn't know</phrase> what kind of <phrase>programming language</phrase> constructs would be best, so <phrase>I</phrase> decided to start <phrase>writing specifications</phrase> directly in <phrase>TLA</phrase>. <phrase>I</phrase> intended to introduce <phrase>programming</phrase> constructs as <phrase>I</phrase> needed them. To my surprise, <phrase>I</phrase> discovered that <phrase>I</phrase> didn't need them. What <phrase>I</phrase> needed was a <phrase>robust</phrase> <phrase>language</phrase> for writing mathematics.Although <phrase>mathematicians</phrase> have developed the <phrase>science</phrase> of writing formulas, they haven't turned that <phrase>science</phrase> into an <phrase>engineering</phrase> discipline. They have developed notations for <phrase>mathematics</phrase> in the small, but not for <phrase>mathematics</phrase> in the large. The specification of a real system can be dozens or even hundreds of pages <phrase>long</phrase>. <phrase>Mathematicians</phrase> know how to write 20-line formulas, not 20-page formulas. So, <phrase>I</phrase> had to introduce notations for writing <phrase>long</phrase> formulas. What <phrase>I</phrase> took from <phrase>programming languages</phrase> were ideas for <phrase>modularizing</phrase> large specifications.The <phrase>language</phrase> <phrase>I</phrase> came up with is called <phrase>TLA+</phrase>. <phrase>I</phrase> refined <phrase>TLA+</phrase> in the course of <phrase>writing specifications</phrase> of disparate systems. But it has changed little in the <phrase>last</phrase> few years. <phrase>I</phrase> have found <phrase>TLA+</phrase> to be quite good for specifying a wide class of systemsfrom program interfaces (<phrase>APIs</phrase>) to <phrase>distributed systems</phrase>. It can be used to write a precise, <phrase>formal description</phrase> of almost any <phrase>sort</phrase> of discrete system. <phrase>It's</phrase> especially <phrase>well suited</phrase> to describing <phrase>asynchronous</phrase> systemsthat is, systems with components that do not operate in <phrase>strict</phrase> <phrase>lock</phrase>-step.About This BookPart <phrase>I</phrase>, consisting of Chapters 1 through 7, is the core of the <phrase>book</phrase> and is meant to be read from beginning to end. It explains how to specify the class of properties known as <phrase>safety</phrase> properties. These properties, which can be specified with almost no <phrase>temporal logic</phrase>, are all that most engineers need to know about. After <phrase>reading</phrase> <phrase>Part I</phrase>, you can read as much of <phrase>Part II</phrase> as you like. Each of its chapters is <phrase>independent</phrase> of the others. <phrase>Temporal logic</phrase> comes to the <phrase>fore</phrase> in <phrase>Chapter</phrase> 8, where it is used to specify the additional class of properties known as <phrase>liveness properties</phrase>. <phrase>Chapter</phrase> 9 describes how to specify <phrase>real-time</phrase> properties, and <phrase>Chapter</phrase> 10 describes how to write specifications as compositions. <phrase>Chapter</phrase> 11 contains more <phrase>advanced</phrase> examples. The three chapters in <phrase>Part III</phrase> serve as the <phrase>reference manual</phrase> for three <phrase>TLA+</phrase> tools: the <phrase>Syntactic</phrase> <phrase>Analyzer</phrase>, the TLATEX <phrase>typesetting</phrase> program, and the <phrase>TLC model checker</phrase>. If <phrase>you want</phrase> to use <phrase>TLA+</phrase>, then you probably want to use these tools. They are available from the <phrase>TLA</phrase> <phrase>Web</phrase> page. <phrase>TLC</phrase> is the most sophisticated of them. The examples on the <phrase>Web</phrase> can get you started using it, but you'll have to read <phrase>Chapter</phrase> 14 to learn to use <phrase>TLC</phrase> effectively.Part <phrase>IV</phrase> is a <phrase>reference manual</phrase> for the <phrase>TLA+</phrase> <phrase>language</phrase>. <phrase>Part I</phrase> provides a <phrase>good enough</phrase> working <phrase>knowledge</phrase> of the <phrase>language</phrase> for most purposes. You need look at <phrase>Part IV</phrase> only if you have questions about the fine points of the <phrase>syntax</phrase> and <phrase>semantics</phrase>. <phrase>Chapter</phrase> 15 gives the <phrase>syntax</phrase> of <phrase>TLA+</phrase>. <phrase>Chapter</phrase> 16 describes the precise meanings and the <phrase>general</phrase> forms of all the built-in operators of <phrase>TLA+</phrase>; <phrase>Chapter</phrase> 17 describes the precise meaning of all the <phrase>higher-level</phrase> <phrase>TLA+</phrase> constructs such as definitions. Together, these two chapters specify the <phrase>semantics</phrase> of the <phrase>language</phrase>. <phrase>Chapter</phrase> 18 describes the standard modulesexcept for module <phrase>RealTime</phrase>, described in <phrase>Chapter</phrase> 9, and module <phrase>TLC</phrase>, described in <phrase>Chapter</phrase> 14. You might want to look at this <phrase>chapter</phrase> if <phrase>you're</phrase> <phrase>curious</phrase> about how standard <phrase>elementary</phrase> <phrase>mathematics</phrase> can be formalized in <phrase>TLA+</phrase>.<phrase>Part IV</phrase> does have something you may want to refer to often: a <phrase>mini</phrase>-manual that compactly presents lots of useful <phrase>information</phrase>. Pages 268-273 list all <phrase>TLA+</phrase> operators, all <phrase>user-definable</phrase> symbols, the <phrase>precedence</phrase> of all operators, all operators defined in the standard modules, and the <phrase>ASCII</phrase> representation of symbols.
<phrase>Data Structures</phrase> and <phrase>Algorithms</phrase>.
<phrase>Databases</phrase> and <phrase>Transaction Processing</phrase>: An <phrase>Application-Oriented</phrase> Approach
The <phrase>AWK</phrase> <phrase>Programming Language</phrase>
The <phrase>Java Virtual Machine</phrase> Specification
Compilers: Princiles, Techniques, and Tools.
<phrase>Algorithms</phrase>
This presentation is a <phrase>tutorial</phrase> on AutoView, an <phrase>AutoMod</phrase> extension package that recreates <phrase>model</phrase> <phrase>animation</phrase> according to a <phrase>user-defined</phrase> <phrase>script</phrase>. AutoView allows users to <phrase>restart</phrase> <phrase>animation</phrase> and move back and <phrase>forth</phrase> in time and 3-<phrase>D</phrase> space. <phrase>Animation</phrase> is created using <phrase>text files</phrase> generated from an <phrase>AutoMod</phrase> <phrase>simulation</phrase> <phrase>model</phrase>. By <phrase>creating</phrase> a <phrase>user-defined</phrase> <phrase>camera</phrase> description file, <phrase>animation</phrase> can <phrase>take place</phrase> that allows for panning from one view to another, as well as for attaching the <phrase>camera</phrase> to a simulated load or <phrase>vehicle</phrase> and traveling with that entity during portions of the <phrase>animation</phrase>. The <phrase>animation</phrase> is provided at <phrase>an enhanced</phrase> <phrase>response time</phrase> because it does not have the <phrase>logical</phrase> and statistical processes of <phrase>AutoMod</phrase> (which can slow <phrase>animation</phrase>). This <phrase>tutorial</phrase> demonstrates several <phrase>animation</phrase> scripts <phrase>previously constructed</phrase> with AutoView, discusses the creation of AutoView files from <phrase>AutoMod</phrase>, and describes the development of a <phrase>camera</phrase> description file.
The <phrase>Java Programming Language</phrase>
<phrase>Algorithms</phrase>, <phrase>2nd Edition</phrase>
The <phrase>Java Programming Language</phrase>, <phrase>Second Edition</phrase>
<phrase>Operating System</phrase> Concepts, <phrase>4th edition</phrase>.
The <phrase>Java Programming Language</phrase>, <phrase>Third Edition</phrase>
The TeXbook
<phrase>Modern Information Retrieval</phrase>
:This is a rigorous and complete <phrase>textbook</phrase> for a first course on <phrase>information retrieval</phrase> from the <phrase>computer science</phrase> (as opposed to a <phrase>user-centred</phrase>) <phrase>perspective</phrase>. The advent of the <phrase>Internet</phrase> and the enormous increase in volume of <phrase>electronically stored</phrase> <phrase>information</phrase> generally has <phrase>led</phrase> to substantial work on <phrase>IR</phrase> from the <phrase>computer science</phrase> <phrase>perspective</phrase> - this <phrase>book</phrase> provides an <phrase>up-to-date</phrase> <phrase>student</phrase> oriented treatment of the subject.
<phrase>Conceptual Structures</phrase>: <phrase>Information Processing</phrase> in <phrase>Mind</phrase> and Machine
<phrase>Concurrency Control</phrase> and Recovery in <phrase>Database Systems</phrase>.
<phrase>Code Reading</phrase>: The <phrase>Open Source</phrase> <phrase>Perspective</phrase>
<phrase>Intelligent Database Systems</phrase>
:a valuable resource for anyone working on <phrase>intelligent database systems</phrase>. Good background coverage of both the field of <phrase>databases</phrase> and that of <phrase>AI</phrase> are provided in the first part of the <phrase>book</phrase>, and later there are some excellent analytical discussions of relevant projects. The authors adopt a very readable style which enables a complex topic to become much <phrase>more accessible</phrase>." - Jenny Carter, <phrase>Department</phrase> of <phrase>Computer Science</phrase>, De Montfort <phrase>University</phrase> This <phrase>book</phrase> provides a <phrase>state</phrase> of the <phrase>art</phrase> guide to the <phrase>new developments</phrase> in <phrase>expert database systems</phrase>, from the unique <phrase>perspective</phrase> of both the <phrase>database</phrase> and <phrase>AI</phrase> areas. It gives complete and detailed coverage of the latest <phrase>research</phrase> and practice, including all the need-to-know technical and <phrase>theoretical approaches</phrase> in the <phrase>area</phrase>. <phrase>Drawing</phrase> on their extensive experience, the authors evaluate how <phrase>AI</phrase> techniques can be integrated with present and future <phrase>database systems</phrase> and <phrase>knowledge</phrase> based <phrase>management</phrase> systems, <phrase>incorporating</phrase> <phrase>AI</phrase> expertise into <phrase>system design</phrase>. The <phrase>book</phrase> also addresses the techniques developed <phrase>recently</phrase> which are directly used, or are the basis, for <phrase>data</phrase> retrieval across <phrase>the world wide web</phrase>. If you are a designer or developer working in the <phrase>database</phrase> <phrase>community</phrase>, with <phrase>database</phrase> and <phrase>AI</phrase> <phrase>products</phrase> or applications, this <phrase>book</phrase> will help you to understand crucial <phrase>research</phrase> developments and to apply the <phrase>results</phrase> in practice. Includes: <phrase>&middot</phrase>; Mechanisms for handling <phrase>data</phrase> and <phrase>knowledge</phrase> including <phrase>XML</phrase>, <phrase>web</phrase> <phrase>indexing</phrase>, <phrase>search engines</phrase> & <phrase>data mining</phrase> <phrase>&middot</phrase>; <phrase>Object Oriented</phrase> <phrase>Database Management Systems</phrase> and <phrase>object-relational DBMS</phrase> <phrase>&middot</phrase>; <phrase>Data modeling</phrase> including techniques suchas <phrase>Entity Relationship</phrase>, <phrase>Functional</phrase> <phrase>Data</phrase> & <phrase>Semantic</phrase> <phrase>Database</phrase> models, as well as using the notations for modeling (<phrase>OMT</phrase> & <phrase>UML</phrase>) Plus! Extended <phrase>case studies</phrase> of <phrase>commercial systems</phrase> About the authors: <phrase>Elisa</phrase> Bertino is a well known <phrase>expert</phrase> in the <phrase>integration</phrase> of <phrase>AI</phrase> and <phrase>database</phrase> techniques, areas of <phrase>O</phrase>-<phrase>O</phrase>, distributed, <phrase>deductive</phrase> and <phrase>multimedia</phrase> <phrase>databases</phrase> and <phrase>database</phrase> <phrase>security</phrase>. She has chaired and given <phrase>tutorials</phrase> at many <phrase>international conferences</phrase> and published hundreds of <phrase>journal</phrase> papers and a <phrase>book</phrase>. <phrase>Elisa</phrase> is currently a <phrase>professor</phrase> of <phrase>computer science</phrase> at the <phrase>University</phrase> of <phrase>Milan</phrase>. <phrase>Barbara</phrase> <phrase>Catania</phrase> is an <phrase>assistant</phrase> <phrase>professor</phrase> of <phrase>computer science</phrase> at the <phrase>University</phrase> of <phrase>Genova</phrase>, <phrase>specializing</phrase> in <phrase>deductive</phrase> and <phrase>multimedia</phrase> <phrase>databases</phrase>, and <phrase>indexing</phrase> techniques in <phrase>object-oriented</phrase> and <phrase>constraint databases</phrase>. She has presented at a number of <phrase>international conferences</phrase> and <phrase>co</phrase>-authored a <phrase>book</phrase>. Gian Piero Zarri is an internationally renowned <phrase>consultant</phrase> and <phrase>researcher</phrase> in the areas of <phrase>knowledge-based systems</phrase>, <phrase>natural-language processing</phrase>, <phrase>databases</phrase> and <phrase>information retrieval</phrase> systems. He is on the <phrase>editorial</phrase> board of a number of <phrase>international scientific</phrase> <phrase>journals</phrase> and on the <phrase>program committee</phrase> of many <phrase>conferences</phrase> on <phrase>Knowledge-Based Systems</phrase>. Gian Piero currently works as <phrase>Research</phrase> <phrase>Director</phrase> for <phrase>CNRS</phrase>, the <phrase>French National Centre for Scientific Research</phrase>.
How to Set Up and Maintain a <phrase>World Wide Web</phrase> Site: The Guide for <phrase>Information</phrase> Providers.
<phrase>Object-Oriented</phrase> <phrase>Database Systems</phrase>
<phrase>Advanced</phrase> <phrase>Programming</phrase> in the <phrase>UNIX</phrase> Environment
<phrase>PROLOG</phrase> <phrase>Programming</phrase> for <phrase>Artificial Intelligence</phrase>, <phrase>Second Edition</phrase>
<phrase>TCP/IP</phrase> Illustrated, Volume 1: The Protocols
<phrase>TCP/IP</phrase> Illustrated, Volume 1 is a complete and detailed guide to the entire <phrase>TCP/IP protocol suite</phrase> - with an important difference from other <phrase>books</phrase> on the subject. Rather than just describing what the RFCs say the <phrase>protocol suite</phrase> should do, this unique <phrase>book</phrase> uses a popular <phrase>diagnostic</phrase> tool so you may actually <phrase>watch</phrase> the protocols in action.By <phrase>forcing</phrase> various conditions to occur - such as <phrase>connection establishment</phrase>, timeout and <phrase>retransmission</phrase>, and fragmentation - and then displaying the <phrase>results</phrase>, <phrase>TCP/IP</phrase> Illustrated gives you a much greater <phrase>understanding</phrase> of these concepts than words alone could provide. Whether you are new to <phrase>TCP/IP</phrase> or you have read other <phrase>books</phrase> on the subject, you will come away with an increased <phrase>understanding</phrase> of how and why <phrase>TCP/IP</phrase> works the way it does, as well as <phrase>enhanced</phrase> <phrase>skill</phrase> at <phrase>developing</phrase> aplications that run over <phrase>TCP/IP</phrase>.
<phrase>Database</phrase> <phrase>Security</phrase>.
<phrase>TCP/IP</phrase> Illustrated, Volume 3: <phrase>TCP</phrase> for Transactions, <phrase>HTTP</phrase>, <phrase>NNTP</phrase>, and the <phrase>UNIX</phrase> Domain Protocolls
Object <phrase>Data Management</phrase>: <phrase>Object-Oriented</phrase> and <phrase>Extended Relational</phrase> <phrase>Database Systems</phrase>
Object <phrase>Data Management</phrase>: <phrase>Object-Oriented</phrase> and <phrase>Extended Relational</phrase> <phrase>Database Systems</phrase> (<phrase>Revised</phrase> <phrase>Edition</phrase>)
The <phrase>C++</phrase> <phrase>Programming Language</phrase>, First <phrase>Edition</phrase>
<phrase>Designing</phrase> <phrase>Database</phrase> Applications with Objects and Rules: The IDEA Methodology
The <phrase>C++</phrase> <phrase>Programming Language</phrase>, <phrase>Second Edition</phrase>
The <phrase>Java</phrase> Developers Almanac 1999
<phrase>Introduction</phrase> to <phrase>Data Mining</phrase>
The <phrase>Java Class Libraries</phrase> - An Annotated Reference
Datenmodelle, Datenbanksprachen und <phrase>Datenbank</phrase>-<phrase>Management</phrase>-<phrase>Systeme</phrase>
The <phrase>Java Class Libraries</phrase>, <phrase>Second Edition</phrase>, Volume 2
Datenmodelle, Datenbanksprachen und <phrase>Datenbank</phrase>-<phrase>Management</phrase>-<phrase>Systeme</phrase>. 2. Auflage
The <phrase>Java Class Libraries</phrase>, <phrase>Second Edition</phrase>, Volume 1
<phrase>Das</phrase> <phrase>DB2</phrase>-<phrase>Handbuch</phrase>.
The <phrase>Java Class Libraries</phrase>, <phrase>Second Edition</phrase>, Volume 1, Supplement for the <phrase>Java</phrase> 2 Platform Standard <phrase>Edition</phrase>, v1.2
<phrase>Time Series</phrase> Prediction: <phrase>Forecasting</phrase> the Future and <phrase>Understanding</phrase> the Past.
The <phrase>Relational Model</phrase> for <phrase>Database Management</phrase>, Version 2
From the <phrase>Preface</phrase> (See <phrase>Front Matter</phrase> for full <phrase>Preface</phrase>) An important <phrase>adjunct</phrase> to precision is a <phrase>sound theoretical foundation</phrase>. The <phrase>relational model</phrase> is solidly based on two parts of <phrase>mathematics</phrase>: firstorder <phrase>predicate logic</phrase> and the theory of relations. This <phrase>book</phrase>, however, does not dwell on the <phrase>theoretical foundations</phrase>, but rather on all the features of the <phrase>relational model</phrase> that <phrase>I</phrase> now perceive as important for <phrase>database</phrase> users, and therefore for <phrase>DBMS</phrase> vendors. My perceptions result from 20 years of <phrase>practical experience</phrase> in <phrase>computing</phrase> and <phrase>data</phrase> processing (chiefly, but not exclusively, with <phrase>large-scale</phrase> customers of <phrase>IBM</phrase>), followed by another 20 years of <phrase>research</phrase>. <phrase>I</phrase> believe that this is the first <phrase>book</phrase> to deal exclusively with the <phrase>relational</phrase> approach. It does, however, include <phrase>design</phrase> principles in Chapters 21 and 22. It is also the first <phrase>book</phrase> on the <phrase>relational model</phrase> by the originator of that <phrase>model</phrase>. All the ideas in the <phrase>relational model</phrase> described in this <phrase>book</phrase> are <phrase>mine</phrase>, except in cases where <phrase>I</phrase> explicitly <phrase>credit</phrase> <phrase>someone else</phrase>. In <phrase>developing</phrase> the <phrase>relational model</phrase>, <phrase>I</phrase> have tried to follow Einstein's advice, "Make it as simple as possible, but no simpler." <phrase>I</phrase> believe that in the <phrase>last</phrase> <phrase>clause</phrase> he was discouraging the <phrase>pursuit</phrase> of simplicity to the extent of distorting <phrase>reality</phrase>. So why does the <phrase>book</phrase> contain 30 chapters and two appendixes? To answer this question, it is necessary to look at the <phrase>history</phrase> of <phrase>research</phrase> and development of the <phrase>relational model</phrase>.
<phrase>Java</phrase> Platform Performance - Strategies and Tactics
:This <phrase>book</phrase> addresses a vital issue for all those <phrase>developing</phrase> <phrase>software</phrase> for the <phrase>Java</phrase>™ platform: how to achieve <phrase>maximum performance</phrase> and <phrase>scalability</phrase> for their applications. <phrase>Drawing</phrase> on the authors' <phrase>knowledge</phrase> of the <phrase>Java programming language</phrase> and their extensive experience working on <phrase>performance issues</phrase>, the <phrase>book</phrase> reveals <phrase>common mistakes</phrase> and misconceptions concerning the <phrase>performance characteristics</phrase> of <phrase>Java</phrase> technologies. It offers overall <phrase>development strategies</phrase> and <phrase>concrete</phrase>, <phrase>battle</phrase>-tested techniques to <phrase>dramatically improve</phrase> the performance of applications constructed with the <phrase>Java programming language</phrase>. <phrase>Java</phrase>™ Platform Performance highlights the importance of <phrase>integrating</phrase> <phrase>performance evaluation</phrase> into the <phrase>application development</phrase> process and discusses <phrase>measurement techniques</phrase>. The <phrase>book</phrase> then presents practical tactics for <phrase>enhancing</phrase> <phrase>application performance</phrase> in the areas of <phrase>I/O</phrase>, <phrase>RAM</phrase> <phrase>footprint</phrase>, small <phrase>object management</phrase>, <phrase>algorithms</phrase>, <phrase>data</phrase> structures, <phrase>Swing</phrase>, and deployment. <phrase>Specific topics</phrase> <phrase>covered</phrase> include: <phrase>Incorporating</phrase> <phrase>performance evaluation</phrase> into the <phrase>development process</phrase> <phrase>Profiling</phrase> and <phrase>benchmarking</phrase> <phrase>Building</phrase> scalable, <phrase>fast</phrase> <phrase>Swing</phrase> GUIs Using <phrase>high</phrase>-speed <phrase>I/O</phrase> <phrase>Computing</phrase> and <phrase>controlling</phrase> the <phrase>RAM</phrase> <phrase>footprint</phrase> <phrase>Reducing</phrase> the number of classes <phrase>Eliminating</phrase> temporary objects <phrase>Selecting</phrase> <phrase>high</phrase>-performance <phrase>algorithms</phrase> and <phrase>data</phrase> structures Using <phrase>Java</phrase> <phrase>native</phrase> code and <phrase>applet</phrase> packaging efficiently <phrase>Garbage collection</phrase> <phrase>Java</phrase> <phrase>HotSpot</phrase>™ <phrase>technology</phrase> With an <phrase>understanding</phrase> of the <phrase>performance issues</phrase> and specific techniques for <phrase>reducing</phrase> overhead discussed in this <phrase>book</phrase>, you will have theinformation you need to enhance the efficiency, speed, and <phrase>scalability</phrase> of your <phrase>software</phrase>.
<phrase>Advanced</phrase> <phrase>C++</phrase>: <phrase>Programming</phrase> Syles and <phrase>Idioms</phrase>
<phrase>Deductive</phrase> <phrase>Databases</phrase> and <phrase>Logic Programming</phrase>
<phrase>High</phrase> performance compilers for <phrase>parallel computing</phrase>
<phrase>An Introduction</phrase> to <phrase>Database Systems</phrase>
:The <phrase>sixth</phrase> <phrase>edition</phrase> of this well-respected text/reference--which has been almost completely rewritten--continues to be the most <phrase>comprehensive</phrase> and <phrase>up-to-date</phrase> treatment of <phrase>database</phrase> <phrase>technology</phrase> currently available. Readers will gain a strong working <phrase>knowledge</phrase> of the overall structure, concepts, and objectives of <phrase>database systems</phrase> and will become familiar with the <phrase>theoretical principles</phrase> underlying the <phrase>construction</phrase> of such systems.
<phrase>TCP/IP</phrase> Illustrated, Volume 2: The Implementation
<phrase>An Introduction</phrase> to <phrase>Database Systems</phrase>, <phrase>2nd Edition</phrase>
<phrase>Human</phrase> Behaviour and the Principle of Least Effort: <phrase>an Introduction</phrase> to <phrase>Human Ecology</phrase>
<phrase>An Introduction</phrase> to <phrase>Database Systems</phrase>, <phrase>3rd Edition</phrase>
:For over 25 years, <phrase>C</phrase>. <phrase>J</phrase>. Date's <phrase>An Introduction</phrase> to <phrase>Database Systems</phrase> has been the authoritative resource for readers interested in <phrase>gaining insight</phrase> into and <phrase>understanding</phrase> of the principles of <phrase>database systems</phrase>. This <phrase>revision</phrase> continues to provide a solid <phrase>grounding</phrase> in the foundations of <phrase>database</phrase> <phrase>technology</phrase> and to provide some ideas as to how the field is likely to develop in the future.. "Readers of this <phrase>book</phrase> will gain a strong working <phrase>knowledge</phrase> of the overall structure, concepts, and objectives of <phrase>database systems</phrase> and will become familiar with the <phrase>theoretical principles</phrase> underlying the <phrase>construction</phrase> of such systems.
The <phrase>INGRES</phrase> Papers: <phrase>Anatomy</phrase> of a <phrase>Relational Database</phrase> System
<phrase>An Introduction</phrase> to <phrase>Database Systems</phrase>, <phrase>Volume II</phrase>.
A Guide to <phrase>DB2</phrase>, <phrase>1st Edition</phrase>
<phrase>An Introduction</phrase> to <phrase>Database Systems</phrase>, Volume <phrase>I</phrase>, <phrase>4th Edition</phrase>.
<phrase>An Introduction</phrase> to <phrase>Database Systems</phrase>, Volume <phrase>I</phrase>, 5th <phrase>Edition</phrase>.
<phrase>An Introduction</phrase> to <phrase>Database Systems</phrase>, 6th <phrase>Edition</phrase>.
<phrase>Relational Database</phrase> Writings 1989-1991
A Guide to <phrase>SQL</phrase> Standard, <phrase>3rd Edition</phrase>
A Guide to <phrase>SQL</phrase> Standard, <phrase>4th Edition</phrase>
A Guide to <phrase>DB2</phrase>, <phrase>2nd Edition</phrase>
A Guide to <phrase>DB2</phrase>, <phrase>3rd Edition</phrase>
<phrase>Cryptography</phrase> and <phrase>Data Security</phrase>
From the <phrase>Preface</phrase> (See <phrase>Front Matter</phrase> for full <phrase>Preface</phrase>) <phrase>Electronic</phrase> <phrase>computers</phrase> have evolved from exiguous <phrase>experimental</phrase> enterprises in the 1940s to prolific practical <phrase>data processing</phrase> systems in the 1980s. As we have come to rely on these systems to process and store <phrase>data</phrase>, we have also come to <phrase>wonder</phrase> about their ability to protect valuable <phrase>data</phrase>. <phrase>Data security</phrase> is the <phrase>science</phrase> and study of methods of <phrase>protecting</phrase> <phrase>data</phrase> in computer and <phrase>communication</phrase> systems from <phrase>unauthorized disclosure</phrase> and modification. The goal of this <phrase>book</phrase> is to introduce the <phrase>mathematical</phrase> principles of <phrase>data security</phrase> and to show how these principles apply to <phrase>operating systems</phrase>, <phrase>database systems</phrase>, and <phrase>computer networks</phrase>. The <phrase>book</phrase> is for students and professionals seeking <phrase>an introduction</phrase> to these principles. There are many references for those who would like to study <phrase>specific topics</phrase> further. <phrase>Data security</phrase> has <phrase>evolved rapidly</phrase> since 1975. We have seen <phrase>exciting developments</phrase> in <phrase>cryptography</phrase>: <phrase>public-key encryption</phrase>, <phrase>digital signatures</phrase>, the <phrase>Data</phrase> <phrase>Encryption</phrase> Standard (<phrase>DES</phrase>), key <phrase>safeguarding</phrase> schemes, and <phrase>key distribution</phrase> protocols. We have developed techniques for <phrase>verifying</phrase> that programs do not leak <phrase>confidential data</phrase>, or transmit classified <phrase>data</phrase> to users with <phrase>lower</phrase> <phrase>security</phrase> <phrase>clearances</phrase>. We have found new controls for <phrase>protecting</phrase> <phrase>data</phrase> in <phrase>statistical databases</phrase>--and new methods of <phrase>attacking</phrase> these <phrase>databases</phrase>. We have come to a better <phrase>understanding</phrase> of the theoretical and practical limitations to <phrase>security</phrase>.
The Annotated <phrase>C++</phrase> <phrase>Reference Manual</phrase>.
<phrase>Functional Programming</phrase>
<phrase>Relational Databases</phrase> and <phrase>Knowledge</phrase> Bases
<phrase>Natural Language Processing</phrase> in <phrase>PROLOG</phrase>
<phrase>Genetic Algorithms</phrase> in Search Optimization and <phrase>Machine Learning</phrase>
<phrase>Smalltalk</phrase>-80: The <phrase>Language</phrase> and Its Implementation.
From the <phrase>Preface</phrase> (See <phrase>Front Matter</phrase> for full <phrase>Preface</phrase>) Advances in the <phrase>design</phrase> and <phrase>production</phrase> of computer hardware have brought many more people into <phrase>direct</phrase> <phrase>contact</phrase> with <phrase>computers</phrase>. Similar advances in the <phrase>design</phrase> and <phrase>production</phrase> of computer <phrase>software</phrase> are required in <phrase>order</phrase> that this increased <phrase>contact</phrase> be as rewarding as possible. The <phrase>Smalltalk</phrase>-80 system is a result of a decade of <phrase>research</phrase> into <phrase>creating</phrase> computer <phrase>software</phrase> that is appropriate for producing <phrase>highly functional</phrase> and interactive <phrase>contact</phrase> with <phrase>personal computer</phrase> systems. This <phrase>book</phrase> is the first detailed account of the <phrase>Smalltalk</phrase>-80 system. It is <phrase>divided into</phrase> four <phrase>major</phrase> parts: Part One -- <phrase>an overview</phrase> of the concepts and <phrase>syntax</phrase> of the <phrase>programming language</phrase>. Part Two -- an annotated and illustrated specification of the <phrase>system's functionality</phrase>. Part Three -- an example of the <phrase>design</phrase> and implementation of a <phrase>moderate-size</phrase> application. Part Four -- a specification of the <phrase>Smalltalk</phrase>-80 <phrase>virtual machine</phrase>.
The <phrase>Java</phrase> <phrase>Language</phrase> Specification.
A <phrase>Retargetable</phrase> <phrase>C</phrase> <phrase>Compiler</phrase>: <phrase>Design</phrase> and Implementation
<phrase>Objektorientierte Datenbanken</phrase>: <phrase>Konzepte</phrase>, <phrase>Modelle</phrase>, <phrase>Systeme</phrase>.
<phrase>Objektorientierte Datenbanken</phrase>: <phrase>Konzepte</phrase>, <phrase>Modelle</phrase>, <phrase>Systeme</phrase>, 2. Auflage.
<phrase>Introduction</phrase> to <phrase>Automata Theory</phrase>, Languages and Computation.
<phrase>An Introduction</phrase> to <phrase>Parallel Algorithms</phrase>
<phrase>Introduction</phrase> to <phrase>Expert Systems</phrase>, <phrase>1st Edition</phrase>.
<phrase>Introduction</phrase> to <phrase>Expert Systems</phrase>, <phrase>2nd Edition</phrase>.
:The <phrase>third edition</phrase> of <phrase>Peter</phrase> <phrase>Jackson's</phrase> <phrase>book</phrase>, <phrase>Introduction</phrase> to <phrase>Expert Systems</phrase>, updates the technological base of <phrase>expert systems</phrase> <phrase>research</phrase> and embeds those <phrase>results</phrase> in the context of a wide <phrase>variety</phrase> of <phrase>application areas</phrase>. The earlier chapters take a more <phrase>practical approach</phrase> to the <phrase>basic</phrase> topics than the previous <phrase>editions</phrase>, while the later chapters introduce new <phrase>topic areas</phrase>, such as <phrase>case-based reasoning</phrase>, <phrase>connectionist</phrase> systems, and <phrase>hybrid</phrase> systems. <phrase>Results</phrase> in <phrase>related areas</phrase>, such as <phrase>machine learning</phrase> and reasoning with uncertainty are also accorded a thorough treatment.
<phrase>Introduction</phrase> to <phrase>Expert Systems</phrase>, <phrase>3rd Edition</phrase>.
:The <phrase>third edition</phrase> of <phrase>Peter</phrase> <phrase>Jackson's</phrase> <phrase>book</phrase>, <phrase>Introduction</phrase> to <phrase>Expert Systems</phrase>, updates the technological base of <phrase>expert systems</phrase> <phrase>research</phrase> and embeds those <phrase>results</phrase> in the context of a wide <phrase>variety</phrase> of <phrase>application areas</phrase>. The earlier chapters take a more <phrase>practical approach</phrase> to the <phrase>basic</phrase> topics than the previous <phrase>editions</phrase>, while the later chapters introduce new <phrase>topic areas</phrase>, such as <phrase>case-based reasoning</phrase>, <phrase>connectionist</phrase> systems, and <phrase>hybrid</phrase> systems. <phrase>Results</phrase> in <phrase>related areas</phrase>, such as <phrase>machine learning</phrase> and reasoning with uncertainty are also accorded a thorough treatment.
The Practice of <phrase>Programming</phrase>
<phrase>Object-Oriented</phrase> Concepts, <phrase>Databases</phrase>, and Applications.
The <phrase>Art</phrase> of <phrase>Computer Programming</phrase>, Volume <phrase>I</phrase>: Fundamental <phrase>Algorithms</phrase>
The <phrase>Art</phrase> of <phrase>Computer Programming</phrase>, <phrase>Volume II</phrase>: Seminumerical <phrase>Algorithms</phrase>
The <phrase>Art</phrase> of <phrase>Computer Programming</phrase>, Volume <phrase>III</phrase>: <phrase>Sorting</phrase> and Searching
The <phrase>Art</phrase> of <phrase>Computer Programming</phrase>, Volume <phrase>I</phrase>: Fundamental <phrase>Algorithms</phrase>, <phrase>2nd Edition</phrase>.
The <phrase>Art</phrase> of <phrase>Computer Programming</phrase>, <phrase>Volume II</phrase>: Seminumerical <phrase>Algorithms</phrase>, <phrase>2nd Edition</phrase>
Inside the <phrase>C++</phrase> <phrase>Object Model</phrase>
Inside the <phrase>C++</phrase> <phrase>Object Model</phrase> focuses on the underlying mechanisms that support <phrase>object-oriented programming</phrase> within <phrase>C++</phrase>: <phrase>constructor</phrase> <phrase>semantics</phrase>, temporary generation, support for <phrase>encapsulation</phrase>, <phrase>inheritance</phrase>, and "the virtuals"-<phrase>virtual</phrase> functions and <phrase>virtual</phrase> <phrase>inheritance</phrase>. This <phrase>book</phrase> shows how your <phrase>understanding</phrase> the underlying implementation models can help you code more efficiently and with <phrase>greater confidence</phrase>. Lippman dispells the misinformation and <phrase>myths</phrase> about the overhead and complexity associated with <phrase>C++</phrase>, while pointing out areas in which costs and <phrase>trade</phrase> offs, sometimes <phrase>hidden</phrase>, do exist. He then explains how the various implementation models arose, points out areas in which they are likely to evolve, and why they are what they are. He covers the <phrase>semantic</phrase> implications of the <phrase>C++</phrase> <phrase>object model</phrase> and how that <phrase>model</phrase> affects your programs.Highlights Explores the <phrase>program behavior</phrase> <phrase>implicit</phrase> in the <phrase>C++</phrase> Object Model's support of <phrase>object-oriented programming</phrase>. Explains the <phrase>basic</phrase> implementation of the <phrase>object-oriented</phrase> features and the <phrase>trade</phrase> offs <phrase>implicit</phrase> in those features. Examines the impact on performance in terms of <phrase>program transformation</phrase>. Provides abundant program examples, <phrase>diagrams</phrase>, and <phrase>performance measurements</phrase> to relate <phrase>object-oriented</phrase> concepts to the underlying object model.If you are a <phrase>C++</phrase> <phrase>programmer</phrase> who desires a <phrase>fuller</phrase> <phrase>understanding</phrase> of what is going on "under the <phrase>hood</phrase>," then Inside the <phrase>C++</phrase> <phrase>Object Model</phrase> is for you!
<phrase>Introduction</phrase> to Linear and <phrase>Nonlinear Programming</phrase>.
<phrase>Design</phrase> of <phrase>Relational Databases</phrase>
<phrase>Tcl</phrase> and the <phrase>Tk</phrase> <phrase>Toolkit</phrase>
From the Book:Tcl was born of frustration. In the <phrase>early 1980s</phrase> my students and <phrase>I</phrase> developed a number of <phrase>interactive tools</phrase> at the <phrase>University</phrase> of <phrase>California</phrase> at <phrase>Berkeley</phrase>, mostly for <phrase>integrated circuit design</phrase>, and we found ourselves spending a <phrase>lot</phrase> of time <phrase>building</phrase> bad <phrase>command languages</phrase>. Each tool needed to have a <phrase>command language</phrase> of some <phrase>sort</phrase>, but our main interest was in the tool rather than its <phrase>command language</phrase>. We spent as little time as possible on the <phrase>command language</phrase> and always ended up with a <phrase>language</phrase> that was <phrase>weak</phrase> and quirky. Furthermore, the <phrase>command language</phrase> for one tool was never quite right for the <phrase>next</phrase> tool, so we ended up <phrase>building</phrase> a new bad <phrase>command language</phrase> for each tool. This became increasingly frustrating.In the fall of 1987 it occurred to <phrase>me</phrase> that the <phrase>solution</phrase> was to build a reusable <phrase>command language</phrase>. If a <phrase>general</phrase>-purpose <phrase>scripting language</phrase> could be built as a <phrase>C</phrase> <phrase>library</phrase> package, then perhaps it could be reused for many different purposes in many different applications. Of course, the <phrase>language</phrase> would need to be <phrase>extensible</phrase> so that each application could add its own <phrase>specific features</phrase> to the core provided by the <phrase>library</phrase>. In the <phrase>spring</phrase> of 1988 <phrase>I</phrase> decided to implement such a <phrase>language</phrase>, and the result was <phrase>Tcl</phrase>. <phrase>Tk</phrase> was also born of frustration. The <phrase>basic</phrase> idea for <phrase>Tk</phrase> arose in response to Apple's <phrase>announcement</phrase> of <phrase>HyperCard</phrase> in the fall of 1987. <phrase>HyperCard</phrase> generated tremendous excitement because of the power of the system and the way in which it allowed many different interactive elements to be <phrase>scripted</phrase> and work together. However, <phrase>I</phrase> was discouraged. The <phrase>HyperCard</phrase> system had obviously taken a large <phrase>development effort</phrase>, and it seemed unlikely to <phrase>me</phrase> that a <phrase>small group</phrase> such as a <phrase>university</phrase> researchproject could ever <phrase>mount</phrase> such a <phrase>massive</phrase> effort. This suggested that we would not be able to participate in the development of new forms of <phrase>interactive software</phrase> in the future.I concluded that the only hope for us was a component approach. Rather than <phrase>building</phrase> a new application as a <phrase>self-contained</phrase> <phrase>monolith</phrase> with hundreds of thousands of <phrase>lines of code</phrase>, we needed to find a way to divide applications into many smaller <phrase>reusable components</phrase>. <phrase>Ideally</phrase> each component would be small enough to be implemented by a <phrase>small group</phrase>, and interesting applications could be created by <phrase>assembling</phrase> components. In this environment it should be possible to create an exciting new application by <phrase>developing</phrase> one new component and then <phrase>combining</phrase> it with existing components.The <phrase>component-based</phrase> approach requires a powerful and flexible "<phrase>glue</phrase>"for <phrase>assembling</phrase> the components, and it occurred to <phrase>me</phrase> that perhaps a shared <phrase>scripting language</phrase> could provide that <phrase>glue</phrase>. Out of this <phrase>thinking</phrase> grew <phrase>Tk</phrase>, an <phrase>X11</phrase> <phrase>toolkit</phrase> based on <phrase>Tcl</phrase>. <phrase>Tk</phrase> allows components to be either <phrase>individual user</phrase>-interface controls or entire applications; in either case components can be <phrase>developed independently</phrase> and <phrase>Tcl</phrase> can be used to assemble the components and communicate between them.I started writing <phrase>Tcl</phrase> and <phrase>Tk</phrase> as a hobby in my spare time. As other people began to use the systems <phrase>I</phrase> found myself spending more and more time on them, to the point where today they occupy almost all of my waking hours and many of my <phrase>sleeping</phrase> ones.Tcl and <phrase>Tk</phrase> have succeeded beyond my wildest <phrase>dreams</phrase>. The <phrase>Tcl/Tk</phrase> <phrase>developer community</phrase> now numbers in the <phrase>tens of thousands</phrase> and there are thousands of <phrase>Tcl</phrase> applications in <phrase>existence</phrase> or under development. The <phrase>application areas</phrase> for <phrase>Tcl</phrase> and <phrase>Tk</phrase> <phrase>cover</phrase> virtually the entire <phrase>spectrum</phrase> of <phrase>graphical</phrase> and <phrase>engineering</phrase> applications, including <phrase>computer-aided design</phrase>, <phrase>software development</phrase>, testing, <phrase>instrument</phrase> control, <phrase>scientific visualization</phrase>, and <phrase>multimedia</phrase>. <phrase>Tcl</phrase> is used by itself in many applications, and <phrase>Tcl</phrase> and <phrase>Tk</phrase> are used together in many others. <phrase>Tcl</phrase> and <phrase>Tk</phrase> are being used by hundreds of companies, large and small, as well as <phrase>universities</phrase> and <phrase>research</phrase> laboratories.One benefit that came as a surprise to <phrase>me</phrase> is that it is possible to create interesting <phrase>graphical user interfaces</phrase> (GUIs) entirely as <phrase>Tcl</phrase> scripts. <phrase>I</phrase> had always assumed that every <phrase>Tcl</phrase> application would contain some new <phrase>C</phrase> code that implements new <phrase>Tcl</phrase> commands, plus some <phrase>Tcl</phrase> scripts that combine the new commands with the built-in facilities provided by <phrase>Tcl</phrase>. However, once a simple <phrase>Tcl/Tk</phrase> application called wish became available, many people began <phrase>creating</phrase> <phrase>user interfaces</phrase> by writing <phrase>Tcl</phrase> scripts for it, without writing any <phrase>C</phrase> code at all! It turned out that the <phrase>Tcl</phrase> and <phrase>Tk</phrase> commands provide a <phrase>high</phrase>-level interface to <phrase>GUI</phrase> <phrase>programming</phrase> that hides many of the details faced by a <phrase>C</phrase> <phrase>programmer</phrase>. As a result, it is <phrase>much easier</phrase> to learn how to use wish than a <phrase>C</phrase>-based <phrase>toolkit</phrase>, and <phrase>user interfaces</phrase> can be written with much less code. Most <phrase>Tcl/Tk</phrase> users never write any <phrase>C</phrase> code at all and most of the <phrase>Tcl/Tk</phrase> applications consist solely of <phrase>Tcl</phrase> scripts.This <phrase>book</phrase> is intended as <phrase>an introduction</phrase> to <phrase>Tcl</phrase> and <phrase>Tk</phrase> for programmers who plan to write or modify <phrase>Tcl/Tk</phrase> applications. <phrase>I</phrase> assume that readers have programmed in <phrase>C</phrase> and have at least passing familiarity with a <phrase>shell</phrase> such as <phrase>sh</phrase> or csh or ksh. <phrase>I</phrase> also assume that readers have used the <phrase>X</phrase> Window System and are familiar with <phrase>basic</phrase> ideas such as using the <phrase>mouse</phrase>, resizing <phrase>windows</phrase>, etc. No <phrase>prior experience</phrase> with <phrase>Tcl</phrase> or <phrase>Tk</phrase> is needed in <phrase>order</phrase> to read this <phrase>book</phrase>, and you need not have written <phrase>X</phrase> applications using other toolkits such as Motif.The <phrase>book</phrase> is organized so that you can learn <phrase>Tcl</phrase> without <phrase>learning</phrase> <phrase>Tk</phrase> if you wish. Also, the discussion of how to write <phrase>Tcl</phrase> scripts is separate from the discussion of how to use the <phrase>C</phrase> <phrase>library</phrase> interfaces provided by <phrase>Tcl</phrase> and <phrase>Tk</phrase>. The first two parts of the <phrase>book</phrase> describe <phrase>Tcl</phrase> and <phrase>Tk</phrase> at the level of writing scripts, and the <phrase>last</phrase> two parts describe the <phrase>C</phrase> interfaces for <phrase>Tcl</phrase> and <phrase>Tk</phrase>; if you are like the <phrase>majority</phrase> of <phrase>Tcl/Tk</phrase> users who only write scripts, you can stop after <phrase>reading</phrase> the first two parts.In spite of my best efforts, <phrase>I'm sure</phrase> that there are errors in this <phrase>edition</phrase> of the <phrase>book</phrase>. <phrase>I'm</phrase> interested in <phrase>hearing</phrase> about any problems that you encounter, whether they are typos, formatting errors, sections or ideas that are hard to understand, or <phrase>bugs</phrase> in the examples. <phrase>I'll</phrase> attempt to correct the problems in future printings of the <phrase>book</phrase>. The best way to <phrase>report</phrase> problems is with <phrase>electronic</phrase> <phrase>mail</phrase> sent to tclbookbugs@cs.berkeley.edu.Many people have helped in the creation of this <phrase>book</phrase>. First and foremost <phrase>I</phrase> would like to <phrase>thank</phrase> <phrase>Brian Kernighan</phrase>, who reviewed several drafts of the <phrase>manuscript</phrase> with almost terrifying thoroughness and uncovered numerous problems both large and small. <phrase>I</phrase> <phrase>am</phrase> also grateful for the detailed comments provided by the other <phrase>Addison-Wesley</phrase> technical <phrase>reviewers</phrase>: <phrase>Richard</phrase> Blevins, Gerard Holzmann, Curt Horkey, <phrase>Ron</phrase> Hutchins, <phrase>Stephen</phrase> <phrase>Johnson</phrase>, <phrase>Oliver</phrase> <phrase>Jones</phrase>, <phrase>David</phrase> <phrase>Korn</phrase>, <phrase>Bill</phrase> Leggett, <phrase>Don</phrase> Libes, <phrase>Kent</phrase> Margraf, <phrase>Stuart</phrase> McRobert, <phrase>David</phrase> <phrase>Richardson</phrase>, Alexei <phrase>Rodrigues</phrase>, <phrase>Gerald</phrase> <phrase>Rosenberg</phrase>, <phrase>John</phrase> <phrase>Slater</phrase>, and <phrase>Win</phrase> Treese. Thanks also to <phrase>Bob</phrase> Sproull, who read the <phrase>next</phrase>-to-<phrase>last</phrase> <phrase>draft</phrase> from <phrase>cover</phrase> to <phrase>cover</phrase> and provided countless <phrase>bug fixes</phrase> and suggestions.I made early drafts of the <phrase>manuscript</phrase> available to the <phrase>Tcl/Tk</phrase> <phrase>community</phrase> via the <phrase>Internet</phrase> and received countless comments and suggestions from all over the world in return. <phrase>I'm</phrase> <phrase>afraid</phrase> that <phrase>I</phrase> didn't keep careful enough records to acknowledge all the people who contributed in this way, but the list of contributors includes at least the following people: <phrase>Marvin</phrase> Aguero, Miriam <phrase>Amos</phrase> Nihart, <phrase>Jim</phrase> <phrase>Anderson</phrase>, Frederik Anheuser, <phrase>Jeff</phrase> Blaine, <phrase>John</phrase> Boller, <phrase>David</phrase> Boyce, <phrase>Terry</phrase> Brannon, <phrase>Richard</phrase> <phrase>Campbell</phrase>, <phrase>J</phrase>. Cazander, <phrase>Wen</phrase> <phrase>Chen</phrase>, <phrase>Richard</phrase> Cheung, <phrase>Peter</phrase> Chubb, De <phrase>Clarke</phrase>, <phrase>Peter</phrase> Collinson, <phrase>Peter</phrase> Costantinidis, <phrase>Alistair</phrase> Crooks, <phrase>Peter</phrase> <phrase>Davies</phrase>, <phrase>Tal</phrase> Dayan, Akim Demaille, <phrase>Mark</phrase> Diekhans, <phrase>Matthew</phrase> Dillon, Tuan Doan, <phrase>Tony</phrase> Duarte, <phrase>Paul</phrase> <phrase>DuBois</phrase>, <phrase>Anton</phrase> Eliens, <phrase>Marc</phrase> <phrase>R</phrase>. Ewing, <phrase>Luis</phrase> Fernandes, <phrase>Martin</phrase> Forssen, <phrase>Ben</phrase> Fried, Matteo Frigo, Andrej Gabara, <phrase>Steve</phrase> Gaede, Sanjay Ghemawat, <phrase>Bob Gibson</phrase>, <phrase>Michael</phrase> <phrase>Halle</phrase>, <phrase>Jun</phrase> Hamano, <phrase>Stephen</phrase> <phrase>Hansen</phrase>, <phrase>Brian</phrase> <phrase>Harrison</phrase>, Marti <phrase>Hearst</phrase>, Fergus Henderson, <phrase>Kevin</phrase> <phrase>Hendrix</phrase>, <phrase>David</phrase> Herron, <phrase>Patrick</phrase> Hertel, Carsten Heyl, Leszek Holenderski, Jamie Honan, <phrase>Rob</phrase> W.W. Hooft, <phrase>Nick</phrase> Hounsome, <phrase>Christopher</phrase> Hylands, <phrase>Jonathan</phrase> <phrase>Jowett</phrase>, Poul-Henning <phrase>Kamp</phrase>, Karen <phrase>L</phrase>. Karavanic, Sunil <phrase>Khatri</phrase>, <phrase>Vivek</phrase> Khera, <phrase>Jon</phrase> <phrase>Knight</phrase>, <phrase>Roger</phrase> <phrase>Knopf</phrase>, Ramkumar Krishnan, <phrase>Dave</phrase> Kristol, <phrase>Peter</phrase> <phrase>LaBelle</phrase>, <phrase>Tor</phrase>-<phrase>Erik Larsen</phrase>, <phrase>Tom</phrase> Legrady, Will <phrase>E</phrase>. Leland, <phrase>Kim</phrase> Lester, <phrase>Joshua</phrase> <phrase>Levy</phrase>, <phrase>Don</phrase> Libes, <phrase>Oscar</phrase> Linares, <phrase>David</phrase> C.P. <phrase>Linden</phrase>, Toumas <phrase>J</phrase>. Lukka, <phrase>Steve</phrase> <phrase>Lord</phrase>, <phrase>Steve</phrase> Lumetta, Earlin <phrase>Lutz</phrase>, <phrase>David</phrase> <phrase>J</phrase>. <phrase>Mackenzie</phrase>, B.G. Mahesh, <phrase>John</phrase> Maline, <phrase>Graham</phrase> <phrase>Mark</phrase>, <phrase>Stuart</phrase> McRobert, <phrase>George</phrase> <phrase>Moon</phrase>, <phrase>Michael</phrase> <phrase>Morris</phrase>, <phrase>Russell</phrase> <phrase>Nelson</phrase>, <phrase>Dale</phrase> <phrase>K</phrase>. Newby, <phrase>Richard</phrase> <phrase>Newton</phrase>, <phrase>Peter</phrase> <phrase>Nguyen</phrase>, <phrase>David</phrase> <phrase>Nichols</phrase>, Marty Olevitch, <phrase>Rita</phrase> Ousterhout, <phrase>John</phrase> Pierce, <phrase>Stephen</phrase> Pietrowicz, <phrase>Anna</phrase> Pluzhnikov, <phrase>Nico</phrase> Poppelier, M.V.S. Ramanath, Cary <phrase>D</phrase>. Renzema, <phrase>Mark</phrase> Roseman, Samir Tiongson Saxena, <phrase>Jay</phrase> Schmidgall, <phrase>Dan</phrase> <phrase>M</phrase>. Serachitopol, <phrase>Hume</phrase> <phrase>Smith</phrase>, <phrase>Frank</phrase> Stajano, <phrase>Larry</phrase> Streepy, <phrase>John</phrase> <phrase>E</phrase>. Stump, <phrase>Michael</phrase> Sullivan, Holger Teutsch, Bennett <phrase>E</phrase>. Todd, <phrase>Glenn</phrase> Trewitt, D.A. <phrase>Vaughan</phrase>-<phrase>Pope</phrase>, <phrase>Richard</phrase> Vieregge, <phrase>Larry</phrase> <phrase>W</phrase>. <phrase>Virden</phrase>, <phrase>David</phrase> Waitzman, <phrase>Matt</phrase> Wartell, <phrase>Glenn</phrase> <phrase>Waters</phrase>, Wally <phrase>Wedel</phrase>, Juergen Weigert, <phrase>Mark Weiser</phrase>, Brent <phrase>Welch</phrase>, <phrase>Alex</phrase> Woo, <phrase>Su</phrase>-<phrase>Lin</phrase> <phrase>Wu</phrase>, Kawata Yasuro, Chut Ngeow Yee, <phrase>Richard</phrase> <phrase>Yen</phrase>, <phrase>Stephen</phrase> Ching-SingYen, and <phrase>Mike</phrase> Young.Many many people have made <phrase>significant contributions</phrase> to the development of <phrase>Tcl</phrase> and <phrase>Tk</phrase>. Without all of their efforts there would have been nothing of interest to write about in this <phrase>book</phrase>. Although <phrase>I</phrase> cannot hope to acknowledge all the people who helped to make <phrase>Tcl</phrase> and <phrase>Tk</phrase> what they are today, <phrase>I</phrase> would like to <phrase>thank</phrase> the following people specially: <phrase>Don</phrase> Libes, for writing the first widely used <phrase>Tcl</phrase> application; <phrase>Mark</phrase> Diekhans and <phrase>Karl</phrase> Lehenbauer, for TclX; Alastair Fyfe, for <phrase>supporting</phrase> the <phrase>early development</phrase> of <phrase>Tcl</phrase>; <phrase>Mary</phrase> <phrase>Ann</phrase> May-Pumphrey, for <phrase>developing</phrase> the original <phrase>Tcl</phrase> <phrase>test suite</phrase>; <phrase>George</phrase> Howlett, <phrase>Michael</phrase> McLennan, and Sani Nassif, for the <phrase>BLT</phrase> extensions; <phrase>Kevin</phrase> Kenny, for showing that <phrase>Tcl</phrase> can be used to communicate with almost any imaginable program; <phrase>Joel</phrase> Bartlett, for many challenging conversations and for inspiring Tk's <phrase>canvas</phrase> widget with his ezd program; <phrase>Larry</phrase> Rowe, for <phrase>developing</phrase> <phrase>Tcl</phrase>-<phrase>DP</phrase> and for providing <phrase>general</phrase> advice and support; Sven Delmas, for <phrase>developing</phrase> the <phrase>XF</phrase> application <phrase>builder</phrase> based on <phrase>Tk</phrase>; and <phrase>Andrew</phrase> Payne, for the widget <phrase>tour</phrase> and for meritorious <phrase>Tcl</phrase> evangelism.Several companies have provided <phrase>financial support</phrase> for the development of <phrase>Tcl</phrase> and <phrase>Tk</phrase>, including <phrase>Digital Equipment Corporation</phrase>, <phrase>Hewlett-Packard</phrase> <phrase>Corporation</phrase>, <phrase>Sun Microsystems</phrase>, and <phrase>Computerized</phrase> Processes Unlimited. <phrase>I</phrase> <phrase>am</phrase> particularly grateful to Digital's <phrase>Western</phrase> <phrase>Research</phrase> <phrase>Laboratory</phrase> and its <phrase>director</phrase>, <phrase>Richard</phrase> <phrase>Swan</phrase>, for providing <phrase>me</phrase> with a one-day-<phrase>per-week</phrase> hideaway where <phrase>I</phrase> could <phrase>go</phrase> to gather my thoughts and work on <phrase>Tcl</phrase> and Tk.Terry Lessard-<phrase>Smith</phrase> and <phrase>Bob</phrase> <phrase>Miller</phrase> have provided fabulous administrative support for this and all my other projects. <phrase>I</phrase> <phrase>don't</phrase> know how <phrase>I</phrase> would get anything done without them.Finally, <phrase>I</phrase> owe a special <phrase>debt</phrase> to my colleague and <phrase>friend</phrase> <phrase>Dave</phrase> <phrase>Patterson</phrase>, whose <phrase>humor</phrase> and <phrase>sage</phrase> advice have inspired and shaped much of my <phrase>professional</phrase> <phrase>career</phrase>, and to my wife <phrase>Rita</phrase> and daughters <phrase>Kay</phrase> and <phrase>Amy</phrase>, who have tolerated my <phrase>workaholic</phrase> tendencies with more cheer and affection than <phrase>I</phrase> deserve. <phrase>John</phrase> Ousterhout <phrase>Berkeley</phrase>, <phrase>California</phrase> <phrase>February</phrase>, 1994
<phrase>Functional Programming</phrase> and <phrase>Parallel</phrase> <phrase>Graph Rewriting</phrase>
<phrase>Web Caching</phrase> and <phrase>Replication</phrase>
<phrase>Web caching</phrase> and <phrase>replication</phrase> provides essential material based on the extensive <phrase>real-world</phrase> experience of two experts from <phrase>AT & T Labs</phrase>. This <phrase>comprehensive</phrase> <phrase>examination</phrase> of <phrase>caching</phrase>, <phrase>replication</phrase>, and load-balacing practices for the <phrase>Web</phrase> <phrase>brings together</phrase> <phrase>information</phrase> from and for the commercial world, including <phrase>real-life</phrase> <phrase>products</phrase>; <phrase>technical standards</phrase> communities, such as <phrase>IETF</phrase> and <phrase>W3C</phrase>; and <phrase>academic</phrase> <phrase>research</phrase>.
Mehrrechner-<phrase>Datenbanksysteme</phrase> - <phrase>Grundlagen</phrase> der verteilten und parallelen Datenbankverarbeitung.
<phrase>Advanced</phrase> <phrase>Prolog</phrase>: Techniques and Examples
<phrase>Automatic Text</phrase> Processing: The Transformation, Analysis, and Retrieval of <phrase>Information</phrase> by Computer.
The <phrase>Design</phrase> and Analysis of <phrase>Spatial Data</phrase> Structures
<phrase>Temporal Deductive Databases</phrase>.
The <phrase>Historical</phrase> <phrase>Relational</phrase> <phrase>Data Model</phrase> (HRDM) <phrase>Revisited</phrase>.
On the <phrase>Completeness</phrase> of <phrase>Query Languages</phrase> for Grouped and Ungrouped <phrase>Historical Data</phrase> Models.
A Temporal <phrase>Model</phrase> and <phrase>Query Language</phrase> for <phrase>EER</phrase> <phrase>Databases</phrase>.
The Time <phrase>Index</phrase> and the <phrase>Monotonic</phrase> <phrase>B+-tree</phrase>.
<phrase>Ben</phrase>-Zvi's <phrase>Pioneering</phrase> Work in <phrase>Relational</phrase> <phrase>Temporal Databases</phrase>.
<phrase>Temporal Databases</phrase>: A <phrase>Prelude</phrase> to <phrase>Parametric</phrase> <phrase>Data</phrase>.
Object and <phrase>Spreadsheet</phrase> Histories.
Differential <phrase>Query Processing</phrase> in Transaction-Time <phrase>Databases</phrase>.
<phrase>Indexing</phrase> Techniques for <phrase>Historical</phrase> <phrase>Databases</phrase>.
<phrase>Stream Processing</phrase>: Temporal <phrase>Query Processing</phrase> and Optimization.
Transaction-Time <phrase>Databases</phrase>.
The <phrase>Interval</phrase>-<phrase>extended Relational</phrase> <phrase>Model</phrase> and Its Applications to Valid-time <phrase>Databases</phrase>.
<phrase>temporal Reasoning</phrase>.
<phrase>Temporal Extensions</phrase> to the <phrase>Relational Model</phrase> and <phrase>SQL</phrase>.
HSQL: A <phrase>Historical</phrase> <phrase>Query Language</phrase>.
<phrase>Join Processing</phrase> and Optimization in <phrase>Temporal Relational Databases</phrase>.
A <phrase>Temporal Data</phrase> <phrase>Model</phrase> Based on Time Sequences.
<phrase>An Overview</phrase> of TQuel.
A <phrase>Generalized</phrase> <phrase>relational</phrase> Framework for Modeling <phrase>Temporal Data</phrase>.
Applications of <phrase>temporal Databases</phrase> to <phrase>Knowledge</phrase>-based Simulations.
<phrase>Integrating</phrase> <phrase>Temporal Data</phrase> in a <phrase>Heterogeneous Environment</phrase>.
A <phrase>Uniform</phrase> <phrase>Model</phrase> for Temporal and <phrase>Versioned</phrase> <phrase>Object-oriented</phrase> <phrase>Databases</phrase>.
<phrase>Relational Database</phrase> Theory
<phrase>Conceptual Database Design</phrase>: An <phrase>Entity-Relationship</phrase> Approach.
<phrase>Object-Oriented Design</phrase> with Applications
<phrase>Fundamentals</phrase> of <phrase>Database Systems</phrase>
<phrase>Fundamentals</phrase> of <phrase>Database Systems</phrase>, <phrase>2nd Edition</phrase>.
:<phrase>Fundamentals</phrase> of <phrase>Database Systems</phrase> combines clear explanations of theory and <phrase>design</phrase>, <phrase>broad coverage</phrase> of models and <phrase>real systems</phrase>, and excellent examples with <phrase>up-to-date</phrase> <phrase>introductions</phrase> to modern <phrase>database</phrase> technologies. This <phrase>edition</phrase> is completely <phrase>revised</phrase> and updated, and reflects the latest trends in technological and <phrase>application development</phrase>. Professors Elmasri and Navathe focus on the <phrase>relational model</phrase> and include coverage of recent <phrase>object-oriented</phrase> developments. They also address <phrase>advanced</phrase> modeling and system enhancements in the areas of <phrase>active databases</phrase>, temporal and <phrase>spatial databases</phrase>, and <phrase>multimedia</phrase> <phrase>information</phrase> systems. This <phrase>edition</phrase> also surveys the latest <phrase>application areas</phrase> of <phrase>data warehousing</phrase>, <phrase>data mining</phrase>, <phrase>web databases</phrase>, <phrase>digital libraries</phrase>, <phrase>GIS</phrase>, and <phrase>genome</phrase> <phrase>databases</phrase>. New to the <phrase>Third Edition</phrase> Reorganized material on <phrase>data</phrase> modeling to clearly separate <phrase>entity relationship</phrase> modeling, <phrase>extended entity relationship</phrase> modeling, and <phrase>object-oriented</phrase> modeling Expanded coverage of the <phrase>object-oriented</phrase> and <phrase>object/relational</phrase> approach to <phrase>data management</phrase>, including <phrase>ODMG</phrase> and SQL3 Uses examples from real <phrase>database systems</phrase> including OracleTM and <phrase>Microsoft</phrase> AccessAE Includes discussion of <phrase>decision support</phrase> applications of <phrase>data warehousing</phrase> and <phrase>data mining</phrase>, as well as <phrase>emerging technologies</phrase> of <phrase>web databases</phrase>, <phrase>multimedia</phrase>, and <phrase>mobile</phrase> <phrase>databases</phrase> Covers <phrase>advanced</phrase> modeling in the areas of <phrase>active</phrase>, temporal, and <phrase>spatial databases</phrase> Provides coverage of issues of <phrase>physical database</phrase> tuning Discusses current <phrase>database application</phrase> areas of <phrase>GIS</phrase>, <phrase>genome</phrase>, and <phrase>digital libraries</phrase>
<phrase>Crafting</phrase> a <phrase>Compiler</phrase> with <phrase>C</phrase>
<phrase>Introduction</phrase> to <phrase>Parallel Computing</phrase>.
<phrase>Computing</phrase> with <phrase>Logic</phrase>: <phrase>Logic Programming</phrase> with <phrase>Prolog</phrase>
<phrase>Temporal Databases</phrase>: Theory, <phrase>Design</phrase>, and Implementation
<phrase>Automaten</phrase>, <phrase>Sprachen</phrase> und Maschinen für Anwender
Rechnerorganisation
Rechnerorganisation, 2. Auflage
Computer-Grafik
Computer-Grafik, 2. Auflage
<phrase>Planen</phrase>: <phrase>Einführung in die</phrase> Planerstellungsmethoden <phrase>der künstlichen Intelligenz</phrase>
Kryptologie
<phrase>Theoretische Grundlagen</phrase> relationaler <phrase>Datenbanksysteme</phrase>
Rechnernetzwerksystemarchitekturen und Datenkommunikation
Datenbankmaschinen: Performanz durch Parallelität
<phrase>Parallele</phrase> <phrase>Transaktionen</phrase> in <phrase>Datenbanksystemen</phrase>
Syntaxanalyse, 3. Auflage
<phrase>C</phrase>
<phrase>Algorithmen und Datenstrukturen</phrase>
<phrase>Algorithmen und Datenstrukturen</phrase>, 2. Auflage
<phrase>Künstliche Intelligenz</phrase>: <phrase>Überblick und</phrase> <phrase>Grundlagen</phrase>; grundlegende <phrase>Konzepte und</phrase> <phrase>Methoden</phrase> <phrase>zur Realisierung von</phrase> <phrase>Systemen</phrase> <phrase>der künstlichen Intelligenz</phrase>
<phrase>Geo</phrase>-<phrase>Datenbanksysteme</phrase>: <phrase>Eine</phrase> <phrase>Speicher</phrase>- und Zugriffsarchitektur
<phrase>Logik</phrase> <phrase>für Informatiker</phrase>
<phrase>Logik</phrase> <phrase>für Informatiker</phrase>, 2. Auflage
<phrase>Logik</phrase> <phrase>für Informatiker</phrase>, 3. Auflage
Softwaretechnologie: <phrase>Eine Einführung</phrase>, 3. Auflage
Softwaretechnologie: <phrase>Eine Einführung</phrase>, 4. Auflage
Mikroprozessoren: <phrase>vom</phrase> Bauteil <phrase>zur Anwendung</phrase>, 2. Auflage
<phrase>Objektorientierte</phrase> Schemaentwicklung: <phrase>Ein</phrase> kategorialer <phrase>Ansatz</phrase> für <phrase>Datenbanken</phrase> und <phrase>Programmierung</phrase>
<phrase>Datenbanksysteme</phrase> <phrase>I</phrase>
<phrase>Datenbanksysteme</phrase> <phrase>II</phrase>
<phrase>Datenbanksysteme</phrase> <phrase>I</phrase>, 2. Auflage
<phrase>Datenbanksysteme</phrase> <phrase>I</phrase>, 3. Auflage
Compilerbau <phrase>I</phrase>: Analyse
Compilerbau <phrase>II</phrase>: <phrase>Synthese</phrase> <phrase>und Optimierung</phrase>
Betriebssysteme: <phrase>Parallele</phrase> <phrase>Prozesse</phrase>, 3. Auflage
Compilerbau <phrase>I</phrase>: Analyse, 2. Auflage
<phrase>Information Retrieval</phrase>.
<phrase>Building</phrase> an <phrase>Optimizing</phrase> <phrase>Compiler</phrase>.
<phrase>Introduction</phrase> to <phrase>Knowledge Base</phrase> Systems
Debuggers for <phrase>Programming Languages</phrase>.
<phrase>Software</phrase> Pipelining.
<phrase>Compilation</phrase> for <phrase>Distributed Memory</phrase> Architectures.
<phrase>Dynamic</phrase> <phrase>Compilation</phrase>.
<phrase>Register Allocation</phrase>.
<phrase>Instruction Scheduling</phrase>.
<phrase>Data</phrase> Flow Testing.
<phrase>Profile-Guided</phrase> <phrase>Compiler</phrase> Optimizations.
<phrase>Data Flow Analysis</phrase>.
Optimizations for <phrase>Object-Oriented</phrase> Languages.
<phrase>Program Slicing</phrase>.
<phrase>Automatic</phrase> Generation of Code Optimizers from <phrase>Formal Specifications</phrase>.
<phrase>Introduction</phrase> to <phrase>Operational Semantics</phrase>.
<phrase>Architecture Description Languages</phrase> for <phrase>Retargetable Compilation</phrase>.
<phrase>Retargetable</phrase> Very <phrase>Long</phrase> Instuction Word <phrase>Compiler</phrase> Framework for <phrase>Digital Signal Processors</phrase>.
<phrase>Dependence Analysis</phrase> and <phrase>Parallelizing</phrase> Transformations.
<phrase>Automatic</phrase> <phrase>Data</phrase> Distribution.
<phrase>Instruction Selection</phrase> Using <phrase>Tree</phrase> <phrase>Parsing</phrase>.
Scalar <phrase>Compiler</phrase> Optimizations on the <phrase>Static Single Assignment Form</phrase> and the <phrase>Flow Graph</phrase>.
<phrase>Type Systems</phrase> in <phrase>Programming Languages</phrase>.
<phrase>Compiling</phrase> <phrase>Safe</phrase> <phrase>Mobile</phrase> Code.
<phrase>Shape Analysis</phrase> and Applications.
<phrase>A Comparative Case Study</phrase> of <phrase>Distributed Network</phrase> Architectures for Different <phrase>Automotive</phrase> Applications.
<phrase>LonWorks</phrase>/EIA-709 Networks EIA 709 Protocol (Lon <phrase>Talk</phrase>).
<phrase>Distributed Components</phrase> in <phrase>Microsoft</phrase> Platforms - <phrase>Technology</phrase> <phrase>Overview</phrase>.
The <phrase>Quest</phrase> for <phrase>Real-Time</phrase> Behavior in <phrase>Ethernet</phrase>.
<phrase>CORBA</phrase> in <phrase>Manufacturing</phrase> - <phrase>Technology</phrase> <phrase>Overview</phrase>.
<phrase>IPv6</phrase>, <phrase>IPSec</phrase>, and <phrase>VPNs</phrase>.
<phrase>Overview</phrase> and Classification of <phrase>IP Routing</phrase> Protocols - <phrase>IP</phrase> Routing: <phrase>Interior and Exterior</phrase> <phrase>Routing Protocols</phrase>.
<phrase>Java</phrase> <phrase>Technology</phrase> and <phrase>Industrial</phrase> Applications.
Internal <phrase>Architecture</phrase> and Features of <phrase>Real-Time</phrase> Embedded Operation Systems.
<phrase>Middleware</phrase>.
<phrase>Network On-Chip</phrase> <phrase>Design</phrase> for <phrase>Gigascale</phrase> Systems-<phrase>on-Chip</phrase>.
Principles and Features of <phrase>PROFINET</phrase>.
<phrase>Knowledge</phrase> Connect - An Approach for an <phrase>Industrial</phrase> IT Service Tool.
<phrase>Intelligent Space</phrase> and <phrase>Mobile</phrase> <phrase>Robots</phrase>.
<phrase>Software</phrase> for <phrase>Wireless Sensor Networks</phrase>.
<phrase>Web-based</phrase> <phrase>Enterprise Computing</phrase> Development using <phrase>J2EE</phrase>.
<phrase>Holonic Manufacturing Systems</phrase>: A <phrase>Technical Overview</phrase>.
The GRAFCET <phrase>Specification Language</phrase>.
The <phrase>IDA</phrase> Standard.
<phrase>Embedded Software</phrase> in the <phrase>SoC</phrase> World. The Concept of HdS in View of the <phrase>HW and SW</phrase> <phrase>Design</phrase> <phrase>Challenge</phrase>.
<phrase>Platform-Based</phrase> and <phrase>Derivative</phrase> <phrase>Design</phrase>.
<phrase>Internet</phrase> <phrase>Programming Languages</phrase>.
<phrase>FOUNDATION</phrase> <phrase>Fieldbus</phrase>: <phrase>History</phrase> and Features.
<phrase>MPLS</phrase> - <phrase>Multiprotocol Label Switching</phrase>.
<phrase>Operating Principles</phrase> and Features of CAN Networks.
<phrase>Robot</phrase> <phrase>Tactile</phrase> Sensing.
<phrase>Hardware/Software</phrase> Interfaces <phrase>Design</phrase> for <phrase>SoC</phrase>.
Giving <phrase>Robots</phrase> a Sense of Smell.
<phrase>Mail</phrase> Transfer and <phrase>File Transfer</phrase> Protocol.
The <phrase>Integrated Services</phrase> <phrase>Architecture</phrase> and <phrase>RSVP</phrase>.
Collaborative (<phrase>Agent-Based</phrase>) <phrase>Factory</phrase> <phrase>Automation</phrase>.
<phrase>Linking</phrase> <phrase>Factory Floor</phrase> and the <phrase>Internet</phrase>.
Which Network for Which Application.
<phrase>Internet</phrase> <phrase>Firewalls</phrase>.
Interconnection of Wireline and <phrase>Wireless</phrase> Fieldbusses.
<phrase>IEEE</phrase> 1394 for <phrase>Factory</phrase> <phrase>Automation</phrase>.
<phrase>Intelligent Sensors</phrase>: Analysis and <phrase>Design</phrase>.
Securtity in <phrase>Automation</phrase> Networks.
<phrase>Integration</phrase> Technologies of <phrase>Field Devices</phrase> in <phrase>Distributed Control</phrase> and <phrase>Engineering</phrase> Systems.
The Standard Message Specification for <phrase>Industrial Automation</phrase> Systems -<phrase>ISO</phrase> 9506 (<phrase>MMS</phrase>).
<phrase>RTP</phrase>, <phrase>RTCP</phrase>, and <phrase>RTSP</phrase> - <phrase>Internet</phrase> Protocols for <phrase>Real-Time</phrase> <phrase>Multimedia</phrase> <phrase>Communication</phrase>.
<phrase>Smart Power</phrase> Systems Rely on Standards for <phrase>Information</phrase> Models and <phrase>Messaging</phrase> - <phrase>IEC</phrase> 61850.
The <phrase>Fundamentals</phrase> of <phrase>Web Services</phrase>.
<phrase>Open</phrase> System <phrase>Architecture</phrase> for Controls within <phrase>Automation</phrase> Systems (OSACA).
<phrase>Programming</phrase> <phrase>Web Services</phrase> with .<phrase>net</phrase> and <phrase>java</phrase>.
<phrase>A Survey</phrase> of Congestion and <phrase>QoS Control</phrase> Mechanisms for the <phrase>Internet</phrase>.
Languages for <phrase>Embedded Systems</phrase>.
<phrase>Switched Ethernet</phrase> in <phrase>Automation</phrase> <phrase>Networking</phrase>.
Enterprise-<phrase>Manufacturing</phrase> <phrase>Data</phrase> Exchange Using <phrase>XML</phrase>.
<phrase>Programming</phrase> with the <phrase>IEC</phrase> 61131-3 Languages and the MatPLC.
The <phrase>Dynamic Host Configuration Protocol</phrase>.
<phrase>Security</phrase> in <phrase>Embedded Systems</phrase>.
The <phrase>Internet Protocol</phrase>.
PROFIsafe - <phrase>Safety</phrase> <phrase>Technology</phrase> with <phrase>PROFIBUS</phrase>.
<phrase>ARP</phrase> - <phrase>Address Resolution Protocol</phrase>.
<phrase>XML</phrase> for the Exchange of <phrase>Automation</phrase> <phrase>Project</phrase> <phrase>Information</phrase>.
The WORLDFIP <phrase>Fieldbus</phrase>.
<phrase>IP</phrase>-Mobility for Cellular and <phrase>Wireless Networks</phrase>.
<phrase>Unified Modeling Language</phrase>: The <phrase>Industry</phrase> Standard for <phrase>Software Development</phrase>.
<phrase>A Survey</phrase> on <phrase>Self-Organizing</phrase> <phrase>Wireless Sensor Networks</phrase>.
<phrase>Web</phrase> Servers, Clients, and <phrase>Browsers</phrase>.
The <phrase>Hypertext Transfer Protocol</phrase> and <phrase>Uniform Resource Identifier</phrase>.
<phrase>Introduction</phrase> to <phrase>Multisensor Data Fusion</phrase>.
Models of Computation for <phrase>Embedded Systems</phrase>.
<phrase>Industrial</phrase> IT-<phrase>Based Network</phrase> <phrase>Management</phrase>.
<phrase>Hardware-level</phrase> <phrase>Design</phrase> Languages.
<phrase>Integration</phrase> Between <phrase>Production</phrase> and <phrase>Business</phrase> Systems.
From <phrase>Holonic Control</phrase> to <phrase>Virtual</phrase> Enterprises: The <phrase>Multi-Agent</phrase> Approach.
Acheiving Reconfigurability of <phrase>Automation</phrase> Systems by Using the New <phrase>International Standard</phrase> <phrase>IEC</phrase> 61499: A Developer's View.
<phrase>IP</phrase>-<phrase>QoS</phrase>: Scalable and Flexible <phrase>Quality-of-Service</phrase> with <phrase>Differentiated</phrase> Services.
<phrase>Real-Time</phrase> Systems.
<phrase>Wireless LAN</phrase> <phrase>Technology</phrase> for the <phrase>Factory Floor</phrase>.
<phrase>Internet</phrase> Still Image and <phrase>Video</phrase> Formats.
Principles of <phrase>Lower-Layer</phrase> Protocols for <phrase>Data</phrase> Communications.
<phrase>Network Management</phrase>: <phrase>Basic</phrase> Notions and Frameworks.
<phrase>Multicast</phrase>.
<phrase>HTTP</phrase> <phrase>Digest</phrase> <phrase>Authentication</phrase> - Theory and Practice.
<phrase>Web Services</phrase> for Integrated <phrase>Automation</phrase> Systems - Challenges, Solutions and Future.
Verification Languages.
<phrase>Mobile IP</phrase> Routing.
<phrase>Remote</phrase> Monitoring and Control over the <phrase>Internet</phrase>.
<phrase>Power Aware</phrase> <phrase>Embedded Computing</phrase>.
<phrase>Robot</phrase> Vision.
<phrase>Bluetooth</phrase>.
<phrase>PROFIBUS</phrase> - <phrase>Open</phrase> Solutions for the World of <phrase>Automation</phrase>.
The <phrase>Fundamentals</phrase> of the <phrase>Quality of Service</phrase>.
<phrase>Ad Hoc</phrase> Networks.
Applications of <phrase>Haptics</phrase> in <phrase>Design</phrase> and <phrase>Manufacturing</phrase>.
Implementation <phrase>af</phrase> a <phrase>Virtual</phrase> <phrase>Factory</phrase> <phrase>Communication</phrase> System using the <phrase>Manufacturing</phrase> Message Specification Standard.
<phrase>Ultrasonic</phrase> Sensors in <phrase>Robotics</phrase>.
<phrase>Microsoft's</phrase> .<phrase>NET</phrase>.
<phrase>Multiagent-based</phrase> <phrase>Architecture</phrase> for <phrase>Plant</phrase> <phrase>Automation</phrase>.
<phrase>Introduction</phrase> to <phrase>e</phrase>-<phrase>Manufacturing</phrase>.
<phrase>Time-Triggered</phrase> <phrase>Communication</phrase> Networks.
<phrase>Internet</phrase>-Based <phrase>Telemanipulation</phrase>.
<phrase>Network Security</phrase> and <phrase>Secure</phrase> Applications.
<phrase>Simple Network Management Protocol</phrase> <phrase>SNMP</phrase>.
<phrase>TCP/IP</phrase> <phrase>Architecture</phrase>, Protocols, and Services.
<phrase>OPC</phrase> - Openness, <phrase>Productivity</phrase>, and Connectivity.
<phrase>Design</phrase> of <phrase>Embedded Systems</phrase>.
A <phrase>Smart</phrase> <phrase>Transducer</phrase> Interface Standard for <phrase>Sensors and Actuators</phrase>.
LonWorksTM over <phrase>IP</phrase>.
The <phrase>Transmission Control Protocol</phrase>.
<phrase>Multidimensional Databases</phrase>.
The <phrase>User Datagram protocol</phrase>.
<phrase>Networked Control Systems</phrase> <phrase>Overview</phrase>.
System-<phrase>on-Chip</phrase> and <phrase>Network-on-Chip</phrase> <phrase>Design</phrase>.
<phrase>Wireless Local Area Networks</phrase> and <phrase>Wireless Personal Area Networks</phrase> (<phrase>WLANs</phrase> and <phrase>WPANs</phrase>).
<phrase>Open</phrase> Controller Enabled by an <phrase>Advanced</phrase> <phrase>Real-Time</phrase> Network (<phrase>OCEAN</phrase>).
IT <phrase>Security</phrase> for <phrase>Automation</phrase> Systems.
The JEVIS <phrase>Service Platform</phrase> - <phrase>Distributed Energy</phrase> <phrase>Data Acquisition</phrase> and <phrase>Management</phrase>.
An <phrase>Introductory</phrase> Survey of <phrase>Networked Embedded Systems</phrase>.
<phrase>Thread Management</phrase> for <phrase>Shared-Memory Multiprocessors</phrase>.
<phrase>Parallelizing</phrase> Compilers.
Renderman®: An Interface for <phrase>Image Synthesis</phrase>.
<phrase>Object-Oriented</phrase> <phrase>Databases</phrase>.
Network and <phrase>Internet</phrase> <phrase>Security</phrase>.
<phrase>Concurrent</phrase>/<phrase>Distributed Programming</phrase> <phrase>Paradigm</phrase>.
<phrase>Parallel Algorithms</phrase>.
<phrase>Formal Models</phrase> and the Specification Process.
<phrase>User Interface Design</phrase> Activities.
<phrase>Virtual Reality</phrase>.
<phrase>Memory</phrase> Systems.
<phrase>Type Systems</phrase>.
<phrase>Computational Fluid Dynamics</phrase>.
Rules in <phrase>Data</phrase>-<phrase>Based Systems</phrase>.
<phrase>Combinatorial</phrase> Optimization.
Distributed and <phrase>Multiprocessor</phrase> Scheduling.
Computational <phrase>Reacting Flow</phrase>.
<phrase>Logic Programming</phrase> and <phrase>Constraint Logic Programming</phrase>.
<phrase>Pattern Matching</phrase> and <phrase>Text Compression</phrase> <phrase>Algorithms</phrase>.
Process and Device Scheduling.
<phrase>Explanation-Based Learning</phrase>.
<phrase>Planning</phrase> and Scheduling.
Traditional <phrase>Software Design</phrase>.
<phrase>Virtual Memory</phrase>.
<phrase>Virtual memory</phrase> is the <phrase>simulation</phrase> of a <phrase>storage space</phrase> so large that programmers do not need to reprogram or recompile their works when the capacity of a <phrase>local</phrase> <phrase>memory</phrase> or the configuration of a network changes. The name, borrowed from <phrase>optics</phrase>, recalls the <phrase>virtual</phrase> images formed by mirrors and lenses--images that are not there but behave as if they are. The designers of the <phrase>Atlas</phrase> Computer at the <phrase>University</phrase> of <phrase>Manchester</phrase> invented <phrase>virtual memory</phrase> in the 1950s to eliminate a <phrase>looming</phrase> <phrase>programming</phrase> problem: <phrase>planning</phrase> and scheduling <phrase>data</phrase> transfers between main and <phrase>secondary</phrase> <phrase>memory</phrase> and recompiling programs for each change of size of <phrase>main memory</phrase>. <phrase>Virtual memory</phrase> is even more useful in the <phrase>computers</phrase> of the 1990s, which have more things to hide-<phrase>on-chip</phrase> caches, separate <phrase>RAM</phrase> chips, <phrase>local</phrase> <phrase>disk storage</phrase>, network <phrase>file servers</phrase> (q.v.), <phrase>large numbers</phrase> of <phrase>separately compiled</phrase> <phrase>program modules</phrase>, other <phrase>computers</phrase> on the <phrase>local</phrase> <phrase>bus</phrase> or <phrase>local</phrase> network, or the <phrase>Internet</phrase>. The <phrase>story</phrase> of <phrase>virtual memory</phrase> from then to now is a <phrase>story</phrase> about machines <phrase>helping programmers</phrase> <phrase>solve problems</phrase> in <phrase>storage allocation</phrase>, protection of <phrase>information</phrase>, sharing and reuse of objects, and <phrase>linking</phrase> of <phrase>program components</phrase>. <phrase>Virtual memory</phrase>, common in all <phrase>computers</phrase> and <phrase>operating systems</phrase> from the <phrase>smallest</phrase> <phrase>microprocessor</phrase> to the largest <phrase>supercomputer</phrase>, is now invading the <phrase>Internet</phrase>.
<phrase>Algebraic</phrase> <phrase>Algorithms</phrase>.
<phrase>Distributed File Systems</phrase> and <phrase>Distributed Memory</phrase>.
<phrase>Real-Time</phrase> and <phrase>Embedded Systems</phrase>.
<phrase>Output Devices</phrase> and Techniques.
Interactive Techniques.
<phrase>Advanced</phrase> <phrase>Geometric</phrase> Modeling.
<phrase>Digital</phrase> <phrase>Logic</phrase>.
<phrase>Malicious Software</phrase> and <phrase>Hacking</phrase>.
What Is an <phrase>Operating System</phrase>?
<phrase>Data Structures</phrase>.
Mainstream <phrase>Rendering Techniques</phrase>.
<phrase>Qualitative</phrase> Reasoning.
<phrase>Genetic Algorithms</phrase>.
<phrase>Concurrency Control</phrase> and Recovery.
Verification and Validation.
<phrase>Software</phrase> Qualities and Principles.
<phrase>Functional Programming Languages</phrase>.
The <phrase>Organizational Context</phrase> of Development and Use.
The <phrase>Object-Oriented Language</phrase> <phrase>Paradigm</phrase>.
<phrase>Overview</phrase> of <phrase>Three-Dimensional</phrase> Graphics.
International <phrase>User-Interface</phrase> <phrase>Standardization</phrase>.
Busses.
<phrase>Parallel</phrase> Architectures.
<phrase>Interactive Software</phrase> <phrase>Technology</phrase>.
<phrase>Computer Vision</phrase>.
<phrase>Query Optimization</phrase>.
<phrase>Input Devices</phrase> and Techniques.
<phrase>Database</phrase> <phrase>Security</phrase> and <phrase>Privacy</phrase>.
<phrase>Formal Models</phrase> and <phrase>Computability</phrase>.
The <phrase>Imperative Language</phrase> <phrase>Paradigm</phrase>.
<phrase>Ethical</phrase> Issues for <phrase>Computer Scientists</phrase> and Engineers.
<phrase>Neural Networks</phrase>.
We present <phrase>an overview</phrase> of <phrase>current research</phrase> on <phrase>artificial neural networks</phrase>, emphasizing a statistical <phrase>perspective</phrase>. We view <phrase>neural networks</phrase> as <phrase>parameterized</phrase> <phrase>graphs</phrase> that make <phrase>probabilistic</phrase> assumptions about <phrase>data</phrase>, and view <phrase>learning</phrase> <phrase>algorithms</phrase> as methods for <phrase>finding</phrase> <phrase>parameter values</phrase> that look probable in the <phrase>light</phrase> of the <phrase>data</phrase>. We discuss <phrase>basic</phrase> issues in representation and <phrase>learning</phrase>, and treat some of the <phrase>practical issues</phrase> that arise in <phrase>fitting</phrase> networks to <phrase>data</phrase>. We also discuss links between <phrase>neural networks</phrase> and the <phrase>general</phrase> formalism of <phrase>graphical</phrase> models.
<phrase>Digital</phrase> <phrase>Computer Architecture</phrase>.
Computational <phrase>Ocean</phrase> Modeling.
<phrase>Volume Visualization</phrase>.
<phrase>Graph</phrase> and Network <phrase>Algorithms</phrase>.
<phrase>Task Analysis</phrase> and the <phrase>Design</phrase> of Functionality.
<phrase>Computational Biology</phrase>.
Search.
<phrase>Case Study</phrase> in <phrase>Algorithms</phrase>: <phrase>VLSI</phrase> Layout.
Protection (<phrase>Security</phrase>) Models and Policy.
<phrase>Computational Geometry</phrase>.
<phrase>Robotics</phrase>.
<phrase>Compilers and Interpreters</phrase>.
<phrase>Complexity Theory</phrase>.
<phrase>Logic</phrase>-Based <phrase>Deductive Reasoning</phrase>.
<phrase>Computer Animation</phrase>.
<phrase>Secondary</phrase> Storage and <phrase>File Systems</phrase>.
The <phrase>SQL</phrase> <phrase>Language</phrase>: <phrase>A Case Study</phrase>.
<phrase>Randomized</phrase> <phrase>Algorithms</phrase>.
<phrase>Overview</phrase> of <phrase>Distributed Operating Systems</phrase>.
Interface <phrase>Software</phrase> <phrase>Technology</phrase>.
<phrase>Security</phrase> and <phrase>Privacy</phrase> Issues in Computer and <phrase>Communication</phrase> Systems.
Computational <phrase>Structural Mechanics</phrase>.
Distributed and <phrase>Parallel</phrase> <phrase>Database Systems</phrase>.
<phrase>Routing Protocols</phrase>.
<phrase>Development Strategies</phrase> and <phrase>Project Management</phrase>.
<phrase>Internetworking</phrase>.
<phrase>Software</phrase> Tools and Environments.
<phrase>Geometric</phrase> Primitives.
<phrase>Access Methods</phrase>.
Testing: Principles and Practice.
<phrase>Online</phrase> <phrase>Support Systems</phrase>: <phrase>Tutorials</phrase>, Documentation, and Help.
<phrase>Computational Electromagnetics</phrase>.
<phrase>Scientific Visualization</phrase>.
<phrase>Data</phrase> Models.
<phrase>Network Organization</phrase> and <phrase>Topologies</phrase>.
<phrase>Computer Science</phrase> and <phrase>Engineering</phrase>: The Discipline and Its Impact.
<phrase>Process Synchronization</phrase> and <phrase>Interprocess Communications</phrase>.
<phrase>Usability</phrase> <phrase>Engineering</phrase>.
:Written by the <phrase>author</phrase> of the best-selling <phrase>HyperText</phrase> & <phrase>HyperMedia</phrase>, this <phrase>book</phrase> provides an excellent guide to the methods of <phrase>usability</phrase> <phrase>engineering</phrase>. <phrase>Special features</phrase>: emphasizes <phrase>cost-effective</phrase> methods that will help developers improve their <phrase>user interfaces</phrase> immediately, shows you how to avoid the four most frequently <phrase>listed</phrase> reasons for delay in <phrase>software</phrase> projects, provides <phrase>step-by-step</phrase> <phrase>information</phrase> about which methods to use at various stages during the <phrase>development life cycle</phrase>, and offers <phrase>information</phrase> on the unique issues relating to <phrase>informational</phrase> <phrase>usability</phrase>. You do not need to have previous <phrase>knowledge</phrase> of <phrase>usability</phrase> to implement the methods provided, yet all of the latest <phrase>research</phrase> is <phrase>covered</phrase>.
<phrase>Knowledge-Based Systems</phrase> for <phrase>Natural Language Processing</phrase>.
<phrase>Run Time</phrase> Environments and <phrase>Memory Management</phrase>.
<phrase>Database</phrase> <phrase>Performance Measurement</phrase>.
<phrase>Graphical</phrase> Models for <phrase>Probabilistic</phrase> and <phrase>Causal</phrase> Reasoning.
<phrase>Foundational</phrase> <phrase>Calculi</phrase> for <phrase>Programming Languages</phrase>.
<phrase>Decision Trees</phrase> and <phrase>Instance-Based</phrase> Classifiers.
<phrase>Basic</phrase> Techniques for <phrase>Design</phrase> and Analysis of <phrase>Algorithms</phrase>.
<phrase>Text Databases</phrase> and <phrase>Information Retrieval</phrase>.
The <phrase>Human</phrase> Factor in <phrase>Programming</phrase> and <phrase>Software Development</phrase>.
<phrase>Authentication</phrase>, <phrase>Access Controls</phrase>, and <phrase>Intrusion Detection</phrase>.
<phrase>Programming Language</phrase> <phrase>Semantics</phrase>.
Like <phrase>English</phrase>, <phrase>French</phrase>, and other "natural" languages, a <phrase>programming language</phrase> possesses both a <phrase>syntax</phrase> (<phrase>grammatical</phrase> laws that define the <phrase>well-formed</phrase> sentences) and a <phrase>semantics</phrase> (rules for giving meaning to <phrase>programming language</phrase> is a simple enough "<phrase>artificial</phrase>" <phrase>language</phrase> that <phrase>precise definitions</phrase> can be formulated for its <phrase>syntax</phrase> and <phrase>semantics</phrase>. The benefits of such <phrase>precise definitions</phrase> are: (1) the definitions standardize the <phrase>programming language</phrase>, so that implementors and users can agree on how the <phrase>language</phrase> bahaves; (2) the definitions can be analyzed for correctness and effciency properties; and (3) they can be used as input to <phrase>automated prototyping</phrase> tools like complier generators.
<phrase>Understanding</phrase> <phrase>Spoken Language</phrase>.
Tuning <phrase>Database Design</phrase> for <phrase>High</phrase> Performance.
<phrase>Software</phrase> Support Challenges for <phrase>Heterogeneous Computing</phrase>.
<phrase>Software Process Models</phrase>.
<phrase>Geometry</phrase>-<phrase>Grid</phrase> Generation.
<phrase>High</phrase>-Speed <phrase>Computer Arithmetic</phrase>.
<phrase>Sampling</phrase>, <phrase>Reconstruction</phrase>, and Antialiasing.
<phrase>Multimedia</phrase>.
The <phrase>Industrial</phrase> <phrase>Information Technology</phrase> <phrase>Handbook</phrase>
<phrase>Design</phrase> of Compilers - Techniques of <phrase>Programming Language</phrase> <phrase>Translation</phrase>
<phrase>Handbook</phrase> of <phrase>Applied Cryptography</phrase>
The <phrase>Computer Science</phrase> and <phrase>Engineering</phrase> <phrase>Handbook</phrase>
The <phrase>Compiler</phrase> <phrase>Design</phrase> <phrase>Handbook</phrase>: Optimizations and <phrase>Machine Code</phrase> Generation
<phrase>Fundamentals</phrase> of Computer <phrase>Algorithms</phrase>.
The Theory of <phrase>Relational Databases</phrase>.
A <phrase>Logical</phrase> <phrase>Language</phrase> for <phrase>Data</phrase> and <phrase>Knowledge</phrase> Bases.
The Theory of <phrase>Database</phrase> <phrase>Concurrency Control</phrase>
<phrase>Introduction</phrase> to <phrase>Compiler</phrase> <phrase>Construction</phrase>
<phrase>Data Compression</phrase>: Methods and Theory.
Principles of <phrase>Database Systems</phrase>, <phrase>1st Edition</phrase>
Principles of <phrase>Database Systems</phrase>, <phrase>2nd Edition</phrase>
Principles of <phrase>Database</phrase> and <phrase>Knowledge-Base</phrase> Systems, Volume <phrase>I</phrase>
Principles of <phrase>Database</phrase> and <phrase>Knowledge-Base</phrase> Systems, <phrase>Volume II</phrase>
<phrase>Algorithmic</phrase> Studies in <phrase>Mass Storage</phrase> Systems.
<phrase>An Introduction</phrase> to <phrase>Unification-Based</phrase> Approaches to <phrase>Grammar</phrase>
<phrase>Word Order</phrase> and <phrase>Constituent Structure</phrase> in <phrase>German</phrase>
<phrase>Nonmonotonic Reasoning</phrase>: <phrase>An Overview</phrase>
<phrase>Specification Language</phrase>.
<phrase>An Introduction</phrase> to <phrase>Pascal</phrase>-Plus.
<phrase>Algorithms</phrase> for <phrase>Parallel Computers</phrase>.
<phrase>Concurrent Pascal</phrase> - An <phrase>Appraisal</phrase>.
A <phrase>Model</phrase> for <phrase>Communicating Sequential Processes</phrase>.
Modules and <phrase>Visibility</phrase> in the <phrase>Ada</phrase> <phrase>Programming Language</phrase>.
<phrase>Information</phrase> Systems: Modelling, Sequencing and Transformations.
Specification and <phrase>design</phrase> of an <phrase>information</phrase> system <phrase>conventionally</phrase> starts from consideration of the system <phrase>function</phrase>. This <phrase>paper</phrase> argues that consideration may more properly be given first to the system as a <phrase>model</phrase> of the <phrase>reality</phrase> with which it is concerned, the <phrase>function</phrase> being <phrase>subsequently</phrase> superimposed on the <phrase>model</phrase>. The form of <phrase>model</phrase> proposed is a network of <phrase>sequential</phrase> processes communicating by <phrase>serial</phrase> <phrase>data</phrase> streams. Such a <phrase>model</phrase> permits a clear representation of change or activity over time, and it also prevents over-specification of sequencing by <phrase>separating</phrase> <phrase>problem-oriented</phrase> from <phrase>solution</phrase>-oriented <phrase>sequencing constraints</phrase>. The <phrase>model</phrase>, however, cannot be efficiently executed on uniprocessor hardware without transformation. Some relevant kinds of transformation are mentioned, and the <phrase>derivation</phrase>, by means of them, of conventional <phrase>information</phrase> system configurations from the proposed <phrase>model</phrase>.
A Structured <phrase>Operating System</phrase>.
Languages for <phrase>Parallel Computers</phrase>.
<phrase>Parallel Processing</phrase> in <phrase>Ada</phrase>.
A Structured <phrase>Compiler</phrase>.
<phrase>Compiling</phrase> with <phrase>Continuations</phrase>
This <phrase>book</phrase> shows how <phrase>continuation-passing style</phrase> is used as an <phrase>intermediate representation</phrase> to perform optimizations and <phrase>program transformations</phrase>. <phrase>Continuations</phrase> can be used to compile most <phrase>programming languages</phrase>. The method is illustrated in a <phrase>compiler</phrase> for the <phrase>programming language</phrase> <phrase>Standard ML</phrase>. <phrase>Prior knowledge</phrase> of <phrase>ML</phrase>, however, is not necessary, as the <phrase>author</phrase> carefully explains each concept as it arises. This is the first <phrase>book</phrase> to show how concepts from the theory of <phrase>programming languages</phrase> can be applied to the <phrase>production</phrase> of practical <phrase>optimizing</phrase> compilers for <phrase>modern languages</phrase> like <phrase>ML</phrase>. All the details of <phrase>compiling</phrase> are <phrase>covered</phrase>, including the interface to a runtime system and <phrase>garbage collector</phrase>.
<phrase>Modern Compiler</phrase> Implementation in <phrase>Java</phrase>: <phrase>Basic</phrase> Techniques
:This <phrase>textbook</phrase> describes all phases of a <phrase>modern compiler</phrase>. It includes good coverage of <phrase>current techniques</phrase> in <phrase>code generation</phrase> and <phrase>register allocation</phrase>, as well as <phrase>functional</phrase> and <phrase>object-oriented</phrase> languages, that is missing from most <phrase>books</phrase>. In a concise way, the <phrase>author</phrase> describes the most accepted and successful techniques, rather than giving an exhaustive <phrase>catalog</phrase> of every possible variant. Detailed descriptions of the interfaces between modules of a <phrase>compiler</phrase> are illustrated with actual <phrase>Java</phrase> classes. A unique feature of the <phrase>book</phrase> is a well designed <phrase>compiler</phrase> implementation <phrase>project</phrase> in <phrase>Java</phrase>, including <phrase>front-end</phrase> and <phrase>high-tech</phrase> <phrase>back-end</phrase> phases, giving a practical example of <phrase>Java</phrase> <phrase>programming</phrase> for students which will also interest <phrase>computer professionals</phrase>.
<phrase>Modern Compiler</phrase> Implementation in <phrase>C</phrase>: <phrase>Basic</phrase> Techniques
:This <phrase>textbook</phrase> describes all phases of a <phrase>modern compiler</phrase>. It includes good coverage of <phrase>current techniques</phrase> in <phrase>code generation</phrase> and <phrase>register allocation</phrase>, as well as <phrase>functional</phrase> and <phrase>object-oriented</phrase> languages, that is missing from most <phrase>books</phrase>. In a concise way, the <phrase>author</phrase> describes the most accepted and successful techniques, rather than giving an exhaustive <phrase>catalog</phrase> of every possible variant. Detailed descriptions of the interfaces between modules of a <phrase>compiler</phrase> are illustrated with actual <phrase>C</phrase> <phrase>header files</phrase>. A unique feature of the <phrase>book</phrase> is a well designed <phrase>compiler</phrase> implementation <phrase>project</phrase> in <phrase>C</phrase>, including <phrase>front-end</phrase> and <phrase>high-tech</phrase> <phrase>back-end</phrase> phases, useful for <phrase>undergraduate</phrase> and <phrase>graduate students</phrase> as well as <phrase>computer professionals</phrase> needing a reference on <phrase>compiler</phrase> implementation.
<phrase>Modern Compiler</phrase> Implementation in <phrase>ML</phrase>: <phrase>Basic</phrase> Techniques
:This <phrase>textbook</phrase> describes all phases of a <phrase>modern compiler</phrase>. It includes good coverage of <phrase>current techniques</phrase> in <phrase>code generation</phrase> and <phrase>register allocation</phrase>, as well as <phrase>functional</phrase> and <phrase>object-oriented</phrase> languages, that is missing from most <phrase>books</phrase>. In a concise way, the <phrase>author</phrase> describes the most accepted and successful techniques, rather than giving an exhaustive <phrase>catalog</phrase> of every possible variant. Detailed descriptions of the interfaces between modules of a <phrase>compiler</phrase> are illustrated with actual <phrase>ML</phrase> <phrase>signatures</phrase>. A unique feature of the <phrase>book</phrase> is a well designed <phrase>compiler</phrase> implementation <phrase>project</phrase> in <phrase>ML</phrase>, including <phrase>front-end</phrase> and <phrase>high-tech</phrase> <phrase>back-end</phrase> phases, useful for <phrase>undergraduate</phrase> and <phrase>graduate students</phrase> as well as <phrase>computer professionals</phrase> needing a reference on <phrase>compiler</phrase> implementation.
<phrase>Modern Compiler</phrase> Implementation in <phrase>Java</phrase>
<phrase>Modern Compiler</phrase> Implementation in <phrase>C</phrase>
<phrase>Modern Compiler</phrase> Implementation in <phrase>ML</phrase>
<phrase>Modern Compiler</phrase> Implementation in <phrase>Java</phrase>, <phrase>2nd edition</phrase>.
<phrase>An Introduction</phrase> to <phrase>Mathematical</phrase> <phrase>Taxonomy</phrase>
<phrase>Biological Sequence Analysis</phrase>: <phrase>Probabilistic</phrase> Models of <phrase>Proteins</phrase> and <phrase>Nucleic Acids</phrase>
<phrase>Algorithms</phrase> on <phrase>Strings</phrase>, <phrase>Trees</phrase>, and Sequences - <phrase>Computer Science</phrase> and <phrase>Computational Biology</phrase>
<phrase>Introduction</phrase> to <phrase>Combinators</phrase> and <phrase>Lambda-Calculus</phrase>.
On the <phrase>Construction</phrase> of Programs
<phrase>LEDA</phrase>: A Platform for <phrase>Combinatorial</phrase> and <phrase>Geometric</phrase> <phrase>Computing</phrase>.
<phrase>Combinatorial</phrase> and <phrase>geometric</phrase> <phrase>computing</phrase> is a core <phrase>area</phrase> of <phrase>computer science</phrase> (<phrase>CS</phrase>). In fact, most <phrase>CS</phrase> curricula contain a course in <phrase>data structures</phrase> and <phrase>algorithms</phrase>. The <phrase>area</phrase> deals with objects such as <phrase>graphs</phrase>, sequences, dictionaries, <phrase>trees</phrase>, <phrase>shortest paths</phrase>, flows, <phrase>matchings</phrase>, points, segments, lines, <phrase>convex hulls</phrase>, and <phrase>Voronoi diagrams</phrase> and forms the basis for <phrase>application areas</phrase> such as <phrase>discrete optimization</phrase>, scheduling, <phrase>traffic control</phrase>, <phrase>CAD</phrase>, and graphics. There is no <phrase>standard library</phrase> of the <phrase>data structures</phrase> and <phrase>algorithms</phrase> of <phrase>combinatorial</phrase> and <phrase>geometric</phrase> <phrase>computing</phrase>. This is in <phrase>sharp</phrase> contrast to many other areas of <phrase>computing</phrase>. There are, for example, packages in <phrase>statistics</phrase> (<phrase>SPSS</phrase>), <phrase>numerical analysis</phrase> (<phrase>LINPACK</phrase>, EISPACK), <phrase>symbolic computation</phrase> (<phrase>MAPLE</phrase>, <phrase>MATHEMATICA</phrase>), and <phrase>linear programming</phrase> (<phrase>CPLEX</phrase>).
<phrase>Randomized</phrase> <phrase>Algorithms</phrase>.
<phrase>Numerical Recipes</phrase> in <phrase>C</phrase>, <phrase>2nd Edition</phrase>.
<phrase>Data Refinement</phrase>: <phrase>Model</phrase>-oriented <phrase>Proof Theories</phrase> and their Comparison
<phrase>Concurrency</phrase> Verification: <phrase>Introduction</phrase> to <phrase>Compositional</phrase> and Noncompositional Methods
<phrase>Wiki</phrase> - <phrase>Planen</phrase>, Einrichten, Verwalten
Technologiebewusstes <phrase>Design</phrase> <phrase>von Web-Anwendungen</phrase>.
Semantisches <phrase>Web</phrase> - <phrase>Das</phrase> <phrase>Netz</phrase> der Bedeutungen <phrase>im Netz</phrase> der Dokumente.
<phrase>Sicherheit</phrase> <phrase>von Web-Anwendungen</phrase>.
<phrase>Betrieb</phrase> <phrase>und Wartung</phrase> <phrase>von Web-Anwendungen</phrase>.
<phrase>Architektur</phrase> <phrase>von Web-Anwendungen</phrase>.
Entwicklungsprozess <phrase>von Web-Anwendungen</phrase>.
Implementierungstechnologien für <phrase>Web-Anwendungen</phrase>.
<phrase>Requirements Engineering</phrase> für <phrase>Web-Anwendungen</phrase>.
<phrase>Usability</phrase> <phrase>von Web-Anwendungen</phrase>.
<phrase>Web Engineering</phrase> - <phrase>Die</phrase> Disziplin <phrase>zur systematischen</phrase> <phrase>Entwicklung</phrase> <phrase>von Web-Anwendungen</phrase>.
Performanz <phrase>von Web-Anwendungen</phrase>.
<phrase>Web</phrase>-Projektmanagement.
<phrase>Modellierung</phrase> <phrase>von Web-Anwendungen</phrase>.
<phrase>Testen</phrase> <phrase>von Web-Anwendungen</phrase>.
Semistrukturierte Datenmodelle und <phrase>XML</phrase>.
<phrase>Benchmarking</phrase> von <phrase>XML</phrase>-<phrase>Datenbanksystemen</phrase>.
Indexstrukturen für <phrase>XML</phrase>.
<phrase>Web</phrase>-basiertes <phrase>Lernen</phrase>: <phrase>Eine Übersicht</phrase> über <phrase>Stand und</phrase> <phrase>Entwicklungen</phrase>.
<phrase>Architektur</phrase> von <phrase>Web</phrase>-<phrase>Informationssystemen</phrase>.
<phrase>Web Services</phrase>.
<phrase>Speicherung</phrase> von <phrase>XML-Dokumenten</phrase>.
<phrase>Anfragen</phrase>, Ändern und Transformieren von <phrase>XML</phrase>.
Kommerzielle <phrase>Systeme</phrase> zur <phrase>Speicherung</phrase>, <phrase>Verwaltung</phrase> und Anfrage von <phrase>XML-Dokumenten</phrase>.
<phrase>Data-Warehouse</phrase>-<phrase>Einsatz</phrase> zur <phrase>Web</phrase>-Zugriffsanalyse.
Datenintegration und Mediatoren.
<phrase>XML Schema</phrase>.
Suchmaschinen.
<phrase>Web Caching</phrase>.
<phrase>Object-Oriented</phrase> <phrase>Reengineering</phrase> Patterns
:The documentation is missing or obsolete, and the original developers have departed. Your <phrase>team</phrase> has limited <phrase>understanding</phrase> of the system, and <phrase>unit tests</phrase> are missing for many, if not all, of the components. When you <phrase>fix</phrase> a bug in one place, another bug <phrase>pops</phrase> up somewhere else in the system. <phrase>Long</phrase> rebuild times make any change difficult. All of these are signs of <phrase>software</phrase> that is close to the <phrase>breaking</phrase> point. Many systems can be upgraded or simply <phrase>thrown away</phrase> if they <phrase>no longer</phrase> serve their purpose. <phrase>Legacy software</phrase>, however, is crucial for operations and needs to be continually available and upgraded. How can you reduce the complexity of a <phrase>legacy</phrase> system sufficiently so that it can continue to be used and adapted at acceptable <phrase>cost? Based</phrase> on the authors' <phrase>industrial</phrase> experiences, this <phrase>book</phrase> is a guide on how to <phrase>reverse engineer</phrase> <phrase>legacy systems</phrase> to understand their problems, and then reengineer those systems to meet new demands. Patterns are used to clarify and explain the process of <phrase>understanding</phrase> <phrase>large code bases</phrase>, <phrase>hence</phrase> <phrase>transforming</phrase> them to meet new requirements. The <phrase>key insight</phrase> is that the right <phrase>design</phrase> and <phrase>organization</phrase> of your system is not something that can be evident from the <phrase>initial requirements</phrase> alone, but rather as a consequence of <phrase>understanding</phrase> how these requirements evolve.
<phrase>Objektorientierte Datenbanksysteme</phrase>. <phrase>Ein</phrase> Praktikum.
<phrase>Digitale</phrase> <phrase>Bibliotheken</phrase> - <phrase>Informatik</phrase>-<phrase>Lösungen</phrase> für globale Wissensmärkte
Objektrelationale und <phrase>objektorientierte</phrase> Datenbankkonzepts und -<phrase>systeme</phrase>
<phrase>Mobile</phrase> <phrase>Datenbanken und Informationssysteme</phrase>: <phrase>Konzepte und</phrase> <phrase>Techniken</phrase>
<phrase>Web Engineering</phrase>: Systematische <phrase>Entwicklung</phrase> <phrase>von Web-Anwendungen</phrase>
<phrase>Linux</phrase> <phrase>Sicherheit</phrase>: <phrase>Security</phrase> <phrase>mit</phrase> <phrase>Open-Source-Software</phrase>, <phrase>Grundlagen und</phrase> <phrase>Praxis</phrase>
Informationsintegration: <phrase>Architekturen</phrase> <phrase>und Methoden zur</phrase> <phrase>Integration</phrase> verteilter und heterogener Datenquellen.
Systemsoftware: <phrase>Grundlagen</phrase> moderner Betriebssysteme
<phrase>Web</phrase> & <phrase>Datenbanken</phrase>. <phrase>Konzepte</phrase>, <phrase>Architekturen</phrase>, <phrase>Anwendungen</phrase>
<phrase>Datenbanken</phrase> & <phrase>Java</phrase> - <phrase>JDBC</phrase>, SQLJ und <phrase>ODMG</phrase>
<phrase>HTML</phrase> & <phrase>XHTML</phrase> - <phrase>die</phrase> <phrase>Sprachen</phrase> <phrase>des</phrase> <phrase>Web</phrase>, Lehrgang und Referenz, 5. Auflage
<phrase>SQL</phrase>:1999 & <phrase>SQL</phrase>:2003 - Objektrelationales <phrase>SQL</phrase>, SQLJ & <phrase>SQL</phrase>/<phrase>XML</phrase>
<phrase>Wissensbasierte</phrase> Textverarbeitung: Schriftsatz und Typographie - <phrase>Möglichkeiten</phrase> einer intelligenteren Textverarbeitung
Anfrageverarbeitung in Komplexobjekt-<phrase>Datenbanksystemen</phrase>
A <phrase>Formal Model</phrase> for <phrase>Lazy</phrase> Implementations of a <phrase>Prolog</phrase>-Compatible <phrase>Functional Language</phrase>.
<phrase>Garbage Collection</phrase> in <phrase>Prolog</phrase> Interpreters.
<phrase>Deduction</phrase> <phrase>Revision</phrase> by <phrase>Intelligent Backtracking</phrase>.
Should <phrase>Prolog</phrase> be List or <phrase>Record Oriented</phrase>.
<phrase>Finding</phrase> <phrase>Backtrack</phrase> Points for <phrase>Intelligent Backtracking</phrase>.
POLER - Implementation of a <phrase>POP</phrase>-2-<phrase>based PLANNER</phrase>.
A <phrase>Note</phrase> on <phrase>Micro</phrase>-Planer.
An <phrase>Interpreting</phrase> <phrase>Algorithm</phrase> for <phrase>Prolog</phrase> Programs.
What the naive user wants from <phrase>Prolog</phrase>.
A <phrase>Prolog</phrase> Interpreter Working with <phrase>Infinite</phrase> Terms.
<phrase>Exeter</phrase> <phrase>Prolog</phrase> - some thoughts on <phrase>Prolog</phrase> <phrase>design</phrase> by a <phrase>LISP</phrase> user.
The Control of Searching and <phrase>Backtracking</phrase> in <phrase>String Pattern Matching</phrase>.
<phrase>Efficient</phrase> Implementation of <phrase>Unification</phrase> of <phrase>Cyclic</phrase> Structures.
How to Implement <phrase>Prolog</phrase> on a <phrase>LISP Machine</phrase>.
The '<phrase>Marseille</phrase> Interpreter' - <phrase>a Personal Perspective</phrase>.
<phrase>Prolog</phrase> - a <phrase>Panacea</phrase>?
<phrase>Integrating</phrase> <phrase>Prolog</phrase> in the POPLOG Environment.
Although <phrase>Prolog</phrase> undoubtedly has its good points, there are some tasks (such as writing a <phrase>screen editor</phrase> or <phrase>network interface controller</phrase>) for which it is not the <phrase>language</phrase> of choice. The most natural computational concepts [2] for these tasks are hard to reconcile with Prolog's <phrase>declarative</phrase> <phrase>nature</phrase>. Just as there is a need for even the most committed <phrase>Prolog</phrase> <phrase>programmer</phrase> to use "conventional" languages for some tasks, so too is there a need for "<phrase>logic</phrase>" oriented components in conventional applications programs, such as <phrase>CAD</phrase> systems [7] and <phrase>relational databases</phrase> [5]. At <phrase>Sussex</phrase>, the problems of <phrase>integrating</phrase> <phrase>logic</phrase> with <phrase>procedural programming</phrase> are being addressed by two projects. One of these [4] involves a distributed <phrase>ring</phrase> of processors communicating by <phrase>message passing</phrase>. The other <phrase>project</phrase> is the POPLOG system, a <phrase>mixed language</phrase> <phrase>AI</phrase> <phrase>programming</phrase> environment which <phrase>runs</phrase> on conventional hardware. This <phrase>paper</phrase> describes the way in which we have integrated <phrase>Prolog</phrase> into POPLOG.
A Proposal for <phrase>Distributed Programming</phrase> in <phrase>Logic</phrase>.
<phrase>Associative</phrase> Evaluation of <phrase>Prolog</phrase> Programs.
The <phrase>World's</phrase> <phrase>Shortest</phrase> <phrase>Prolog</phrase> Interpreter?
Formal <phrase>Vienna</phrase>-Definition-Method Models of <phrase>Prolog</phrase>.
<phrase>Logic</phrase> Control with <phrase>Logic</phrase>.
Epilog: A <phrase>Language</phrase> for Extended <phrase>Programming</phrase> in <phrase>Logic</phrase>.
<phrase>W</phrase>-<phrase>Grammars</phrase> for <phrase>Logic Programming</phrase>.
The <phrase>Taming</phrase> of the Sleuth.
EPILOG: <phrase>Re</phrase>-<phrase>interpreting</phrase> and <phrase>Extending</phrase> <phrase>Prolog</phrase> for a <phrase>Multiprocessor</phrase> Environment.
System <phrase>Simulation</phrase> and <phrase>Cooperative</phrase> <phrase>Problem-solving</phrase> on a <phrase>Prolog</phrase> Basis.
On <phrase>Prolog</phrase> <phrase>DBMS</phrase> Connections: A <phrase>Step Forward</phrase> from Educe.
<phrase>Grid</phrase> Files for <phrase>Efficient</phrase> <phrase>Prolog</phrase> <phrase>Clause</phrase> Access.
A <phrase>Source-to-Source</phrase> <phrase>Meta</phrase>-<phrase>Translation</phrase> System for <phrase>Database Query Languages</phrase> - Implementation in <phrase>Prolog</phrase>.
A Flexible <phrase>Prolog</phrase>-Based <phrase>Lexical</phrase> <phrase>Database</phrase> System.
A <phrase>Generalized</phrase> Interface Between <phrase>Prolog</phrase> and <phrase>Relational Databases</phrase>.
A <phrase>Prolog</phrase>-<phrase>Relational Database</phrase> Interface.
TREQL (Thornton <phrase>Research</phrase> Easy <phrase>Query Language</phrase>): <phrase>An Intelligent</phrase> <phrase>Front-End</phrase> to a <phrase>Relational Database</phrase>.
<phrase>Modular</phrase> Commitment in <phrase>Persistent</phrase> <phrase>Prolog</phrase>.
<phrase>Implementing</phrase> <phrase>Query Languages</phrase> in <phrase>Prolog</phrase>.
On <phrase>Transaction Processing</phrase>, <phrase>Knowledge-Based Systems</phrase> and <phrase>Databases</phrase>.
<phrase>An Object-Oriented Database</phrase> for Storage and Analysis of <phrase>Protein Structure</phrase> <phrase>Data</phrase>.
The <phrase>NU</phrase>-<phrase>Prolog</phrase> <phrase>Deductive</phrase> <phrase>Database</phrase> System.
<phrase>Software Configuration Management</phrase> Using <phrase>Prolog</phrase>.
<phrase>Guarded</phrase> Default <phrase>Databases</phrase>: A <phrase>Prototype</phrase> Implementation.
An Interface from <phrase>Prolog</phrase> to a <phrase>Binary</phrase> <phrase>Relational Database</phrase>.
A <phrase>Data</phrase>-Driven <phrase>Execution Mechanism</phrase> for <phrase>Transaction-Oriented</phrase> <phrase>Information</phrase> Systems.
The Interaction Between <phrase>BIM</phrase>-<phrase>Prolog</phrase> and <phrase>Relational Databases</phrase>.
<phrase>Recursive Query Processing</phrase>: Fundamental <phrase>Algorithms</phrase> and the DedGin System.
The TRACE <phrase>Club</phrase> <phrase>Expert System</phrase> and <phrase>Databases</phrase>.
<phrase>Benchmarking</phrase> <phrase>Prolog</phrase> for <phrase>Database</phrase> Applications.
<phrase>Abstract Interpretation</phrase> of <phrase>Declarative</phrase> Languages
Statistical and <phrase>Scientific Databases</phrase>
<phrase>Machine Learning</phrase>, Neural and <phrase>Statistical Classification</phrase>
<phrase>Pascal</phrase> Implementation: The <phrase>P4</phrase> <phrase>Compiler</phrase> and Interpreter
<phrase>Classical</phrase> <phrase>Type Theory</phrase>.
<phrase>Unification</phrase> Theory.
<phrase>Normal Form</phrase> Transformations.
<phrase>Automated Deduction</phrase> for <phrase>Many-Valued Logics</phrase>.
<phrase>Resolution Theorem Proving</phrase>.
<phrase>Proof-Assistants</phrase> Using <phrase>Dependent Type Systems</phrase>.
Solving <phrase>Numerical Constraints</phrase>.
The <phrase>Automation</phrase> of Proof by <phrase>Mathematical Induction</phrase>.
Reasoning in <phrase>Expressive Description Logics</phrase>.
<phrase>Automated Reasoning</phrase> in <phrase>Geometry</phrase>.
<phrase>Model Checking</phrase>.
Inductionless <phrase>Induction</phrase>.
The <phrase>Early History</phrase> of <phrase>Automated Deduction</phrase>.
The <phrase>Inverse</phrase> Method.
<phrase>Equality</phrase> Reasoning in <phrase>Sequent</phrase>-Based <phrase>Calculi</phrase>.
<phrase>Rewriting</phrase>.
<phrase>Nonmonotonic Reasoning</phrase>: Towards <phrase>Efficient</phrase> <phrase>Calculi</phrase> and Implementations.
<phrase>Higher-Order Unification</phrase> and Matching.
Resolution <phrase>Decision Procedures</phrase>.
<phrase>Tableaux</phrase> and Related Methods.
<phrase>Model Elimination</phrase> and <phrase>Connection Tableau</phrase> Procedures.
<phrase>Paramodulation</phrase>-<phrase>Based Theorem Proving</phrase>.
<phrase>Computing</phrase> Small <phrase>Clause</phrase> <phrase>Normal Forms</phrase>.
Encoding Two-Valued <phrase>Nonclassical</phrase> Logics in <phrase>Classical Logic</phrase>.
<phrase>Logical</phrase> Frameworks.
<phrase>Term Indexing</phrase>.
<phrase>Preface</phrase>.
Connections in <phrase>Nonclassical</phrase> Logics.
<phrase>Combining</phrase> <phrase>Superposition</phrase>, Sorts and <phrase>Splitting</phrase>.
<phrase>Computer-Aided</phrase> <phrase>Database Design</phrase>: the DATAID approach.
A <phrase>Software Engineering</phrase> Approach to <phrase>Database Design</phrase>: The <phrase>Galileo</phrase> <phrase>Project</phrase>.
A Tool for Modeling Dynamics in <phrase>Conceptual Design</phrase>.
GINCOD: A <phrase>Graphical</phrase> Tool for <phrase>Conceptual Design</phrase> of <phrase>Data</phrase> Base Applications.
The <phrase>Logical</phrase> <phrase>Design</phrase> in the DATAID <phrase>Project</phrase>: The EASYMAP System.
A <phrase>Workbench</phrase> for <phrase>Conceptual Design</phrase> in <phrase>Galileo</phrase>.
DATAID-<phrase>D</phrase>: Methodology for <phrase>Distributed Database</phrase> <phrase>Design</phrase>.
Dynamics in <phrase>Logical</phrase> <phrase>Database Design</phrase>.
<phrase>Architecture</phrase> of a <phrase>Physical Design</phrase> Tool for <phrase>Relational DBMSs</phrase>.
<phrase>Important Issues</phrase> in <phrase>Database Design</phrase> Methodologies and Tools.
Integrated Tools for <phrase>Physical Database Design</phrase> in <phrase>CODASYL</phrase> Environment.
Concepts, Implementation, and Applications of a <phrase>Typed</phrase> <phrase>Logic Programming</phrase> <phrase>Language</phrase>.
<phrase>Combinatorial</phrase> <phrase>Problem Solving</phrase> in <phrase>Constraint Logic Programming</phrase> with <phrase>Cooperating</phrase> Solvers.
The <phrase>WAM</phrase> - Definition and <phrase>Compiler</phrase> Correctness.
Using <phrase>Constraint Logic Programming</phrase> for <phrase>Industrial</phrase> <phrase>Scheduling Problems</phrase>.
<phrase>Temporal Logic</phrase> <phrase>Programming</phrase> Applied to <phrase>Image Sequence</phrase> Evaluation.
<phrase>Goal-Directed</phrase> <phrase>Forward Chaining</phrase>: <phrase>Tuple</phrase>-oriented <phrase>Bottom-up</phrase> Approach.
<phrase>Logic Program</phrase> Modules for <phrase>Interoperable Information Systems</phrase>.
<phrase>Robot Control</phrase> Systems as <phrase>Contextual</phrase> <phrase>Logic</phrase> Programs.
<phrase>Logic Programming</phrase> - Past or Future?
<phrase>Polymorphic</phrase> <phrase>Feature Types</phrase>.
<phrase>Automatic</phrase> Verification of <phrase>Parallel</phrase> <phrase>Logic</phrase> Programs: <phrase>Termination</phrase>.
Scheduling and <phrase>Meta</phrase>-Scheduling.
<phrase>Efficient</phrase> <phrase>Object-Oriented Programming</phrase> in <phrase>Prolog</phrase>.
A <phrase>Generic</phrase> <phrase>Scheduling Framework</phrase> developed in <phrase>Prolog</phrase>.
Dialogo: <phrase>An Interactive</phrase> Environment for <phrase>Conceptual Design</phrase> in <phrase>Galileo</phrase>.
Requirements Collection and Analysis.
INCOD-<phrase>DTE</phrase>: A System for Interative <phrase>Conceptual Design</phrase> of <phrase>Data</phrase>, Transactions and Events.
Views <phrase>Integration</phrase>.
<phrase>Logical</phrase> <phrase>Design</phrase> in <phrase>Codasyl</phrase> and <phrase>Relational</phrase> Environment.
A <phrase>Separability</phrase>-<phrase>Based Method</phrase> for <phrase>Secondary</phrase> <phrase>Index</phrase> Selection in <phrase>Physical Database Design</phrase>.
A Set of Integrated Tools for the <phrase>Conceptual Design</phrase> of <phrase>Database</phrase> Schemas and Transactions.
Views <phrase>Conceptual Design</phrase>.
Methodology and Tools for <phrase>Data</phrase> Base <phrase>Design</phrase> in the DATAID <phrase>Project</phrase>.
NLDA: A <phrase>Natural Language</phrase> Reasoning System for the Analysis of <phrase>Data</phrase> Base Requirements.
<phrase>Physical Data Base</phrase> <phrase>Design</phrase> for <phrase>Codasyl DBMS</phrase>.
<phrase>Algorithms</phrase> for <phrase>Finding</phrase> Patterns in <phrase>Strings</phrase>.
<phrase>Logic Programming</phrase>.
<phrase>Functional Programming</phrase> and <phrase>Lambda Calculus</phrase>.
<phrase>Context-Free</phrase> Languages.
<phrase>Machine Models</phrase> and <phrase>Simulation</phrase>.
The Complexity of <phrase>Finite Functions</phrase>.
<phrase>Graph Rewriting</phrase>: <phrase>An Algebraic</phrase> and <phrase>Logic</phrase> Approach.
<phrase>Recursive</phrase> <phrase>Applicative</phrase> <phrase>Program Schemes</phrase>.
Methods and Logics for <phrase>Proving Programs</phrase>.
<phrase>Rewrite Systems</phrase>.
Temporal and <phrase>Modal Logic</phrase>.
<phrase>Semantic</phrase> Domains.
A <phrase>Catalog</phrase> of <phrase>Complexity Classes</phrase>.
Elements of <phrase>Relational Database</phrase> Theory.
The goal of this <phrase>paper</phrase> is to provide a <phrase>systematic</phrase> and <phrase>unifying</phrase> <phrase>introduction</phrase> to <phrase>relational database</phrase> theory, including some of the <phrase>recent developments</phrase> in <phrase>database</phrase> <phrase>logic programming</phrase>. The first part of the presentation covers the two <phrase>basic</phrase> components of the <phrase>relational</phrase> <phrase>data model</phrase>: its specification component, that is the <phrase>database</phrase> scheme with dependencies, and its operational component, that is the <phrase>relational algebra</phrase> <phrase>query language</phrase>. The choice of <phrase>basic</phrase> constructs for specifying the <phrase>semantically meaningful</phrase> <phrase>databases</phrase> and for <phrase>querying</phrase> them is justified through an in-depth investigation of their properties. Some important <phrase>research</phrase> themes are reviewed in this context: the analysis of the <phrase>hypergraph</phrase> <phrase>syntax</phrase> of a <phrase>database</phrase> scheme and the extensions of the <phrase>query language</phrase> using <phrase>deduction</phrase> or <phrase>universal</phrase> relation assumptions. The subsequent parts of the presentation are structured around the two <phrase>fundamental concepts</phrase> illustrated in the first part, dependencies and queries. The <phrase>main themes</phrase> of <phrase>dependency theory</phrase> are <phrase>implication problems</phrase> and applications to <phrase>database</phrase> scheme <phrase>design</phrase>. Queries are classified in a <phrase>variety</phrase> of ways, with <phrase>emphasis</phrase> on the connections between the <phrase>expressibility</phrase> of <phrase>query languages</phrase>, <phrase>finite model theory</phrase> and <phrase>logic programming</phrase>. The theory of queries is very much related to <phrase>research</phrase> on <phrase>database</phrase> <phrase>logic</phrase> programs, which are an elegant formalism for the study of the principles of <phrase>knowledge base</phrase> systems. The optimization of such programs involves both techniques developed for the <phrase>relational</phrase> <phrase>data model</phrase> and new methods for <phrase>analyzing</phrase> <phrase>recursive</phrase> definitions. The <phrase>exposition</phrase> closes with a discussion of how <phrase>relational database</phrase> theory deals with the problems of <phrase>complex objects</phrase>, <phrase>incomplete information</phrase> and <phrase>database</phrase> updates.
<phrase>Parallel Algorithms</phrase> for <phrase>Shared-Memory</phrase> Machines.
Logics of Programs.
None Available
<phrase>Distributed Computing</phrase>: Models and Methods.
<phrase>Graph</phrase> <phrase>Algorithms</phrase>.
<phrase>VLSI</phrase> Theory.
<phrase>Algorithms</phrase> in <phrase>Number Theory</phrase>.
<phrase>Kolmogorov Complexity</phrase> and its Applications.
<phrase>Data Structures</phrase>.
Operational and <phrase>Algebraic</phrase> <phrase>Semantics</phrase> of <phrase>Concurrent</phrase> Processes.
<phrase>Type Systems</phrase> for <phrase>Programming Languages</phrase>.
<phrase>Denotational Semantics</phrase>.
<phrase>Finite Automata</phrase>.
<phrase>Communication</phrase> Networks.
<phrase>Cryptography</phrase>.
<phrase>Formal Language</phrase> and <phrase>Power Series</phrase>.
<phrase>Algorithmic</phrase> <phrase>Motion Planning</phrase> in <phrase>Robotics</phrase>.
<phrase>Machine-Independent</phrase> <phrase>Complexity Theory</phrase>.
<phrase>Algebraic</phrase> <phrase>Complexity Theory</phrase>.
<phrase>Automata</phrase> on <phrase>Infinite</phrase> Objects.
<phrase>General</phrase> Purpose <phrase>Parallel</phrase> Architectures.
<phrase>Average-Case</phrase> Analysis of <phrase>Algorithms</phrase> and <phrase>Data Structures</phrase>.
<phrase>Algebraic</phrase> Specification.
<phrase>Computational Geometry</phrase>.
<phrase>Suffix</phrase>, <phrase>prefix</phrase> and <phrase>maximal</phrase> <phrase>tree</phrase> codes.
<phrase>Fixed point</phrase> characterization of <phrase>weak monadic</phrase> <phrase>logic</phrase> <phrase>definable</phrase> sets of <phrase>trees</phrase>.
<phrase>Recognizing</phrase> sets of <phrase>labelled</phrase> <phrase>acyclic</phrase> <phrase>graphs</phrase>.
<phrase>Recognizable</phrase> sets of <phrase>unrooted trees</phrase>.
<phrase>Structural</phrase> complexity of classes of <phrase>tree</phrase> languages.
<phrase>Decidability</phrase> of the inclusion in <phrase>monoids</phrase> generated by <phrase>tree</phrase> transformation classes.
<phrase>Unification</phrase> procedures in <phrase>automated deduction</phrase> methods based on matings: <phrase>A survey</phrase>.
<phrase>Algebraic</phrase> specification of <phrase>action</phrase> <phrase>trees</phrase> and <phrase>recursive</phrase> processes.
<phrase>Trees</phrase> and <phrase>algebraic</phrase> <phrase>semantics</phrase>.
<phrase>Tree-adjoining grammars</phrase> and <phrase>lexicalized grammars</phrase>.
<phrase>Computing</phrase> <phrase>trees</phrase> with <phrase>graph rewriting</phrase> systems with priorities.
<phrase>Binary tree</phrase> codes.
A <phrase>monoid</phrase> approach to <phrase>tree</phrase> <phrase>automata</phrase>.
<phrase>A survey</phrase> of <phrase>tree transductions</phrase>.
<phrase>Rational</phrase> and <phrase>recognizable</phrase> <phrase>infinite</phrase> <phrase>tree</phrase> sets.
<phrase>Automata on infinite trees</phrase> and <phrase>rational</phrase> control.
Interpretability and <phrase>tree</phrase> <phrase>automata</phrase>: A simple way to solve <phrase>algorithmic</phrase> problems on <phrase>graphs</phrase> <phrase>closely related</phrase> to <phrase>trees</phrase>.
Ambiguity and valuedness.
A <phrase>short</phrase> proof of the factorization <phrase>forest</phrase> theorem.
A theory of <phrase>tree</phrase> <phrase>language varieties</phrase>.
<phrase>Computer-Aided</phrase> <phrase>Database Design</phrase>: the DATAID approach.
<phrase>Computability</phrase>, Complexity, <phrase>Logic</phrase> (<phrase>English</phrase> <phrase>translation</phrase> of "Berechenbarkeit, <phrase>Komplexität</phrase>, <phrase>Logik</phrase>" from 1985)
Methodology and Tools for <phrase>Data</phrase> Base <phrase>Design</phrase>.
<phrase>Data</phrase> and <phrase>Reality</phrase>, <phrase>1st edition</phrase>.
<phrase>Handbook</phrase> of <phrase>Theoretical Computer Science</phrase>, Volume A: <phrase>Algorithms</phrase> and Complexity
<phrase>Handbook</phrase> of <phrase>Theoretical Computer Science</phrase>, Volume <phrase>B</phrase>: <phrase>Formal Models</phrase> and <phrase>Semantics</phrase>
<phrase>Tree</phrase> <phrase>Automata</phrase> and Languages.
<phrase>Handbook</phrase> of <phrase>Automated Reasoning</phrase> (in 2 <phrase>volumes</phrase>)
Classification, Estimation and <phrase>Pattern Recognition</phrase>.
<phrase>Méthodes</phrase> de <phrase>Programmation</phrase>, <phrase>1st edition</phrase>
<phrase>Méthodes</phrase> de <phrase>Programmation</phrase>, <phrase>3rd edition</phrase>
LogOut - Warum Computer nichts <phrase>im</phrase> Klassenzimmer zu suchen haben <phrase>und andere</phrase> <phrase>High-Tech</phrase>-Ketzereien
<phrase>Fractal Geometry</phrase> of <phrase>Nature</phrase>.
<phrase>Fractals</phrase>, <phrase>Chaos</phrase>, <phrase>Power Laws</phrase>: Minutes From an <phrase>Infinite</phrase> <phrase>Paradise</phrase>.
<phrase>Computers</phrase> and <phrase>Intractability</phrase>: A Guide to the Theory of <phrase>NP-Completeness</phrase>.
<phrase>Spatial</phrase> Analysis and <phrase>GIS</phrase>.
<phrase>Deterministic</phrase> <phrase>Translation</phrase> <phrase>Grammars</phrase>
The Analysis of a Practical and <phrase>Nearly Optimal</phrase> Priorty Queue
<phrase>Queueing Network Models</phrase> of <phrase>Multiprogramming</phrase>
A Practical Formal <phrase>Semantic</phrase> Definition and Verification System for <phrase>TYPED</phrase> <phrase>LISP</phrase>
<phrase>Linear Lists</phrase> and Prorty Queues as <phrase>Balanced Binary Trees</phrase>
Computer Display of <phrase>Curved</phrase> Surfaces
The Application of <phrase>Theorem Proving</phrase> to <phrase>Question-Answering</phrase> Systems
<phrase>Decidability</phrase> Questions for <phrase>Petri Nets</phrase>
An <phrase>understanding</phrase> of the <phrase>mathematical</phrase> properties of <phrase>Petri Nets</phrase> is essential when one wishes to use <phrase>Petri Nets</phrase> as an <phrase>abstract</phrase> <phrase>model</phrase> for <phrase>concurrent</phrase> systems. The <phrase>decidability</phrase> of various problems which arise in this context is an important <phrase>aspect</phrase> of this question. The fact that these problems also arise in the context of other <phrase>mathematical</phrase> theories, such as <phrase>commutative semigroups</phrase>, closure under <phrase>linear relations</phrase>, Matrix <phrase>Context-Free grammars</phrase>, or <phrase>Weak</phrase> <phrase>Counter Automata</phrase>, provides further <phrase>motivation</phrase>. The <phrase>Reachability</phrase> Problem for <phrase>Vector</phrase> Addition Systems - whose <phrase>decidability</phrase> is still an <phrase>open</phrase> question - is of central importance. We show that a number of <phrase>Petri Net</phrase> problems are recursively equivalent to this problem. These include the <phrase>Liveness</phrase> Problem (e.g. can a system reach a deadlocked <phrase>state</phrase>?), the <phrase>persistence</phrase> problem (can a given transition ever be disabled by the firing of another transition?), and the membership and emptiness problems for certain classes of languages generated by <phrase>Petri Nets</phrase>. The power of the unrestricted <phrase>Petri Net</phrase> <phrase>model</phrase> is illustrated by various <phrase>undecidable</phrase> <phrase>equivalence</phrase> <phrase>results</phrase>. In particular, we show that the <phrase>equality</phrase> of <phrase>Reachability</phrase> Sets and the <phrase>equivalence</phrase> of two <phrase>Petri Nets</phrase> in terms of their <phrase>language</phrase>-<phrase>generating</phrase> capability are <phrase>recursive</phrase> <phrase>undecidable</phrase>. It is hoped that the constructions used to prove our <phrase>results</phrase> will shed some <phrase>light</phrase> on the source of the complexities of the unrestricted <phrase>Petri Net</phrase> <phrase>model</phrase>, and may eventually <phrase>permit</phrase> us to achieve an <phrase>optimal</phrase> balance between representational transparency and analytical power of the <phrase>Petri Net</phrase> <phrase>model</phrase>.
<phrase>Control-Theoretic</phrase> Formulation of <phrase>Operating Systems</phrase> <phrase>Resource Management</phrase> Policies
The Metanovel: Writing <phrase>Stories</phrase> by Computer
A <phrase>Processor Design</phrase> for the <phrase>Efficient</phrase> Implementation of <phrase>APL</phrase>
The <phrase>Design</phrase> and <phrase>Construction</phrase> of Flexible and <phrase>Efficient</phrase> <phrase>Interactive Programming</phrase> Systems
Reasoning from <phrase>Incomplete Knowledge</phrase> in a <phrase>Procedural</phrase> <phrase>Deduction</phrase> System
<phrase>Axiomatic Proof</phrase> Techniques for <phrase>Parallel</phrase> Programs
This <phrase>thesis</phrase> presents <phrase>an axiomatic</phrase> method for proving certain <phrase>correctness properties</phrase> of <phrase>parallel</phrase> programs. <phrase>Axioms</phrase> and <phrase>inference rules</phrase> for <phrase>partial</phrase> correctness are given for two <phrase>parallel programming</phrase> languages: The <phrase>General</phrase> <phrase>Parallel</phrase> <phrase>Language</phrase> and the <phrase>Restricted</phrase> <phrase>Parallel</phrase> <phrase>Language</phrase>. The <phrase>General</phrase> <phrase>Language</phrase> is flexible enough to represent most standard <phrase>synchronizers</phrase> (e.g. <phrase>semaphores</phrase>, events), so that programs using these <phrase>synchronizers</phrase> may be verified using the <phrase>GPL</phrase> <phrase>deductive</phrase> system. However, proofs for <phrase>GPL</phrase> programs are in <phrase>general</phrase> quite complex. The <phrase>Restricted</phrase> <phrase>Language</phrase> reduces this complexity by requiring <phrase>shared variables</phrase> to be <phrase>protected</phrase> by <phrase>critical sections</phrase>, so that only one process at a time has access to them. This discipline does not <phrase>significantly reduce</phrase> the power of the <phrase>language</phrase>, and it <phrase>greatly simplifies</phrase> the process of <phrase>program verification</phrase>. Although the <phrase>axioms</phrase> and <phrase>inference rules</phrase> are <phrase>primarily intended</phrase> for proofs of <phrase>partial</phrase> correctness, there are a number of other <phrase>important properties</phrase> of <phrase>parallel</phrase> programs. We give some practical techniques which use <phrase>information</phrase> obtained from a <phrase>partial correctness</phrase> proof to derive other <phrase>correctness properties</phrase>, including <phrase>program termination</phrase>, <phrase>mutual exclusion</phrase>, and <phrase>freedom from deadlock</phrase>. A number of examples of such proofs are given. <phrase>Finally</phrase>, the <phrase>axioms</phrase> and <phrase>inference rules</phrase> are shown to be consistent and complete (in a special sense) with respect to an <phrase>interpretive</phrase> <phrase>model</phrase> of <phrase>parallel</phrase> execution. Thus the <phrase>deductive</phrase> system gives an accurate description of <phrase>program execution</phrase> and is powerful enough to yield a proof of any true <phrase>partial</phrase> correctness formula.
Shellsort and <phrase>Sorting</phrase> Networks
<phrase>Machine Perception</phrase> of <phrase>Three-Dimensional</phrase> <phrase>Solids</phrase>
<phrase>Source Language</phrase> <phrase>Debugging</phrase> Tools
<phrase>Quicksort</phrase>
<phrase>Queueing Models</phrase> for <phrase>Computer Systems</phrase> with <phrase>General Service Time Distributions</phrase>
A <phrase>Data</phrase> <phrase>Definition Facility</phrase> for <phrase>Programming Languages</phrase>
<phrase>Sketchpad</phrase>, A <phrase>Man</phrase>-Machine <phrase>Graphical</phrase> <phrase>Communication</phrase> System
The <phrase>Sketchpad</phrase> system makes it possible for a <phrase>man</phrase> and a computer to <phrase>converse</phrase> rapidly through the medium of <phrase>line drawings</phrase>. Heretofore, most interaction between <phrase>man</phrase> and <phrase>computers</phrase> has been <phrase>slowed down</phrase> by the need to reduce all <phrase>communication</phrase> to written statements that can be <phrase>typed</phrase>; in the past, we have been writing <phrase>letters</phrase> to rather than conferring with our <phrase>computers</phrase>. For many types of <phrase>communication</phrase>, such as describing the shape of a mechanical part or the connections of an <phrase>electrical circuit</phrase>, <phrase>typed</phrase> statements can prove cumbersome. The <phrase>Sketchpad</phrase> system, by <phrase>eliminating</phrase> <phrase>typed</phrase> statements (except for <phrase>legends</phrase>) in favor of <phrase>line drawings</phrase>, <phrase>opens up</phrase> a new <phrase>area</phrase> of <phrase>man-machine communication</phrase>.
<phrase>Automatic</phrase> Verification of Programs with <phrase>Complex Data Structures</phrase>
Studies in <phrase>Extensible</phrase> <phrase>Programming Languages</phrase>
<phrase>Automatic</phrase> Generation of Assemblers
<phrase>Understanding</phrase> <phrase>Goal-Based</phrase> <phrase>Stories</phrase>
Predicate-<phrase>Oriented Database</phrase> <phrase>Search Algorithms</phrase>
<phrase>Semantics</phrase> For a <phrase>Question-Answering</phrase> System
The <phrase>Hensel</phrase> <phrase>Lemma</phrase> in <phrase>Algebraic</phrase> Manipulation
<phrase>Cluster Analysis</phrase>.
<phrase>Objektorientierte</phrase> <phrase>Softwareentwicklung</phrase>
Erfolgsschlüssel Objekttechnologie -- Managerführer zur Neuorganisation <phrase>des</phrase> Softwareprozesses
<phrase>Logic</phrase> for <phrase>Computer Science</phrase>: Foundations of <phrase>Automatic Theorem Proving</phrase>
<phrase>An Introduction</phrase> to <phrase>Compiler</phrase> Contruction
<phrase>Artificial Intelligence</phrase> Architectures for Composition and Performance Environment.
<phrase>Dynamic Programming</phrase> for <phrase>Interactive Music</phrase> Systems.
The <phrase>Mechanization</phrase> of <phrase>Intelligence</phrase> and the <phrase>Human</phrase> Aspects of <phrase>Music</phrase>.
<phrase>Artificial Intelligence</phrase> in <phrase>Music Education</phrase>: <phrase>A Critical Review</phrase>.
<phrase>Music</phrase>, <phrase>Intelligence</phrase> and Artificiality.
Regarding <phrase>Music</phrase>, Machines, <phrase>Intelligence</phrase> and the <phrase>Brain</phrase>: <phrase>An Introduction</phrase> to <phrase>Music</phrase> and <phrase>AI</phrase>.
Computer Analysis of <phrase>Jazz</phrase> <phrase>Chord</phrase> <phrase>Sequence</phrase>: Is <phrase>Solar</phrase> a <phrase>Blues</phrase>?
<phrase>Musical</phrase> <phrase>Pattern Extraction</phrase> and <phrase>Similarity Assessment</phrase>.
<phrase>Interactive Music</phrase> Systems in <phrase>Ensemble</phrase> Performance.
<phrase>Symbolic</phrase> <phrase>AI</phrase> versus <phrase>Connectionism</phrase> in <phrase>Music</phrase> <phrase>Research</phrase>.
On the Potential of <phrase>Machine Learning</phrase> for <phrase>Music</phrase> <phrase>Research</phrase>.
<phrase>Musical</phrase> <phrase>Knowledge</phrase>: What can <phrase>Artificial Intelligence</phrase> Bring to the <phrase>Musician</phrase>?
<phrase>Artificial Intelligence</phrase> and <phrase>Music Education</phrase>.
Readings in <phrase>Music</phrase> and <phrase>Artificial Intelligence</phrase>
<phrase>Information Extraction</phrase> from <phrase>Free</phrase>-Text <phrase>Business</phrase> Documents.
The objective of this <phrase>chapter</phrase> is an investigation of the applicability of <phrase>information extraction</phrase> techniques in <phrase>real-world</phrase> <phrase>business</phrase> applications dealing with <phrase>textual data</phrase> since <phrase>business</phrase> <phrase>relevant data</phrase> is mainly transmitted through <phrase>free-text</phrase> documents. In particular, we give <phrase>an overview</phrase> of the <phrase>information extraction</phrase> task, <phrase>designing</phrase> <phrase>information extraction</phrase> systems and some examples of existing <phrase>information extraction</phrase> systems applied in the financial, <phrase>insurance</phrase> and <phrase>legal</phrase> domains. Furthermore, we demonstrate the enormous <phrase>indexing</phrase> potential of <phrase>lightweight</phrase> <phrase>linguistic</phrase> <phrase>text processing</phrase> techniques applied in <phrase>information extraction</phrase> systems and other <phrase>closely related</phrase> fields of <phrase>information technology</phrase> which concern processing <phrase>vast</phrase> amounts of <phrase>textual data</phrase>.
<phrase>Active</phrase> Rules and <phrase>Active Databases</phrase>: Concepts and Application.
This <phrase>chapter</phrase> surveys the topic of <phrase>active</phrase> rules and <phrase>active databases</phrase>. We analyze the <phrase>state</phrase> of the <phrase>art</phrase> of <phrase>active databases</phrase> and <phrase>active</phrase> rules, their properties and applications. In particular, we describe the case of triggers following the <phrase>SQL</phrase>-1999 Standard <phrase>Committee</phrase> <phrase>point of view</phrase>. Then, we consider the case of <phrase>dynamic</phrase> constraints for which we use a <phrase>temporal logic</phrase> formalism. <phrase>Finally</phrase>, we discuss the applicability, limitations and <phrase>partial</phrase> solutions found when attempting to ensure the satisfaction of <phrase>dynamic</phrase> constraints.
<phrase>Applying</phrase> <phrase>JAVA</phrase>-Triggers for <phrase>X</phrase>-<phrase>Link Management</phrase> in the <phrase>Industrial</phrase> Framework.
This <phrase>chapter</phrase> focuses on <phrase>referential</phrase> link integrity problems. In the <phrase>industrial</phrase> context, the <phrase>life</phrase> cycle of a document plays a central role in describing the "steps out" of a product. Users realize some manipulations like creation, <phrase>edition</phrase>, suppression and <phrase>querying</phrase> under a <phrase>multi-user</phrase> environment, risking possible destruction or the alteration of the document's integrity. A <phrase>classical</phrase> impact is the infamous "Error 404: file not found." However, the <phrase>user needs</phrase> a notification <phrase>alert</phrase> mechanism to prevent and warrant the <phrase>coherence</phrase> of manipulations over all the <phrase>life</phrase> cycle processes of a product. The <phrase>main objective</phrase> of this <phrase>chapter</phrase> is to provide a <phrase>generic</phrase> relationship <phrase>validation mechanism</phrase> to remedy this shortcoming. We believe in the combination of some standard features of <phrase>XML</phrase>, <phrase>specifically</phrase> XLL specification as a support for <phrase>integrity management</phrase> and <phrase>Java</phrase>-Triggers approach as an <phrase>alert</phrase> method. This study, compared with actual approaches, proposes a <phrase>solution</phrase> based on <phrase>active</phrase> functionalities.
Novel <phrase>Indexing</phrase> Method of Relations Between <phrase>Salient Objects</phrase>.
Since the <phrase>last</phrase> decade, images have been integrated into several <phrase>application domains</phrase> such as <phrase>GIS</phrase>, <phrase>medicine</phrase>, etc. This <phrase>integration</phrase> necessitates new <phrase>managing</phrase> methods particularly in <phrase>image retrieval</phrase>. Queries should be formulated using different types of features such as <phrase>low-level</phrase> features of images (histograms, <phrase>color</phrase> distribution, etc.), <phrase>spatial</phrase> and <phrase>temporal relations</phrase> between <phrase>salient objects</phrase>, <phrase>semantic</phrase> features, etc. In this <phrase>chapter</phrase>, we propose a novel method for <phrase>identifying</phrase> and <phrase>indexing</phrase> several types of relations between <phrase>salient objects</phrase>. <phrase>Spatial</phrase> relations are used here to show how our method can provide <phrase>high</phrase> <phrase>expressive power</phrase> to relations in comparison to the <phrase>traditional methods</phrase>.
On the Computation of <phrase>Recursion</phrase> in <phrase>Relational Databases</phrase>.
A <phrase>composite</phrase> object represented as a <phrase>directed graph</phrase> is an important <phrase>data structure</phrase> which requires <phrase>efficient</phrase> support in <phrase>CAD/CAM</phrase>, CASE, <phrase>office</phrase> systems, <phrase>software</phrase> <phrase>management</phrase>, <phrase>Web</phrase> <phrase>databases</phrase> and <phrase>document databases</phrase>. It is cumbersome to handle such an object in <phrase>relational database</phrase> systems when it involves <phrase>recursive</phrase> relationships. In this <phrase>chapter</phrase>, we present a new <phrase>encoding method</phrase> to support the <phrase>efficient</phrase> computation of <phrase>recursion</phrase>. In addition, we devise a <phrase>linear time</phrase> <phrase>algorithm</phrase> to identify a <phrase>sequence</phrase> of reachable <phrase>trees</phrase> (w.r.t.) a <phrase>directed acyclic graph</phrase> (<phrase>DAG</phrase>), which covers all the edges of the <phrase>graph</phrase>. Together with the new <phrase>encoding method</phrase>, this <phrase>algorithm</phrase> enables us to compute <phrase>recursion</phrase> w.r.t, a <phrase>DAG</phrase> in time <phrase>O</phrase>(<phrase>e</phrase>), where <phrase>e</phrase> represents the number of edges of the <phrase>DAG</phrase>. <phrase>More importantly</phrase>, this method is especially suitable for a <phrase>relational</phrase> environment.
<phrase>Building</phrase> <phrase>Signature-Trees</phrase> on <phrase>Path Signatures</phrase> in <phrase>Document Databases</phrase>.
<phrase>Java</phrase> is a prevailing implementation platform for <phrase>XML-based</phrase> systems. Several <phrase>high</phrase>-quality in-<phrase>memory</phrase> implementations for the standardized <phrase>XML</phrase>-<phrase>DOM</phrase> <phrase>API</phrase> are available. However, <phrase>persistency</phrase> support has not been addressed. In this <phrase>chapter</phrase>, we discuss this problem and introduce PDOM (<phrase>persistent</phrase> <phrase>DOM</phrase>) to accommodate documents as permanent object sets. In addition, we propose a new <phrase>indexing</phrase> technique: <phrase>path signatures</phrase> to <phrase>speed up</phrase> the evaluation of <phrase>path-oriented</phrase> queries against document object sets, which is further <phrase>enhanced</phrase> by <phrase>combining</phrase> the technique of <phrase>signature-trees</phrase> with it to expedite scanning of <phrase>signatures</phrase> stored in a physical file.
Dealing with Relationship <phrase>Cardinality</phrase> Constraints in <phrase>Relational</phrase> <phrase>Database Design</phrase>.
<phrase>Conceptual models</phrase> are well-known tools to achieve a good <phrase>design</phrase> of <phrase>information</phrase> systems. Nevertheless, the <phrase>understanding</phrase> and use of all the constructs and constraints which are presented in such models are not an easy task and sometimes it is cause of loss of interest.In this <phrase>chapter</phrase> we have tried to study in depth and clarify the meaning of the features of <phrase>conceptual models</phrase>. The disagreements between main <phrase>conceptual models</phrase>, the confusion in the use of some of their constructs and some <phrase>open</phrase> problems in these models are shown. Another important topic treated in this <phrase>chapter</phrase> is the conceptual-to-<phrase>logic</phrase> <phrase>schemata</phrase> transformation process.Some solutions are presented in <phrase>order</phrase> to clarify the relationship construct and to extend the <phrase>cardinality</phrase> constraint concept in <phrase>ternary</phrase> relationships. How to preserve the <phrase>cardinality</phrase> constraint <phrase>semantics</phrase> in <phrase>binary</phrase> and <phrase>ternary</phrase> relationships for their implementation in a <phrase>DBMS</phrase> with <phrase>active</phrase> capabilities has also been developed.
<phrase>Repairing</phrase> and <phrase>Querying Inconsistent Databases</phrase>.
The <phrase>integration</phrase> of <phrase>knowledge</phrase> from <phrase>multiple sources</phrase> is an important <phrase>aspect</phrase> in several areas such as <phrase>data warehousing</phrase>, <phrase>database</phrase> <phrase>integration</phrase>, <phrase>automated reasoning</phrase> systems, <phrase>active</phrase> <phrase>reactive</phrase> <phrase>databases</phrase> and others. Thus a central topic in <phrase>databases</phrase> is the <phrase>construction</phrase> of <phrase>integration</phrase> systems, designed for <phrase>retrieving</phrase> and <phrase>querying</phrase> <phrase>uniform</phrase> <phrase>data</phrase> stored in <phrase>multiple information sources</phrase>. This <phrase>chapter</phrase> illustrates recent techniques for <phrase>computing</phrase> repairs as well as <phrase>consistent answers</phrase> over <phrase>inconsistent databases</phrase>. Often <phrase>databases</phrase> may be inconsistent with respect to a set of <phrase>integrity constraints</phrase>, that is, one or more <phrase>integrity constraints</phrase> are not satisfied. Most of the techniques for <phrase>computing</phrase> repairs and queries over <phrase>inconsistent databases</phrase> work for <phrase>restricted</phrase> cases and only <phrase>recently</phrase> there have been proposals to consider more <phrase>general</phrase> constraints. In this <phrase>chapter</phrase> we give an <phrase>informal description</phrase> of the main techniques proposed in the <phrase>literature</phrase>.
<phrase>Unifying</phrase> Access to Heterogeneous <phrase>Document Databases</phrase> Through <phrase>Contextual</phrase> <phrase>Metadata</phrase>.
<phrase>Document databases</phrase> available on the <phrase>Internet</phrase> carry <phrase>massive</phrase> <phrase>information</phrase> resources. To a person needing a piece of <phrase>information</phrase> on a <phrase>specific domain</phrase>, <phrase>finding</phrase> the piece, however, is often quite problematic even <phrase>though</phrase> there were a representative collection of <phrase>databases</phrase> available on the domain. The languages used in the content, the names of <phrase>document types</phrase>, their structures, the ways documents are organized and their <phrase>retrieval techniques</phrase> often vary in the <phrase>databases</phrase>. The <phrase>databases</phrase> containing <phrase>legal information</phrase> on the <phrase>Internet</phrase> offer a typical example. For <phrase>finding relevant</phrase> documents and for being able to interpret the content of the documents correctly, the user may need <phrase>information</phrase> about the context where the documents have been created. In this <phrase>chapter</phrase> we introduce a method for collecting <phrase>contextual metadata</phrase> and for representing the <phrase>metadata</phrase> to the users by <phrase>graphical</phrase> models. The <phrase>solution</phrase> is demonstrated by a case of <phrase>retrieving</phrase> <phrase>information</phrase> from distributed <phrase>European</phrase> <phrase>legal</phrase> <phrase>databases</phrase>.
<phrase>Managing</phrase> Document Taxonomies in <phrase>Relational Databases</phrase>.
This <phrase>chapter</phrase> addresses the <phrase>challenge</phrase> of <phrase>applying</phrase> <phrase>relational database</phrase> technologies to manage taxonomies, which are <phrase>commonly used</phrase> to classify documents, <phrase>knowledge</phrase> and <phrase>websites</phrase> into a hierarchy of topics. It first describes how denormalizing the <phrase>data model</phrase> can facilitate <phrase>data</phrase> retrieval from such <phrase>topic hierarchies</phrase>. It then shows how the typical <phrase>data</phrase> maintenance difficulties associated with denormalized <phrase>data</phrase> models can be solved using <phrase>database</phrase> triggers.
<phrase>Database Management</phrase> Issues in the <phrase>Web</phrase> Environment.
The focus of this <phrase>chapter</phrase> is on the <phrase>progressive</phrase> adaptation of <phrase>database</phrase> techniques to <phrase>Web</phrase> usage in a way quite similar to the <phrase>evolution</phrase> from integrated <phrase>file management</phrase> systems to <phrase>database management systems</phrase>. We review related and <phrase>open</phrase> issues, such as the <phrase>semi-structured data</phrase> and <phrase>XML</phrase>, integrity problem, <phrase>query optimization</phrase> problem, and <phrase>integration</phrase> issues in both the <phrase>Web</phrase> and <phrase>Semantic Web</phrase> environments. The representation of <phrase>meta-information</phrase> along with <phrase>data</phrase> <phrase>opens up</phrase> a new way to automatically process <phrase>Web information</phrase> due to the use of explicit <phrase>semantic</phrase> <phrase>information</phrase>. We hope that researchers will take into account <phrase>traditional database</phrase> techniques and how they can assist new <phrase>Web</phrase> technologies. In this sense, the <phrase>amalgamation</phrase> of <phrase>Web</phrase> and <phrase>database</phrase> <phrase>technology</phrase> appears to be very promising.
Interactive <phrase>Indexing</phrase> of Documents with a <phrase>Multilingual</phrase> <phrase>Thesaurus</phrase>.
With the growing significance of <phrase>digital libraries</phrase> and the <phrase>Internet</phrase>, more and more <phrase>electronic</phrase> texts become accessible to a wide and geographically <phrase>disperse</phrase> <phrase>public</phrase>. This requires adequate tools to facilitate <phrase>indexing</phrase>, storage and retrieval of documents written in different languages. We present a method for <phrase>semi-automatic</phrase> <phrase>indexing</phrase> of <phrase>electronic</phrase> documents and <phrase>construction</phrase> of a <phrase>multilingual</phrase> <phrase>thesaurus</phrase>, which can be used for <phrase>query formulation</phrase> and <phrase>information retrieval</phrase>. We use special dictionaries and <phrase>user interaction</phrase> in <phrase>order</phrase> to solve ambiguities and find adequate <phrase>canonical</phrase> terms in the <phrase>language</phrase> and an adequate <phrase>abstract</phrase> <phrase>language</phrase>-<phrase>independent</phrase> term. The <phrase>abstract</phrase> <phrase>thesaurus</phrase> is <phrase>updated incrementally</phrase> by new <phrase>indexed documents</phrase> and is used to search for documents using adequate terms.
<phrase>Understanding</phrase> <phrase>Functional</phrase> Dependency.
In <phrase>explaining</phrase> <phrase>functional</phrase> dependency to students, <phrase>I</phrase> have noticed in texts a mixture of two types of elements: <phrase>intensional</phrase> (or <phrase>psychological</phrase> or meaning) and <phrase>extensional</phrase> (patterns of <phrase>repetition</phrase> in the <phrase>data</phrase>). In this <phrase>chapter</phrase> <phrase>I</phrase> examine whether it is possible to consider <phrase>functional</phrase> dependency, in particular, in second and third <phrase>normal forms</phrase>, solely on an <phrase>extensional</phrase> basis. The <phrase>Microsoft Access</phrase> <phrase>Analyzer</phrase> utility seems to do so. <phrase>I</phrase> illustrate the <phrase>mix</phrase> of <phrase>intensional</phrase> and <phrase>extensional</phrase> elements in <phrase>textbook</phrase> definitions of <phrase>functional</phrase> dependency. <phrase>I</phrase> conclude that although in principle first, second and <phrase>third normal form</phrase> can be done solely by <phrase>extensional</phrase> means, in practice <phrase>intensional</phrase> considerations are indispensable. <phrase>Finally</phrase>, <phrase>I</phrase> discuss these questions with respect to the "<phrase>higher order</phrase>" <phrase>normal forms</phrase>, namely <phrase>Boyce-Codd</phrase>, <phrase>fourth</phrase>, <phrase>fifth</phrase> and Domain/Key <phrase>normal form</phrase>.
<phrase>Keyword-Based</phrase> Queries Over <phrase>Web</phrase> <phrase>Databases</phrase>.
In this <phrase>chapter</phrase>, we propose an approach to using <phrase>keywords</phrase> (as in a <phrase>Web search engine</phrase>) for <phrase>querying</phrase> <phrase>databases</phrase> over the <phrase>Web</phrase>. The approach is based on a <phrase>Bayesian network</phrase> <phrase>model</phrase> and provides a suitable <phrase>alternative</phrase> to the use of interfaces based on multiple forms with several fields. Two <phrase>major</phrase> steps are involved when <phrase>querying</phrase> a <phrase>Web</phrase> <phrase>database</phrase> using this approach. First, structured (<phrase>database</phrase>-like) queries are derived from a query composed only of the <phrase>keywords</phrase> specified by the user. <phrase>Next</phrase>, the <phrase>structured queries</phrase> are submitted to a <phrase>Web</phrase> <phrase>database</phrase>, and the <phrase>retrieved results</phrase> are presented to the user as <phrase>ranked answers</phrase>. To demonstrate the feasibility of the approach, a simple <phrase>prototype</phrase> <phrase>Web search</phrase> system based on the approach is presented. <phrase>Experimental</phrase> <phrase>results</phrase> obtained with this system indicate that the approach allows for accurately <phrase>structuring</phrase> the <phrase>user queries</phrase> and <phrase>retrieving</phrase> appropriate answers with <phrase>minimum</phrase> intervention from the user.
System of <phrase>Information Retrieval</phrase> in <phrase>XML</phrase> Documents.
This <phrase>chapter</phrase> introduces the process to retrieve units (or subdocuments) of <phrase>relevant information</phrase> from <phrase>XML</phrase> documents. For this, we use the <phrase>Extensible Markup Language</phrase> (<phrase>XML</phrase>) which is considered as a new standard for <phrase>data</phrase> representation and exchange on the <phrase>Web</phrase>. <phrase>XML</phrase> opens opportunities to develop a new generation of <phrase>Information Retrieval</phrase> System (<phrase>IRS</phrase>) to improve the <phrase>interrogation</phrase> process of <phrase>document bases</phrase> on the Web.Our work focuses <phrase>instead</phrase> on <phrase>end-users</phrase> who do not have expertise in the domain (like a <phrase>majority</phrase> of the <phrase>end-users</phrase>). This approach supports <phrase>keyword-based</phrase> searching like <phrase>classical</phrase> <phrase>IRS</phrase> and integrates structured searching with the search attributes notion. It is based on an <phrase>indexing</phrase> method of document <phrase>tree</phrase> <phrase>leafs</phrase> which authorize a <phrase>content-oriented</phrase> retrieval. The retrieval subdocuments are ranked according to their similarity with the <phrase>user's query</phrase>. We use a <phrase>similarity measure</phrase> which is a compromise between two measures: exhaustiveness and <phrase>specificity</phrase>.
A <phrase>Taxonomy</phrase> for <phrase>Object-Relational</phrase> Queries.
A <phrase>comprehensive</phrase> study of <phrase>object-relational</phrase> queries gives not only an <phrase>understanding</phrase> of full capability of <phrase>object-relational</phrase> <phrase>query language</phrase> but also a direction for <phrase>query processing</phrase> and optimization. This <phrase>chapter</phrase> classifies <phrase>object-relational</phrase> queries into <phrase>REF</phrase> queries, <phrase>aggregate queries</phrase> and <phrase>inheritance</phrase> queries. <phrase>REF</phrase> queries are <phrase>queries involving</phrase> <phrase>REF</phrase> pointers, whereas <phrase>aggregation queries</phrase> use either <phrase>nested table</phrase> structures or <phrase>index</phrase> on clusters. <phrase>Finally</phrase>, <phrase>inheritance</phrase> queries are queries on <phrase>inheritance hierarchies</phrase>.
<phrase>Re-Engineering</phrase> and <phrase>Automation</phrase> of <phrase>Business Processes</phrase>: Criteria for <phrase>Selecting</phrase> <phrase>Supporting</phrase> Tools.
<phrase>Re-engineering</phrase> of <phrase>business processes</phrase> and their <phrase>automation</phrase> is an activity very common in most organizations in <phrase>order</phrase> to keep or create a <phrase>competitive business</phrase> advantage in the <phrase>changing business environment</phrase>. <phrase>Business Process Modeling</phrase> Tools (BPMTs) and <phrase>Workflow</phrase> <phrase>Management</phrase> Systems (WFMSs) are the most popular tools used for <phrase>business process</phrase> transformation and <phrase>automation</phrase> of the redesigned <phrase>business processes</phrase> within and outside organization's boundaries. This <phrase>chapter</phrase> describes a set of criteria for <phrase>selecting</phrase> appropriate BPMTs and WFMSs among the diversity of the tools offered in the market in <phrase>order</phrase> to assist the interested <phrase>manager</phrase> or <phrase>business process</phrase> <phrase>engineer</phrase> to more successfully manage the <phrase>business process</phrase> transformation. While establishing the proposed criteria, we considered currently available <phrase>technology</phrase> and standards for <phrase>visual</phrase> enterprise support and <phrase>inter-organizational business process</phrase> modeling and <phrase>automation</phrase>.
Metrics for <phrase>Data Warehouse</phrase> Quality.
This <phrase>chapter</phrase> proposes a set of metrics to assess <phrase>data warehouse</phrase> quality. A set of <phrase>data warehouse</phrase> metrics is presented, and the formal and empirical validations that have been done with them. As we consider that <phrase>information</phrase> is the main organizational <phrase>asset</phrase>, one of our primary duties should be <phrase>assuring</phrase> its quality. Although some interesting guidelines have been proposed for <phrase>designing</phrase> "good" <phrase>data</phrase> models for <phrase>data warehouses</phrase>, more <phrase>objective indicators</phrase> are needed. Metrics are a useful objective mechanism for <phrase>improving</phrase> the quality of <phrase>software</phrase> <phrase>products</phrase> and also for <phrase>determining</phrase> the best ways to help professionals and researchers. In this way, our goal is to elaborate a set of metrics for <phrase>measuring</phrase> <phrase>data warehouse</phrase> quality which can help designers in choosing the best option among more than one <phrase>alternative</phrase> <phrase>design</phrase>.
<phrase>Integrity Constraints</phrase> in an <phrase>Active</phrase> <phrase>Database</phrase> Environment.
This <phrase>chapter</phrase> surveys the interaction between <phrase>active</phrase> rules and <phrase>integrity constraints</phrase>. First, we analyze the static case following the <phrase>SQL</phrase>-1999 Standard <phrase>Committee</phrase> <phrase>point of view</phrase> which, <phrase>up to date</phrase>, represents the <phrase>state</phrase> of the <phrase>art</phrase>. Then, we consider the case of <phrase>dynamic</phrase> constraints for which we use a <phrase>temporal logic</phrase> formalism. <phrase>finally</phrase>, we discuss the applicabilty, limitations and <phrase>partial</phrase> solutions found when attempting to ensure the satisfaction of <phrase>dynamic</phrase> constraints.
<phrase>Integrity Constraints</phrase> in <phrase>Spatial Databases</phrase>.
Preserving Relationship <phrase>Cardinality</phrase> Constraints in <phrase>Relational Schemata</phrase>.
<phrase>Translating</phrase> <phrase>Advanced</phrase> <phrase>Integrity Checking</phrase> <phrase>Technology</phrase> to <phrase>SQL</phrase>.
<phrase>Introduction</phrase>.
Consistent Queries Over <phrase>Databases</phrase> with <phrase>Integrity Constraints</phrase>.
<phrase>Integrity Issues</phrase> in the <phrase>Web</phrase>: Beyond <phrase>Distributed Databases</phrase>.
<phrase>Functional</phrase> Dependencies for Value Based Identification in <phrase>Object-Oriented</phrase> <phrase>Databases</phrase>.
<phrase>Database</phrase> Integrity: Fundamental and <phrase>Current Implementations</phrase>.
In <phrase>Part I</phrase>, this <phrase>chapter</phrase> survyes the <phrase>state</phrase> of the <phrase>art</phrase> of the <phrase>semantic integrity constraints</phrase> in some <phrase>relational</phrase> and <phrase>object relational</phrase> available <phrase>database systems</phrase>. In <phrase>Part II</phrase>, it also provides <phrase>an overview</phrase> of the <phrase>SQL</phrase> standard <phrase>integrity issues</phrase> and describes <phrase>semantic</phrase> integrity support in the following <phrase>DBMSs</phrase>: <phrase>Oracle</phrase>, <phrase>IBM DB2</phrase>, <phrase>Informix</phrase>, <phrase>sybase</phrase> and PostgreSQL.The <phrase>major differences</phrase> and similarities among these systems are analyzed in relation to the definition, <phrase>semantics</phrase> and fidelity to the <phrase>SQL</phrase> standard <phrase>prescriptions</phrase>.
<phrase>Integrity Maintenance</phrase> in <phrase>Extensible</phrase> <phrase>Databases</phrase>.
<phrase>Project Management</phrase> in <phrase>Graduate Education</phrase>.
Alignment of <phrase>Business</phrase> and <phrase>Knowledge Management</phrase> Strategy.
<phrase>Project Management</phrase> <phrase>Best Practices</phrase> to Increase Success.
<phrase>Autopoietic</phrase> Approach for <phrase>Information</phrase> System Development.
<phrase>Sponsorship</phrase> in IT <phrase>Project Management</phrase>.
<phrase>A Systematic Approach</phrase> for <phrase>Information</phrase> Systems Evaluation.
Organizing <phrase>Multimedia</phrase> Objects by Using Class <phrase>Algebra</phrase>.
<phrase>ICT</phrase>-Supported <phrase>Gaming</phrase> for <phrase>Competitive Intelligence</phrase>.
<phrase>Virtual</phrase> Communities in Practice.
Concepts and Dynamics of the <phrase>Application Service Provider</phrase> <phrase>Industry</phrase>.
IT <phrase>Supporting</phrase> <phrase>Strategy Formulation</phrase>.
<phrase>Credit Card</phrase> Users' <phrase>Data Mining</phrase>.
Better <phrase>Executive</phrase> <phrase>Information</phrase> with the <phrase>Dashboard</phrase> Approach.
<phrase>Project Management</phrase> Models in IT.
<phrase>Human Motion</phrase> Tracking and Recognition.
<phrase>Expanding</phrase> <phrase>Data Mining</phrase> Power with System Dynamics.
<phrase>Enhancing</phrase> Competitiveness of <phrase>B2B</phrase> and <phrase>B2C E-Commerce</phrase>.
<phrase>Natural Computing</phrase>.
<phrase>Information Technology</phrase> Usage in <phrase>Nigeria</phrase>.
<phrase>Distance Education</phrase> <phrase>Success Factors</phrase>.
Impacts of the <phrase>Intranet</phrase> on PDO.
<phrase>Online Learning</phrase> as a Form of Accomodation.
<phrase>SMEs</phrase> <phrase>Amidst</phrase> <phrase>Global</phrase> Technological Changes.
<phrase>Legal</phrase> Issues of <phrase>Virtual</phrase> Organizations.
<phrase>Telemedicine</phrase> in <phrase>Healthcare</phrase> Organisations.
<phrase>Multicast Routing</phrase> Protocols, <phrase>Algorithms</phrase> and its <phrase>QoS</phrase> Extensions.
Triggers, Rules and Constraints in <phrase>Databases</phrase>.
<phrase>Data Mining</phrase> for <phrase>Combining</phrase> Forecasts in <phrase>Inventory Management</phrase>.
<phrase>Spatial</phrase> Modeling of <phrase>Risk</phrase> Factors for <phrase>Gender</phrase>-Specific <phrase>Child Mortality</phrase>.
<phrase>Content-Based</phrase> Retrieval Concept.
<phrase>Knowledge Management</phrase> and <phrase>Social Learning</phrase>.
<phrase>Interface Design</phrase> Issues for <phrase>Mobile Commerce</phrase>.
Perturbations, Accuracy and Robustness in <phrase>Neural Networks</phrase>.
A Duplicate <phrase>Chinese</phrase> <phrase>Document Image Retrieval</phrase> System.
<phrase>Multimedia</phrase> Evaluations Based on <phrase>Cognitive Science</phrase> Findings.
One-to-One <phrase>Video-Conferencing</phrase> <phrase>Education</phrase>.
International <phrase>Digital</phrase> Studies Approach for <phrase>Examining</phrase> International <phrase>Online</phrase> Interactions.
Structure- and <phrase>Content-Based</phrase> Retrieval for <phrase>XML</phrase> Documents.
<phrase>Strategic</phrase> Utilization of <phrase>Data Mining</phrase>.
<phrase>Incorporating</phrase> <phrase>Data Stream</phrase> Analysis into <phrase>Decision Support Systems</phrase>.
<phrase>Semantic Web</phrase> <phrase>Fundamentals</phrase>.
Novel <phrase>Indexing</phrase> Method of Relations Between <phrase>Salient Objects</phrase>.
<phrase>Democratic</phrase> <phrase>E-Governance</phrase>.
<phrase>Graph</phrase> Encoding and <phrase>Recursion</phrase> Computation.
<phrase>Strategic</phrase> <phrase>Knowledge Management</phrase> in <phrase>Public</phrase> Organizations.
<phrase>Organization</phrase> and <phrase>Management</phrase> Issues of <phrase>End User Computing</phrase>.
<phrase>Management</phrase> Considerations for <phrase>B2B</phrase> <phrase>Online</phrase> Exchanges.
<phrase>Behavioral Perspective</phrase> of <phrase>Groupware</phrase> <phrase>Adoption</phrase>.
Addressing the Central Problem in <phrase>Cyber</phrase> <phrase>Ethics</phrase> through <phrase>Stories</phrase>.
<phrase>Data Mining</phrase> in Practice.
<phrase>Web</phrase> Technologies And <phrase>Data Warehousing</phrase> Strategies.
Similarity <phrase>Web Pages</phrase> Retrieval Technologies on the <phrase>Internet</phrase>.
<phrase>Content Description</phrase> for <phrase>Face Animation</phrase>.
<phrase>Data Mining</phrase> in <phrase>Franchise</phrase> Organizations.
<phrase>Diffusion</phrase> of <phrase>E-Learning</phrase> as an <phrase>Educational Innovation</phrase>.
<phrase>Franchising</phrase> and <phrase>Information Technology</phrase>.
<phrase>Diffusion</phrase> of Innovations in Organisations.
<phrase>Neural Networks</phrase> for <phrase>Automobile</phrase> <phrase>Insurance</phrase> Customers.
<phrase>Project Management</phrase> for IT Projects.
<phrase>Incremental Expansion</phrase> of a <phrase>Distributed Database</phrase> Systems.
<phrase>Integrative</phrase> Document and <phrase>Content Management</phrase> Solutions.
<phrase>Managing</phrase> <phrase>Strategic</phrase> IT <phrase>Investment</phrase> Decisions.
<phrase>Innovative Thinking</phrase> in <phrase>Software Development</phrase>.
<phrase>Effective Learning</phrase> Through <phrase>Optimum</phrase> Distance Among <phrase>Team Members</phrase>.
User <phrase>Spreadsheet</phrase> <phrase>Systems Development</phrase>.
<phrase>History</phrase> and <phrase>Future Development</phrase> of <phrase>Group Support Systems</phrase>.
<phrase>Migrating Legacy Systems</phrase> to the <phrase>Web</phrase>.
Evaluation of an <phrase>Open</phrase> <phrase>Learning</phrase> Environment.
<phrase>Reasoning About</phrase> <phrase>User Preferences</phrase>.
Portable <phrase>Portals</phrase> for <phrase>M-Commerce</phrase>.
<phrase>Collective</phrase> <phrase>Intentional</phrase> <phrase>Action</phrase> in <phrase>Virtual</phrase> Communities.
<phrase>Communication</phrase> <phrase>Management</phrase> for Large Modules.
<phrase>Building</phrase> <phrase>Police</phrase>/<phrase>Community</phrase> Relations Through <phrase>Virtual</phrase> Communities.
<phrase>Critical Success Factors</phrase> of <phrase>ERP</phrase> Implementation.
<phrase>Executive</phrase> <phrase>Judgement</phrase> in <phrase>E</phrase>-<phrase>Business</phrase> Strategy.
<phrase>Mobile</phrase> Transaction Models Framework.
<phrase>Audience Response Systems</phrase> and <phrase>Face-to-Face</phrase> <phrase>Learning</phrase>.
Isoluminance Contours for <phrase>Animated</phrase> Visualization.
<phrase>Data Warehouse</phrase> Development.
<phrase>Web</phrase> Initiatives and <phrase>E-Commerce</phrase> Strategy.
IS Implementation in the <phrase>UK</phrase> <phrase>Health</phrase> Sector.
<phrase>Geographic Information Systems</phrase> as Decision Tools.
<phrase>Macromedia Flash</phrase> on the Client and the Server.
Relationship <phrase>Cardinality</phrase> Constraints in <phrase>Relational</phrase> <phrase>Database Design</phrase>.
<phrase>Outsourcing</phrase> <phrase>Information Technology</phrase> in <phrase>Australia</phrase>.
<phrase>Virtual</phrase> Teams as <phrase>Sociotechnical Systems</phrase>.
<phrase>Web</phrase> Access by <phrase>Older Adult</phrase> Users.
Market of Resources for <phrase>Agile</phrase>/<phrase>Virtual</phrase> <phrase>Enterprise Integration</phrase>.
<phrase>Web</phrase> <phrase>Usability</phrase>.
Challenges in <phrase>Quality of Service</phrase> for <phrase>Tomorrow's</phrase> Networks.
<phrase>Artificial Intelligence</phrase> Techniques in <phrase>Medicine</phrase> and <phrase>Healthcare</phrase>.
Methods for <phrase>Understanding</phrase> IS Failures.
Women in the IT <phrase>Profession</phrase>.
<phrase>Exception Rules</phrase> in <phrase>Data Mining</phrase>.
<phrase>Virtual</phrase> Work <phrase>Research Agenda</phrase>.
<phrase>Web Caching</phrase>.
<phrase>Governance</phrase> in IT <phrase>Outsourcing</phrase> Partnerships.
<phrase>Context-Aware</phrase> Framework for <phrase>ERP</phrase>.
<phrase>Usability</phrase> Evaluation of <phrase>Online Learning</phrase> Programs.
<phrase>Hypothetical Reasoning</phrase> Over <phrase>Databases</phrase>.
Computer <phrase>Attitude</phrase> and <phrase>Anxiety</phrase>.
<phrase>Tertiary Education</phrase> and the <phrase>Internet</phrase>.
<phrase>Trust</phrase> in <phrase>Technology</phrase> Partnerships.
<phrase>Object Database</phrase> Benchmarks.
<phrase>Hyper</phrase> <phrase>Video</phrase> for <phrase>Distance Learning</phrase>.
<phrase>Rotating</phrase> <phrase>Banner Advertisements</phrase> on <phrase>the World Wide Web</phrase>.
New Perspectives on Rewards and <phrase>Knowledge</phrase> Sharing.
<phrase>Formal Methods</phrase> in <phrase>Software Engineering</phrase>.
<phrase>Design</phrase> Levels for Distance and <phrase>Online Learning</phrase>.
Concepts of <phrase>Emergence</phrase> <phrase>Index</phrase> in <phrase>Image Databases</phrase>.
<phrase>Interactivity</phrase> and <phrase>Amusement</phrase> in <phrase>Electronic Commerce</phrase>.
<phrase>Media</phrase> and Personal Involvement in the Perceptions of <phrase>Data Quality</phrase>.
Principles of <phrase>Advanced</phrase> <phrase>Database Integrity</phrase> Checking.
eCRM in a <phrase>Manufacturing</phrase> Environment.
Alignment of <phrase>Information Technology</phrase> and <phrase>Human Resources</phrase> Strategies.
<phrase>Integrating</phrase> <phrase>Security</phrase> in the <phrase>Development Process</phrase> with <phrase>UML</phrase>.
Principles to Guide the <phrase>Integration</phrase> and Implementation of <phrase>Educational Technology</phrase>.
<phrase>Strategic</phrase> Vision for <phrase>Information Technology</phrase>.
The <phrase>CRM</phrase>-<phrase>KDD</phrase> <phrase>Nexus</phrase>.
<phrase>Balancing</phrase> Risks and Rewards of <phrase>ERP</phrase>.
From <phrase>Digital Divide</phrase> to <phrase>Digital</phrase> <phrase>Dividend</phrase>.
<phrase>Business Model</phrase> Application of <phrase>UML</phrase> <phrase>Stereotypes</phrase>.
<phrase>Motivation</phrase> for Using Microcomputers.
<phrase>Globalization</phrase> of <phrase>Consumer</phrase> <phrase>E-Commerce</phrase>.
<phrase>Journalism</phrase> <phrase>Online</phrase> in <phrase>Peru</phrase>.
<phrase>Object-Oriented</phrase> <phrase>Software</phrase> Reuse in <phrase>Business</phrase> Systems.
<phrase>Global</phrase> Implications of <phrase>E-Commerce</phrase> Tool and Artifact Creation.
Impediments for <phrase>Knowledge</phrase> Sharing in <phrase>Professional</phrase> <phrase>Service Firms</phrase>.
Issues and Challenges in IT in <phrase>Small Business</phrase>.
<phrase>Audio Analysis</phrase> Applications for <phrase>Music</phrase>.
<phrase>Web-Based</phrase> <phrase>Distance Learning</phrase> and the Second <phrase>Digital Divide</phrase>.
<phrase>Web-based</phrase> <phrase>distance learning</phrase> programs promise <phrase>learning</phrase> options anywhere, <phrase>anytime</phrase>, to anyone. However, some individuals with disabilities are <phrase>locked</phrase> out of these opportunities when courses are designed in such a way that they are inaccessible to individuals using <phrase>assistive technology</phrase>. This <phrase>chapter</phrase> provides <phrase>an overview</phrase> of access challenges for <phrase>people with disabilities</phrase>; suggestions for course developers on <phrase>creating</phrase> accessible courses; and suggestions for administrators on <phrase>developing</phrase> accessiblity policies, guidelines, and procedures.
<phrase>Data</phrase> Communications and <phrase>E-Learning</phrase>.
<phrase>Online</phrase> <phrase>Academic</phrase> <phrase>Libraries</phrase> and <phrase>Distance Learning</phrase>.
<phrase>Use Cases</phrase> and the <phrase>UML</phrase>.
<phrase>U.S</phrase>. Disabilities <phrase>Legislation</phrase> Affecting <phrase>Information Technology</phrase>.
<phrase>Critical Realism</phrase> as an <phrase>Underlying Philosophy</phrase> for IS <phrase>Research</phrase>.
<phrase>Engineering</phrase> <phrase>Emotionally Intelligent</phrase> Agents.
<phrase>Managing</phrase> the <phrase>Organisational</phrase> Impacts of <phrase>Information</phrase> Systems.
<phrase>Learning</phrase> <phrase>Portals</phrase> as New <phrase>Academic</phrase> Spaces.
<phrase>Database</phrase> Integrity.
<phrase>Critical Realism</phrase> in IS <phrase>Research</phrase>.
Informationbase - A New <phrase>Information</phrase> System Layer.
<phrase>Building</phrase> <phrase>Educational Technology</phrase> Partnerships Through <phrase>Participatory Design</phrase>.
<phrase>Self-Organizing</phrase> <phrase>Networked Learning</phrase> Environments.
<phrase>Recursive</phrase> <phrase>Nature</phrase> of the Market for <phrase>Enterprise Applications</phrase>.
<phrase>E-Commerce</phrase> Training for <phrase>SMEs</phrase>.
<phrase>Decision Support Systems</phrase> in <phrase>Small Businesses</phrase>.
<phrase>Learnability</phrase>.
<phrase>Contingency</phrase> Theory, <phrase>Agent-Based</phrase> Systems and a <phrase>Virtual</phrase> <phrase>Advisor</phrase>.
<phrase>Process-Aware Information Systems</phrase> for <phrase>Virtual Teamwork</phrase>.
<phrase>Assessing</phrase> the Value of <phrase>Information</phrase> Systems Investments.
<phrase>Business Processes</phrase> and <phrase>Knowledge Management</phrase>.
<phrase>Moderator</phrase> in Governmen <phrase>t</phrase>-Initiated <phrase>Online</phrase> Discussions.
<phrase>Wireless Ad Hoc Networking</phrase>.
<phrase>Knowledge Management</phrase> Systems Acceptance.
This <phrase>chapter</phrase> introduces a framework of <phrase>knowledge management</phrase> systems acceptance labeled Requirements of <phrase>Acceptance Model</phrase> (<phrase>RAM</phrase>). It argues that acceptance of <phrase>knowledge management</phrase> systems is dependent on <phrase>perceived relevance</phrase>, systems accessibility, and <phrase>management</phrase> support. Together these components constitute the <phrase>RAM</phrase>. Further, it argues that implementation of systems is <phrase>at large</phrase> a process of acceptance where the requirements of acceptance are attained. <phrase>Finally</phrase>, it argues that to achieve the requirements of acceptance, implementation should be <phrase>iterative</phrase> and <phrase>cooperative</phrase> between users and developers by continually <phrase>developing</phrase>, <phrase>implementing</phrase>, and testing <phrase>prototypes</phrase>.
An <phrase>ERP</phrase> <phrase>Life</phrase>-Cycle Costs <phrase>Model</phrase>.
<phrase>Socio-Cognitive</phrase> <phrase>Model</phrase> of <phrase>Trust</phrase>.
<phrase>Video</phrase> <phrase>Content-Based Retrieval</phrase> Techniques.
<phrase>Forward</phrase> <phrase>Engineering</phrase> of <phrase>UML</phrase> Static Models.
Reuse of <phrase>Formal Specifications</phrase>.
<phrase>Trust</phrase> Placement Process in Metateam Projects.
Issues of <phrase>E-Learning</phrase> in <phrase>Third World Countries</phrase>.
Teams and <phrase>Electronic</phrase> Technologies.
<phrase>Unified Modeling Language</phrase>.
<phrase>Functional Integration</phrase> of <phrase>Decision Making</phrase> Support.
Stickiness and <phrase>Web-Based</phrase> <phrase>Customer Loyalty</phrase>.
<phrase>Decision-Making Support Systems</phrase>.
<phrase>Collaborative Learning</phrase> <phrase>On-Demand</phrase>.
<phrase>Enterprise Resource Planning</phrase> for Intelligent Enterprises.
<phrase>E</phrase>-<phrase>Mail</phrase> Usage in <phrase>South</phrase> <phrase>Pacific</phrase> <phrase>Distance Education</phrase>.
<phrase>Privacy</phrase>-<phrase>Dangers</phrase> and Protections.
<phrase>Usability</phrase> of <phrase>Online Learning</phrase> Systems and <phrase>Course Materials</phrase>.
<phrase>Software</phrase> Contracts for <phrase>Component-Based</phrase> <phrase>Web Engineering</phrase>.
<phrase>Translation</phrase> of <phrase>Natural Language</phrase> Patterns to Object and <phrase>Process Modeling</phrase>.
<phrase>Client/Server</phrase> and the <phrase>Knowledge</phrase> <phrase>Directory</phrase>.
<phrase>Multilingual</phrase> <phrase>Electronic Commerce</phrase> in a <phrase>Global</phrase> <phrase>Economy</phrase>.
<phrase>Census</phrase> <phrase>Data</phrase> for <phrase>Health</phrase> Preparedness and Response.
Using <phrase>Geographic Information Systems</phrase> to Solve <phrase>Community</phrase> Problems.
Agent- and <phrase>Web-Based</phrase> <phrase>Employment</phrase> Marketspaces in the <phrase>U.S</phrase>. <phrase>Department</phrase> of <phrase>Defense</phrase>.
<phrase>Parallel</phrase> and <phrase>Distributed Multimedia</phrase> <phrase>Databases</phrase>.
<phrase>Knowledge</phrase>, IT, and the <phrase>Firm</phrase>.
<phrase>Information</phrase> Systems and <phrase>Systems Theory</phrase>.
Heuristics in <phrase>Medical</phrase> <phrase>Data Mining</phrase>.
<phrase>Optical Music Recognition</phrase> with <phrase>Wavelets</phrase>.
<phrase>Marketplace</phrase> <phrase>Architecture</phrase> for <phrase>Enterprise Integration</phrase>.
<phrase>Mobile Location</phrase> Services.
<phrase>Software</phrase> and <phrase>Systems Engineering</phrase> <phrase>Integration</phrase>.
<phrase>Ethics</phrase> of New Technologies.
<phrase>Supporting</phrase> Assurnace and <phrase>Compliance</phrase> Monitoring.
Infocratic <phrase>Perspective</phrase> on the Delivery of Personal <phrase>Financial Services</phrase>.
Benefits and Challenges of <phrase>Blended Learning</phrase> Environments.
<phrase>Computer-Mediated</phrase> <phrase>Learning</phrase> Groups.
<phrase>Quality Assurance</phrase> Issues for <phrase>Online</phrase> <phrase>Universities</phrase>.
Consistent Queries Over <phrase>Databases</phrase> with <phrase>Integrity Constraints</phrase>.
<phrase>User Perceptions</phrase> and <phrase>Groupware</phrase> Use.
The Changing <phrase>Library</phrase> <phrase>Education</phrase> <phrase>Curriculum</phrase>.
<phrase>Diffusion</phrase> Patterns of the <phrase>Internet</phrase> <phrase>Technology</phrase> Cluster in <phrase>Irish</phrase> <phrase>SMEs</phrase>.
<phrase>Internet Abuse</phrase> and <phrase>Addiction</phrase> in the <phrase>Workplace</phrase>.
<phrase>Application Service Provision</phrase> for Intelligent Enterprises.
Agents and <phrase>Payment Systems</phrase> in <phrase>E-Commerce</phrase>.
<phrase>Mobile</phrase> Agent <phrase>Authentication</phrase> and <phrase>Authorization</phrase> in <phrase>E-Commerce</phrase>.
<phrase>Ontology</phrase>-Based Query Formation and <phrase>Information Retrieval</phrase>.
<phrase>Theoretical Framework</phrase> for <phrase>CRM</phrase> <phrase>Outsourcing</phrase>.
<phrase>Packet Inter-Arrival</phrase> <phrase>Distributions</phrase> in <phrase>Computer Network</phrase> Workloads.
<phrase>Information</phrase> Modeling in <phrase>UML</phrase> and <phrase>ORM</phrase>.
<phrase>Web-Based</phrase> <phrase>Supply Chain</phrase> Strategy.
<phrase>Metadata</phrase> for <phrase>Electronic</phrase> Documents Using the <phrase>Dublin Core</phrase>.
<phrase>Overcoming</phrase> Barriers in the <phrase>Planning</phrase> of a <phrase>Virtual</phrase> <phrase>Library</phrase>.
<phrase>Library</phrase> <phrase>Management</phrase> and <phrase>Organizational Change</phrase>.
<phrase>Technology</phrase> of <phrase>Formal Education</phrase>.
<phrase>Security</phrase> Issues in <phrase>Distributed Transaction Processing</phrase> Systems.
<phrase>Offshore Software Development</phrase> <phrase>Outsourcing</phrase>.
Successful <phrase>Health</phrase> <phrase>Information</phrase> System Implementation.
<phrase>Space Opera</phrase>- <phrase>GIS</phrase> <phrase>Basics</phrase>.
<phrase>Chief</phrase> <phrase>Knowledge</phrase> <phrase>Officers</phrase>.
<phrase>Intelligent Software Agents</phrase>.
<phrase>VRML</phrase>-Based System for a 3D <phrase>Virtual</phrase> <phrase>Museum</phrase>.
<phrase>Dot</phrase>-Comming <phrase>SMEs</phrase> in <phrase>Singapore</phrase> for a New <phrase>Economy</phrase>.
<phrase>Electronic</phrase> <phrase>Government</phrase> Strategies and <phrase>Research</phrase> in the <phrase>U.S</phrase>..
<phrase>Process-Based</phrase> <phrase>Data Mining</phrase>.
<phrase>Automation</phrase> of <phrase>American</phrase> <phrase>Criminal Justice</phrase>.
Measurement Issues in <phrase>Decision Support Systems</phrase>.
After a brief discussion on the <phrase>history</phrase> of <phrase>decision-making</phrase>, this <phrase>chapter</phrase> focuses on metrics for justifying <phrase>investment</phrase> in <phrase>information</phrase> systems and <phrase>technology</phrase> and for <phrase>measuring</phrase> <phrase>business</phrase> and <phrase>management</phrase> performance. The discussion of metrics is linked to <phrase>current practices</phrase> in <phrase>decision support systems</phrase> and focuses on the needs for <phrase>future systems</phrase>. With several examples drawn from contemporary practice, we introduce implementation guidelines for <phrase>DSS</phrase> development <phrase>incorporating</phrase> new metrics that <phrase>go</phrase> beyond <phrase>ROI</phrase> and <phrase>Balanced Scorecard</phrase>-like measures. Suggested guidelines include simplicity, <phrase>selectivity</phrase>, a focus on <phrase>research</phrase> and <phrase>learning</phrase>, and <phrase>benchmarking</phrase>. These guidelines suggest that future metrics to support <phrase>decision support systems</phrase> should be grouped into <phrase>meaningful categories</phrase> and tied more closely to system <phrase>architecture</phrase>.
<phrase>ICTs</phrase> as <phrase>Participatory</phrase> Vehicles.
<phrase>Content Management</phrase> in Organizations.
Current <phrase>Multicast</phrase> <phrase>Technology</phrase>.
<phrase>Technology's</phrase> Role in <phrase>Distance Education</phrase>.
Dimensions of <phrase>Database</phrase> Quality.
<phrase>World Wide Web</phrase> Search Technologies.
<phrase>Information</phrase> Systems and <phrase>Small Business</phrase>.
<phrase>Trust</phrase> in <phrase>Knowledge</phrase>-Based Organizations.
<phrase>Enterprise Resource Planning</phrase> and <phrase>Systems Integration</phrase>.
<phrase>Instant Messaging</phrase> Moves From the <phrase>Home</phrase> to the <phrase>Office</phrase>.
<phrase>Electronic Commerce</phrase> Policies for <phrase>Dutch</phrase> <phrase>SMEs</phrase>.
<phrase>Measuring</phrase> Collaboration in <phrase>Online</phrase> Communications.
<phrase>Electronic</phrase>/<phrase>Digital</phrase> <phrase>Government</phrase> <phrase>Innovation</phrase>, and <phrase>Publishing</phrase> Trends with IT.
<phrase>E-Government</phrase>, <phrase>E-Democracy</phrase> and the Politicians.
<phrase>Simulation</phrase> for <phrase>Business</phrase> <phrase>Engineering</phrase> of <phrase>Electronic</phrase> Markets.
The Past, Present, and Future of <phrase>End-User</phrase> Performance.
<phrase>Adoption</phrase> of <phrase>E-Commerce</phrase> in the <phrase>Value Chain</phrase> by <phrase>SMEs</phrase>.
<phrase>Internet</phrase> Support for <phrase>Knowledge Management</phrase> Systems.
<phrase>Case-Based Learning</phrase> in Computer <phrase>Information</phrase> Systems.
A <phrase>Language</phrase>/<phrase>Action Based</phrase> Approach to <phrase>Information</phrase> Modeling.
<phrase>Harmonizing</phrase> IT and <phrase>Business</phrase> Strategies.
This <phrase>chapter</phrase> proposes that all <phrase>business</phrase> strategies should be <phrase>harmonized</phrase> into a <phrase>single</phrase> strategy, rather than attempt to align IT strategy with <phrase>business</phrase> strategy. It focuses on two hypotheses: <phrase>firstly</phrase>, that IT strategy is not widely aligned with <phrase>business</phrase> strategy; and <phrase>secondly</phrase>, that IT is still thought of as "something different" in businesses. The <phrase>chapter</phrase> proposes that rather than attempt to align IT strategy with <phrase>business</phrase> strategy, the strategies should be <phrase>harmonized</phrase> into a <phrase>single</phrase> strategy. The <phrase>chapter</phrase> attempts to use <phrase>lessons</phrase> from geese to outline the process of <phrase>strategic</phrase> development.
Intelligent Metabusiness.
Small Busines Transformation Through <phrase>Knowledge Management</phrase>.
<phrase>Fundamentals</phrase> of <phrase>Multirate</phrase> Systems.
Simple Methods for <phrase>Design</phrase> of <phrase>Narrowband</phrase> <phrase>Highpass</phrase> <phrase>FIR</phrase> Filters.
One Method for <phrase>Design</phrase> of <phrase>Narrowband</phrase> <phrase>Lowpass</phrase> Filters.
This <phrase>chapter</phrase> describes a <phrase>design</phrase> of a <phrase>narrowband</phrase> <phrase>lowpass</phrase> <phrase>finite impulse response</phrase> (<phrase>FIR</phrase>) filter using a small number of multipliers per output sample (<phrase>MPS</phrase>). The method is based on the use of a <phrase>frequency</phrase>-improved <phrase>recursive</phrase> running <phrase>sum</phrase> (RRS), called the <phrase>sharpening</phrase> RRS filter, and the interpolated <phrase>finite impulse response</phrase> (IFIR) structure. The filter <phrase>sharpening</phrase> technique uses <phrase>multiple copies</phrase> of the same filter according to an <phrase>amplitude</phrase> change <phrase>function</phrase> (ACF), which <phrase>maps</phrase> a <phrase>transfer function</phrase> before <phrase>sharpening</phrase> to a desired form after <phrase>sharpening</phrase>. Three ACFs are used in the <phrase>design</phrase>, as illustrated in the accompanying examples.
<phrase>Flexible Job-Shop Scheduling Problems</phrase>.
The <phrase>Software Industry</phrase> in <phrase>Egypt</phrase>.
On the <phrase>Relativity</phrase> of <phrase>Ontological</phrase> Domains and Their Specifications.
<phrase>E</phrase>-<phrase>Collaboration Support</phrase> Systems Issues to be Addressed.
<phrase>Cross-Cultural Research</phrase> in <phrase>MIS</phrase>.
Standards for <phrase>Web-Based</phrase> <phrase>Integration</phrase> Adapters.
<phrase>Interoperability</phrase> in <phrase>Geospatial Information</phrase> Systems.
<phrase>Usability</phrase> and <phrase>Learnability</phrase> Evaluation of <phrase>Web-Based</phrase> ODL Programs.
Facial and Body <phrase>Feature Extraction</phrase> for <phrase>Emotionally-Rich</phrase> <phrase>HCI</phrase>.
<phrase>Gender</phrase> and <phrase>Computer Anxiety</phrase>.
<phrase>Cache Management</phrase> for <phrase>Web-Powered</phrase> <phrase>Databases</phrase>.
<phrase>E-Learning</phrase> Environment.
<phrase>Formal Development</phrase> of <phrase>Reactive Agent-Based</phrase> Systems.
<phrase>Contracting</phrase> Mechanisms in IS/IT <phrase>Outsourcing</phrase> Phenomenon.
<phrase>Archival</phrase> Issues Related to <phrase>Digital</phrase> Creations.
<phrase>Curriculum</phrase> Development in <phrase>Web-Based</phrase> <phrase>Education</phrase>.
<phrase>Online</phrase> Communities and <phrase>Community</phrase> <phrase>Building</phrase>.
<phrase>Information</phrase> Resources Development Challenges in a <phrase>Cross-Cultural</phrase> Environment.
Organizations in the <phrase>Western world</phrase> devote much attention to the development of <phrase>information</phrase> systems as <phrase>strategic</phrase> resources. The transfer of this <phrase>management</phrase> practice to a different <phrase>cultural</phrase> environment generates new challenges as reported in the experience of a <phrase>Pacific Basin</phrase> <phrase>public</phrase> institution with <phrase>Western</phrase> <phrase>affiliation</phrase>, while under strong influence of <phrase>local</phrase> cultures and practices. The value of the <phrase>investment</phrase> in <phrase>information</phrase> resources is judged not only on technical merits, but also on the ability of the <phrase>organization</phrase> to properly address the <phrase>cultural</phrase> and <phrase>organizational issues</phrase> related to <phrase>information</phrase> usage.
<phrase>Real Options</phrase> Analysis in <phrase>Strategic</phrase> <phrase>Information Technology</phrase> <phrase>Adoption</phrase>.
<phrase>Virtualization</phrase> and Its Role in <phrase>Business</phrase>.
This <phrase>chapter</phrase> presents some of the aspects of virtualisation and its role in <phrase>modern society</phrase>. In today's world, a controlled virtualisation process creates enormous <phrase>opportunity</phrase> for <phrase>economic growth</phrase> of those countries and organisations, which, so far, due to various restrictions, have had no <phrase>chance</phrase> to become competitive in the <phrase>global</phrase> market. Those people and organisations that know how to make use of the opportunities presented by virtualisation may become more effective in <phrase>business</phrase>. Moreover, virtualisation creates the best options for intellectual enterprise development. Virtualisation is a very complex process. The <phrase>author</phrase> would like to discusses both the <phrase>positive impact</phrase> virtualisation can have on <phrase>society</phrase> and also some <phrase>dangers</phrase> or problems.
<phrase>Information Technology</phrase> <phrase>Strategic</phrase> Alignment.
<phrase>Promotion</phrase> of <phrase>e-Government</phrase> in <phrase>Japan</phrase> and Its Operation.
<phrase>Knowledge</phrase> Discovery Using Heuristics.
<phrase>Artificial Neural Networks</phrase> Used in <phrase>Automobile</phrase> <phrase>Insurance</phrase> <phrase>Underwriting</phrase>.
Modeling <phrase>ERP</phrase> Acedemic Deployment via <phrase>AST</phrase>.
Scenarios for <phrase>Web</phrase>-<phrase>Enhanced Learning</phrase>.
<phrase>Business Model</phrase> <phrase>Innovation</phrase> in the <phrase>Digital Economy</phrase>.
<phrase>Enterprise Resource Planning</phrase> Maintenance Concepts.
<phrase>Multimedia</phrase> Content <phrase>Adaption</phrase>.
Triangular <phrase>Strategic</phrase> Analysis for <phrase>Hybrid</phrase> <phrase>E</phrase>-Retailers.
<phrase>E-Commerce</phrase> <phrase>Curriculum</phrase>.
<phrase>Virtual</phrase> <phrase>Organization</phrase> in the <phrase>Human</phrase> <phrase>Mind</phrase>.
Experiential <phrase>Perspective</phrase> on <phrase>Knowledge Management</phrase>.
<phrase>Mobile Commerce</phrase> <phrase>Technology</phrase>.
<phrase>Bridging</phrase> the <phrase>Industry</phrase>-<phrase>University</phrase> <phrase>Gap</phrase> through <phrase>Action Research</phrase>.
Challenges in <phrase>M-Commerce</phrase>.
Contemporary IT-Assisted <phrase>Retail</phrase> <phrase>Management</phrase>.
<phrase>Security</phrase> and <phrase>Trust</phrase> of <phrase>Online Auction</phrase> Systems.
Quality of <phrase>UML</phrase>.
MESH <phrase>Object-Oriented</phrase> <phrase>Hypermedia</phrase> Framework.
Usable <phrase>M-Commerce</phrase> Systems.
Application of <phrase>Fuzzy Logic</phrase> <phrase>Fraud</phrase> Detection.
<phrase>Structural</phrase> <phrase>Text Mining</phrase>.
The Impact of <phrase>Sound</phrase> Relationships on Achieving Alignment.
<phrase>Internet</phrase> <phrase>Data Mining</phrase> Using <phrase>Statistical Techniques</phrase>.
<phrase>Business</phrase> Modelling with Client-Oriented Requirements Strategy.
<phrase>Adaptive</phrase> <phrase>Mobile</phrase> Applications.
<phrase>Technology</phrase> and Work in the <phrase>Virtual</phrase> <phrase>Organization</phrase>.
<phrase>Enterprise Resource Planning</phrase> and <phrase>Integration</phrase>.
<phrase>Database</phrase> Support for <phrase>M-Commerce</phrase>.
Minorities and the <phrase>Digital Divide</phrase>.
Eight <phrase>Key Elements</phrase> of Successful Self-Funding <phrase>E-Learning</phrase> Programs.
<phrase>DRM</phrase> <phrase>Technology</phrase> for <phrase>Mobile</phrase> <phrase>Multimedia</phrase>.
<phrase>Empirical Study</phrase> of <phrase>E-Commerce</phrase> <phrase>Adoption</phrase> <phrase>SMEs</phrase> in <phrase>Thailand</phrase>.
<phrase>Information</phrase> Resources Development in <phrase>China</phrase>.
<phrase>Certifying</phrase> <phrase>Software</phrase> Product and Processes.
<phrase>Comparing</phrase> Conventional and <phrase>Non-Parametric</phrase> <phrase>Option Pricing</phrase>.
<phrase>Contextual</phrase> <phrase>Metadata</phrase> for <phrase>Document Databases</phrase>.
<phrase>Bayesian</phrase> <phrase>Machine Learning</phrase>.
Intelligent <phrase>Business</phrase> <phrase>Portals</phrase>.
Implementation <phrase>Management</phrase> of an <phrase>E-Commerce</phrase>-<phrase>Enabled Enterprise</phrase> <phrase>Information</phrase> System.
<phrase>Culture</phrase> and <phrase>Anonymity</phrase> in <phrase>GSS</phrase> Meetings.
<phrase>Public Sector</phrase> <phrase>Case Study</phrase> on the Benefits of IS/IT.
Faculty Perceptions and Participation in <phrase>Distance Education</phrase>.
<phrase>Spatial</phrase> Analysis in a <phrase>Public Health</phrase> Setting.
<phrase>User Experiences</phrase> of the <phrase>E-commerce</phrase> Site with the Standard <phrase>User Interface</phrase>.
Newcomer <phrase>Assimilation</phrase> in <phrase>Virtual Team</phrase> <phrase>Socialization</phrase>.
Softening the <phrase>MIS</phrase> <phrase>Curriculum</phrase> for a <phrase>Technology</phrase>-Based <phrase>Profession</phrase>.
<phrase>Strategic</phrase> Alignment of <phrase>Organizational Strategies</phrase>.
<phrase>Introducing</phrase> <phrase>Java</phrase> to the IT <phrase>Master's</phrase> <phrase>Curriculum</phrase>.
Inexperienced and <phrase>Global</phrase> <phrase>Software</phrase> Teams.
<phrase>Simulation</phrase> and <phrase>Gaming</phrase> in IT <phrase>Education</phrase>.
<phrase>Systems Thinking</phrase> and the <phrase>Internet</phrase>.
Speech and <phrase>Audio Signal</phrase> Applications.
<phrase>Wireless</phrase> <phrase>Middleware</phrase>.
<phrase>Trust</phrase> in <phrase>B2C E-Commerce</phrase> for the <phrase>New Zealand</phrase> Maori.
<phrase>Technology</phrase> <phrase>Planning</phrase> in <phrase>Schools</phrase>.
<phrase>Multimedia</phrase> <phrase>Information</phrase> Filtering.
<phrase>Designing</phrase> OMIS-Based Collaboration for <phrase>Learning</phrase> Organizations.
Personal <phrase>Internet</phrase> Usage and Quality of Work <phrase>Life</phrase>.
Trends in <phrase>Information Technology Governance</phrase>.
<phrase>Bridging</phrase> the <phrase>Digital Divide</phrase> in <phrase>Scotland</phrase>.
Critical Strategies for IS Projects.
<phrase>Behavioral</phrase> Factors in <phrase>Strategic Alliances</phrase>.
Multiple <phrase>Internet</phrase> Technologies in In-Class <phrase>Education</phrase>.
<phrase>Business Process</phrase> and <phrase>Workflow</phrase> Modeling in <phrase>Web Services</phrase>.
<phrase>Signature-Based</phrase> <phrase>Indexing</phrase> Techniques for <phrase>Web Access</phrase> Logs.
Transfering <phrase>Technology</phrase> to the <phrase>Developing</phrase> World.
<phrase>Qos</phrase>-Oriented <phrase>MAC</phrase> Protocols for <phrase>Future Mobile</phrase> Applications.
<phrase>Learning</phrase> <phrase>Systems Engineering</phrase>.
Delivering <phrase>Web-Based</phrase> <phrase>Education</phrase>.
<phrase>Object-Oriented</phrase> <phrase>Software</phrase> Metrics.
<phrase>Critical Success Factors</phrase> for <phrase>Distance Education</phrase> Programs.
<phrase>Designing</phrase> Agents with <phrase>Negotiation</phrase> Capabilities.
INFOSEC Policy - The <phrase>Foundation</phrase> for an Effective <phrase>Security</phrase> Program.
<phrase>Decision-Making Support Systems</phrase> and <phrase>Representation Levels</phrase>.
<phrase>Integrating</phrase> <phrase>Requirements Engineering</phrase> Techniques and <phrase>Formal Methods</phrase>.
Future of <phrase>Small Business</phrase> <phrase>E-Commerce</phrase>.
<phrase>Staying</phrase> <phrase>Up-to-Date</phrase> with Changes in IT.
Complex <phrase>Adaptive</phrase> Enterprises.
Success <phrase>Surrogates</phrase> in Representational <phrase>Decision Support Systems</phrase>.
<phrase>Cooperation</phrase> of <phrase>Geographic</phrase> and <phrase>Multidimensional Databases</phrase>.
<phrase>Managing</phrase> <phrase>Value-Creation</phrase> In The <phrase>Digital Economy</phrase>.
<phrase>Hierarchies</phrase> in <phrase>Multidimensional Databases</phrase>.
<phrase>E</phrase>-<phrase>Mail</phrase> as a <phrase>Strategic</phrase> Tool in Organizations.
<phrase>Decision Support Systems</phrase> Concept.
IS <phrase>Project Management</phrase> <phrase>Contemporary Research</phrase> Challenges.
<phrase>Classification-Rule</phrase> Discovery with <phrase>an Ant Colony</phrase> <phrase>Algorithm</phrase>.
<phrase>Internet</phrase> <phrase>Diffusion</phrase> in the <phrase>Hospitality Industry</phrase>.
A <phrase>Web</phrase>-<phrase>Geographical Information System</phrase> to Support <phrase>Territorial</phrase> <phrase>Data Integration</phrase>.
<phrase>Educating</phrase> the <phrase>Business</phrase> <phrase>Information</phrase> Technologist.
<phrase>Text Mining</phrase> in the Context of <phrase>Business Intelligence</phrase>.
<phrase>Web Search</phrase> via <phrase>Learning</phrase> from <phrase>Relevance Feedback</phrase>.
<phrase>Animated</phrase> Characters within the <phrase>MPEG</phrase>-4 Standard.
<phrase>Bayesian</phrase> Modelling for <phrase>Machine Learning</phrase>.
Current <phrase>Network Security</phrase> <phrase>Software</phrase>.
<phrase>Building</phrase> and <phrase>Management</phrase> of <phrase>Trust</phrase> in <phrase>Information</phrase> Systems.
Sharing <phrase>Organizational Knowledge</phrase> through <phrase>Knowledge</phrase> Repositories.
<phrase>Efficient</phrase> <phrase>Multirate</phrase> Filtering.
<phrase>Basic</phrase> Notions on <phrase>Multidimensional</phrase> <phrase>Aggregate Data</phrase>.
<phrase>Managing</phrase> <phrase>Hierarchies</phrase> and Taxonomies in <phrase>Relational Databases</phrase>.
<phrase>Intelligent Software Agents</phrase> in <phrase>E-Commerce</phrase>.
<phrase>Innovation</phrase> Link Between <phrase>Organization</phrase> <phrase>Knowledge</phrase> and <phrase>Customer Knowledge</phrase>.
<phrase>Intelligent Agents</phrase> For <phrase>Competitive Advantage</phrase>.
<phrase>Technology</phrase> and <phrase>Knowledge Management</phrase>.
<phrase>E-Commerce</phrase> <phrase>Taxation</phrase> Issues.
Policy Frameworks for <phrase>Secure</phrase> <phrase>Electronic</phrase> <phrase>Business</phrase>.
A <phrase>Socio-Technical</phrase> <phrase>Case Study</phrase> of <phrase>Bangladesh</phrase>.
Strategically-Focused <phrase>Enterprise Knowledge Management</phrase>.
<phrase>Data Mining</phrase> for <phrase>Supply Chain Management</phrase> <phrase>Complex Networks</phrase>.
Functionalities and Position of <phrase>Manufacturing</phrase> Execution Systems.
<phrase>Constructionist</phrase> <phrase>Perspective</phrase> of Organizational <phrase>Data Mining</phrase>.
<phrase>Next</phrase>-Generation <phrase>ERP</phrase>.
<phrase>Evolution</phrase> of <phrase>ERP</phrase> Systems.
<phrase>Database</phrase> Technologies on the <phrase>Web</phrase>.
Modeling for <phrase>E-Learning</phrase> Systems.
Limited-<phrase>Perspective</phrase> Bias in <phrase>Technology</phrase> Projects.
<phrase>XML Schema</phrase> <phrase>Integration</phrase> and <phrase>E-Commerce</phrase>.
<phrase>Web Accessibility</phrase> and the <phrase>Law</phrase>.
<phrase>Geospatial Information</phrase> Systems and <phrase>Enterprise Collaboration</phrase>.
Discovery of <phrase>Classification Rules</phrase> from <phrase>Databases</phrase>.
Technological Collaboration and <phrase>Trust</phrase> in <phrase>Virtual</phrase> Teams.
<phrase>Change Process</phrase> Drivers for <phrase>E</phrase>-<phrase>Business</phrase>.
Relating <phrase>Cognitive</phrase> <phrase>Problem-Solving</phrase> Style to <phrase>User Resistance</phrase>.
<phrase>Antecedents</phrase> of <phrase>Trust</phrase> in <phrase>Online</phrase> Communities.
<phrase>Digital</phrase> <phrase>Government</phrase> and <phrase>Individual Privacy</phrase>.
The growth of the <phrase>Internet</phrase> and <phrase>digital</phrase> <phrase>government</phrase> has <phrase>dramatically increased</phrase> the <phrase>Federal</phrase> <phrase>government's</phrase> ability to collect, analyze, and disclose <phrase>personal information</phrase> about many <phrase>private</phrase> aspects of citizens' lives. <phrase>Personal information</phrase> once available only on <phrase>paper</phrase> to a limited number of people is now instantly retrievable anywhere in the world by anyone with a computer and an <phrase>Internet</phrase> connection. Over time, there has also been a declining level of <phrase>trust</phrase> by <phrase>Americans</phrase> in <phrase>government</phrase>, and currently, many perceive the <phrase>government</phrase> as a <phrase>potential threat</phrase> to their <phrase>privacy</phrase>. Given these forces at work in our <phrase>society</phrase>, one should not be surprised to read the <phrase>results</phrase> of surveys that show <phrase>privacy</phrase> as a <phrase>top</phrase> concern of citizens in the <phrase>21st century</phrase>. If citizens do not believe that the <phrase>government</phrase> is adequately <phrase>protecting</phrase> the <phrase>privacy</phrase> of their individual <phrase>information</phrase>, they may be less willing to provide this <phrase>information</phrase>. Such reluctance could compromise the ability of <phrase>government</phrase> to collect <phrase>important information</phrase> necessary to develop, administer and evaluate the impact of various policies and programs. <phrase>Privacy</phrase> issues discussed in this <phrase>chapter</phrase> include challenges regarding (1) <phrase>protecting personal</phrase> <phrase>privacy</phrase>; (2) ensuring confidentiality of <phrase>data</phrase> collected; and (3) <phrase>implementing</phrase> appropriate <phrase>security</phrase> controls. Perspectives on <phrase>privacy</phrase> and <phrase>stewardship</phrase> responsibilities of agencies are also discussed.
<phrase>Dynamic</phrase> <phrase>Multidimensional Data Cubes</phrase> for Interactive Analysis of <phrase>Massive</phrase> Datasets.
<phrase>Virtual</phrase> Work, <phrase>Trust</phrase> and <phrase>Rationality</phrase>.
Extensions to <phrase>UML</phrase> Using <phrase>Stereotypes</phrase>.
<phrase>Agent-Based Negotiation</phrase> in <phrase>E</phrase>-<phrase>Marketing</phrase>.
<phrase>Risk Management</phrase> in the <phrase>Digital Economy</phrase>.
<phrase>Contract</phrase>-Based <phrase>Workflow</phrase> <phrase>Design Patterns</phrase> in <phrase>M-Commerce</phrase>.
Modeling <phrase>Information</phrase> Systems in <phrase>UML</phrase>.
<phrase>E</phrase>-<phrase>Business</phrase> Transaction in <phrase>Web</phrase> <phrase>Integrated Network</phrase> Environment.
<phrase>Inclusion Dependencies</phrase>.
<phrase>Multimedia</phrase> <phrase>Computing</phrase> Environment for <phrase>Telemedical</phrase> Applications.
<phrase>Conducting</phrase> <phrase>Ethical</phrase> <phrase>Research</phrase> in <phrase>Virtual</phrase> Environments.
<phrase>Technology-Mediated</phrase> <phrase>Progressive</phrase> <phrase>Inquiry</phrase> in <phrase>Higher Education</phrase>.
<phrase>Adaptive</phrase> <phrase>Playout</phrase> <phrase>Control Schemes</phrase> for Speech over the <phrase>Internet</phrase>.
Issues in Delivering <phrase>Course Material</phrase> via the <phrase>Web</phrase>.
How Teachers Use <phrase>Instructional Design</phrase> in Real Classrooms.
<phrase>Strategic</phrase> <phrase>Experimentation</phrase> and <phrase>Knowledge Management</phrase>.
Trends and Perspectives in <phrase>Online</phrase> <phrase>Education</phrase>.
<phrase>Evaluating</phrase> <phrase>Computer-Supported</phrase> <phrase>Learning</phrase> Initiatives.
<phrase>Designing</phrase> <phrase>Web Applications</phrase>.
Innovations for <phrase>Online</phrase> <phrase>Collaborative Learning</phrase> in <phrase>Mathematics</phrase>.
<phrase>Shaping</phrase> the <phrase>Evolution</phrase> of <phrase>Mobile Commerce</phrase>.
<phrase>Basics</phrase> of the <phrase>Triune</phrase> <phrase>Continuum</phrase> <phrase>Paradigm</phrase>.
A <phrase>University</phrase>/<phrase>Community</phrase> <phrase>Partnership</phrase> to <phrase>Bridge</phrase> the <phrase>Digital Divide</phrase>.
<phrase>Data Mining</phrase> and <phrase>Mobile</phrase> <phrase>Business</phrase> <phrase>Data</phrase>.
<phrase>Virtual</phrase> <phrase>Schools</phrase>.
<phrase>Wireless</phrase> Technologies to Enable <phrase>Electronic</phrase> <phrase>Business</phrase>.
<phrase>Developing</phrase> <phrase>Dynamic</phrase> <phrase>Balanced Scorecards</phrase>.
<phrase>Music</phrase> Score <phrase>Watermarking</phrase>.
<phrase>Non-Functional Requirements</phrase> and <phrase>UML</phrase> <phrase>Stereotypes</phrase>.
<phrase>Knowledge</phrase>-Based <phrase>Support Environment</phrase>.
<phrase>Combining</phrase> <phrase>Local</phrase> and <phrase>Global</phrase> Expertise in Services.
Bibliomining for <phrase>Library</phrase> <phrase>Decision-Making</phrase>.
Defining and <phrase>Understanding</phrase> <phrase>ERP</phrase> Systems.
<phrase>Interoperability</phrase> of <phrase>Information</phrase> Systems.
Survey of 3D <phrase>Human</phrase> Body Representations.
<phrase>Classroom</phrase> <phrase>Communication</phrase> on a Different <phrase>Blackboard</phrase>.
<phrase>Implementing</phrase> an <phrase>Online</phrase> <phrase>Academic</phrase> Evaluation System.
<phrase>Delineating</phrase> <phrase>Knowledge</phrase> Flows for <phrase>Enterprise Agility</phrase>.
The <phrase>Organizational Context</phrase> in the Use of a <phrase>Workflow</phrase> System.
Critical Trends in <phrase>Telecommunications</phrase>.
<phrase>Social Responsibility</phrase> and the <phrase>Technology</phrase> <phrase>Paradigm</phrase> in <phrase>Latin America</phrase>.
Distributed <phrase>Recommender Systems</phrase> for <phrase>Internet</phrase> <phrase>Commerce</phrase>.
<phrase>Model</phrase>-Supported Alignment of IS <phrase>Architecture</phrase>.
A <phrase>Primer</phrase> on <phrase>E-Government</phrase>.
<phrase>Enhancing</phrase> Workplaces with Constructine <phrase>Online</phrase> Recreation.
<phrase>Digitization</phrase> of <phrase>Library</phrase> <phrase>Information</phrase> and its Accessibilty for <phrase>People with Disabilities</phrase>.
Progammed Instruction, Programmed <phrase>Branching</phrase>, and <phrase>Learning</phrase> Outcomes.
<phrase>Software</phrase> Requirements <phrase>Risk</phrase> and <phrase>Maintainability</phrase>.
<phrase>Human Body</phrase> Part Classification and <phrase>Activity Recognition</phrase> for <phrase>Real-Time Systems</phrase>.
<phrase>Functional</phrase> Dependency and Other Related Dependancies.
<phrase>Software</phrase> Reuse in <phrase>Hypermedia</phrase> Applications.
<phrase>Computing</phrase> <phrase>Curriculum</phrase> Analysis and Development.
Storage and <phrase>Access Control</phrase> Issues for <phrase>XML</phrase> Documents.
Strategies of <phrase>E-Commerce</phrase> <phrase>Business</phrase> Value Optimization.
<phrase>Developing</phrase> <phrase>Trust</phrase> in <phrase>Virtual</phrase> Teams.
<phrase>Software</phrase> Agents in <phrase>E-Commerce</phrase> Systems.
New <phrase>SQL</phrase> Standard in <phrase>Database</phrase> Modeling.
<phrase>Leader</phrase>-Facilitated <phrase>Relationship Building</phrase> in <phrase>Virtual</phrase> Teams.
<phrase>Program Execution</phrase> and Visualization on the <phrase>Web</phrase>.
<phrase>Programming</phrase> is a <phrase>demanding task</phrase> with an <phrase>education</phrase> program that requires the <phrase>assistance</phrase> of complex tools such as <phrase>programming</phrase> environments, <phrase>algorithm</phrase> animators, problem graders, etc. In this <phrase>chapter</phrase>, we give a <phrase>comprehensive</phrase> presentation of tools for <phrase>program execution</phrase> and visualization on the <phrase>Web</phrase>. We summarize the technical <phrase>evolution</phrase> of these tools, describe educational uses, <phrase>report</phrase> <phrase>lessons</phrase> learned, and look at formal evaluations of their <phrase>educational effectiveness</phrase>. We also deal with a <phrase>closely related</phrase> <phrase>matter</phrase>, namely, collections of <phrase>Web</phrase> documents containing <phrase>programming</phrase> exercises. <phrase>Finally</phrase>, we outline our view of <phrase>future trends</phrase> in the use of the <phrase>Web</phrase> for <phrase>programming</phrase> <phrase>education</phrase>, and we give our personal conclusions. This <phrase>chapter</phrase> is of interest to educators and researchers, because it gives a <phrase>comprehensive</phrase> presentation of the <phrase>main issues</phrase> and <phrase>results</phrase> of a field where most of the contributions are <phrase>sparse</phrase> in the <phrase>literature</phrase>.
Metrics for <phrase>Data Warehouse</phrase> Quality.
<phrase>Institutional</phrase> Dimensions of <phrase>Information</phrase> Systems Evaluation.
IT <phrase>Productivity</phrase> Impacts in <phrase>Manufacturing</phrase> Contexts.
Obstacles for <phrase>SMEs</phrase> for <phrase>E</phrase>-<phrase>Adoption</phrase> in the <phrase>Asia Pacific Region</phrase>.
<phrase>SMEs</phrase> in <phrase>Knowledge</phrase>-Based Economies.
<phrase>End-User Computing</phrase> Success Measurement.
<phrase>Essentials</phrase> of <phrase>Functional</phrase> and <phrase>Object-Oriented</phrase> Methodology.
Students' Perceptions of <phrase>Online</phrase> Courses.
<phrase>Information</phrase> Systems and <phrase>Technology</phrase> in <phrase>South Africa</phrase>.
Departure of the <phrase>Expert Systems</phrase> <phrase>Project</phrase> <phrase>Champion</phrase>.
The <phrase>Social Contract</phrase> <phrase>Revised</phrase>.
Observations on <phrase>Implementing</phrase> Specializations Within an IT Program.
<phrase>Citizenship</phrase> and New Technologies.
<phrase>Changing Trends</phrase> in the <phrase>Preparation</phrase> of <phrase>Print Media</phrase>.
<phrase>Generic</phrase> Framework for Defining <phrase>Domain-Specific</phrase> Models.
<phrase>Management</phrase> of <phrase>Cognitive</phrase> and <phrase>Affective</phrase> <phrase>Trust</phrase> to Support Collaboration.
<phrase>Life</phrase> Cycle of <phrase>ERP</phrase> Systems.
<phrase>Liability</phrase> for System and <phrase>Data Quality</phrase>.
Uses and <phrase>Gratifications</phrase> for <phrase>the World Wide Web</phrase>.
<phrase>Tailorable</phrase> <phrase>Information</phrase> Systems.
<phrase>Best Practices</phrase> for Effective <phrase>Virtual</phrase> Teams.
System Development for <phrase>E</phrase>-<phrase>Business</phrase>.
<phrase>Public-Key Cryptography</phrase>.
<phrase>Component-Oriented</phrase> Approach for <phrase>Designing</phrase> <phrase>Enterprise Architecture</phrase>.
<phrase>Digital Asset Management</phrase> Concepts.
Organizational <phrase>Hypermedia</phrase> <phrase>Document Management</phrase> Through <phrase>Metadata</phrase>.
<phrase>Governance</phrase> Structures for IT in the <phrase>Health Care</phrase> <phrase>Industry</phrase>.
<phrase>Histogram</phrase> Generation from the <phrase>HSV</phrase> <phrase>Color Space</phrase>.
<phrase>Legal</phrase> <phrase>Expert Systems</phrase> in Administrative Organizations.
<phrase>Technology</phrase> in the <phrase>Foreign Language</phrase> <phrase>Classroom</phrase>.
<phrase>Integration</phrase> Framework for <phrase>Complex Systems</phrase>.
<phrase>Personal Information</phrase> <phrase>Privacy</phrase> and <phrase>Internet</phrase> <phrase>Technology</phrase>.
<phrase>Cognitive</phrase> <phrase>Research</phrase> in <phrase>Information</phrase> Systems.
<phrase>Mobile</phrase> <phrase>Telecommunications</phrase> and <phrase>M-Commerce</phrase> Applications.
<phrase>Agent-Based</phrase> <phrase>Intelligence</phrase> <phrase>Infrastructure</phrase>.
<phrase>ERP</phrase> <phrase>Adoption</phrase> by <phrase>Indian</phrase> Organizations.
<phrase>Information</phrase> Laws.
<phrase>Cross-Culture</phrase> <phrase>Communication</phrase>.
<phrase>Bridging</phrase> the Growing <phrase>Digital Divide</phrase>.
<phrase>Actor</phrase>-<phrase>Network Theory</phrase> in <phrase>Information</phrase> Systems <phrase>Research</phrase>.
Modelling <phrase>Technological Change</phrase> in <phrase>Small Business</phrase>.
<phrase>Actor</phrase>-<phrase>Network Theory</phrase> and <phrase>Adoption</phrase> of <phrase>E-Commerce</phrase> in <phrase>SMEs</phrase>.
<phrase>Ecological</phrase> Models and <phrase>Information</phrase> Systems <phrase>Curriculum</phrase>.
<phrase>Knowledge</phrase> Exchange in <phrase>Electronic</phrase> Networks of Practice.
<phrase>Designing</phrase> <phrase>Hypertext</phrase> and the <phrase>Web</phrase>.
<phrase>Business</phrase> Strategy, Structure and IT Alignment.
<phrase>Building</phrase> <phrase>Local</phrase> Capacity via <phrase>Scaleable</phrase> <phrase>Web-Based</phrase> Services.
<phrase>Querying</phrase> <phrase>Multidimensional Data</phrase>.
A powerful and easy-to-use <phrase>querying</phrase> environment is certainly one of the most important components in a <phrase>multidimensional</phrase> <phrase>database</phrase>, and its effectiveness is influenced by many other aspects, both <phrase>logical</phrase> (<phrase>data model</phrase>, <phrase>integration</phrase>, policy of <phrase>view materialization</phrase>, etc.) and physical (<phrase>multidimensional</phrase> or <phrase>relational</phrase> storage, indexes, etc.). As is evident, <phrase>multidimensional</phrase> <phrase>querying</phrase> is often based on the <phrase>metaphor</phrase> of the <phrase>data</phrase> <phrase>cube</phrase> and on the concepts of facts, measures, and dimensions. In contrast to conventional <phrase>transactional</phrase> environments, <phrase>multidimensional</phrase> <phrase>querying</phrase> is often <phrase>an exploratory</phrase> process, performed by <phrase>navigating</phrase> along the dimensions and measures, increasing/decreasing the <phrase>level of detail</phrase> and focusing on specific subparts of the <phrase>cube</phrase> that appear to be "promising" for the required information.In this <phrase>chapter</phrase> we focus on the main languages proposed in the <phrase>literature</phrase> to express <phrase>multidimensional</phrase> queries, particularly those based on: (<phrase>i</phrase>) <phrase>an algebraic</phrase> approach, (<phrase>ii</phrase>) a <phrase>declarative</phrase> <phrase>paradigm</phrase> (<phrase>calculus</phrase>), and (<phrase>iii</phrase>) <phrase>visual</phrase> constructs and <phrase>syntax</phrase>. We analyze the problem of evaluation, i.e., the issues related to the <phrase>efficient</phrase> <phrase>data</phrase> retrieval and calculation, possibly (often necessarily) using some <phrase>pre-computed</phrase> <phrase>data</phrase>, a problem known in the <phrase>literature</phrase> as the problem of <phrase>rewriting</phrase> a query using views. We also illustrate the use of particular <phrase>index</phrase> structures to <phrase>speed up</phrase> the <phrase>query evaluation</phrase> process.
<phrase>Improving</phrase> <phrase>Virtual</phrase> Teams Through <phrase>Creativity</phrase>.
Leapfrogging an IT Sector.
<phrase>Qualitative</phrase> Methods in IS <phrase>Research</phrase>.
<phrase>E</phrase>-<phrase>Business</phrase> Systems <phrase>Security</phrase> for Intelligent Enterprise.
<phrase>Implementing</phrase> the Shared Event <phrase>Paradigm</phrase>.
<phrase>Audience-Driven</phrase> <phrase>Web Site Design</phrase>.
<phrase>Web</phrase> Tools for <phrase>Molecular Biological</phrase> <phrase>Data Analysis</phrase>.
Monitoring Strategies for <phrase>Internet</phrase> Technologies.
<phrase>Digital Literacy</phrase> and the Position of the <phrase>End-User</phrase>.
<phrase>Intranet</phrase> Use and <phrase>Emergence</phrase> of Networks of Practice.
Metrics for the Evaluation of <phrase>Test</phrase> <phrase>Delivery Systems</phrase>.
<phrase>Face Expression</phrase> and <phrase>Motion Analysis</phrase> over <phrase>Monocular</phrase> Images.
<phrase>Artificial Neural Networks</phrase> in <phrase>Financial Trading</phrase>.
<phrase>Surveying</phrase> <phrase>Mobile Commerce</phrase> Environments.
<phrase>Content-Based Image Retrieval</phrase> Query Paradigms.
<phrase>Analyzing</phrase> the Quality of <phrase>Virtual</phrase> Teams.
<phrase>Bayesian Analysis</phrase> of Geographical Variation in <phrase>Disease</phrase> <phrase>Risk</phrase>.
<phrase>Simulation</phrase> in <phrase>Information</phrase> Systems <phrase>Research</phrase>.
<phrase>Cluster Analysis</phrase> Using <phrase>Rough Clustering</phrase> and <phrase>k-Means Clustering</phrase>.
Networks and <phrase>Electronic Commerce</phrase> <phrase>Adoption</phrase> in <phrase>Small Businesses</phrase>.
<phrase>Information</phrase> and <phrase>Communication</phrase> <phrase>Technology</phrase> Tools for <phrase>Competitive Intelligence</phrase>.
<phrase>Supporting</phrase> the Evaluation of Intelligent Sources.
<phrase>Data</phrase> Dissemination in <phrase>Mobile</phrase> <phrase>Databases</phrase>.
<phrase>Trust</phrase> in <phrase>B2C E-Commerce</phrase> Interface.
<phrase>GIS</phrase>-Based Accessibility Measures and Application.
IT <phrase>Industry</phrase> Success in <phrase>Finland</phrase> and <phrase>New Zealand</phrase>.
<phrase>Enhanced</phrase> <phrase>Knowledge</phrase> <phrase>Warehouse</phrase>.
<phrase>Learning</phrase> 3D <phrase>Face Animation</phrase> <phrase>Model</phrase>.
<phrase>E</phrase>-Governement <phrase>Interoperability</phrase>.
<phrase>Data</phrase> Collection Methodologies for <phrase>Web-Based</phrase> Experiments.
<phrase>Ethical</phrase> Implications of <phrase>Investigating</phrase> <phrase>Internet</phrase> Relationships.
"<phrase>Anytime</phrase>, Anywhere" in the Context of <phrase>Mobile</phrase> Work.
<phrase>Knowledge</phrase> Discovery Solutions for Intelligent Enterprises.
<phrase>Evaluating</phrase> IS Quality as a Measure of IS Effectiveness.
<phrase>E</phrase>-<phrase>Mail</phrase> and <phrase>Communication</phrase>.
IT Implementation in <phrase>Small Business</phrase>.
<phrase>Trust</phrase> in <phrase>Virtual</phrase> Enterprises.
<phrase>Designing</phrase> <phrase>High</phrase> Performance <phrase>Virtual</phrase> Teams.
<phrase>Improving</phrase> <phrase>Public Sector</phrase> <phrase>Service Delivery</phrase> through <phrase>Knowledge</phrase> Sharing.
<phrase>Traversal Pattern Mining</phrase> in <phrase>Web Usage Data</phrase>.
<phrase>Applying</phrase> a <phrase>Metadata</phrase> Framework to Improve <phrase>Data Quality</phrase>.
<phrase>Java 2 Micro Edition</phrase> for <phrase>Wireless</phrase> Enterprose.
Distributed <phrase>Construction</phrase> through <phrase>Participatory Design</phrase>.
<phrase>Tactic</phrase> <phrase>Knowledge</phrase> and <phrase>Discourse Analysis</phrase>.
<phrase>Advanced</phrase> Techniques for <phrase>Object-Based Image Retrieval</phrase>.
<phrase>Knowledge Management</phrase> on the <phrase>Web</phrase>.
<phrase>Neural Networks</phrase> for <phrase>Retail</phrase> <phrase>Sales Forecasting</phrase>.
New Advancements in <phrase>Image Segmentation</phrase> for <phrase>CBIR</phrase>.
The Impact of IT on <phrase>Business</phrase> Partnerships and <phrase>Organizational Structures</phrase>.
<phrase>Open Source Software</phrase> Development <phrase>Model</phrase>.
<phrase>Fault Tolerance</phrase> for Distributed and <phrase>Networked</phrase> Systems.
Isochronus <phrase>Distributed Multimedia</phrase> Synchronization.
<phrase>Integrated-Services</phrase> <phrase>Architecture</phrase> for <phrase>Building</phrase> <phrase>Internet</phrase> <phrase>Multimedia</phrase> Applications.
<phrase>Knowledge</phrase> Discovery from <phrase>Databases</phrase>.
<phrase>Discovering Association Rules</phrase> in <phrase>Temporal Databases</phrase>.
<phrase>Kernelized</phrase> <phrase>Database Systems</phrase> <phrase>Security</phrase>.
<phrase>Collective Knowledge</phrase> Composition in a <phrase>P2P</phrase> Network.
<phrase>E-Government</phrase> <phrase>Databases</phrase>.
<phrase>Converting</phrase> a <phrase>Legacy</phrase> <phrase>Database</phrase> to <phrase>Object-Oriented</phrase> <phrase>Database</phrase>.
<phrase>E</phrase>-<phrase>Mail</phrase> <phrase>Data</phrase> Stores.
Proper Placement of <phrase>Derived Classes</phrase> in the <phrase>Class Hierarchy</phrase>.
<phrase>Replication</phrase> Mechanisms Over a Set of Distributed <phrase>UDDI Registries</phrase>.
<phrase>Logic</phrase> <phrase>Databases</phrase> and <phrase>Inconsistency</phrase> Handling.
<phrase>High</phrase> Quality Conceptual Schemes.
A <phrase>Rhetorical</phrase> <phrase>Perspective</phrase> on Localization and International <phrase>Outsourcing</phrase>.
<phrase>Hierarchical</phrase> <phrase>Architecture</phrase> of <phrase>Expert Systems</phrase> for <phrase>Database Management</phrase>.
<phrase>Ontological</phrase> Assumptions in <phrase>Information</phrase> Modeling.
<phrase>Intension</phrase> <phrase>Mining</phrase>.
<phrase>Integrative</phrase> Document and <phrase>Content Management</phrase> <phrase>Systems Architecture</phrase>.
Dataveillance and Panoptic Marketspaces.
<phrase>Advanced</phrase> <phrase>Query Optimization</phrase>.
<phrase>Main Memory Databases</phrase>.
<phrase>Business</phrase> Rules in <phrase>Databases</phrase>.
<phrase>Database Replication</phrase> Protocols.
<phrase>Data Warehouses</phrase>.
<phrase>Text Databases</phrase>.
<phrase>Relational</phrase>, <phrase>Object-Oriented</phrase> and <phrase>Object-Relational</phrase> <phrase>Data</phrase> Models.
<phrase>Online</phrase> <phrase>Data Mining</phrase>.
<phrase>Extended Entity Relationship</phrase> Modeling.
<phrase>Symbolic</phrase> Objects and <phrase>Symbolic</phrase> <phrase>Data Analysis</phrase>.
<phrase>Integration</phrase> of <phrase>Data</phrase> <phrase>Semantics</phrase> in <phrase>Heterogeneous Database</phrase> <phrase>Federations</phrase>.
<phrase>Query Operators</phrase> in <phrase>Temporal XML</phrase> <phrase>Databases</phrase>.
<phrase>Raster</phrase> <phrase>Databases</phrase>.
Since the launch of <phrase>Google Earth</phrase> at the latest it is clear that <phrase>online</phrase> services for <phrase>multi-Terabyte</phrase> <phrase>satellite imagery</phrase> are becoming <phrase>integral</phrase> part of our <phrase>Internet</phrase> experience. Actually, 2-<phrase>D</phrase> imagery is but the <phrase>tip</phrase> of the <phrase>iceberg</phrase> - the <phrase>general</phrase> concept of <phrase>multi-dimensional</phrase> <phrase>spatio-temporal</phrase> <phrase>raster</phrase> <phrase>data</phrase> covers 1-<phrase>D</phrase> <phrase>sensor</phrase> <phrase>time series</phrase>, 2-<phrase>D</phrase> imagery, 3-<phrase>D</phrase> image <phrase>time series</phrase> (<phrase>x/y</phrase>/<phrase>t</phrase>) and <phrase>exploration</phrase> <phrase>data</phrase> (<phrase>x/y/z</phrase>), 4-<phrase>D</phrase> <phrase>climate</phrase> models (<phrase>x/y/z</phrase>/<phrase>t</phrase>), and many more.
Ensuring <phrase>Serializability</phrase> for <phrase>Mobile</phrase>-Client <phrase>Data Caching</phrase>.
<phrase>Databases</phrase> for <phrase>Mobile</phrase> Applications.
<phrase>Rough Sets</phrase>.
<phrase>Data Model</phrase> <phrase>Versioning</phrase> and <phrase>Database</phrase> <phrase>Evolution</phrase>.
<phrase>Vertical</phrase> <phrase>Database Design</phrase> for Scalable <phrase>Data Mining</phrase>.
<phrase>Ontology</phrase>-Based <phrase>Data Integration</phrase>.
<phrase>Database</phrase> Support for <phrase>Workflow</phrase> <phrase>Management</phrase> Systems.
<phrase>Real-Time</phrase> <phrase>Databases</phrase>.
<phrase>Object Modeling</phrase> of <phrase>RDBMS Based</phrase> Applications.
<phrase>Business-to-Business Integration</phrase>.
<phrase>Knowledge</phrase> <phrase>Mining</phrase>.
<phrase>Enterprise Application Integration</phrase>.
<phrase>Moving Objects</phrase> <phrase>Databases</phrase>.
<phrase>Database</phrase> <phrase>Engineering</phrase> Focusing on Modern Dynamism Crises.
<phrase>Multimedia</phrase> <phrase>Databases</phrase>.
Using Views to Query <phrase>XML</phrase> Documents.
<phrase>Open Source Software</phrase> and <phrase>Information</phrase> Systems on the <phrase>Web</phrase>.
<phrase>Set Valued</phrase> Attributes.
Normalizing <phrase>Multimedia</phrase> <phrase>Databases</phrase>.
Consistency in <phrase>Spatial Databases</phrase>.
Metric <phrase>Databases</phrase>.
<phrase>Storing XML Documents</phrase> in <phrase>Databases</phrase>.
<phrase>Path-Oriented</phrase> Queries and <phrase>Tree Inclusion</phrase> Problems.
<phrase>Ubiquitous Computing</phrase> and <phrase>Databases</phrase>.
<phrase>Signature Files</phrase> and <phrase>Signature File</phrase> <phrase>Construction</phrase>.
<phrase>Semantic</phrase> <phrase>Information Management</phrase>.
Sensors, Uncertainty Models, and <phrase>Probabilistic</phrase> Queries.
<phrase>Data Warehousing</phrase> and <phrase>OLAP</phrase>.
The <phrase>Information</phrase> Quality of <phrase>Databases</phrase>.
<phrase>Text Categorization</phrase>.
<phrase>Active</phrase> <phrase>Database Management Systems</phrase>.
Querical <phrase>Data</phrase> Networks.
<phrase>Query Processing</phrase> in <phrase>Spatial Databases</phrase>.
<phrase>Extraction-Transformation-Loading</phrase> Processes.
<phrase>Free Software</phrase> and <phrase>Open Source</phrase> <phrase>Databases</phrase>.
<phrase>Open Source</phrase> <phrase>Database Management Systems</phrase>.
Set Comparison in <phrase>Relational Query Languages</phrase>.
<phrase>Biological Data Mining</phrase>.
<phrase>Deriving</phrase> <phrase>Spatial Integrity Constraints</phrase> from <phrase>Geographic</phrase> Application Schemas.
<phrase>Query Processing</phrase> for <phrase>RDF</phrase> <phrase>Data</phrase>.
<phrase>Data Warehousing</phrase>, <phrase>Multi-Dimensional Data</phrase> Models, and <phrase>OLAP</phrase>.
Modeling and <phrase>Querying</phrase> <phrase>Temporal Data</phrase>.
<phrase>Temporal Databases</phrase>.
<phrase>Benchmarking</phrase> and <phrase>Data</phrase> Generation in <phrase>Moving Objects</phrase> <phrase>Databases</phrase>.
<phrase>Mathematics</phrase> of <phrase>Generic</phrase> Specifications for <phrase>Model</phrase> <phrase>Management</phrase>, <phrase>I</phrase>.
<phrase>Spatio-Temporal Indexing</phrase> Techniques.
<phrase>Mathematics</phrase> of <phrase>Generic</phrase> Specifications for <phrase>Model</phrase> <phrase>Management</phrase>, <phrase>II</phrase>.
<phrase>Active</phrase> <phrase>Federated Database Systems</phrase>.
<phrase>Generic Model Management</phrase>.
<phrase>Digital Media</phrase> <phrase>Warehouses</phrase>.
Semantically Modeled <phrase>Enterprise Databases</phrase>.
<phrase>Biometric</phrase> <phrase>Databases</phrase>.
<phrase>Knowledge</phrase> Discovery and <phrase>Geographical Databases</phrase>.
Multiparticipant <phrase>Decision Making</phrase> and <phrase>Balanced Scorecard</phrase> Collaborative.
<phrase>Semantic Enrichment</phrase> of <phrase>Geographical Databases</phrase>.
<phrase>Knowledge Management</phrase> in <phrase>Tourism</phrase>.
<phrase>Syntactical</phrase> and <phrase>Semantical</phrase> Correctness of <phrase>Pictorial</phrase> Queries for <phrase>GIS</phrase>.
<phrase>Ontologies</phrase> and Their <phrase>Practical Implementation</phrase>.
<phrase>Data</phrase> Dissemination.
Using <phrase>Semantic Web</phrase> Tools for <phrase>Ontologies</phrase> <phrase>Construction</phrase>.
<phrase>Repairing</phrase> Inconsistent <phrase>XML</phrase> <phrase>Data</phrase> with <phrase>Functional</phrase> Dependencies.
<phrase>Geometric</phrase> Quality in <phrase>Geographic Information</phrase>.
<phrase>Managing</phrase> <phrase>Inconsistent Databases</phrase> Using <phrase>Active Integrity Constraints</phrase>.
<phrase>Object-Relational</phrase> Modeling in the <phrase>UML</phrase>.
<phrase>Replication</phrase> Methods and Their Properties.
Service Mechanism Quality for <phrase>Enhanced</phrase> <phrase>Mobile</phrase> <phrase>Multimedia</phrase> <phrase>Database</phrase> <phrase>Query Processing</phrase>.
Transaction <phrase>Concurrency</phrase> Methods.
<phrase>Common Information Model</phrase>.
<phrase>Document Versioning</phrase> in <phrase>Digital Libraries</phrase>.
<phrase>Multilevel</phrase> <phrase>Databases</phrase>.
<phrase>Component-Based</phrase> <phrase>Generalized</phrase> <phrase>Database</phrase> <phrase>Index</phrase> <phrase>Model</phrase>.
An <phrase>XML</phrase> <phrase>Multi-Tier</phrase> Pattern Dissemination System.
<phrase>Bioinformatics</phrase> <phrase>Data Management</phrase> and <phrase>Data Mining</phrase>.
<phrase>Natural Language Front-End</phrase> for a <phrase>Database</phrase>.
<phrase>Applying</phrase> <phrase>Database</phrase> Techniques to the <phrase>Semantic Web</phrase>.
Preferred Repairs for <phrase>Inconsistent Databases</phrase>.
<phrase>Rewriting</phrase> and <phrase>Efficient</phrase> Computation of Bound <phrase>Disjunctive Datalog</phrase> Queries.
<phrase>Rewriting</phrase> and <phrase>Efficient</phrase> Computation of Bound <phrase>Disjunctive Datalog</phrase> Queries.
<phrase>Transformation-Based</phrase> <phrase>Database</phrase> <phrase>Engineering</phrase>.
<phrase>CASE Tools</phrase> for <phrase>Database</phrase> <phrase>Engineering</phrase>.
<phrase>Checking Integrity Constraints</phrase> in a <phrase>Distributed Database</phrase>.
Optimization of <phrase>Continual</phrase> Queries.
<phrase>Security</phrase> Controls for <phrase>Database</phrase> <phrase>Technology</phrase> and Applications.
<phrase>Similarity Search</phrase> in <phrase>Time Series</phrase> <phrase>Databases</phrase>.
<phrase>Database Query</phrase> <phrase>Personalization</phrase>.
<phrase>Data Quality</phrase> Assessment.
A <phrase>Development Environment</phrase> for <phrase>Customer-Oriented</phrase> <phrase>Web</phrase> <phrase>Business</phrase>.
<phrase>Transactional</phrase> Support for <phrase>Mobile</phrase> <phrase>Databases</phrase>.
<phrase>Engineering</phrase> <phrase>Information</phrase> Modeling in <phrase>Databases</phrase>.
Fuzzy <phrase>Database</phrase> Modeling.
<phrase>Semistructured Data</phrase> and its <phrase>Conceptual Models</phrase>.
<phrase>Management</phrase> of Large <phrase>Moving Objects</phrase> Datasets: <phrase>Indexing</phrase>, <phrase>Benchmarking</phrase> and Uncertainty in Movement Representation.
<phrase>Approximate</phrase> Computation of <phrase>Distance-Based</phrase> Queries.
<phrase>Spatiotemporal</phrase> Prediction using <phrase>Data Mining</phrase> Tools.
<phrase>Object-Relational</phrase> <phrase>Spatial Indexing</phrase>.
<phrase>Integrating</phrase> <phrase>Web Data</phrase> and <phrase>Geographic</phrase> <phrase>Knowledge</phrase> into <phrase>Spatial Databases</phrase>.
<phrase>Spatial</phrase> Joins: <phrase>Algorithms</phrase>, <phrase>Cost Models</phrase> and <phrase>Optimization Techniques</phrase>.
<phrase>Quadtree</phrase>-<phrase>Based Image</phrase> Representation and Retrieval.
Similarity <phrase>Learning</phrase> in <phrase>GIS</phrase>: <phrase>An Overview</phrase> of Definitions, Prerequisites and Challenges.
Survey on <phrase>Spatial Data</phrase> <phrase>Modelling Approaches</phrase>.
<phrase>Indexing</phrase> <phrase>Multi-Dimensional</phrase> Trajectories for <phrase>Similarity Queries</phrase>.
<phrase>Mining</phrase> in <phrase>Spatiotemporal Databases</phrase>.
Applications of <phrase>Moving Objects</phrase> <phrase>Databases</phrase>.
Simple and <phrase>Incremental</phrase> <phrase>Nearest-Neighbor Search</phrase> for <phrase>Spatiotemporal Databases</phrase>.
<phrase>Source Integration</phrase> for <phrase>Data Warehousing</phrase>.
While the <phrase>main goal</phrase> of a <phrase>data warehouse</phrase> is to provide support for <phrase>data analysis</phrase> and management's decisions, a fundamental <phrase>aspect</phrase> in <phrase>design</phrase> of a <phrase>data warehouse</phrase> system is the process of <phrase>acquiring</phrase> the <phrase>raw data</phrase> from a set of <phrase>relevant information</phrase> sources. We will call <phrase>source integration</phrase> system the component of a <phrase>data warehouse</phrase> system dealing with this process. The <phrase>main goal</phrase> of a <phrase>source integration</phrase> system is to deal with the transfer of <phrase>data</phrase> from the set of sources constituting the <phrase>application-oriented</phrase> <phrase>operational environment</phrase>, to the <phrase>data warehouse</phrase>. Since sources are typically <phrase>autonomous</phrase>, distributed, and heterogeneous, this task has to deal with the problem of <phrase>cleaning</phrase>, reconciling, and <phrase>integrating</phrase> <phrase>data</phrase> coming from the sources. The <phrase>design</phrase> of a <phrase>source integration</phrase> system is a very <phrase>complex task</phrase>, which comprises several different issues. The purpose of this <phrase>chapter</phrase> is to discuss the most important <phrase>problems arising</phrase> in the <phrase>design</phrase> of a <phrase>source integration</phrase> system, with <phrase>special emphasis</phrase> on <phrase>schema integration</phrase>, <phrase>processing queries</phrase> for <phrase>data integration</phrase>, and <phrase>data cleaning</phrase> and <phrase>reconciliation</phrase>.
<phrase>Incomplete Information</phrase> in <phrase>Multidimensional Databases</phrase>.
While <phrase>incomplete information</phrase> is <phrase>endemic</phrase> to <phrase>real-world data</phrase>, current <phrase>multidimensional data</phrase> models are not engineered to manage <phrase>incomplete information</phrase> in base <phrase>data</phrase>, <phrase>derived data</phrase>, and dimensions. This <phrase>chapter</phrase> presents several strategies for <phrase>managing</phrase> <phrase>incomplete information</phrase> in <phrase>multidimensional databases</phrase>. Which strategy to use is dependent on the kind of <phrase>incomplete information</phrase> present, and also on where it occurs in the <phrase>multidimensional</phrase> <phrase>database</phrase>. A relatively simple strategy is to replace <phrase>incomplete information</phrase> with appropriate, <phrase>complete information</phrase>. The advantage of this strategy is that all <phrase>multidimensional databases</phrase> can manage <phrase>complete information</phrase>. Other strategies require more substantial changes to the <phrase>multidimensional</phrase> <phrase>database</phrase>. One strategy is to reflect the <phrase>incompleteness</phrase> in computed aggregates, which is possible only if the <phrase>multidimensional</phrase> <phrase>database</phrase> allows incomplete values in its <phrase>hierarchies</phrase>. Another strategy is to measure the amount of <phrase>incompleteness</phrase> in <phrase>aggregated values</phrase> by tallying how much <phrase>uncertain information</phrase> went into their <phrase>production</phrase>.
<phrase>Privacy</phrase> in <phrase>Multidimensional Databases</phrase>.
When <phrase>answering queries</phrase> that <phrase>ask</phrase> for, <phrase>summary statistics</phrase>, the query-system of a <phrase>multidimensional</phrase> <phrase>database</phrase> should <phrase>guard</phrase> <phrase>confidential data</phrase>, that is, it should avoid revealing (<phrase>directly or indirectly</phrase>) individual <phrase>data</phrase>, which could be exactly calculated or <phrase>accurately estimated</phrase> from the values of <phrase>answered queries</phrase>. In <phrase>order</phrase> to prevent the <phrase>disclosure of confidential</phrase> <phrase>data</phrase>, the query-system should be provided with an <phrase>auditing</phrase> procedure which, each time a new query is processed, checks that its answer does not allow a (<phrase>knowledgeable</phrase>) user to disclose any <phrase>sensitive data</phrase>. A promising approach consists in keeping <phrase>track</phrase> of (or <phrase>auditing</phrase>) <phrase>answered queries</phrase> by means a <phrase>dynamic</phrase> <phrase>graphical</phrase> <phrase>data</phrase> structure, here called the answer <phrase>map</phrase>, whose <phrase>size increases</phrase> with the number of <phrase>answered queries</phrase> and with the number of dimensions of the <phrase>database</phrase>, so that the problem of the <phrase>existence</phrase> of <phrase>an efficient</phrase> <phrase>auditing</phrase> procedure <phrase>naturally arises</phrase>. This <phrase>chapter</phrase> reviews <phrase>recent results</phrase> on this problem for "<phrase>additive</phrase>" queries (such as <phrase>COUNT</phrase> and <phrase>SUM</phrase> queries) by <phrase>listing</phrase> some <phrase>polynomially solvable</phrase> problems as well as some <phrase>hard problems</phrase>, and suggests directions for future work.
Time in <phrase>Multidimensional Databases</phrase>.
In spite of the obvious importance of time in <phrase>data warehousing</phrase> and <phrase>OLAP</phrase>, <phrase>current commercial</phrase> systems do not support tracking the <phrase>history</phrase> of a <phrase>data warehouse</phrase>, either at the schema or <phrase>instance level</phrase>. In this <phrase>chapter</phrase> we address this issue, <phrase>introducing</phrase> the Temporal <phrase>Multidimensional</phrase> <phrase>Model</phrase> and a <phrase>query language</phrase>, denoted TOLAP, allowing expressing <phrase>temporal OLAP</phrase> queries at a <phrase>high</phrase> level of abstraction. Further, we show that previous work in <phrase>temporal databases</phrase> needs to be extended in <phrase>order</phrase> to handle <phrase>evolution</phrase> and <phrase>versioning</phrase> in <phrase>OLAP</phrase>. <phrase>Finally</phrase>, we present an implementation, along with <phrase>preliminary experimental results</phrase>.
Materialized Viewsin <phrase>Multidimensional Databases</phrase>.
<phrase>Cooperation</phrase> with <phrase>Geographic Databases</phrase>.
The purpose of this <phrase>chapter</phrase> is to create <phrase>cooperation</phrase> between <phrase>geographic databases</phrase> (GDBs) and <phrase>multidimensional databases</phrase> (MDDBs), which are considered as the most promising and <phrase>efficient</phrase> <phrase>information</phrase> technologies for <phrase>supporting decision making</phrase>. We focus on the common <phrase>key elements</phrase> between <phrase>geographic</phrase> and <phrase>multidimensional data</phrase> which allow effective support in <phrase>data</phrase> <phrase>cooperating</phrase>. These elements are basically time and space, which are present <phrase>implicitly or explicitly</phrase> in MDDB and are modeled on the dimensions, Time and Location. Thus, because GDBs are primarily concerned with <phrase>geographic data</phrase>, we will focus on space as a <phrase>bridge</phrase> element for <phrase>cooperating</phrase> MDDBs and GDBs. We propose an approach that extends the <phrase>geographic data</phrase> structure through special attributes, called binding attributes, in <phrase>order</phrase> to describe all phenomena represented by MDDBs. This extension will make it possible to answer more specific "<phrase>OLAP</phrase>-based" queries within GDBs without modifying the <phrase>physical organization</phrase> of <phrase>data</phrase> in both environments.
<phrase>Hierarchies</phrase>.
In this <phrase>chapter</phrase> we will focus on the rules of <phrase>aggregation hierarchies</phrase> in analysis dimensions of a <phrase>cube</phrase>. We give <phrase>an overview</phrase> of the <phrase>related works</phrase> on the <phrase>basic</phrase> concepts of the different types of <phrase>aggregation hierarchies</phrase>. We then discuss the <phrase>hierarchies</phrase> from two different <phrase>points of view</phrase>: mapping between domain values and <phrase>hierarchical</phrase> structures. In relation to them, we introduce the characterization of some <phrase>OLAP</phrase> operators on <phrase>hierarchies</phrase> and give a set of operators that concern the change in the hierarchy structure. <phrase>Finally</phrase>, we propose an <phrase>enlargement</phrase> of the operator set concerning <phrase>hierarchies</phrase>.
<phrase>Basic</phrase> Notions.
This <phrase>chapter</phrase> presents the <phrase>basic</phrase> notions regarding <phrase>multidimensional</phrase> (aggregate) <phrase>databases</phrase> by referring to different definitions given for them in the <phrase>literature</phrase>. It illustrates the <phrase>important concepts</phrase> of <phrase>micro</phrase>, <phrase>macro</phrase>, and <phrase>metadata</phrase>; presents a <phrase>formal definition</phrase> of the aggregation process, discussing the concepts of <phrase>dimension</phrase> and <phrase>dimension hierarchies</phrase>; describes the <phrase>multidimensional</phrase> <phrase>aggregate data</phrase> structure, <phrase>distinguishing</phrase> between simple, complex, and <phrase>composite</phrase> structure; illustrates the different types of <phrase>null</phrase> values; and discusses <phrase>differences and similarities</phrase> which exist between <phrase>multidimensional</phrase> <phrase>aggregate data</phrase> (generally called <phrase>statistical data</phrase> because they are used mainly by statisticians) and the <phrase>On-Line</phrase>-<phrase>Analytic</phrase> Processing (<phrase>OLAP</phrase>) of <phrase>multidimensional data</phrase> represented by different <phrase>data cubes</phrase>, also discussing the different (<phrase>symmetric and nonsymmetric</phrase>) treatment of dimensions and measures required by <phrase>OLAP</phrase> and aggregate <phrase>multidimensional databases</phrase>. <phrase>Finally</phrase> it discusses a <phrase>graph</phrase> <phrase>model</phrase> and a <phrase>tabular</phrase> <phrase>model</phrase> for this kind of <phrase>data</phrase>, and gives a set of definitions regarding the <phrase>OLAP</phrase> <phrase>terminology</phrase>.
Operators for <phrase>Multidimensional</phrase> <phrase>Aggregate Data</phrase>.
In this <phrase>chapter</phrase> the <phrase>author</phrase> proposes the different approaches for defining operators able to manipulate this <phrase>multidimensional</phrase> structure. In particular, he initially considers operators for <phrase>multidimensional</phrase> <phrase>aggregate data</phrase> which extend <phrase>relational algebra</phrase> and <phrase>relational</phrase> <phrase>calculus</phrase> (the so-called enlarged <phrase>relational model</phrase>). Then he discusses operators for <phrase>multidimensional</phrase> <phrase>aggregate data</phrase> defined in a <phrase>tabular</phrase> environment. In both the cases the <phrase>author</phrase> defines such <phrase>data</phrase> as statistical (aggregate) <phrase>data</phrase>. <phrase>Subsequently</phrase> he introduces the operators for <phrase>OLAP</phrase> applications, giving a <phrase>terminology</phrase> <phrase>correspondence</phrase> between the <phrase>multidimensional</phrase> aggregate (statistical) <phrase>databases</phrase> and <phrase>OLAP</phrase> areas. Then he defines the fundamental operators deduced from the previous ones, which form the <phrase>basic</phrase> <phrase>algebra</phrase> for the manipulation of <phrase>multidimensional</phrase> <phrase>aggregate data</phrase>, giving their <phrase>formal definitions</phrase> and some <phrase>explanatory</phrase> examples.
<phrase>Dynamic</phrase> <phrase>Multidimensional Data Cubes</phrase>.
<phrase>Data cubes</phrase> are ubiquitous tools in <phrase>data warehousing</phrase>, <phrase>online analytical processing</phrase>, and <phrase>decision support</phrase> applications. Based on a selection of <phrase>pre-computed</phrase> and <phrase>materialized aggregate</phrase> values, they can dramatically <phrase>speed up</phrase> aggregation and <phrase>summarization</phrase> over <phrase>large data</phrase> collections. Traditionally, the <phrase>emphasis</phrase> has been on <phrase>lowering</phrase> query costs with little regard to maintenance, i.e., <phrase>update cost</phrase> issues. We argue that <phrase>current trends</phrase> require <phrase>data cubes</phrase> to be not only query-<phrase>efficient</phrase>, but also <phrase>dynamic</phrase> at the same time, and we also show how this can be achieved. Several <phrase>array-based</phrase> techniques with different <phrase>tradeoffs between</phrase> query and <phrase>update cost</phrase> are discussed in detail. We also survey selected approaches for <phrase>sparse data</phrase> and the popular <phrase>data</phrase> <phrase>cube</phrase> operator, <phrase>CUBE</phrase>. Moreover, this work includes <phrase>an overview</phrase> of <phrase>future trends</phrase> and their impact on <phrase>data cubes</phrase>.
<phrase>Multidimensionality</phrase> in Statistical, <phrase>OLAP</phrase>, and <phrase>Scientific Databases</phrase>.
The term "<phrase>multidimensional</phrase> databses" refers to <phrase>data</phrase> that can be viewed conceptually in a <phrase>multidimensional</phrase> space, where each <phrase>dimension</phrase> represents some attributes of the <phrase>data</phrase>. Viewing <phrase>data</phrase> in this form is natural for many applications, yet the concepts are not treated in a <phrase>uniform</phrase> way in the <phrase>database</phrase> <phrase>literature</phrase>. In this <phrase>chapter</phrase>, we show the commonality of concepts between three <phrase>database</phrase> areas: statistical, <phrase>OLAP</phrase>, and <phrase>scientific databases</phrase>. We show that these domains have two main <phrase>structural</phrase> concepts: the <phrase>cross-product</phrase> space of the dimensions, and the <phrase>classification hierarchy</phrase> structure associated with each <phrase>dimension</phrase>. In the first part of this <phrase>chapter</phrase> we describe how these structures are <phrase>sed</phrase> to represent <phrase>data</phrase> in statistical and <phrase>OLAP</phrase> <phrase>databases</phrase> and how <phrase>summarization</phrase> operators can be applied to them. Further, we discuss how these structures can be extended to represent <phrase>related information</phrase> using <phrase>federated database</phrase> concepts. In the second part of the <phrase>chapter</phrase> we show that these concepts are common to many <phrase>scientific database</phrase> application. In particular, we discuss the importance of <phrase>supporting</phrase> classification structures and the difficulty in representing them as tables in <phrase>relational databases</phrase>. We also discuss <phrase>data structures</phrase> to support <phrase>multidimensional databases</phrase>, emphasizing <phrase>space-time</phrase> representation, <phrase>clustering</phrase> in <phrase>multidimensional</phrase> space, <phrase>indexing</phrase> in <phrase>multidimensional</phrase> space, and <phrase>supporting</phrase> classification structures. We conclude by <phrase>arguing</phrase> that the concepts of <phrase>multidimensionality</phrase> and classification structures as well as the operation over them should be elevated to "<phrase>first class</phrase>" <phrase>object types</phrase>. These <phrase>object types</phrase> should be visible by the application user explicitly in the <phrase>conceptual schemas</phrase> as well as <phrase>exposing</phrase> them in the <phrase>user interfaces</phrase>.
<phrase>Querying</phrase> <phrase>Multidimensional Data</phrase>.
A powerful and easy-to-use <phrase>querying</phrase> environment is certainly one of the most important components in a <phrase>multidimensional</phrase> <phrase>database</phrase>, and its effectiveness is influenced by many other aspects, both <phrase>logical</phrase> (<phrase>data model</phrase>, <phrase>integration</phrase>, policy of <phrase>view materialization</phrase>, etc.) and physical (<phrase>multidimensional</phrase> or <phrase>relational</phrase> storage, indexes, etc.). As is evident, <phrase>multidimensional</phrase> <phrase>querying</phrase> is often based on the <phrase>metaphor</phrase> of the <phrase>data</phrase> <phrase>cube</phrase> and on the concepts of facts, measures, and dimensions. In contrast to conventional <phrase>transactional</phrase> environments, <phrase>multidimensional</phrase> <phrase>querying</phrase> is often <phrase>an exploratory</phrase> process, performed by <phrase>navigating</phrase> along the dimensions and measures, increasing/decreasing the <phrase>level of detail</phrase> and focusing on specific subparts of the <phrase>cube</phrase> that appear to be "promising" for the required information.In this <phrase>chapter</phrase> we focus on the main languages proposed in the <phrase>literature</phrase> to express <phrase>multidimensional</phrase> queries, particularly those based on: (<phrase>i</phrase>) <phrase>an algebraic</phrase> approach, (<phrase>ii</phrase>) a <phrase>declarative</phrase> <phrase>paradigm</phrase> (<phrase>calculus</phrase>), and (<phrase>iii</phrase>) <phrase>visual</phrase> constructs and <phrase>syntax</phrase>. We analyze the problem of evaluation, i.e., the issues related to the <phrase>efficient</phrase> <phrase>data</phrase> retrieval and calculation, possibly (often necessarily) using some <phrase>pre-computed</phrase> <phrase>data</phrase>, a problem known in the <phrase>literature</phrase> as the problem of <phrase>rewriting</phrase> a query using views. We also illustrate the use of particular <phrase>index</phrase> structures to <phrase>speed up</phrase> the <phrase>query evaluation</phrase> process.
<phrase>Conceptual Multidimensional</phrase> Models.
A <phrase>variety</phrase> of <phrase>multidimensional data</phrase> models have <phrase>recently</phrase> been proposed by both <phrase>academic</phrase> and <phrase>industry</phrase> communities. but <phrase>consensus</phrase> on formalism or even a <phrase>common terminology</phrase> has not yet emerged. In this <phrase>chapter</phrase>, we first discuss the requirements that an ideal <phrase>conceptual multidimensional</phrase> <phrase>model</phrase> should fulfill. These requirements are suggested by <phrase>general</phrase> <phrase>information</phrase> system modeling principles and the <phrase>specific characteristics</phrase> of <phrase>OLAP</phrase> applications. <phrase>Building</phrase> on these requirements, we then present a <phrase>general</phrase> <phrase>conceptual multidimensional</phrase> <phrase>data model</phrase> and show how it can be used to describe the <phrase>basic</phrase> aspects of a <phrase>business</phrase> application in a way that is <phrase>easy to understand</phrase> and <phrase>independent</phrase> of the criteria for <phrase>actual data</phrase> <phrase>organization</phrase> in the various systems. Starting from the characteristics of the <phrase>model</phrase> proposed, we summarize the <phrase>general</phrase> features that a <phrase>multidimensional</phrase> <phrase>conceptual model</phrase> should support. We then survey various <phrase>multidimensional</phrase> models proposed and relate their characteristics to these <phrase>general</phrase> features. <phrase>Finally</phrase>, we discuss the main points raised in the <phrase>chapter</phrase> and some problems that remain to be solved in this context.
Towards an <phrase>Autopoietic</phrase> Approach for <phrase>Information Systems</phrase> Development.
<phrase>Business</phrase> <phrase>Action</phrase> and <phrase>Information</phrase> Modeling - the Task of the <phrase>Next</phrase> <phrase>Millennium</phrase>.
Event Modeling.
<phrase>Information System Design</phrase> Based on Reuse of Conceptual Components.
An Environment for <phrase>Managing</phrase> Enterprise <phrase>Domain Ontology</phrase>.
<phrase>Spatial</phrase> and <phrase>Topological</phrase> <phrase>Data</phrase> Models.
<phrase>Coherent</phrase>, Consistent, and <phrase>Comprehensive</phrase> Modeling of <phrase>Communication</phrase>, <phrase>Information</phrase>, <phrase>Action</phrase>, and <phrase>Organization</phrase>.
A <phrase>Unifying</phrase> <phrase>Translation</phrase> of <phrase>Natural Language</phrase> Patterns to Object and <phrase>Process Modeling</phrase>.
An <phrase>Information Management</phrase> Environment Based on the <phrase>Model</phrase> of Object Primitives.
<phrase>Designing</phrase> <phrase>Model-Based</phrase> Intelligent <phrase>Dialogue</phrase> Systems.
<phrase>Conceptual Modeling</phrase> Process and the Notion of a Concept.
<phrase>Integrating</phrase> <phrase>Fact-oriented Modeling</phrase> with <phrase>Object-oriented</phrase> Modeling.
A <phrase>Language</phrase>/<phrase>action Based</phrase> Approach to <phrase>Information</phrase> Modeling.
From <phrase>Information</phrase> <phrase>Model</phrase> to <phrase>Controllable</phrase> Implementation.
Modeling of Customers' <phrase>Interactive Control</phrase> of <phrase>Service Processes</phrase>.
On the Convergence of Analysis and <phrase>Design Methods</phrase> for <phrase>Multi-agent</phrase>, <phrase>Component-based</phrase> and <phrase>Object-oriented</phrase> systems.
Requirements for <phrase>Web Engineering</phrase> Methodologies.
A <phrase>Genre-Based</phrase> Method for <phrase>Information</phrase> Systems <phrase>Planning</phrase>.
Metrics for <phrase>Managing</phrase> Quality in <phrase>Information</phrase> Modeling.
<phrase>Preface</phrase>.
<phrase>Object-Oriented</phrase> <phrase>Web Applications</phrase> Modeling.
<phrase>Information</phrase> Modeling in the <phrase>Internet</phrase> <phrase>Age</phrase> - Challenges, Issues, and <phrase>Research</phrase> Directions.
Conceptual <phrase>Web</phrase> Site Modeling.
<phrase>Information</phrase> Models for <phrase>Document Engineering</phrase>.
<phrase>Audience-driven</phrase> <phrase>Web Design</phrase>.
A <phrase>Systematic</phrase> <phrase>Relationship Analysis</phrase> for Modeling <phrase>Information</phrase> Domains.
<phrase>HMT</phrase>: Modeling Interactive and <phrase>Adaptive</phrase> <phrase>Hypermedia</phrase> Applications.
Mapping <phrase>UML</phrase> Techniques to <phrase>Design</phrase> Activities.
<phrase>Seamless</phrase> <phrase>Formalizing</phrase> the <phrase>UML</phrase> <phrase>Semantics</phrase> through <phrase>Metamodels</phrase>.
The Whole-Part Relationship in <phrase>the Unified Modeling Language</phrase>: A New Approach.
Temporal <phrase>OCL</phrase> Meeting Specification Demands for <phrase>Business</phrase> Components.
<phrase>A Systematic Approach</phrase> to Transform <phrase>UML</phrase> Static Models to <phrase>Object-Oriented</phrase> Code.
<phrase>An Interactive</phrase> <phrase>Viewpoint</phrase> on the Role of <phrase>UML</phrase>.
<phrase>Supplementing</phrase> <phrase>UML</phrase> with concepts from <phrase>ORM</phrase>.
<phrase>Systematic</phrase> <phrase>Design</phrase> of <phrase>Web Applications</phrase> with <phrase>UML</phrase>.
<phrase>RUP</phrase> - A <phrase>process model</phrase> for working with <phrase>UML</phrase>.
Extension of <phrase>the Unified Modeling Language</phrase> for <phrase>Mobile</phrase> Agents.
Using a <phrase>Semiotic</phrase> Framework to Evaluate <phrase>UML</phrase> for the Development of Models of <phrase>High</phrase> Quality.
Rendering <phrase>Distributed Systems</phrase> in <phrase>UML</phrase>.
<phrase>Linking</phrase> <phrase>UML</phrase> with Integrated <phrase>Formal Techniques</phrase>.
<phrase>Data</phrase> Modeling And <phrase>UML</phrase>.
<phrase>Rational Unified Process</phrase> and <phrase>Unified Modeling Language</phrase> - A <phrase>GOMS</phrase> Analysis.
<phrase>Preface</phrase>.
<phrase>UML</phrase> Modeling Support for Early Reuse Decisions in <phrase>Component-Based</phrase> Development.
Modeling of <phrase>Business</phrase> Rules for <phrase>Active</phrase> <phrase>Database</phrase> Application Specification.
<phrase>Active</phrase> <phrase>database applications</phrase> require the classic cycle of analysis, <phrase>design</phrase>, <phrase>prototyping</phrase> and implementation. During analysis and <phrase>design</phrase> steps of the <phrase>information</phrase> system <phrase>engineering</phrase> process, modeling behavior is an important task. This task is both essential and crucial when <phrase>information</phrase> system is centered on <phrase>active databases</phrase>, which allow the replacement of parts of <phrase>application programs</phrase> with <phrase>active</phrase> rules. For that reason, the specification of <phrase>business</phrase> rules during analysis and <phrase>design</phrase> steps becomes an actual requirement. <phrase>Business</phrase> rules ensure the well-functioning of <phrase>information</phrase> system. They are <phrase>descriptive</phrase> (<phrase>integrity constraints</phrase>) or <phrase>functional</phrase> (<phrase>derivation</phrase> rules and <phrase>active</phrase> rules). To relieve programmers from using either traditional or <phrase>ad hoc</phrase> techniques to <phrase>design</phrase> <phrase>active databases</phrase>, it is necessary to develop new techniques to <phrase>model</phrase> <phrase>business</phrase> rules. These techniques have to enhance the specification of <phrase>dynamic</phrase> <phrase>aspect</phrase> through a <phrase>high-level description</phrase> <phrase>language</phrase> able to express precisely and completely rule <phrase>semantic</phrase>. In this <phrase>chapter</phrase>, we propose a <phrase>uniform</phrase> approach to <phrase>model</phrase> <phrase>business</phrase> rules (<phrase>active</phrase> rules, <phrase>integrity constraints</phrase>, etc.). To improve the <phrase>behavior specification</phrase> we extend the <phrase>state diagrams</phrase> that are widely used for <phrase>dynamic</phrase> modeling. This extension is a transformation of <phrase>state</phrase> transitions according to rule <phrase>semantics</phrase>. In addition, we outline new functionalities of <phrase>Computer-Aided</phrase> System <phrase>Engineering</phrase> (CASE) to take into consideration the <phrase>active</phrase> <phrase>database</phrase> specificities. In this way, the designer can be assisted to control, maintain and reuse a set of rules.
<phrase>CMU</phrase>-<phrase>WEB</phrase>: A <phrase>Conceptual Model</phrase> with Metrics for Testing and <phrase>Designing</phrase> <phrase>Usability</phrase> in <phrase>Web Applications</phrase>.
With the ubiquitous <phrase>availability</phrase> of <phrase>browsers</phrase> and <phrase>Internet access</phrase>, the <phrase>last</phrase> few years have seen a <phrase>tremendous growth</phrase> in the number of applications being developed on <phrase>the World Wide Web</phrase> (<phrase>WWW</phrase>). Models for <phrase>analyzing</phrase> and <phrase>designing</phrase> these applications are only just <phrase>beginning to emerge</phrase>. In this work, we propose a <phrase>three-dimensional</phrase> classification space for <phrase>WWW</phrase> applications, consisting of a <phrase>degree</phrase> of structure of pages <phrase>dimension</phrase>, a <phrase>degree</phrase> of support for interrelated events <phrase>dimension</phrase> and a location of processing <phrase>dimension</phrase>. <phrase>Next</phrase>, we propose <phrase>usability</phrase> <phrase>design</phrase> metrics for <phrase>WWW</phrase> applications along the structure of pages <phrase>dimension</phrase>. To measure these, we propose <phrase>CMU</phrase>-<phrase>WEB</phrase>-a <phrase>conceptual model</phrase> that can be used to <phrase>design</phrase> <phrase>WWW</phrase> applications, such that its schema provide values for the <phrase>design</phrase> metrics. This work represents the first effort, to the best of our <phrase>knowledge</phrase>, to provide a <phrase>conceptual model</phrase> that measures quantifiable metrics that can be used for the <phrase>design</phrase> of more usable <phrase>Web applications</phrase>, and that can also be used to compare the <phrase>usability</phrase> of <phrase>existing Web applications</phrase>, without <phrase>empirical testing</phrase>.
<phrase>Enforcing</phrase> <phrase>Cardinality</phrase> Constraints in the <phrase>ER</phrase> <phrase>Model</phrase> with Integrity Methods.
<phrase>Entity-Relationship</phrase> (<phrase>ER</phrase>) schemas include <phrase>cardinality</phrase> constraints that restrict the dependencies among entities within a relationship type. The <phrase>cardinality</phrase> constraints have <phrase>direct</phrase> impact on application transactions, since <phrase>insertions or deletions</phrase> of entities or relationships might affect <phrase>related entities</phrase>. Application transactions can be strengthened to preserve the consistency of a <phrase>database</phrase> with respect to the <phrase>cardinality</phrase> constraints in a schema. Yet, once an <phrase>ER</phrase> schema is translated into a <phrase>logical</phrase> <phrase>database schema</phrase>, the <phrase>direct</phrase> correlation between the <phrase>cardinality</phrase> constraints and application transaction is <phrase>lost</phrase>, since the components of the <phrase>ER</phrase> schema might be decomposed among those of the <phrase>logical</phrase> <phrase>database</phrase> schema.We suggest <phrase>extending</phrase> the <phrase>Enhanced</phrase>-<phrase>ER</phrase> (<phrase>EER</phrase>) <phrase>data model</phrase> with integrity methods that can enforce the <phrase>cardinality</phrase> constraints. The integrity methods can be fully defined by the <phrase>cardinality</phrase> constraints, using a small number of primitive update methods, and are <phrase>automatically created</phrase> for a given <phrase>EER</phrase> <phrase>diagram</phrase>. A <phrase>translation</phrase> of an <phrase>EER</phrase> schema into a <phrase>logical</phrase> <phrase>database schema</phrase> can create integrity routines by <phrase>translating</phrase> the primitive update methods alone. These integrity routines may be implemented as <phrase>database</phrase> procedures, if a <phrase>relational</phrase> <phrase>DBMS</phrase> is utilized, or as class methods, if <phrase>an object-oriented</phrase> <phrase>DBMS</phrase> is utilized.
<phrase>Algorithm</phrase> Development, <phrase>Simulation</phrase> Analysis, and <phrase>Parametric</phrase> Studies for <phrase>Data</phrase> Allocation in <phrase>Distributed Database</phrase> Systems.
In a <phrase>distributed database</phrase> system, an increase in workload typically necessitates the installation of additional <phrase>database</phrase> servers followed by the implementation of expensive <phrase>data reorganization</phrase> strategies. We present the <phrase>Partial</phrase> REALLOCATE and Full REALLOCATE heuristics for <phrase>efficient</phrase> <phrase>data reallocation</phrase>. Complexity is controlled and cost minimized by allowing only <phrase>incremental</phrase> <phrase>introduction</phrase> of servers into the <phrase>distributed database</phrase> system. Using first <phrase>simple examples</phrase> and then, a simulator, our framework for <phrase>incremental</phrase> growth and <phrase>data reallocation</phrase> in <phrase>distributed database</phrase> systems is shown to produce <phrase>near optimal</phrase> solutions when compared with exhaustive methods.
<phrase>Object-Oriented</phrase> <phrase>Database</phrase> Benchmarks.
The Role of <phrase>Use Cases</phrase> in the <phrase>UML</phrase>: A <phrase>Review and Research Agenda</phrase>.
A <phrase>use case</phrase> is a description of a <phrase>sequence</phrase> of actions constituting a complete task or transaction in an application. <phrase>Use cases</phrase> were first proposed by <phrase>Jacobson</phrase> (1987) and have since been incorporated as one of the key <phrase>modeling constructs</phrase> in the <phrase>UML</phrase>(<phrase>Booch</phrase>, <phrase>Jacobson</phrase>, & Rumbaugh, 1999) and the <phrase>Unified</phrase> <phrase>Software Development Process</phrase>(<phrase>Jacobson</phrase>, <phrase>Booch</phrase>, & Rumbaugh, 1999). This <phrase>chapter</phrase> traces the development of <phrase>use cases</phrase>, and identifies a number of problems with both their application and <phrase>theoretical underpinnings</phrase>. From an application <phrase>perspective</phrase>, the <phrase>use-case</phrase> concept is marked by a <phrase>high</phrase> <phrase>degree</phrase> of <phrase>variety</phrase> in the level of abstraction versus implementation detail advocated by various authors. In addition, <phrase>use cases</phrase> are promoted as a primary mechanism for <phrase>identifying</phrase> objects in an application, even <phrase>though</phrase> they focus on processes rather than objects. Moreover, there is an apparent <phrase>inconsistency</phrase> between the so-called naturalness of <phrase>object models</phrase> and the <phrase>commonly held</phrase> view that <phrase>use cases</phrase> should be the primary means of communicating and <phrase>verifying</phrase> requirements with users. From a <phrase>theoretical standpoint</phrase>, the <phrase>introduction</phrase> of <phrase>implementation issues</phrase> in <phrase>use cases</phrase> can be seen as prematurely <phrase>anchoring</phrase> the analysis to particular implementation decisions. In addition, the fragmentation of objects across <phrase>use cases</phrase> creates <phrase>conceptual difficulties</phrase> in <phrase>developing</phrase> a <phrase>comprehensive</phrase> <phrase>class diagram</phrase> from a set of <phrase>use cases</phrase>. Moreover, the role of categorization in <phrase>human thinking</phrase> suggests that <phrase>class diagrams</phrase> may serve directly as a good mechanism for communicating and <phrase>verifying</phrase> <phrase>application requirements</phrase> with users. We <phrase>conclude by outlining</phrase> a framework for further <phrase>empirical research</phrase> to resolve <phrase>issues raised</phrase> in our analysis.
<phrase>Object-Process Methodology</phrase> Applied to Modeling <phrase>Credit Card</phrase> Transactions.
<phrase>Object-Process Methodology</phrase> (<phrase>OPM</phrase>) is a system development and specification approach that combines the <phrase>major</phrase> system aspects-<phrase>function</phrase>, structure and behavior-within a <phrase>single</phrase> <phrase>graphic</phrase> and textual <phrase>model</phrase>. Having applied <phrase>OPM</phrase> in a <phrase>variety</phrase> of domains, this <phrase>chapter</phrase> specifies an <phrase>electronic commerce</phrase> system in a <phrase>hierarchical</phrase> manner, at the <phrase>top</phrase> of which are the processes of <phrase>managing</phrase> a <phrase>generic</phrase> product <phrase>supply chain</phrase> before and after the product is manufactured. Focusing on the <phrase>post</phrase>-product <phrase>supply chain management</phrase>, we gradually refine the details of the fundamental, almost "<phrase>classical</phrase>" <phrase>electronic commerce</phrase> interaction between the <phrase>retailer</phrase> and the end-customer, namely payment over the <phrase>Internet</phrase> using the customer's <phrase>credit card</phrase>. The specification <phrase>results</phrase> in a set of Object-Process <phrase>Diagrams</phrase> and a corresponding equivalent set of Object-Process <phrase>Language</phrase> sentences. The <phrase>synergy</phrase> of <phrase>combining</phrase> structure and behavior within a <phrase>single</phrase> <phrase>formal model</phrase>, expressed both graphically and textually, yields a <phrase>highly expressive</phrase> system modeling and <phrase>specification tool</phrase>. The <phrase>comprehensive</phrase>, unambiguous treatment of this <phrase>basic</phrase> <phrase>electronic commerce</phrase> process is formal, yet intuitive and clear, suggesting that <phrase>OPM</phrase> is a <phrase>prime</phrase> candidate for becoming a common standard <phrase>vehicle</phrase> for defining, specifying, and <phrase>analyzing</phrase> <phrase>electronic commerce</phrase> and <phrase>supply chain management</phrase> systems.
<phrase>Information</phrase> Analysis in <phrase>UML</phrase> and <phrase>ORM</phrase>: A Comparison.
Since its <phrase>adoption</phrase> by the <phrase>Object Management Group</phrase> as a <phrase>language</phrase> for <phrase>object-oriented analysis and design</phrase>, <phrase>the Unified Modeling Language</phrase> (<phrase>UML</phrase>) has become widely used for <phrase>designing</phrase> <phrase>object-oriented</phrase> code. However, <phrase>UML</phrase> has had only <phrase>minimal</phrase> <phrase>adoption</phrase> among practitioners for the purposes of <phrase>information</phrase> analysis and <phrase>database design</phrase>. One main reason for this is that the <phrase>class diagrams</phrase> used in <phrase>UML</phrase> for <phrase>data</phrase> modeling provide only <phrase>weak</phrase>, and awkward, support for the kinds of <phrase>business</phrase> rules found in <phrase>data-intensive applications</phrase>. Moreover, <phrase>UML's</phrase> <phrase>graphical</phrase> <phrase>language</phrase> does not lend itself readily to <phrase>verbalization</phrase> and <phrase>multiple instantiation</phrase> for <phrase>validating</phrase> <phrase>data</phrase> models with <phrase>domain experts</phrase>. These defects can be remedied by using a <phrase>fact-oriented</phrase> approach for <phrase>information</phrase> analysis, from which <phrase>UML class diagrams</phrase> may be derived. <phrase>Object-Role Modeling</phrase> (<phrase>ORM</phrase>) is currently the most popular <phrase>fact-oriented modeling</phrase> approach. This <phrase>chapter</phrase> examines the <phrase>relative strengths</phrase> and weaknesses of <phrase>UML</phrase> and <phrase>ORM</phrase> for <phrase>conceptual data modeling</phrase>, and indicates how models in one notation can be translated into the other.
<phrase>Cooperative</phrase> <phrase>Query Processing</phrase> via <phrase>Knowledge</phrase> Abstraction and <phrase>Query Relaxation</phrase>.
As <phrase>database</phrase> users adopt a <phrase>query language</phrase> to obtain <phrase>information</phrase> from a <phrase>database</phrase>, a more <phrase>intelligent query answering</phrase> system is increasingly needed that cooperates with the users to provide informative responses by <phrase>understanding</phrase> the <phrase>intent</phrase> behind a query. The effectiveness of <phrase>decision support</phrase> would improve significantly if the <phrase>query answering</phrase> system returned <phrase>approximate</phrase> answers rather than a <phrase>null</phrase> <phrase>information</phrase> response when there is no matching <phrase>data</phrase> available. Even when <phrase>exact</phrase> answers are found, neighboring <phrase>information</phrase> is still useful to users if the query is intended to explore some hypothetical <phrase>information</phrase> or <phrase>abstract</phrase> <phrase>general</phrase> fact. This <phrase>chapter</phrase> proposes an <phrase>abstraction hierarchy</phrase> as a framework to practically derive such <phrase>approximate</phrase> answers from ordinary everyday <phrase>databases</phrase>. It provides a <phrase>knowledge</phrase> abstraction <phrase>database</phrase> to facilitate the <phrase>approximate query answering</phrase>. The <phrase>knowledge</phrase> abstraction <phrase>database</phrase> <phrase>specifically</phrase> adopts an abstraction approach to extract <phrase>semantic</phrase> <phrase>data</phrase> relationships from the underlying <phrase>database</phrase>, and uses a <phrase>multi-level</phrase> hierarchy for <phrase>coupling</phrase> <phrase>multiple levels</phrase> of abstraction <phrase>knowledge</phrase> and <phrase>data</phrase> values. In <phrase>cooperation</phrase> with the underlying <phrase>database</phrase>, the <phrase>knowledge</phrase> abstraction <phrase>database</phrase> allows the relaxation of query conditions so that the original <phrase>query scope</phrase> can be broadened and thus <phrase>information</phrase> <phrase>approximate</phrase> to <phrase>exact</phrase> answers can be obtained. Conceptually <phrase>abstract</phrase> queries can also be posed to provide a less rigid <phrase>query interface</phrase>. A <phrase>prototype</phrase> system has been implemented at <phrase>KAIST</phrase> and is being tested with a personnel <phrase>database</phrase> system to demonstrate the usefulness and practicality of the <phrase>knowledge</phrase> abstraction <phrase>database</phrase> in ordinary <phrase>database systems</phrase>.
<phrase>Ternary</phrase> Relationships: <phrase>Semantic</phrase> Requirements and <phrase>Logically Correct</phrase> Alternatives.
<phrase>A Case Study</phrase> of the Use of the Viable System <phrase>Model</phrase> in the <phrase>Organization</phrase> of <phrase>Software Development</phrase>.
This <phrase>chapter</phrase> considers the usefulness of the Viable System <phrase>Model</phrase> (<phrase>VSM</phrase>) in the study of <phrase>organizational adaptation</phrase>. The <phrase>VSM</phrase> is a rigorous <phrase>organizational model</phrase> that was developed from the study of <phrase>cybernetics</phrase> and has been given <phrase>considerable attention</phrase> by <phrase>management science</phrase> <phrase>research</phrase>. The <phrase>chapter</phrase> presents <phrase>a longitudinal case study</phrase> that focuses upon a <phrase>software development team</phrase>. The <phrase>VSM</phrase> was useful in <phrase>diagnosing</phrase> the likely consequences of different <phrase>organizational designs</phrase> and in <phrase>prescribing</phrase> an <phrase>alternative</phrase> <phrase>solution</phrase>.
Using <phrase>Weakly Structured</phrase> Documents at the <phrase>User-Interface</phrase> Level to Fill in a <phrase>Classical</phrase> <phrase>Database</phrase>.
<phrase>Electronic</phrase> documents have become a <phrase>universal</phrase> way of <phrase>communication</phrase> due to <phrase>Web</phrase> <phrase>expansion</phrase>. But using <phrase>structured information</phrase> stored in <phrase>databases</phrase> is still essential for <phrase>data</phrase> <phrase>coherence</phrase> <phrase>management</phrase>, <phrase>querying</phrase> facilities, etc. We thus face a <phrase>classical</phrase> problem-known as "<phrase>impedance mismatch</phrase>" in the <phrase>database</phrase> world; two <phrase>antagonist</phrase> approaches have to collaborate. Using documents at the <phrase>end-user</phrase> interface level provides simplicity and flexibility. But it is possible to take documents as <phrase>data</phrase> sources only if helped by a <phrase>human</phrase> being; <phrase>automatic document</phrase> analysis systems have a significant <phrase>error rate</phrase>. <phrase>Databases</phrase> are an <phrase>alternative</phrase> as <phrase>semantics</phrase> and format of <phrase>information</phrase> are <phrase>strict</phrase>; queries via <phrase>SQL</phrase> provide 100% <phrase>correct responses</phrase>. The aim of this work is to provide a system that associates document capture freedom with <phrase>database</phrase> storage structure.The system we propose does not intend to be <phrase>universal</phrase>. It can be used in specific cases where people usually work with <phrase>technical documents</phrase> dedicated to a particular domain. Our examples concern <phrase>medicine</phrase> and more explicitly <phrase>medical</phrase> records. <phrase>Computerization</phrase> has very often been rejected by <phrase>physicians</phrase> because it necessitates <phrase>too much</phrase> <phrase>standardization</phrase> and form-based <phrase>user interfaces</phrase> are not <phrase>easily adapted</phrase> to their <phrase>daily</phrase> practice. In this domain, we think that this study provides a <phrase>viable alternative</phrase> approach. This system offers freedom to <phrase>doctors</phrase>; they would fill in documents with the <phrase>information</phrase> they want to store, in a convenient <phrase>order</phrase> and in a freer way. We have developed a system that allows a <phrase>database</phrase> to fill in <phrase>quasi</phrase>-automatically from documents paragraphs.The <phrase>database</phrase> used is an already existing <phrase>database</phrase> that can be queried in a <phrase>classical</phrase> way for statistical studies or <phrase>epidemiological</phrase> purposes. In this system, the document <phrase>fund</phrase> and the <phrase>database</phrase> containing extractions from dccuments coexist. Queries are sent to the <phrase>database</phrase>, answers include <phrase>data</phrase> from the <phrase>database</phrase> and references to <phrase>source documents</phrase>.
<phrase>Extending</phrase> <phrase>UML</phrase> for Space- and <phrase>Time-Dependent</phrase> Applications.
Changing the Face of <phrase>War</phrase> through <phrase>Telemedicine</phrase> and <phrase>Mobile</phrase> <phrase>E-commerce</phrase>.
FOOM - <phrase>Functional</phrase> and <phrase>Object-Oriented</phrase> Methodology for Analysis and <phrase>Design</phrase> of <phrase>Information</phrase> Systems.
FOOM is <phrase>an integrated</phrase> methodology for analysis and <phrase>design</phrase> of <phrase>information</phrase> systems, which combines the two essential <phrase>software-engineering</phrase> paradigms: the <phrase>functional</phrase>- (or process-) <phrase>oriented approach</phrase> and the <phrase>object-oriented</phrase> (<phrase>OO</phrase>) approach. In FOOM, system analysis includes both <phrase>functional</phrase> and <phrase>data</phrase> modeling activities, thereby producing both a <phrase>functional</phrase> <phrase>model</phrase> and a <phrase>data model</phrase>. These activities can be performed either by starting with <phrase>functional analysis</phrase> and continuing with <phrase>data</phrase> modeling, <phrase>or vice versa</phrase>. FOOM <phrase>products</phrase> of the analysis phase include:a)a hierarchy of <phrase>OO</phrase>-<phrase>DFDs</phrase> (<phrase>object-oriented</phrase> <phrase>data flow diagrams</phrase>), and <phrase>b</phrase>) an initial <phrase>object schema</phrase>, which can be created directly from the <phrase>user requirements</phrase> specification or from an <phrase>entity-relationship diagram</phrase> (<phrase>ERD</phrase>) that is mapped to that <phrase>object schema</phrase>. <phrase>System design</phrase> is performed according to the <phrase>OO</phrase> approach. The <phrase>products</phrase> of the <phrase>design</phrase> phase include: a) a complete <phrase>object schema</phrase>, consisting of the classes and their relationships, attributes, and method interfaces; <phrase>b</phrase>) <phrase>object classes</phrase> for the menus, forms and reports; and <phrase>c</phrase>) a behavior schema, which consists of detailed descriptions of the methods and the application transactions, expressed in <phrase>pseudo</phrase>-code and message <phrase>diagrams</phrase>. The <phrase>seamless</phrase> transition from analysis to <phrase>design</phrase> is <phrase>attributed</phrase> to ADISSA methodology, which facilitates the <phrase>design</phrase> of the menus, forms and reports classes, and the system behavior schema, from <phrase>DFDs</phrase> and the application transactions.
The <phrase>Psychology</phrase> of <phrase>Information</phrase> Modeling.
<phrase>Information</phrase> modeling is the <phrase>cornerstone</phrase> of <phrase>information</phrase> <phrase>systems analysis</phrase> and <phrase>design</phrase>. <phrase>Information</phrase> models, the <phrase>products</phrase> of <phrase>information</phrase> modeling, not only provide the abstractions required to facilitate <phrase>communication</phrase> between the analysts and <phrase>end-users</phrase>, but they also provide a <phrase>formal basis</phrase> for <phrase>developing</phrase> tools and techniques used in <phrase>information systems</phrase> development. The process of <phrase>designing</phrase>, <phrase>constructing</phrase>, and <phrase>adapting</phrase> <phrase>information modeling</phrase> methods for <phrase>information systems</phrase> development is known as <phrase>method engineering</phrase>. Despite the <phrase>pivotal role</phrase> of <phrase>modeling methods</phrase> in successful <phrase>information systems</phrase> development, most <phrase>modeling methods</phrase> are designed based on <phrase>common sense</phrase> and intuition of the method designers with little or no <phrase>theoretical foundation</phrase> or <phrase>empirical evidence</phrase>. <phrase>Systematic</phrase> scientific approach is missing! This <phrase>chapter</phrase> proposes the use of <phrase>cognitive psychology</phrase> as a <phrase>reference discipline</phrase> for <phrase>information</phrase> modeling and <phrase>method engineering</phrase>. Theories in <phrase>cognitive psychology</phrase> are reviewed in this <phrase>chapter</phrase> and their application to <phrase>information</phrase> modeling and <phrase>method engineering</phrase> is discussed.
How Complex Is <phrase>the Unified Modeling Language</phrase>?
<phrase>Unified Modeling Language</phrase> (<phrase>UML</phrase>)has emerged as the <phrase>software</phrase> <phrase>industry's</phrase> dominant <phrase>modeling language</phrase>. It is the <phrase>de facto</phrase> <phrase>modeling language</phrase> standard for specifying, <phrase>visualizing</phrase>, <phrase>constructing</phrase>, and documenting the components of <phrase>software</phrase> systems. Despite its prominence and status as the standard <phrase>modeling language</phrase>, <phrase>UML</phrase> has its <phrase>critics</phrase>. Opponents argue that it is complex and difficult to learn. Some question the rationale of having nine <phrase>diagramming</phrase> techniques in <phrase>UML</phrase> and the raison d'être of those nine techniques in <phrase>UML</phrase>. Others point out that <phrase>UML</phrase> lacks a <phrase>comprehensive</phrase> methodology to guide its users, which makes the <phrase>language</phrase> even more convoluted. A few studies on <phrase>UML</phrase> can be found in the <phrase>literature</phrase>. However, no study exists to provide a <phrase>quantitative</phrase> measure of <phrase>UML</phrase> complexity or to compare <phrase>UML</phrase> with other <phrase>object-oriented</phrase> techniques. In this <phrase>research</phrase>, we evaluate the complexity of <phrase>UML</phrase> using <phrase>complexity metrics</phrase>. The objective is to provide a <phrase>reliable</phrase> and accurate <phrase>quantitative</phrase> measure of <phrase>UML</phrase> complexity. A comparison of the complexity <phrase>metrical</phrase> values of <phrase>UML</phrase> with other <phrase>object-oriented</phrase> techniques was also carried out. Our <phrase>findings suggest</phrase> that each <phrase>diagram</phrase> in <phrase>UML</phrase> is not distinctly more complex than techniques in other <phrase>modeling methods</phrase>. But as a whole, <phrase>UML</phrase> is very complex-2-11 times more complex than other <phrase>modeling methods</phrase>.
<phrase>Managing</phrase> Organizational <phrase>Hypermedia</phrase> Documents: A <phrase>Meta-information</phrase> System.
<phrase>Recently</phrase>, many organizations have attempted to build <phrase>hypermedia</phrase> systems to expand their <phrase>working areas</phrase> into <phrase>Internet</phrase>-based <phrase>virtual</phrase> work places. Increasingly, it becomes more important than ever to manage organizational <phrase>hypermedia</phrase> documents (OHDs); <phrase>metadata</phrase> plays a critical role for <phrase>managing</phrase> these documents. This <phrase>chapter</phrase> redefines <phrase>metadata</phrase> roles and proposes a <phrase>metadata</phrase> classification and the corresponding <phrase>metadata</phrase> schema for OHDs. Furthermore, a <phrase>meta-information</phrase> system, HyDoMiS (<phrase>Hyperdocument</phrase> <phrase>Meta-information</phrase> System) built on the basis of this schema is proposed. HyDoMiS performs three functions: <phrase>metadata</phrase> <phrase>management</phrase>, search, and reporting. The <phrase>metadata</phrase> <phrase>management</phrase> <phrase>function</phrase> is concerned with <phrase>workflow</phrase>, documents, and <phrase>databases</phrase>. The system is more likely to help implement and maintain <phrase>hypermedia</phrase> <phrase>information</phrase> systems effectively.
<phrase>Formal Approaches</phrase> to <phrase>Systems Analysis</phrase> Using <phrase>UML</phrase>: <phrase>An Overview</phrase>.
<phrase>Implementation Techniques</phrase> For <phrase>Extensible</phrase> <phrase>Object Storage</phrase> Systems.
A Review of Experiments on <phrase>Natural Language</phrase> Interfaces.
A Framework for <phrase>Analyzing</phrase> <phrase>Mobile</phrase> Transaction Models.
Methodology <phrase>Evaluation Framework</phrase> for <phrase>Component-Based</phrase> System Development.
Considering Mobility in <phrase>Query Processing</phrase> for <phrase>Mobile Commerce</phrase> Systems.
A <phrase>Run-Time</phrase> Based Technique to Optimize Queries in Distributed <phrase>Internet</phrase> <phrase>Databases</phrase>.
Towards Flexible Specification, Composition, and <phrase>Coordination</phrase> of <phrase>Workflow</phrase> Activities.
On The Representation Of <phrase>Temporal Dynamics</phrase>.
<phrase>Software</phrase> Agents for <phrase>Mobile Commerce</phrase> Services Support.
The Development of <phrase>Ordered</phrase> <phrase>SQL</phrase> Packages in <phrase>Peer-to-Peer</phrase> <phrase>Warehousing</phrase> Environment.
Performance Implication of <phrase>Knowledge Discovery</phrase> Techniques in <phrase>Databases</phrase>.
<phrase>Applying</phrase> <phrase>UML</phrase> For <phrase>Designing</phrase> <phrase>Multidimensional Databases</phrase> And <phrase>OLAP</phrase> Applications.
<phrase>Meta-model</phrase> Based <phrase>Information</phrase> <phrase>Mediation</phrase>.
<phrase>Federated</phrase> Process Framework for <phrase>Transparent</phrase> <phrase>Process Monitoring</phrase> in <phrase>Business Process Outsourcing</phrase>.
Fuzzy Aggregations and Fuzzy Specializations in <phrase>Eindhoven</phrase> Fuzzy <phrase>EER Model</phrase>.
Using <phrase>DEMO</phrase> and <phrase>ORM</phrase> in <phrase>Concert</phrase>: <phrase>A Case Study</phrase>.
<phrase>Improving</phrase> the <phrase>Understandability</phrase> of <phrase>Dynamic</phrase> <phrase>Semantics</phrase>: <phrase>An Enhanced</phrase> <phrase>Metamodel</phrase> for <phrase>UML</phrase> <phrase>State</phrase> Machines.
<phrase>Online</phrase> <phrase>Analytic</phrase> <phrase>Mining</phrase> for <phrase>Web Access</phrase> Patterns.
Modeling Motion: <phrase>Building</phrase> Blocks of a Motion <phrase>Database</phrase>.
<phrase>Comparing</phrase> <phrase>Metamodels</phrase> for <phrase>ER</phrase>, <phrase>ORM</phrase> and <phrase>UML</phrase> <phrase>Data</phrase> Models.
<phrase>Regression</phrase> <phrase>Test</phrase> Selection for <phrase>Database</phrase> Applications.
Framework for the <phrase>Rapid</phrase> Development of Modeling Environments.
<phrase>Revisiting</phrase> <phrase>Workflow</phrase> Modeling with <phrase>Statecharts</phrase>.
Normalization of Relations with <phrase>Nulls</phrase> in <phrase>Candidate Keys</phrase>: Traditional and Domain Key <phrase>Normal Forms</phrase>.
Metrics for <phrase>Workflow</phrase> <phrase>Design</phrase>: How an <phrase>Information Processing</phrase> View on <phrase>Business Processes</phrase> Helps to Make Good Designs.
<phrase>Preface</phrase>.
<phrase>Agile Development</phrase> Methods and <phrase>Component-Orientation</phrase>: A Review and Analysis.
An <phrase>Evaluation Framework</phrase> for <phrase>Component-Based</phrase> and <phrase>Service-Oriented</phrase> System <phrase>Development Methodologies</phrase>.
<phrase>Toward</phrase> <phrase>an Extended</phrase> Framework for <phrase>Human Factors</phrase> <phrase>Research</phrase> on <phrase>Data Modeling</phrase>.
An Attempt to Establish a <phrase>Correspondence</phrase> between <phrase>Development Methods</phrase> and <phrase>Problem Domains</phrase>.
Evaluation of <phrase>Component-Based Development</phrase> Methods.
Two <phrase>Meta</phrase>-Models for <phrase>Object-Role Modeling</phrase>.
<phrase>Comprehension</phrase> of <phrase>Hierarchical</phrase> <phrase>ER</phrase> <phrase>Diagrams</phrase> Compared to <phrase>Flat</phrase> <phrase>ER</phrase> <phrase>Diagrams</phrase>.
<phrase>Analyzing</phrase> and <phrase>Comparing</phrase> <phrase>Ontologies</phrase> with <phrase>Meta</phrase>-Methods.
<phrase>Participatory</phrase> Development of <phrase>Enterprise Process</phrase> Models.
Constraints on Conceptual <phrase>Join Paths</phrase>.
<phrase>Evaluating</phrase> Conceptual <phrase>Coherence</phrase> in Multi-<phrase>Modeling Techniques</phrase>.
A Comparison of the FOOM and <phrase>OPM</phrase> Methodologies for User <phrase>Comprehension</phrase> of Analysis Specifications.
<phrase>An Empirical Investigation</phrase> of <phrase>Requirements Specification</phrase> Languages: <phrase>Detecting</phrase> Defects While <phrase>Formalizing</phrase> Requirements.
<phrase>Goal Modeling</phrase> in <phrase>Requirements Engineering</phrase>: Analysis and Critique of <phrase>Current Methods</phrase>.
<phrase>Assessing</phrase> <phrase>Enterprise Modeling</phrase> Languages Using a <phrase>Generic</phrase> Quality Framework.
<phrase>Preface</phrase>.
<phrase>Validating</phrase> an <phrase>Evaluation Framework</phrase> for <phrase>Requirements Engineering</phrase> Tools.
An Approach for <phrase>Evolution</phrase>-Driven <phrase>Method Engineering</phrase>.
A <phrase>Taxonomic</phrase> Class <phrase>Modeling Methodology</phrase> for <phrase>Object-Oriented</phrase> Analysis.
A <phrase>Service-Oriented</phrase> Component <phrase>Modeling Approach</phrase>.
Using a <phrase>Semiotic</phrase> Framework for <phrase>a Comparative Study</phrase> of <phrase>Ontology</phrase> Languages and Tools.
Using <phrase>Logic</phrase> for <phrase>Querying XML Data</phrase>.
<phrase>Ubiquitous Access</phrase> to <phrase>Web</phrase> <phrase>Databases</phrase>.
<phrase>Protecting</phrase> Datasources over the <phrase>Web</phrase>: Policies, Models, and Mechanisms.
Practical <phrase>Case Study</phrase> of <phrase>a Web-based</phrase> <phrase>Tutor</phrase> Payment System.
<phrase>Web Content Management</phrase> and <phrase>Dynamic Web Pages</phrase> - A <phrase>Tutorial</phrase>.
<phrase>Cache Management</phrase> for <phrase>Web-Powered</phrase> <phrase>Databases</phrase>.
<phrase>Database</phrase>-Driven <phrase>Product Catalog</phrase> System.
The Development of <phrase>On-line</phrase> <phrase>Tests</phrase> Based on <phrase>Multiple Choice</phrase> Questions.
<phrase>Web Mining</phrase> to Create a <phrase>Domain Specific</phrase> <phrase>Web Portal</phrase> <phrase>Database</phrase>.
CODAR - A <phrase>POA</phrase>-based <phrase>CORBA</phrase> <phrase>Database</phrase> <phrase>Adaptor</phrase> for <phrase>Web Service</phrase> Infrastructures.
<phrase>Web-Powered</phrase> <phrase>Databases</phrase>: The <phrase>Low Level</phrase> in <phrase>C++</phrase>.
Effective <phrase>Databases</phrase> for Text & <phrase>Document Management</phrase>.
<phrase>Database</phrase> Integrity: Challenges and Solutions
<phrase>Encyclopedia</phrase> of <phrase>Information Science</phrase> and <phrase>Technology</phrase> (5 <phrase>Volumes</phrase>)
<phrase>Encyclopedia</phrase> of <phrase>Database</phrase> Technologies and Applications
<phrase>Multidimensional Databases</phrase>: Problems and Solutions
<phrase>Information</phrase> Modeling in the <phrase>New Millennium</phrase>
<phrase>Unified Modeling Language</phrase>: <phrase>Systems Analysis</phrase>, <phrase>Design</phrase> and <phrase>Development Issues</phrase>
<phrase>Advanced</phrase> Topics in <phrase>Database</phrase> <phrase>Research</phrase>, Vol. 1
<phrase>Advanced</phrase> Topics in <phrase>Database</phrase> <phrase>Research</phrase>, Vol. 2
<phrase>Advanced</phrase> Topics in <phrase>Database</phrase> <phrase>Research</phrase>, Vol. 3
<phrase>Information Modeling</phrase> Methods and Methodologies
<phrase>Spatial Databases</phrase>: Technologies, Techniques and Trends
<phrase>Web-Powered</phrase> <phrase>Databases</phrase>
Advances in <phrase>Real-Time</phrase> Systems.
<phrase>Ein</phrase> Datenbankkern zur <phrase>Speicherung</phrase> variabel strukturierter Feature-Terme. Implementierungstechniken.
<phrase>Eine</phrase> fallbasierte Lernkomponente als integraler Bestandteil der MOLTKE-Werkbank zur Diagnose <phrase>technischer Systeme</phrase>.
Oberflächenbasierte <phrase>Segmentierung von</phrase> Tiefenbildern.
<phrase>Ein</phrase> planbasierter <phrase>Ansatz</phrase> <phrase>zur Generierung</phrase> multimedialer Präsentationen.
<phrase>Effiziente</phrase> Pufferverwaltung in parallelen relationalen <phrase>Datenbanksystemen</phrase>.
Operationalisierung <phrase>des</phrase> Modells der Expertise <phrase>mit</phrase> <phrase>KARL</phrase>.
<phrase>Integration</phrase> of <phrase>Active</phrase> and <phrase>Deductive</phrase> <phrase>Database</phrase> Rules.
Indexierung und Retrieval von Feature-Bäumen <phrase>am</phrase> <phrase>Beispiel der</phrase> linguistischen <phrase>Analyse von</phrase> Textkorpora.
Inkrementelle wörterbuchbasierte Wortschatzerweiterungen in sprachverarbeitenden <phrase>Systemen</phrase>. <phrase>Entwurf</phrase> einer konstruktiven Lexikonkonzeption.
<phrase>Parallele</phrase> <phrase>Modelle</phrase> für Deduktionssysteme.
HAMVIS: <phrase>Generierung von</phrase> Visualisierungen in einem Rahmensystem <phrase>zur systematischen</phrase> <phrase>Entwicklung von</phrase> <phrase>Benutzungsschnittstellen</phrase>.
<phrase>Ein</phrase> modellgestütztes Analysesystem zum Bildverstehen strukturierter Dokumente.
<phrase>Verwendung von</phrase> Bildauswertungsmethoden <phrase>zur Erkennung</phrase> und Lagebestimmung von generischen polyedrischen <phrase>Objekten</phrase> <phrase>im</phrase> <phrase>Raum</phrase>.
<phrase>Implementierung</phrase> einer effizienten Anfrageauswertung <phrase>für ein</phrase> deduktives <phrase>Datenbanksystem</phrase>.
Fehlertolerante <phrase>und effiziente</phrase> <phrase>automatische</phrase> Analyse digitalisierter Dokumente zur Gewinnung von Hypertextstrukturen.
Effizientes Problemlösen durch flexible <phrase>Wiederverwendung von</phrase> Fällen auf verschiedenen Abstraktionsebenen.
Modellkonstruktion in <phrase>MIKE</phrase>. <phrase>Methoden und Werkzeuge</phrase>.
Steuerungsansätze <phrase>auf der Basis</phrase> <phrase>Neuronaler Netze</phrase> für sechsbeinige Laufmaschinen.
<phrase>Validierung</phrase> konzeptueller <phrase>Schemata</phrase>.
Fuzzy-<phrase>Techniken</phrase> in objektorientierten <phrase>Datenbanksystemen</phrase> <phrase>zur Unterstützung von</phrase> Entwurfsprozessen.
Pragmatische Programmsynthese.
<phrase>Dear KV</phrase>, <phrase>I</phrase> hope you <phrase>don't</phrase> <phrase>mind</phrase> if <phrase>I</phrase> <phrase>ask</phrase> you about a non-work-related problem, <phrase>though</phrase> <phrase>I</phrase> guess if you do <phrase>mind</phrase> you just won't answer. <phrase>I</phrase> work on <phrase>an open source</phrase> <phrase>project</phrase> when <phrase>I</phrase> have the time, and we have some annoying nontechnical problems. The problems are really people, and <phrase>I</phrase> think you know the ones <phrase>I</phrase> mean: people who constantly fight with other members of the <phrase>project</phrase> over what seem to be the most trivial points, or who contribute very little to the <phrase>project</phrase> but seem to require a huge amount of help for their particular needs. <phrase>I</phrase> find myself <phrase>thinking</phrase> it would be <phrase>nice</phrase> if such people just went away, but <phrase>I</phrase> <phrase>don't</phrase> think starting a <phrase>flame</phrase> <phrase>war</phrase> on our <phrase>mailing lists</phrase> over these things would really help. Any thoughts on this nontechnical problem?
<phrase>Ein</phrase> Informationsmodell für Ableitungsprozesse <phrase>und ihre</phrase> <phrase>Ergebnisse</phrase> <phrase>im</phrase> Wissensgewinnungsprozeß.
Separierung und Resolution multipler <phrase>Perspektiven</phrase> in der konzeptuellen <phrase>Modellierung</phrase>.
<phrase>Erweiterung der</phrase> Wissensbasierten <phrase>CAD</phrase>-<phrase>Konstruktion</phrase> <phrase>um</phrase> Restriktionsnetztechniken.
<phrase>Zur Darstellung</phrase> <phrase>und Verarbeitung von</phrase> <phrase>Wissen</phrase> über Himmelsrichtungen.
<phrase>Adaptive</phrase> <phrase>Neuronale Netze</phrase> <phrase>und ihre Anwendung</phrase> als <phrase>Modelle der</phrase> <phrase>Entwicklung</phrase> kortikaler Karten.
<phrase>Das</phrase> 3-stufige Frame-Repräsentationsschema - <phrase>eine</phrase> mehrdimensional modulare Basis <phrase>für die Entwicklung von</phrase> Expertensystemkernen.
<phrase>Extraktion von</phrase> linienförmigen Merkmalen und <phrase>Ermittlung des</phrase> optischen Flusses <phrase>mit</phrase> seinen Ableitungen aus Voll- und Halbbildfolgen.
Verfeinerung in objektorientierten Spezifikationen.
<phrase>Analyse und Optimierung</phrase> von Indexstrukturen in <phrase>Geo</phrase>-<phrase>Datenbanksystemen</phrase>.
Externe <phrase>Schemata</phrase> in objektorientierten Datenbansystemen.
Erklärungsbasiertes Computer-Sehen von Bildfolgen.
Zur natürlichsprachlichen interaktiven <phrase>Unterstützung</phrase> <phrase>im</phrase> Datenbankentwurf.
<phrase>Optimierung</phrase> deklarativer <phrase>Anfragen</phrase> in Objektbanken.
<phrase>Die</phrase> Bildanalysesprache TRIAS.
Deduktion <phrase>mit</phrase> Shannongraphen für Prädikatenlogik erster Stufe.
<phrase>Parallele</phrase> <phrase>Suche</phrase> <phrase>mit</phrase> randomisiertem Wettbewerb in Inferenzsystemen.
Erklärungen <phrase>für komplexe</phrase> <phrase>Wissensbasen</phrase>.
<phrase>Wissensbasierte</phrase> <phrase>Verfahren zur</phrase> <phrase>Synthese</phrase> mathematischer Beweise: <phrase>Eine</phrase> kombinatorische <phrase>Anwendung</phrase>.
Definition of Behavior in <phrase>Object-Oriented</phrase> <phrase>Databases</phrase> by <phrase>View Integration</phrase>.
Schematransformationen in <phrase>Datenbanken</phrase>.
<phrase>Ein</phrase> Regelsystem zur Integrtätssicherung in aktiven relationalen <phrase>Datenbanksystemen</phrase>.
<phrase>Verteiltes</phrase> und <phrase>kooperatives</phrase> <phrase>Planen</phrase> in einer flexiblen Fertigungsumgebung.
<phrase>Eine</phrase> <phrase>parallele</phrase> <phrase>Architektur</phrase> zur inkrementellen <phrase>Generierung</phrase> multimodaler Dialogbeiträge.
<phrase>View Integration</phrase> <phrase>für objektorientierte</phrase> <phrase>Datenbanken</phrase>.
Grammatikentwicklung <phrase>mit</phrase> Constraint <phrase>Logik</phrase> <phrase>Programmierung</phrase>. <phrase>Implementierung</phrase> einer Grammatik <phrase>für das</phrase> <phrase>Deutsche</phrase> <phrase>mit</phrase> <phrase>PROLOG</phrase> <phrase>III</phrase>.
Replikationsmanagement in verteilten <phrase>Informationssystemen</phrase>.
A <phrase>Tour</phrase> on TriGS. Devolopment of an <phrase>Active</phrase> System and Application of Rule Patterns for <phrase>Active</phrase> <phrase>Database Design</phrase>.
<phrase>Optimierung von</phrase> Speicherzugriffskosten in Objektbanken: <phrase>Clustering</phrase> und <phrase>Prefetching</phrase>.
Transaction Services for <phrase>Knowledge Base</phrase> <phrase>Management</phrase> Systems. Modeling Aspects, <phrase>Architectural</phrase> Issues, and Realization Techniques.
<phrase>Diagnosis</phrase> and Repair of <phrase>Constraint Violations</phrase> in <phrase>Database Systems</phrase>.
Föderierte Datenbanktechnologie <phrase>für die</phrase> Molekularbiologie: <phrase>Konzepte</phrase>, <phrase>Einsatz</phrase> <phrase>und Nutzen</phrase>.
<phrase>Das</phrase> <phrase>digital</phrase> <phrase>lecture</phrase> board. <phrase>Konzeption</phrase>, <phrase>Design</phrase> <phrase>und Entwicklung</phrase> eines <phrase>Whiteboards</phrase> für synchrones Teleteaching.
<phrase>DB</phrase>-gestützte Kooperationsdienste für <phrase>technische</phrase> Entwurfsanwendungen.
Bedarfsorientierte Dienstvermittlung in vernetzten <phrase>Systemen</phrase>.
Materialisation and Parallelism in the Mapping of an <phrase>Object Model</phrase> to a <phrase>Relational</phrase> <phrase>Multi-processor</phrase> System.
Flexible Kontrolle in <phrase>Expertensystemen</phrase> <phrase>zur Planung und</phrase> <phrase>Konfigurierung</phrase> in technischen Domänen.
<phrase>Wissensbasiertes</phrase> Lösen von Ablaufplanungsproblemen durch explizite Heuristiken.
<phrase>Ein</phrase> Basisdienst <phrase>für die</phrase> zuverlässige Abwicklung langdauernder Aktivitäten.
Interoperabilität <phrase>von Datenbanksystemen</phrase> bei struktureller Heterogenität. <phrase>Architektur</phrase>, Beschreibungs- und Ausführungsmodell <phrase>zur Unterstützung der</phrase> <phrase>Integration</phrase> und Migration.
Konzeptionelle <phrase>Modellierung</phrase> <phrase>von Informationssystemen</phrase> als <phrase>verteilte</phrase> Objektsysteme.
Trabsaktionsverwaltung in heterogenen, <phrase>föderierten Datenbanksystemen</phrase>.
<phrase>Entwurf</phrase> einer <phrase>Sprache</phrase> <phrase>für die</phrase> verhaltensorientierte konzeptionelle <phrase>Modellierung</phrase> <phrase>von Informationssystemen</phrase>.
Schemaintegration <phrase>für den Entwurf</phrase> föderierter <phrase>Datenbanken</phrase>.
Kommunikationsoptimierung <phrase>für mobile</phrase> <phrase>Agenten</phrase> durch hierarchisches Klonen.
Erwartungsgestützte Analyse medizinischer Befundungstexte. <phrase>Ein wissensbasiertes</phrase> <phrase>Modell</phrase> zur Sprachverarbeitung.
Einheitliche <phrase>Theorie</phrase> für korrekte <phrase>parallele</phrase> und fehlertolerante <phrase>Ausführung von</phrase> Datenbanktransaktionen.
<phrase>Architektur</phrase> verteilter <phrase>Workflow-Management-Systeme</phrase>.
ALCP - <phrase>Ein</phrase> hybrider <phrase>Ansatz zur Modellierung</phrase> von Unsicherheit in terminologischen Logiken.
<phrase>Das Konzept</phrase> der Transaktionshülle zur konsistenten <phrase>Spezifikation von</phrase> Abhänigigkeiten in komplexen <phrase>Anwendungen</phrase>.
Kognitives <phrase>Parsing</phrase>: <phrase>Repräsentation und Verarbeitung</phrase> sprachlichen <phrase>Wissens</phrase>.
<phrase>Dynamische</phrase>, situationsbezogene <phrase>Hypertext</phrase>-Handbücher <phrase>für komplexe</phrase> Tätigkeiten.
<phrase>Effiziente</phrase> Konsistenzprüfunf in <phrase>Datenbanksystemen</phrase>.
MoKon - <phrase>Ein Ansatz zur</phrase> Wissensbasierten <phrase>Konfiguration von</phrase> Variantenerzeugnissen.
Skalierbare <phrase>Multicast</phrase>-<phrase>Kommunikation</phrase> in Weitverkehrsnetzen.
<phrase>Source-to-Source</phrase> Transformationen zur Erklärung <phrase>des</phrase> Programmverhaltens bei <phrase>deduktiven Datenbanken</phrase>.
Symbolisches Lösen mathematischer <phrase>Probleme</phrase> durch <phrase>Kooperation</phrase> algorithmischer und logischer <phrase>Systeme</phrase>.
Situationsanalyse bei Kontakten <phrase>während der</phrase> <phrase>Ausführung von</phrase> Roboterbewegungen in unsicheren <phrase>Umgebungen</phrase>.
Begleitende Montageablaufplanung <phrase>für ein</phrase> sensorgestütztes Zweiarm-Manipulatorsystem.
Sichtenmanagement in <phrase>Client-Server</phrase>-<phrase>Systemen</phrase>.
<phrase>Dynamische</phrase> Modularisierung lexikalischer <phrase>Informationen</phrase> in einem Wiederverwendungsszenario.
<phrase>Wissensbasierte</phrase> Analyse medizinischer Bilder - <phrase>das</phrase> Biotop-<phrase>Verfahren</phrase>.
Benutzeranpaßbare <phrase>semantische</phrase> Sprachanalyse und Begriffsrepräsentation <phrase>für die medizinische</phrase> <phrase>Dokumentation</phrase>.
<phrase>Heuristic</phrase> and <phrase>Randomised</phrase> <phrase>Optimisation</phrase> Techniques in <phrase>Object-Oriented</phrase> <phrase>Database Systems</phrase>.
Änderungskontrolle in <phrase>deduktiven Datenbanken</phrase>.
Verdeckungen und spezielle Sichten <phrase>bei der</phrase> Polyederrekonstruktion.
<phrase>Access Control</phrase> in <phrase>Object-Oriented</phrase> <phrase>Federated Database Systems</phrase>.
<phrase>Generierung</phrase> domänenspezifischer Wissensrepräsentationssysteme und Transformation <phrase>von Wissensbasen</phrase> <phrase>mit</phrase> einer <phrase>Anwendung</phrase> in der Rechtsinformatik.
<phrase>Interaktive</phrase> Akquisition elementarer Roboterfähigkeiten.
Modulare Problemlösungsarchitekturen für Konstruktionssysteme.
Toleranz- und Kongruenzrelationen in <phrase>relationalen Datenbanken</phrase>.
<phrase>Modellierung von</phrase> Expertise über Konfigurierungsaufgaben.
<phrase>Reduktion</phrase> <phrase>zur effizienten</phrase> <phrase>Programmierung von</phrase> <phrase>Methoden</phrase> in deduktiven objektorientierten <phrase>Datenbanken</phrase>.
An Approach to <phrase>Query Processing</phrase> in <phrase>Advanced</phrase> <phrase>Database Systems</phrase>.
<phrase>Metadata</phrase>-Based <phrase>Middleware</phrase> for <phrase>Integrating</phrase> <phrase>Information</phrase> Systems.
<phrase>Semantic Integrity Constraints</phrase> in <phrase>Federated</phrase> <phrase>Database Schemata</phrase>.
<phrase>MODEL</phrase>-<phrase>K</phrase>: <phrase>Modellierung</phrase> und Operationalisierung von Selbsteinschätzung <phrase>und -steuerung</phrase> durch <phrase>Reflexion</phrase> und Metawissen.
EMSY - <phrase>Ein</phrase> Modellierungskonzept für ökologische und biologische <phrase>Systeme</phrase> <phrase>unter besonderer Berücksichtigung</phrase> ihrer dynamischen Veränderung.
Akquisition von Integritätsbedingungen in <phrase>Datenbanken</phrase>.
Inkrementelle, domänenunabhängige Thesauruserstellung in dokumentbasierten <phrase>Informationssystemen</phrase> durch <phrase>Kombination von</phrase> Konstruktionsverfahren.
<phrase>Unterstützung</phrase> anwendungsspezifischer Zugriffsprofile in Objektbanksystemen.
<phrase>Dynamische</phrase> Beziehungen als <phrase>Modell</phrase> der <phrase>Kooperation</phrase> in verteilten Objektsystemen.
<phrase>Eine</phrase> mehrschichtige <phrase>Architektur</phrase> <phrase>zur Fehlerdiagnose</phrase> und Fehlerbehebung <phrase>bei der Entwicklung</phrase> logischer <phrase>Programme</phrase>.
<phrase>Entwurf eines</phrase> objektorientierten Datenbankmodells <phrase>Für relationale</phrase> <phrase>Datenbanksysteme</phrase>.
Vorgangsmodelle. <phrase>Ein Ansatz zur</phrase> <phrase>Repräsentation und</phrase> Analyse zeitabhängigen <phrase>Verhaltens</phrase> <phrase>bei der</phrase> <phrase>Überwachung und</phrase> Diagnose <phrase>technischer Systeme</phrase>.
Terminierung und Konfluenz in einer aktiven objektorientierten <phrase>Datenbank</phrase>.
<phrase>Integration</phrase> von Aktionsplanung und <phrase>Konfigurierung</phrase>.
Distributed <phrase>Machine Learning</phrase>.
Detektion, Verfolgung <phrase>und Klassifikation</phrase> bewegter <phrase>Objekte</phrase> in monokularen Bildfolgen <phrase>am</phrase> <phrase>Beispiel von</phrase> Straßenverkehrsszenen.
Produkorientierte <phrase>automatische</phrase> <phrase>Planung von</phrase> Prüfoperationen <phrase>bei der</phrase> robotergestützten <phrase>Montage</phrase>.
<phrase>Ein Verfahren zur</phrase> semi-automatischen <phrase>Generierung von</phrase> Mediatorspezifikationen.
<phrase>Wissensbasierte</phrase> Verkehrsszenenanalyse zur Fahrerunterstützung.
Replikation in vernetzten <phrase>Systemen mit</phrase> mobilen Teilnehmern.
Funktionsorientiertes <phrase>Management</phrase> heterogener <phrase>ATM</phrase>-<phrase>Netzwerke</phrase>.
<phrase>Control Mechanisms</phrase> in <phrase>Distributed Object</phrase> Bases. Synchronization, <phrase>Deadlock</phrase> Detection, Migration.
Zeitrepräsentation und merkmalsgesteuerte <phrase>Suche</phrase> zur Terminplanung.
Aktive <phrase>Mechanismen</phrase> zur Konsistenzsicherung in Föderationen heterogener und autonomer <phrase>Datenbanken</phrase>.
<phrase>Modellbildung</phrase> und <phrase>Architektur von</phrase> verteilten <phrase>Workflow-Management-Systemen</phrase>.
Flexible <phrase>Steuerung</phrase> eines sprachverstehenden Systems <phrase>mit</phrase> homogener Wissensbasis.
<phrase>Wissensbasierte</phrase> Greifplanung für Mehrfinger-Roboterhände.
<phrase>Entwicklung</phrase> verteilter Objektstrukturen für skalierbare und hochgradig verfügbare <phrase>Informationssysteme</phrase>.
<phrase>Konzeption eines</phrase> regelbasierten Systems für Produktdatenmanagement in <phrase>CIM</phrase>.
<phrase>Digitale</phrase> und Allgemeine Topologie in der bildhaften <phrase>Wissensrepräsentation</phrase>.
Einbettung von Konzepthierarchien in <phrase>ein</phrase> Deduktives <phrase>Datenbanksystem</phrase>.
Typsichere Objektbankmigration.
<phrase>MISTRAL</phrase>: Processing <phrase>Relational</phrase> Queries using a <phrase>Multidimensional</phrase> Access Technique.
Wissensintensives <phrase>Lernen</phrase> für zeitkritische <phrase>technische</phrase> Diagnoseaufgaben.
Selbstorganisierende <phrase>neuronale</phrase> Netzwerkmodelle zur Bewegungssteuerung.
<phrase>Lernen</phrase> durch Genetisch-<phrase>Neuronale</phrase> <phrase>Evolution</phrase>: Aktive <phrase>Anpassung</phrase> an unbekannte <phrase>Umgebungen</phrase> <phrase>mit</phrase> selbstentwickelten parallelen <phrase>Netzwerken</phrase>.
Schema-unabhängige <phrase>Anfragesprachen für</phrase> <phrase>relationale Datenbanken</phrase>.
<phrase>Qualitative</phrase> Analyse <phrase>im Rahmen</phrase> qualitativen und modellbasierten Schließens.
<phrase>Ein</phrase> Dialogmodul <phrase>für ein</phrase> Spracherkennungs- und Dialogsystem.
<phrase>Cyclops</phrase> - <phrase>Wissensbasierte</phrase> <phrase>Bildanalyse</phrase> in <phrase>der Medizin</phrase>.
Hypermediabasiertes <phrase>Knowledge Engineering</phrase> <phrase>für verteilte</phrase> <phrase>wissensbasierte Systeme</phrase>.
Anfrageoptimierung in objektrelationalen <phrase>Datenbanken</phrase> durch kostenbedingte Termersetzungen
<phrase>Dynamische</phrase> <phrase>semantische</phrase> <phrase>Netze</phrase> - Zur Kontextabhängigkeit von Wortbedeutungen.
<phrase>Extending</phrase> the <phrase>Stratification</phrase> Approach for <phrase>Deductive</phrase> <phrase>Database Systems</phrase>.
<phrase>Wissensbasierte</phrase> <phrase>Synthese von</phrase> Bildanalyseprogrammen.
<phrase>Adaptive</phrase> Roboterkontrolle <phrase>mit</phrase> konnektionistischen <phrase>Systemen</phrase>.
<phrase>Design</phrase> and Implementation of a <phrase>Database</phrase> <phrase>Programming Language</phrase> for <phrase>XML-based</phrase> Applications.
Towards the Intelligent <phrase>On-line</phrase> <phrase>Home Office</phrase>.
The IT <phrase>Leap</phrase> and the Sektornet.
<phrase>Technology</phrase> as the <phrase>Catalyst</phrase> of Users' Acceptance in <phrase>Electronic Commerce</phrase>.
<phrase>Introduction</phrase> by the <phrase>Editors</phrase>.
<phrase>ACCORD</phrase> Solutions for Flexible Working.
Flexible <phrase>Quality-of-Service</phrase> <phrase>Technology</phrase> for <phrase>Supporting</phrase> <phrase>Voice/Data</phrase>-Integrated <phrase>Nomadic</phrase> <phrase>Networking</phrase>.
The Telco's Goldmine - 50 <phrase>Mb/s</phrase> to the <phrase>General</phrase> <phrase>Public</phrase> over the <phrase>Local</phrase> <phrase>Telephone</phrase> Lines.
<phrase>Support Services</phrase> for <phrase>Business Process</phrase> Oriented <phrase>Telework</phrase>. The COBIP <phrase>Project</phrase>.
New Ways of Flexible Working: The Contribution of ACTS, and Issues for <phrase>IST</phrase>.
<phrase>Interoperability</phrase> for <phrase>Multimedia</phrase> Services: The Approach of the <phrase>Standards Bodies</phrase> - <phrase>An Overview</phrase> Based on ACTS Guideline SII G06.
<phrase>Net</phrase> Working in the <phrase>Knowledge Economy</phrase>.
<phrase>Internet Service</phrase> Architectures and <phrase>ATM</phrase> - The <phrase>ELISA</phrase> Approach.
<phrase>Developing</phrase> a <phrase>Reference Model</phrase> for <phrase>Networked</phrase> Flexible Work through <phrase>Industry</phrase> Trials.
New <phrase>Business</phrase> Paradigms.
UMPTIDUMPTI - <phrase>Anytime</phrase>, Anywhere, Anybody - <phrase>UMTS</phrase> for ALL.
Giving <phrase>Mobile</phrase> Users Access to <phrase>Net-Based</phrase> Services - A <phrase>Mobile</phrase> Agent Approach.
<phrase>Gestalt</phrase> - <phrase>On-line</phrase> <phrase>Education</phrase> and Training - <phrase>State</phrase> of the <phrase>Art</phrase>.
TECODIS. The Experience of Teleworking for <phrase>Software</phrase> Developers.
Flexible Working <phrase>Technology</phrase> for <phrase>Sustainable</phrase> Development and <phrase>Social Inclusion</phrase>.
On Modeling Conformance for Flexible Transformation over <phrase>Data</phrase> Models.
<phrase>Knowledge Representation</phrase> and Transformation in <phrase>Ontology</phrase>-based <phrase>Data Integration</phrase>.
The '<phrase>Family</phrase> of Languages' Approach to <phrase>Semantic</phrase> <phrase>Interoperability</phrase>.
<phrase>UML</phrase> for the <phrase>Semantic Web</phrase>: <phrase>Transformation-Based</phrase> Approaches.
<phrase>Tracing</phrase> <phrase>Data Lineage</phrase> Using <phrase>Schema Transformation</phrase> Pathways.
<phrase>Transforming</phrase> <phrase>UML</phrase> <phrase>Domain Descriptions</phrase> into <phrase>Configuration Knowledge Bases</phrase>.
<phrase>Transforming</phrase> <phrase>Data</phrase> Models with <phrase>UML</phrase>.
<phrase>Schema Conversion</phrase> Methods between <phrase>XML</phrase> and <phrase>Relational</phrase> Models.
RDFT: A Mapping <phrase>Meta</phrase>-<phrase>Ontology</phrase> for <phrase>Web Service</phrase> <phrase>Integration</phrase>.
A <phrase>Logic Programming</phrase> Approach to <phrase>RDF</phrase> Document and <phrase>Query Transformation</phrase>.
<phrase>Ontology</phrase> Extraction for <phrase>Distributed Environments</phrase>.
<phrase>Knowledge</phrase> Transformation for the <phrase>Semantic Web</phrase>
Machine <phrase>Reconstruction</phrase> of <phrase>Human</phrase> <phrase>Control Strategies</phrase>
Flexible Working - New <phrase>Network Technologies</phrase>
<phrase>Natural Language Processing</phrase> for <phrase>Online</phrase> Applications: <phrase>Text Retrieval</phrase>, Extraction & Categorization
<phrase>WFMS</phrase>: The <phrase>Next</phrase> Generation of <phrase>Distributed Processing</phrase> Tools.
<phrase>Semantic</phrase>-Based Decomposition of Transactions.
<phrase>An Extensible</phrase> Approach to <phrase>Realizing</phrase> <phrase>Advanced</phrase> Transaction Models.
The <phrase>Reflective</phrase> Transaction Framework.
<phrase>Customizable</phrase> <phrase>Concurrency Control</phrase> for <phrase>Persistent</phrase> <phrase>Java</phrase>.
<phrase>Inter- and Intra</phrase>-Transaction Parallelism for Combined <phrase>OLTP</phrase>/<phrase>OLAP</phrase> Workloads.
Transaction <phrase>Optimization Techniques</phrase>.
Towards Distributed <phrase>Real-Time</phrase> <phrase>Concurrency</phrase> and <phrase>Coordination</phrase> Control.
Flexible <phrase>Commit Protocols</phrase> for <phrase>Advanced</phrase> <phrase>Transaction Processing</phrase>.
<phrase>Toward</phrase> <phrase>Formalizing</phrase> Recovery of (<phrase>Advanced</phrase>) Transactions.
ConTracts <phrase>Revisited</phrase>.
<phrase>Transaction Processing</phrase> in <phrase>Broadcast</phrase> Disk Environments.
Transactions in <phrase>Transactional Workflows</phrase>.
<phrase>Logical</phrase> Handling of Inconsistent and Default <phrase>Information</phrase>.
<phrase>Approximate Reasoning</phrase> Systems: <phrase>Handling Uncertainty</phrase> and Imprecision in <phrase>Information</phrase> Systems.
<phrase>An Introduction</phrase> to the <phrase>Fuzzy Set</phrase> and <phrase>Possibility Theory</phrase>-Based Treatment of <phrase>Flexible Queries</phrase> and Uncertain or Imprecise <phrase>Databases</phrase>.
Uncertainty in Intelligent <phrase>Databases</phrase>.
A <phrase>Bibliography</phrase> on <phrase>Uncertainty Management</phrase> in <phrase>Information</phrase> Systems.
<phrase>Probabilistic</phrase> and <phrase>Bayesian</phrase> Representations of Uncertainty in <phrase>Information</phrase> Systems: A <phrase>Pragmatic</phrase> <phrase>Introduction</phrase>.
Uncertain, Incomplete, and <phrase>Inconsistent Data</phrase> in Scientific and <phrase>Statistical Databases</phrase>.
On the Classification of Uncertainty Techniques in Relation to the Application Needs.
<phrase>Introduction</phrase>.
Sources of Uncertainty, Imprecision, and <phrase>Inconsistency</phrase> in <phrase>Information</phrase> Systems.
<phrase>Knowledge</phrase> Discovery and Acquisition From <phrase>Imperfect Information</phrase>.
<phrase>Imperfect Information</phrase>: <phrase>Imprecision and Uncertainty</phrase>.
The <phrase>Transferable Belief Model</phrase> for <phrase>Belief</phrase> Representation.
Uncertainty in <phrase>Information Retrieval</phrase> Systems.
<phrase>Imperfect Information</phrase> in <phrase>Relational Databases</phrase>.
<phrase>STORM</phrase>: <phrase>An Object-Oriented</phrase> <phrase>Multimedia</phrase> <phrase>DBMS</phrase>.
Synchronization and <phrase>User Interaction</phrase> in <phrase>Distributed Multimedia</phrase> Presentation Systems.
<phrase>Database</phrase> Approach for the <phrase>Management</phrase> of <phrase>Multimedia</phrase> <phrase>Information</phrase>.
A <phrase>Visual</phrase> <phrase>Multimedia</phrase> <phrase>Query Language</phrase> for <phrase>Temporal Analysis</phrase> of <phrase>Video</phrase> <phrase>Data</phrase>.
A <phrase>Multimedia</phrase> <phrase>Query Specification</phrase> <phrase>Language</phrase>.
<phrase>Searching and Browsing</phrase> a Shared <phrase>Video</phrase> <phrase>Database</phrase>.
<phrase>Load-Balanced</phrase> <phrase>Data</phrase> Placement for <phrase>Variable</phrase>-Rate <phrase>Continuous</phrase> <phrase>Media</phrase> Retrieval.
<phrase>Multimedia</phrase> <phrase>DBMS</phrase> - <phrase>Reality</phrase> of <phrase>Hype</phrase>?
<phrase>Model</phrase> for <phrase>Interactive Retrieval</phrase> of Videos and Still Images.
<phrase>Playout</phrase> <phrase>Management</phrase> in <phrase>Multimedia</phrase> <phrase>Database Systems</phrase>.
<phrase>An Object-Oriented</phrase> Modeling of <phrase>Multimedia</phrase> <phrase>Database</phrase> Objects and Applications.
<phrase>Integration</phrase> of <phrase>Simulation</phrase> and <phrase>Multimedia</phrase> in <phrase>Automatically Generated</phrase> <phrase>Internet</phrase> Courses.
A <phrase>Visual</phrase> <phrase>Simulation</phrase> Environment for <phrase>MIPS</phrase> Based on <phrase>VHDL</phrase>.
An <phrase>Authoring</phrase> Environment for the SimulNet Educational Platform.
BabelWin: An environment for <phrase>learning</phrase> and monitoring <phrase>reading and writing</phrase> skills.
An <phrase>Internet</phrase> <phrase>Distance-Learning</phrase> Operating <phrase>Model</phrase>.
<phrase>Synchronous</phrase> <phrase>Drawing</phrase> Actions in Environments of <phrase>Collaborative Learning</phrase> of <phrase>Design</phrase>.
Interconnecting <phrase>Courseware</phrase> Modules via <phrase>WWW</phrase>.
APRISA: A Tool for <phrase>Teaching</phrase> the Interconnection of <phrase>Open Systems</phrase>.
<phrase>Adaptive</phrase> <phrase>Internet</phrase>-<phrase>based learning</phrase> with the TANGOW system.
Interactive <phrase>Mathematics</phrase> <phrase>Teaching</phrase> with Mathedu.
<phrase>Teaching</phrase> Support Units.
The Interactive <phrase>Physics</phrase> Course on the <phrase>Internet</phrase>.
<phrase>Task Based</phrase> Training of Application Users.
SUMA <phrase>Project</phrase> (<phrase>Open</phrase> <phrase>Murcia</phrase> <phrase>University</phrase> Services).
<phrase>Introducing</phrase> <phrase>Waves</phrase> Using Simulations Controled From <phrase>Html</phrase> Files.
Using <phrase>Bayesian</phrase> Networks in <phrase>Computerized Adaptive</phrase> <phrase>Tests</phrase>.
<phrase>XML</phrase>-based <phrase>Integration</phrase> of <phrase>Hypermedia</phrase> <phrase>Design</phrase> and <phrase>Component-Based</phrase> Techniques in the <phrase>Production</phrase> of <phrase>Educational Applications</phrase>.
<phrase>Computers</phrase> in <phrase>Education</phrase>: the <phrase>Near Future</phrase>.
<phrase>Learning</phrase> <phrase>Basque</phrase> in a Distance-<phrase>Adaptive</phrase> way.
<phrase>Collaborative planning</phrase> for <phrase>problem solution</phrase> in <phrase>distance learning</phrase>.
<phrase>High</phrase> <phrase>Level Design</phrase> of <phrase>Web-Based</phrase> Environments for <phrase>Distance Education</phrase>.
M.A.C. A <phrase>Hypermedia</phrase> System for <phrase>Learning</phrase> <phrase>Electronics</phrase>.
Computer-<phrase>Human</phrase> <phrase>Learning</phrase>.
<phrase>Natural Language Processing</phrase> in Educational <phrase>Computer Science</phrase>.
<phrase>Educational Web Sites</phrase>: Some Issues for Evaluation.
<phrase>Building</phrase> a <phrase>Virtual Learning Environment</phrase> Using Agents.
Approach to Intelligent <phrase>Adaptive</phrase> Testing.
<phrase>Evaluation Criteria</phrase> for <phrase>Hypermedia</phrase> <phrase>Educational Systems</phrase>.
Using teachers as heuristics evaluators of <phrase>educational software</phrase> interfaces.
<phrase>Creating</phrase> <phrase>Collaborative Environments</phrase> for <phrase>Web-based Training</phrase> Scenarios.
The <phrase>Next</phrase> Step in <phrase>Computer Based</phrase> <phrase>Education</phrase>: the <phrase>Learning</phrase> Technologies <phrase>Standardisation</phrase>.
<phrase>Advanced</phrase> <phrase>Learning</phrase> Environments: Changed Views and <phrase>Future Perspectives</phrase>.
Development of <phrase>Didactic</phrase> Resources for <phrase>Distance Learning</phrase> based on <phrase>Simulation</phrase>.
TutorMap. Past, Present and Future of a <phrase>Mathematics</phrase> <phrase>Tutoring</phrase> System.
<phrase>Learning</phrase> Communities in the <phrase>Web</phrase>: Concepts and strategies.
<phrase>Symbolic</phrase> <phrase>Calculus</phrase> Training by Means of MathTrainer.
EJS: An <phrase>Authoring</phrase> Tool to Develop <phrase>Java</phrase> Applications.
<phrase>ADAM</phrase> CASE. Using <phrase>upper</phrase> <phrase>CASE tools</phrase> in <phrase>Software Engineering</phrase> <phrase>Laboratory</phrase>.
SICAS. Interactive system for <phrase>algorithm</phrase> development and <phrase>simulation</phrase>.
Simurob and JRF. <phrase>Teaching</phrase> tools for <phrase>robot</phrase> <phrase>simulation</phrase> and <phrase>programming</phrase>.
Collares Ortofónicos. System for the training of the <phrase>suprasegmental</phrase> parameters of intensity and <phrase>rhythm</phrase> of the articulated <phrase>sound</phrase>.
EXercita. A System for <phrase>Archiving</phrase> and <phrase>Publishing</phrase> <phrase>Programming</phrase> Exercises.
<phrase>Interactive Design</phrase> of <phrase>Adaptive</phrase> Courses.
Using <phrase>Simulation</phrase> and <phrase>Virtual Reality</phrase> for <phrase>Distance Education</phrase>.
ED68K. A <phrase>design</phrase> framework for the development of <phrase>digital</phrase> systems based on <phrase>MC68000</phrase>.
An Experience on <phrase>Virtual</phrase> <phrase>Teaching</phrase>: AulaNet.
<phrase>Guided</phrase> Collaborative <phrase>Chess</phrase> <phrase>Tutoring</phrase> through <phrase>Game</phrase> <phrase>History</phrase> Analysis.
Using Analysis, <phrase>Design</phrase> and Development of <phrase>Hypermedia</phrase> Applications in the Educational Domain.
<phrase>Ubiquitous Computing</phrase> and Collaboration. New <phrase>interaction paradigms</phrase> in the <phrase>classroom</phrase> for the <phrase>21st Century</phrase>.
<phrase>Shared Whiteboard</phrase> <phrase>Manager</phrase> and <phrase>Student</phrase> <phrase>Notebook</phrase> for the PLAN-<phrase>G</phrase> <phrase>Telematic</phrase> Platform.
Creation of a <phrase>Multimedia</phrase> System for <phrase>Learning</phrase> about Oscillations.
Guiding the user. An element to aid <phrase>knowledge</phrase> <phrase>construction</phrase> in <phrase>adaptive</phrase> <phrase>hypermedia</phrase> systems.
<phrase>Pedagogical</phrase> Strategies With <phrase>Hypermedia</phrase>. Limiting access to <phrase>hyperspace</phrase> for <phrase>educational purposes</phrase>.
<phrase>Artificial Intelligence</phrase> in the HyperClass: <phrase>Design</phrase> Issues.
<phrase>Improving</phrase> the <phrase>Language</phrase> <phrase>Mastery</phrase> through <phrase>Responsive</phrase> Environments.
<phrase>Test</phrase> <phrase>Construction</phrase> and <phrase>Management</phrase> with Network <phrase>Adaptive Control</phrase>.
Foundations of <phrase>Programming</phrase>: a <phrase>Teaching</phrase> Improvement.
<phrase>HCI</phrase> Curricula in <phrase>Spain</phrase>. A cooperatively designed, <phrase>free</phrase> <phrase>Web</phrase>-access <phrase>syllabus</phrase>.
<phrase>SQL</phrase>-92 <phrase>Compatibility Issues</phrase>.
<phrase>Temporal Data</phrase> Types.
Aggregates
Modification.
A Second Example.
Schema Specification.
The From <phrase>Clause</phrase>.
Rationale for a Temporal Extension to <phrase>SQL</phrase>.
<phrase>Supporting</phrase> Multiple Calendars.
The <phrase>Surrogate Data</phrase> Type.
Vacuuming.
The <phrase>Data Model</phrase> for Time.
A <phrase>Timestamp</phrase> Representation.
<phrase>Temporal Granularity</phrase>.
Temporal Indeterminancy.
The Baseline <phrase>Clock</phrase>.
<phrase>``</phrase>Now''.
Valid-Time Selection and <phrase>Projection</phrase>.
Cursors.
The TSQL2 <phrase>Data Model</phrase>.
Transaction Time Support.
<phrase>Schema Versioning</phrase>.
<phrase>Introduction</phrase> to TSQL2.
TSQL2 <phrase>Tutorial</phrase>.
Event Tables.
An <phrase>Algebra</phrase> for TSQL2
An <phrase>Architectural</phrase> Framework.
Frontmatter.
References, <phrase>Author</phrase> <phrase>Index</phrase>, <phrase>Syntax</phrase> <phrase>Index</phrase>, <phrase>Subject Index</phrase>.
<phrase>Language</phrase> Specification.
<phrase>Clustering</phrase> in <phrase>Metric Spaces</phrase> with Applications to <phrase>Information Retrieval</phrase>.
Techniques for <phrase>Textual Document</phrase> <phrase>Indexing</phrase> and Retrieval <phrase>Knowledge</phrase> Sources and <phrase>Data Mining</phrase>.
A <phrase>Science</phrase> <phrase>Data</phrase> System <phrase>Architecture</phrase> for <phrase>Information Retrieval</phrase>.
<phrase>Finding</phrase> Topics in Collections of Documents: A Shared <phrase>Nearest Neighbor</phrase> Approach.
Techniques for <phrase>Clustering</phrase> <phrase>Massive Data Sets</phrase>.
On <phrase>Quantitative</phrase> Evaluation of <phrase>Clustering</phrase> Systems.
<phrase>Document Clustering</phrase>, Visualization, and Retrieval <phrase>Link Mining</phrase>.
<phrase>Clustering</phrase> Techniques for <phrase>Large Database</phrase> <phrase>Cleansing</phrase>.
Query <phrase>Clustering</phrase> in the <phrase>Web</phrase> Context.
<phrase>Granular Computing</phrase> for the <phrase>Design</phrase> of <phrase>Information Retrieval</phrase> <phrase>Support Systems</phrase>.
<phrase>Indexing</phrase> Techniques for <phrase>Advanced</phrase> <phrase>Database Systems</phrase>
<phrase>Advanced</phrase> <phrase>Relational</phrase> <phrase>Programming</phrase>: <phrase>Mathematics</phrase> and Its Applications.
<phrase>Mining</phrase> <phrase>the World Wide Web</phrase>: An <phrase>Information</phrase> Search Approach
Logics for <phrase>Databases</phrase> and <phrase>Information</phrase> Systems (the <phrase>book</phrase> grow out of the <phrase>Dagstuhl Seminar</phrase> 9529: Role of Logics in <phrase>Information</phrase> Systems, 1995)
The Discovery of the <phrase>Artificial</phrase>. Behavior, <phrase>Mind</phrase> and Machines Before and Beyond <phrase>Cybernetics</phrase>
<phrase>Multimedia</phrase> <phrase>Mining</phrase>: A <phrase>Highway</phrase> to <phrase>Intelligent Multimedia</phrase> Documents
Client <phrase>Data Caching</phrase>: A <phrase>Foundation</phrase> for <phrase>High</phrase> Performance <phrase>Object Oriented</phrase> <phrase>Database Systems</phrase>
<phrase>Software Prototyping</phrase> in <phrase>Data</phrase> and <phrase>Knowledge Engineering</phrase>
<phrase>Advanced</phrase> Transaction Models and Architectures
<phrase>Advanced</phrase> <phrase>Database</phrase> <phrase>Indexing</phrase>
<phrase>Advanced</phrase> Signature <phrase>Indexing</phrase> for <phrase>Multimedia</phrase> and <phrase>Web Applications</phrase>
:<phrase>Advanced</phrase> Signature <phrase>Indexing</phrase> for <phrase>Multimedia</phrase> and <phrase>Web Applications</phrase> is an excellent reference for professionals involved in the development of applications in <phrase>multimedia</phrase> <phrase>databases</phrase> or the <phrase>Web</phrase> and may also serve as a <phrase>textbook</phrase> for <phrase>advanced</phrase> level courses in <phrase>database</phrase> and <phrase>information retrieval</phrase> systems.
<phrase>Ontology</phrase>-Based <phrase>Query Processing</phrase> for <phrase>Global Information Systems</phrase>
<phrase>Ontology</phrase>-based <phrase>query processing</phrase> for <phrase>global</phrase> <phrase>information</phrase> systems describes an <phrase>initiative</phrase> for <phrase>enhancing</phrase> <phrase>query processing</phrase> in a <phrase>global</phrase> <phrase>information</phrase> system. The following are some of the <phrase>relevant features</phrase>: Providing <phrase>semantic</phrase> descriptions of <phrase>data</phrase> repositories using <phrase>ontologies</phrase>. Dealing with different vocabularies so that users are not forced to use a common one. Defining a strategy that permits the <phrase>incremental</phrase> <phrase>enrichment</phrase> of answers by visiting new <phrase>ontologies</phrase>. <phrase>Managing</phrase> imprecise answers and estimations of the incurred loss of <phrase>information</phrase>.
Compression and Coding <phrase>Algorithms</phrase>
<phrase>Open Source</phrase> <phrase>GIS</phrase>: A <phrase>GRASS GIS</phrase> Approach
<phrase>Computers</phrase> and <phrase>Education</phrase> in the <phrase>21st Century</phrase>
<phrase>Computers</phrase> and <phrase>Education</phrase>. Towards an Interconnected <phrase>Society</phrase>
The <phrase>Design</phrase> and Implementation of a <phrase>Log-Structured File-System</phrase>.
This <phrase>dissertation</phrase> presents a new technique for <phrase>disk storage</phrase> <phrase>management</phrase> called a <phrase>log-structured file system</phrase>. The technique writes all <phrase>file system</phrase> changes in large <phrase>sequential</phrase> transfers to a log-like structure on disk. The key benefit is a <phrase>high</phrase> <phrase>write performance</phrase> that is <phrase>independent</phrase> of the workload. The large transfers also enable the <phrase>efficient</phrase> use of <phrase>large disk arrays</phrase> such as <phrase>RAIDs</phrase>. The technique minimizes the overhead of <phrase>computing</phrase> the redundancy <phrase>information</phrase> required by large <phrase>RAIDs</phrase>. A <phrase>log-structured file system</phrase> <phrase>achieves high</phrase> write rates <phrase>without sacrificing</phrase> <phrase>file retrieval</phrase> performance. Files are read back from the log efficiently due to the <phrase>indexing</phrase> <phrase>information</phrase> that is maintained The log structure also permits <phrase>fast</phrase> recovery from system crashes. Using a recovery system based on checkpoints and <phrase>roll</phrase>-<phrase>forward</phrase> the <phrase>log-structured file system</phrase> can quickly <phrase>restore</phrase> the disk to a consistent <phrase>state</phrase>. An important focus of this <phrase>dissertation</phrase> is the technique used for <phrase>free</phrase> space <phrase>management</phrase> in a <phrase>log-structured file system</phrase>. The approach taken was to divide the disk into large segments to which the log was written. A segment cleaner mechanism exists to compress the <phrase>live</phrase> <phrase>information</phrase> from heavily fragmented segments. The mechanism reads in the fragmented segments, compacts the <phrase>live</phrase> <phrase>data</phrase>, and writes the <phrase>data</phrase> back to segments on disk. The <phrase>dissertation</phrase> includes a series of simulations that demonstrate the efficiency of a simple segment <phrase>cleaning</phrase> <phrase>policy based</phrase> on cost and benefit. The segment cleaner decides which segments to clean based on a <phrase>function</phrase> of the fraction <phrase>alive</phrase> in the segment and the <phrase>age</phrase> of the <phrase>data</phrase> in the segment. <phrase>I</phrase> have implemented a <phrase>prototype</phrase> <phrase>log-structured file system</phrase> called <phrase>Sprite</phrase> <phrase>LFS</phrase>; it outperforms current <phrase>Unix</phrase> <phrase>file systems</phrase> by an <phrase>order</phrase> of <phrase>magnitude</phrase> for small-<phrase>file writes</phrase> and <phrase>matches or exceeds</phrase> <phrase>Unix</phrase> performance for reads and large writes. Even when the overhead for <phrase>cleaning</phrase> is included, <phrase>Sprite</phrase> <phrase>LFS</phrase> can use 70% of the <phrase>disk bandwidth</phrase> for writing. <phrase>Unix</phrase> <phrase>file systems</phrase> typically can use only 5-10%.
The TSQL2 <phrase>Temporal Query Language</phrase>
<phrase>Data Quality</phrase>
<phrase>Clustering</phrase> and <phrase>Information Retrieval</phrase>
<phrase>Loop Tiling</phrase> for Parallelism
A Framework for <phrase>Meta-Information</phrase> in <phrase>Digital Libraries</phrase>.
<phrase>Metadata</phrase> Handling in HyperStorM.
<phrase>Overview</phrase> on Using <phrase>Metadata</phrase> to manage <phrase>Multimedia</phrase> <phrase>Data</phrase>.
<phrase>Metadata</phrase> for <phrase>Mixed-Media</phrase> Access.
<phrase>Content-Based Image Retrieval</phrase> using <phrase>Metadata</phrase> and <phrase>Relaxation Techniques</phrase>.
<phrase>Metadata</phrase> <phrase>Management</phrase> for <phrase>Geographic Information</phrase> Discovery and Exchange.
Using <phrase>Metadata</phrase> for the <phrase>Intelligent Browsing</phrase> of Structured <phrase>Media</phrase> Objects.
<phrase>Metadata</phrase> in <phrase>Geographic</phrase> and <phrase>Environmental</phrase> <phrase>Data Management</phrase>.
<phrase>Video</phrase> <phrase>Data Management</phrase> Systems: <phrase>Metadata</phrase> and <phrase>Architecture</phrase>.
A <phrase>Metadatabase</phrase> System for <phrase>Semantic</phrase> <phrase>Image Search</phrase> by a <phrase>Mathematical Model</phrase> of Meaning.
In the <phrase>design</phrase> of <phrase>multimedia</phrase> <phrase>database systems</phrase>, one of the most <phrase>important issues</phrase> is to extract images dynamically according to the <phrase>user's impression</phrase> and the image's contents. In this <phrase>paper</phrase>, we present a <phrase>metadatabase</phrase> system which realizes the <phrase>semantic</phrase> <phrase>associative</phrase> search for images by giving <phrase>keywords</phrase> representing the <phrase>user's impression</phrase> and the image's contents.This <phrase>metadatabase</phrase> system provides several functions for performing the <phrase>semantic</phrase> <phrase>associative</phrase> search for images by using the <phrase>metadata</phrase> representing the features of images. These functions are realized by using our proposed <phrase>mathematical model</phrase> of meaning. The <phrase>mathematical model</phrase> of meaning is extended to compute specific meanings of <phrase>keywords</phrase> which are used for <phrase>retrieving</phrase> images unambiguously and dynamically. The <phrase>main feature</phrase> of this <phrase>model</phrase> is that the <phrase>semantic</phrase> <phrase>associative</phrase> search is performed in the <phrase>orthogonal</phrase> <phrase>semantic</phrase> space. This space is created for dynamically <phrase>computing</phrase> <phrase>semantic equivalence</phrase> or similarity between the <phrase>metadata</phrase> items of the images and <phrase>keywords</phrase>.
The Use of <phrase>Metadata</phrase> for the Rendering of <phrase>Personalized</phrase> <phrase>Video</phrase> Delivery.
<phrase>Metadata</phrase> for <phrase>Content-based</phrase> Retrieval of Speech <phrase>Recording</phrase>.
<phrase>Microsoft SQL Server</phrase> (<phrase>Chapter 27</phrase>)
<phrase>Database Systems</phrase> - Concepts, Languages and Architectures
<phrase>SQL</phrase> - The Standard <phrase>Handbook</phrase>
<phrase>Distributed Databases</phrase>: Principles and Systems
<phrase>Introduction</phrase> to <phrase>Algorithms</phrase>
<phrase>Introduction</phrase> to <phrase>Algorithms</phrase>, <phrase>Second Edition</phrase>
<phrase>Oracle</phrase> (<phrase>Chapter</phrase> 25)
<phrase>IBM DB2</phrase> <phrase>Universal</phrase> <phrase>Database</phrase> (<phrase>Chapter</phrase> 26)
<phrase>Database Management Systems</phrase>.
<phrase>Introduction</phrase> to <phrase>Modern Information Retrieval</phrase>.
<phrase>Multimedia</phrase> <phrase>Data Management</phrase>: Using <phrase>Metadata</phrase> to Integrate and Apply <phrase>Digital Media</phrase>
<phrase>Database</phrase> System Concepts, <phrase>1st Edition</phrase>.
<phrase>Database</phrase> System Concepts, <phrase>2nd Edition</phrase>.
<phrase>Database</phrase> System Concepts, <phrase>4th Edition</phrase>.
:This acclaimed <phrase>revision</phrase> of a classic <phrase>database systems</phrase> text offers a complete background in the <phrase>basics</phrase> of <phrase>database design</phrase>, languages, and system implementation. It provides the latest <phrase>information</phrase> combined with <phrase>real-world</phrase> examples to help readers <phrase>master</phrase> concepts. All concepts are presented in a <phrase>technically</phrase> complete yet <phrase>easy-to-understand</phrase> style with notations kept to a <phrase>minimum</phrase>. A running example of a <phrase>bank</phrase> enterprise illustrates concepts at work. To further optimize <phrase>comprehension</phrase>, figures and examples, rather than proofs, portray concepts and anticipate <phrase>results</phrase>.
<phrase>Database</phrase> System Concepts, <phrase>3rd Edition</phrase>.
:This acclaimed <phrase>revision</phrase> of a classic <phrase>database systems</phrase> text offers a complete background in the <phrase>basics</phrase> of <phrase>database design</phrase>, languages, and system implementation. It provides the latest <phrase>information</phrase> combined with <phrase>real-world</phrase> examples to help readers <phrase>master</phrase> concepts. All concepts are presented in a <phrase>technically</phrase> complete yet <phrase>easy-to-understand</phrase> style with notations kept to a <phrase>minimum</phrase>. A running example of a <phrase>bank</phrase> enterprise illustrates concepts at work. To further optimize <phrase>comprehension</phrase>, figures and examples, rather than proofs, portray concepts and anticipate <phrase>results</phrase>.
<phrase>Database Design</phrase>, <phrase>Revised</phrase> <phrase>2nd Edition</phrase>.
<phrase>Database Design</phrase>.
<phrase>Database Design</phrase>, <phrase>Second Edition</phrase>.
File <phrase>Organisation</phrase> for <phrase>Database Design</phrase>.
<phrase>Extracting</phrase> <phrase>Reaction</phrase> <phrase>Information</phrase> from <phrase>Chemical Databases</phrase>.
<phrase>Integrated Learning</phrase> in a Real Domain.
<phrase>Attribute-Oriented Induction</phrase> in <phrase>Relational Databases</phrase>.
<phrase>Statistical Technique</phrase> for <phrase>Extracting</phrase> <phrase>Classificatory</phrase> <phrase>Knowledge</phrase> from <phrase>Databases</phrase>.
<phrase>Summary Data</phrase> Estimation Using <phrase>Decision Trees</phrase>.
<phrase>Information</phrase> Discovery through <phrase>Hierarchical</phrase> <phrase>Maximum Entropy</phrase> <phrase>Discretization</phrase> and <phrase>Synthesis</phrase>.
Using Functions to Encode Domain and <phrase>Contextual Knowledge</phrase> in Statistical <phrase>Induction</phrase>.
<phrase>Knowledge</phrase> Discovery in <phrase>Databases</phrase>: <phrase>An Overview</phrase>.
The <phrase>Trade</phrase>-Off between <phrase>Knowledge</phrase> and <phrase>Data</phrase> in <phrase>Knowledge</phrase> Acquisition.
<phrase>Automated</phrase> <phrase>Knowledge</phrase> Generation From a <phrase>CAD</phrase> <phrase>Database</phrase>.
<phrase>Incremental</phrase> Discovery of Rules and Structure by <phrase>Hierarchical</phrase> and <phrase>Parallel</phrase> <phrase>Clustering</phrase>.
A Support System for <phrase>Interpreting</phrase> <phrase>Statistical Data</phrase>.
<phrase>Mining</phrase> for <phrase>Knowledge</phrase> in <phrase>Databases</phrase>: Goals and <phrase>General</phrase> Description of the INLEN System.
<phrase>Automating</phrase> the Discovery of <phrase>Causal</phrase> Relationships in a <phrase>Medical</phrase> Records <phrase>Database</phrase>: The POSCH <phrase>AI</phrase> <phrase>Project</phrase>.
<phrase>Induction of Decision Trees</phrase> from Complex <phrase>Structured Data</phrase>.
Discovery of <phrase>Medical</phrase> <phrase>Diagnostic Information</phrase>: <phrase>An Overview</phrase> of Methods and <phrase>Results</phrase>.
<phrase>Knowledge</phrase> Discovery as a <phrase>Threat</phrase> to <phrase>Database</phrase> <phrase>Security</phrase>.
<phrase>Minimal</phrase>-Length Encoding and <phrase>Inductive Inference</phrase>.
Discovery, Analysis, and Presentation of Strong Rules
On Evaluation of <phrase>Domain-Independent</phrase> Scientific <phrase>Function</phrase>-<phrase>Finding</phrase> Systems.
Justification-Based <phrase>Refinement</phrase> of <phrase>Expert Knowledge</phrase>.
<phrase>Rule Discovery</phrase> for <phrase>Query Optimization</phrase>.
<phrase>Unsupervised</phrase> Discovery in an Operational Control Setting.
<phrase>Rule Induction</phrase> Using <phrase>Information Theory</phrase>.
<phrase>Learning</phrase> Useful Rules from Inconclusive <phrase>Data</phrase>.
<phrase>Integration</phrase> of <phrase>Heuristic</phrase> and <phrase>Bayesian</phrase> Approaches in a <phrase>Pattern-Classification</phrase> System.
<phrase>Discovering</phrase> <phrase>Functional</phrase> Relationships from <phrase>Observational Data</phrase>.
On <phrase>Linguistic</phrase> Summaries of <phrase>Data</phrase>.
The Discovery, Analysis, and Representation of <phrase>Data</phrase> Dependencies in <phrase>Databases</phrase>.
Interactive <phrase>Mining</phrase> of Regularities in <phrase>Databases</phrase>.
<phrase>Fast</phrase> Discovery of <phrase>Association Rules</phrase>.
<phrase>Predicting</phrase> <phrase>Equity</phrase> Returns from <phrase>Securities</phrase> <phrase>Data</phrase>.
<phrase>Finding</phrase> Patterns in <phrase>Time Series</phrase>: A <phrase>Dynamic Programming</phrase> Approach.
The Process of <phrase>Knowledge</phrase> Discovery in <phrase>Databases</phrase>.
<phrase>Graphical</phrase> Models for Discivering <phrase>Knowledge</phrase>.
<phrase>Bayesian</phrase> Classification (AutoClass): Theory and <phrase>Results</phrase>.
<phrase>Inductive Logic Programming</phrase> and <phrase>Knowledge</phrase> Discovery in <phrase>Databases</phrase>.
A Statistical <phrase>Perspective</phrase> on <phrase>Knowledge</phrase> Discovery in <phrase>Databases</phrase>.
<phrase>Automating</phrase> the Analysis and Cataloging of <phrase>Sky</phrase> Surveys.
From <phrase>Data Mining</phrase> to <phrase>Knowledge</phrase> Discovery: <phrase>An Overview</phrase>.
<phrase>Transformation Rules</phrase> and <phrase>Trees</phrase>.
<phrase>Discovering</phrase> <phrase>Informative Patterns</phrase> and <phrase>Data Cleaning</phrase>.
<phrase>Attribute-Oriented Induction</phrase> in <phrase>data Mining</phrase>.
<phrase>Bayesian</phrase> Networks for <phrase>Knowledge</phrase> Discovery.
<phrase>Data</phrase> <phrase>Surveyor</phrase>: Searching the <phrase>Nuggets</phrase> in <phrase>Parallel</phrase>.
Using <phrase>Inductive Learning</phrase> To Generate Rules for <phrase>Semantic Query Optimization</phrase>.
Explora: A Multipattern and <phrase>Multistrategy</phrase> Discovery <phrase>Assistant</phrase>.
<phrase>Knowledge</phrase> Discovery in <phrase>Database</phrase> <phrase>Terminology</phrase>.
<phrase>Selecting</phrase> and reporting What Is Interesting.
<phrase>Data Mining</phrase> and <phrase>Knowledge</phrase> Discovery <phrase>Internet</phrase> Resources.
Metaqueries for <phrase>Data Mining</phrase>.
<phrase>Integrating</phrase> <phrase>Inductive</phrase> and <phrase>Deductive Reasoning</phrase> for <phrase>Data Mining</phrase>.
Modeling <phrase>Subjective Uncertainty</phrase> in <phrase>Image Annotation</phrase>.
From <phrase>Data Mining</phrase> to <phrase>Knowledge</phrase> Discovery: <phrase>Current Challenges</phrase> and <phrase>Future Directions</phrase>.
From <phrase>Contingency Tables</phrase> to Various Forms of <phrase>Knowledge</phrase> in <phrase>Databases</phrase>.
<phrase>Conceptual Modeling</phrase> of <phrase>Workflows</phrase>.
A <phrase>Behaviorally</phrase> <phrase>Driven Approach</phrase> to <phrase>Object-Oriented</phrase> Analysis and <phrase>Design</phrase> with <phrase>Object Oriented</phrase> <phrase>Data Modeling</phrase>.
<phrase>Coordinated</phrase> Collaboration of Objects.
<phrase>Identifying</phrase> Objects by <phrase>Declarative</phrase> Queries.
<phrase>Temporally Enhanced</phrase> <phrase>Database Design</phrase>.
An <phrase>Active</phrase>, <phrase>Object-Oriented</phrase>, <phrase>Model</phrase>-Equivalent <phrase>Programming Language</phrase>.
Mapping <phrase>an Extended</phrase> <phrase>Entity-Relationship</phrase> into a Schema of <phrase>Complex Objects</phrase>.
Advances in <phrase>Object-Oriented</phrase> Modeling.
<phrase>Leveraging</phrase> <phrase>Relational</phrase> <phrase>Data</phrase> Assets.
Modeling <phrase>Object Dynamics</phrase>.
<phrase>Database</phrase> <phrase>Integration</phrase>: The Key to <phrase>Data</phrase> <phrase>Interoperability</phrase>.
On the <phrase>Design</phrase> of Behavior Consistent Specializations of <phrase>Object Life Cycles</phrase> in OBD and <phrase>UML</phrase>.
Objects and Events as Modeling Drivers.
The Type System of LML.
A Regular Type <phrase>Language</phrase> for <phrase>Logic</phrase> Programs.
<phrase>Logic Programming</phrase> with Type Specifications.
<phrase>Semantic</phrase> Types for <phrase>Logic</phrase> Programs.
A <phrase>Semantics</phrase> for <phrase>Typed Logic Programs</phrase>.
A <phrase>Pragmatic</phrase> View of Types for <phrase>Logic</phrase> Programs.
The Type System of a <phrase>Higher-Order Logic</phrase> <phrase>Programming Language</phrase>.
The type system of the <phrase>logic</phrase> <phrase>programming language</phrase> $<phrase>\lambda</phrase>$<phrase>Prolog</phrase> is discussed. The <phrase>incorporation</phrase> of <phrase>higher-order</phrase> notions within this <phrase>language</phrase> requires the use of a typing scheme to distinguish between expressions of different <phrase>function</phrase> types. Thus $<phrase>\lambda</phrase>$<phrase>Prolog</phrase> is a (strongly) <phrase>typed</phrase> <phrase>language</phrase>, in contrast to the typeless <phrase>language</phrase> that underlies the idea of <phrase>descriptive</phrase> types in <phrase>logic programming</phrase>. The <phrase>typing discipline</phrase> that is employed in the <phrase>language</phrase> is based on the notion of <phrase>simple types</phrase> in the $<phrase>\lambda</phrase>$-<phrase>calculus</phrase>. This form of typing enforces <phrase>arity</phrase> restrictions on functions and predicates and provides a builtin <phrase>functional</phrase> hierarchy over terms. The <phrase>language</phrase> contains a facility for defining new <phrase>primitive types</phrase> and thus permits <phrase>finer grained</phrase> distinctions to be introduced by the user. Further, the use of <phrase>type variables</phrase> and <phrase>type constructors</phrase> provides a form of <phrase>polymorphism</phrase> that is similar in certain respects to that present in the <phrase>language</phrase> <phrase>ML</phrase>. The notion of <phrase>type checking</phrase> in $<phrase>\lambda</phrase>$<phrase>Prolog</phrase> is discussed and shown to be an operation that can be performed at the time of <phrase>compilation</phrase>. The value of typing distinctions in <phrase>determining</phrase> the <phrase>clarity</phrase> of programs and their usefulness in conjunction with <phrase>type checking</phrase> in <phrase>preventing</phrase> <phrase>run-time</phrase> errors due to type violations is also discussed. In addition to their <phrase>function</phrase> in <phrase>type checking</phrase>, types also have a <phrase>major</phrase> role in <phrase>determining</phrase> computations in the <phrase>logic programming</phrase> context. We discuss this <phrase>aspect</phrase> of types that is in contrast to their behavior in other <phrase>programming</phrase> paradigms and we show how this leads to a presence of types in the <phrase>runtime environment</phrase>. While typing has several advantages, it is sometimes to the <phrase>programmer</phrase>''<phrase>s</phrase> advantage to be able to omit their mention. <phrase>Type reconstruction</phrase> provides a means for filling missing <phrase>type information</phrase> in and we discuss issues pertinent to this process in the context of $<phrase>\lambda</phrase>$<phrase>Prolog</phrase>.
Types and the <phrase>Intended Meaning</phrase> of <phrase>Logic</phrase> Programs.
<phrase>Dependent Types</phrase> in <phrase>Logic Programming</phrase>.
<phrase>Polymorphically Typed</phrase> <phrase>Logic</phrase> Programs.
Using <phrase>Moded</phrase> <phrase>Type Systems</phrase> to Support Abstraction in <phrase>Logic</phrase> Programs.
<phrase>Actors</phrase>: A <phrase>Conceptual Foundation</phrase> for <phrase>Concurrent Object-Oriented Programming</phrase>.
Groundwork for an <phrase>Object Database</phrase> <phrase>Model</phrase>.
Definition Groups: Making Sources into <phrase>First-Class</phrase> Objects.
<phrase>Object-Oriented</phrase> Specifications.
<phrase>Unifying</phrase> <phrase>Functional</phrase>, <phrase>Object-Oriented</phrase> and <phrase>Relational</phrase> <phrase>Programming</phrase> with <phrase>Logical</phrase> <phrase>Semantics</phrase>.
A <phrase>Model</phrase> for <phrase>Object-Based</phrase> <phrase>Inheritance</phrase>.
Vulcan: <phrase>Logical</phrase> <phrase>Concurrent</phrase> Objects.
The <phrase>BETA</phrase> <phrase>Programming Language</phrase>.
<phrase>Block-Structure</phrase> and <phrase>Object-Oriented</phrase> Languages.
Development and Implementation of <phrase>an Object-Oriented</phrase> <phrase>DBMS</phrase>.
A Mechanism for Specifying the Structure of Large, <phrase>Layered</phrase> Systems.
<phrase>An Object-Oriented</phrase> Framework for Conceptual <phrase>Programming</phrase>.
Type <phrase>Evolution</phrase> in <phrase>an Object-Oriented Database</phrase>.
A Substrate for <phrase>Object-Oriented</phrase> <phrase>Interface Design</phrase>.
<phrase>Inheritance</phrase> and the Development of Encapsulated <phrase>Software</phrase> Systems.
The <phrase>Object-Oriented</phrase> Classification <phrase>Paradigm</phrase>.
<phrase>Workflow</phrase> <phrase>Management</phrase>: Models, Methods, and Systems
Structure and Interpretation of <phrase>Computer Programs</phrase>
Structure and Interpretation of <phrase>Computer Programs</phrase>, <phrase>Second Edition</phrase>
Warren's <phrase>Abstract Machine</phrase>: A <phrase>Tutorial</phrase> <phrase>Reconstruction</phrase>
<phrase>Digital Library</phrase> Use: <phrase>Social Practice</phrase> in <phrase>Design</phrase> and Evaluation
<phrase>Visual</phrase> <phrase>Reconstruction</phrase>
<phrase>Vector</phrase> Models for <phrase>Data</phrase>-<phrase>Parallel Computing</phrase>
From <phrase>Gutenberg</phrase> to the <phrase>Global Information</phrase> <phrase>Infrastructure</phrase>
Advances in <phrase>Knowledge</phrase> Discovery and <phrase>Data Mining</phrase>.
<phrase>Introduction</phrase> to <phrase>Object-Oriented</phrase> <phrase>Databases</phrase>
Advances in <phrase>Object-Oriented</phrase> <phrase>Data Modeling</phrase>
<phrase>Knowledge</phrase> Discovery in <phrase>Databases</phrase>
Concepts, Techniques, and Models of <phrase>Computer Programming</phrase>
The <phrase>Art</phrase> of <phrase>Prolog</phrase> - <phrase>Advanced</phrase> <phrase>Programming</phrase> Techniques
The <phrase>Art</phrase> of <phrase>Prolog</phrase> - <phrase>Advanced</phrase> <phrase>Programming</phrase> Techniques, <phrase>2nd Ed</phrase>.
The Intellectual <phrase>Foundation</phrase> of <phrase>Information</phrase> <phrase>Organization</phrase>
<phrase>Instant</phrase> <phrase>electronic</phrase> access to <phrase>digital</phrase> <phrase>information</phrase> is the <phrase>single</phrase> most <phrase>distinguishing</phrase> attribute of the <phrase>information age</phrase>. The elaborate <phrase>retrieval mechanisms</phrase> that support such access are a product of <phrase>technology</phrase>. But <phrase>technology</phrase> is not enough. The effectiveness of a system for <phrase>accessing information</phrase> is a <phrase>direct</phrase> <phrase>function</phrase> of the <phrase>intelligence</phrase> put into organizing it. Just as the practical field of <phrase>engineering</phrase> has <phrase>theoretical physics</phrase> as its underlying base, the <phrase>design</phrase> of systems for <phrase>organizing information</phrase> rests on an intellectual <phrase>foundation</phrase>. The subject of this <phrase>book</phrase> is the systematized body of <phrase>knowledge</phrase> that constitutes this foundation.Integrating the disparate disciplines of <phrase>descriptive</phrase> cataloging, subject cataloging, <phrase>indexing</phrase>, and classification, the <phrase>book</phrase> adopts <phrase>a conceptual framework</phrase> that views the process of <phrase>organizing information</phrase> as the use of a special <phrase>language</phrase> of description called a <phrase>bibliographic</phrase> <phrase>language</phrase>. The <phrase>book</phrase> is <phrase>divided into</phrase> two parts. The first part is an <phrase>analytic</phrase> discussion of the intellectual <phrase>foundation</phrase> of <phrase>information</phrase> <phrase>organization</phrase>. The second part moves from generalities to particulars, presenting <phrase>an overview</phrase> of three <phrase>bibliographic</phrase> languages: work languages, document languages, and subject languages. It looks at these languages in terms of their <phrase>vocabulary</phrase>, <phrase>semantics</phrase>, and <phrase>syntax</phrase>. The <phrase>book</phrase> is written in an exceptionally clear style, at <phrase>a level</phrase> that makes it understandable to those outside the discipline of <phrase>library</phrase> and <phrase>information</phrase> science.Digital <phrase>Libraries</phrase> and <phrase>Electronic Publishing</phrase> series
<phrase>Research</phrase> Directions in <phrase>Object-Oriented Programming</phrase>
<phrase>Journey</phrase> to <phrase>Data Quality</phrase>
All organizations today confront <phrase>data quality</phrase> problems, both <phrase>systemic</phrase> and <phrase>structural</phrase>. Neither <phrase>ad hoc</phrase> approaches nor fixes at the systems levelinstalling the latest <phrase>software</phrase> or <phrase>developing</phrase> an expensive <phrase>data</phrase> warehousesolve the <phrase>basic</phrase> problem of bad <phrase>data</phrase> quality practices. <phrase>Journey</phrase> to <phrase>Data Quality</phrase> offers a <phrase>roadmap</phrase> that can be used by practitioners, <phrase>executives</phrase>, and students for <phrase>planning</phrase> and <phrase>implementing</phrase> a viable <phrase>data</phrase> and <phrase>information</phrase> <phrase>quality management</phrase> program. This practical guide, based on rigorous <phrase>research</phrase> and <phrase>informed</phrase> by <phrase>real-world</phrase> examples, describes the challenges of <phrase>data management</phrase> and provides the principles, strategies, tools, and techniques necessary to meet them. The authors, all leaders in the <phrase>data</phrase> quality field for many years, discuss how to make the economic case for <phrase>data quality</phrase> and the importance of getting an organization's leaders <phrase>on board</phrase>. They outline different approaches for <phrase>assessing</phrase> <phrase>data</phrase>, both subjectively (by users) and objectively (using <phrase>sampling</phrase> and other techniques). They describe <phrase>real problems</phrase> and solutions, including efforts to find the <phrase>root</phrase> causes of <phrase>data quality</phrase> problems at a <phrase>healthcare</phrase> <phrase>organization</phrase> and <phrase>data quality</phrase> initiatives taken by a large <phrase>teaching hospital</phrase>. They address setting <phrase>company</phrase> policy on <phrase>data quality</phrase> and, <phrase>finally</phrase>, they consider <phrase>future challenges</phrase> on the <phrase>journey</phrase> to <phrase>data quality</phrase>.
<phrase>Self-Stabilization</phrase>
<phrase>Heterogenous</phrase> <phrase>Active</phrase> Agents
<phrase>Digital Libraries</phrase>
<phrase>Datenbanken</phrase>: <phrase>Konzepte und</phrase> <phrase>Sprachen</phrase>
<phrase>Datenbanken</phrase>: Implementierungstechniken
<phrase>Datenbanken</phrase>: <phrase>Konzepte und</phrase> <phrase>Sprachen</phrase>, 3. Auflage
<phrase>Object Identity</phrase> as a <phrase>Query Language</phrase> Primitive.
We demonstrate the power of object identities (oid's) as a <phrase>database</phrase> <phrase>query language</phrase> primitive. We develop an <phrase>object-based</phrase> <phrase>data model</phrase>, whose <phrase>structural</phrase> part generalizes most of the known <phrase>complex-object</phrase> <phrase>data</phrase> models: cyclicity is allowed in both its schemas and instances. Our <phrase>main contribution</phrase> is the operational part of the <phrase>data model</phrase>, the <phrase>query language</phrase> IQL, which uses oid's for three critical purposes: (1) to represent <phrase>data-structures</phrase> with sharing and cycles, (2) to manipulate sets and (3) to express any <phrase>computable</phrase> <phrase>database</phrase> query. IQL can be statically <phrase>type checked</phrase>, can be evaluated <phrase>bottom-up</phrase> and <phrase>naturally generalizes</phrase> most popular <phrase>rule-based</phrase> <phrase>database</phrase> languages. The <phrase>model</phrase> can also be extended to incorporate <phrase>type inheritance</phrase>, without changes to IQL. <phrase>Finally</phrase>, we investigate an analogous value-based <phrase>data model</phrase>, whose <phrase>structural</phrase> part is founded on regular <phrase>infinite trees</phrase> and whose operational part is IQL.
Method Schemas.
The concept of method schemas is proposed as a simple <phrase>model</phrase> for <phrase>object-oriented programming</phrase> with features such as classes with methods and <phrase>inheritance</phrase>, method name overloading, and <phrase>late binding</phrase>. An <phrase>important issue</phrase> is to check whether a given method schema can possibly <phrase>lead</phrase> to inconsistencies in some interpretations. The <phrase>consistency problem</phrase> for method schemas is studied. The problem is shown to be <phrase>undecidable</phrase> in <phrase>general</phrase>. <phrase>Decidability</phrase> is obtained for <phrase>monadic</phrase> and/or <phrase>recursion</phrase>-<phrase>free</phrase> method schemas. The effect of <phrase>covariance</phrase> is considered. The issues of <phrase>incremental</phrase> <phrase>consistency checking</phrase> and of a <phrase>sound</phrase> <phrase>algorithm</phrase> for the <phrase>general</phrase> case are <phrase>briefly discussed</phrase>.
Self-explained Toolboxes.
The <phrase>Object-Oriented</phrase> <phrase>Database</phrase> System <phrase>Manifesto</phrase>.
A <phrase>Query Language</phrase> for <phrase>O2</phrase>.
<phrase>Introduction</phrase> to Languages.
<phrase>LISP</phrase> <phrase>O2</phrase>: a <phrase>Persistent Object</phrase>-Oriented <phrase>Lisp</phrase>.
<phrase>Clustering</phrase> Strategies in <phrase>O2</phrase>: <phrase>An Overview</phrase>.
Handling Distribution in the <phrase>O2</phrase> System.
The <phrase>O2</phrase> <phrase>Programming</phrase> Environment.
<phrase>Integrating</phrase> <phrase>Concurrency Control</phrase> into <phrase>an Object-Oriented Database</phrase> System.
Consistency of Versions in <phrase>Object-Oriented</phrase> <phrase>Databases</phrase>.
Reloop, an <phrase>Algebra</phrase> Based <phrase>Query Language</phrase> for <phrase>an Object-Oriented Database</phrase> System.
Three <phrase>Alternative</phrase> <phrase>Workstation</phrase>-<phrase>Server Architectures</phrase>.
<phrase>Introduction</phrase> to the <phrase>Programming</phrase> Environment.
<phrase>Introduction</phrase> to the System.
The <phrase>Story</phrase> of <phrase>O2</phrase>.
Using a <phrase>Database</phrase> System to Implement a <phrase>Debugger</phrase>.
Using <phrase>Database</phrase> Applications to Compare <phrase>Programming Languages</phrase>.
<phrase>A Guided Tour</phrase> of an <phrase>O2</phrase> Applications.
<phrase>Introduction</phrase> to the <phrase>Data Model</phrase>.
<phrase>Incremental</phrase> <phrase>Compilation</phrase> in <phrase>O2</phrase>.
The <phrase>O2</phrase> <phrase>Database</phrase> <phrase>Programming Language</phrase>.
<phrase>O2</phrase>, <phrase>an Object-Oriented Data Model</phrase>.
The <phrase>Altair</phrase> <phrase>group</phrase> is currently <phrase>designing</phrase> <phrase>an object-oriented</phrase> <phrase>data</phrase> base system called <phrase>O2</phrase>. This <phrase>paper</phrase> presents a <phrase>formal description</phrase> of the <phrase>object-oriented</phrase> <phrase>data model</phrase> of this system. It proposes a type system defined in the framework of a set-and-<phrase>tuple</phrase> <phrase>data model</phrase>. It models the well known <phrase>inheritance</phrase> mechanism and enforces <phrase>strong typing</phrase>.
<phrase>Building</phrase> <phrase>User Interfaces</phrase> with Looks.
<phrase>Geographic</phrase> Applications: An Experience with <phrase>O2</phrase>.
The <phrase>O2</phrase> <phrase>Object Manager</phrase>: <phrase>An Overview</phrase>.
A Framework for <phrase>Schema Updates</phrase> In <phrase>An Object-Oriented Database</phrase> System.
All Your <phrase>Data</phrase>: The <phrase>Oracle</phrase> <phrase>Extensibility</phrase> <phrase>Architecture</phrase>.
Enabling Component <phrase>Databases</phrase> with <phrase>OLE DB</phrase>.
The <phrase>Architecture</phrase> of a <phrase>Database</phrase> System for <phrase>Mobile</phrase> and <phrase>Embedded Devices</phrase>.
<phrase>Distributed Component</phrase> <phrase>Database Management Systems</phrase>.
<phrase>Extensible</phrase> <phrase>Indexing</phrase> Support in <phrase>DB2</phrase> <phrase>Universal</phrase> <phrase>Database</phrase>.
Component <phrase>Database Systems</phrase>: <phrase>Introduction</phrase>, Foundations, and <phrase>Overview</phrase>.
Conclusions and Perspectives.
<phrase>Foreword</phrase>.
<phrase>Building</phrase> Component <phrase>Database Systems</phrase> Using <phrase>CORBA</phrase>.
An <phrase>Architecture</phrase> for <phrase>Transparent</phrase> Access to <phrase>Diverse Data Sources</phrase>.
<phrase>Transaction Management</phrase> in <phrase>Database Systems</phrase>
A Transaction <phrase>Model</phrase> for <phrase>Active</phrase> <phrase>Distributed Object Systems</phrase>
<phrase>ACTA</phrase>: The <phrase>SAGA</phrase> Continues
<phrase>ACTA</phrase> is a <phrase>comprehensive</phrase> transaction framework that permits a transaction <phrase>modeler</phrase> to specify the effects of <phrase>extended transactions</phrase> on each other and on objects in the <phrase>database</phrase>. <phrase>ACTA</phrase> allows the specification of (1) the interactions between transactions in terms of relationships between significant (transaction <phrase>manage- ment</phrase>) events, such as begin, commit, abort, delegate, <phrase>split</phrase>, and join, pertaining to different transactions and (2) transactions'' effects on objects'' <phrase>state</phrase> and <phrase>concur</phrase>- rency status (i.e., synchronization <phrase>state</phrase>). Various extended traditional models have been proposed to deal with <phrase>applica- tions</phrase> that involve <phrase>reactive</phrase> (endless), <phrase>open</phrase>-ended (<phrase>long</phrase>-lived) and collaborative (interactive) activities. One such <phrase>model</phrase> is Sagas [GS87] <phrase>independent</phrase> (component) transactions <phrase>T1</phrase>, <phrase>T2</phrase>,..., <phrase>Tn</phrase> which can interleave in any way with component <phrase>trans</phrase>- actions of other Sagas. Components can commit even before the <phrase>Saga</phrase> commits. However, if the <phrase>Saga</phrase> <phrase>subsequently</phrase> aborts, effects of the committed components are nullified through the <phrase>invocation</phrase> of <phrase>compensating</phrase> transactions. After giving a brief <phrase>introduction</phrase> to the <phrase>modeling primitives</phrase> of <phrase>ACTA</phrase>, we illustrate their use by giving a complete formal characterization of Sagas. Sub- sequently, the reasoning power of <phrase>ACTA</phrase> is shown by proving properties of Sagas. <phrase>Finally</phrase>, the flexibility of <phrase>ACTA</phrase> is displayed through a series of variations to the original <phrase>model</phrase> of Sagas, each variation coming out of changes to the formal characterization of Sagas.
<phrase>Introduction</phrase> to <phrase>Advanced</phrase> Transaction Models
A Flexible Framework for <phrase>Transaction Management</phrase> in <phrase>Engineering</phrase> Environments
<phrase>Dynamic</phrase> <phrase>Restructuring</phrase> of Transactions
<phrase>Multidatabase</phrase> Transaction and <phrase>Query Processing</phrase> in <phrase>Logic</phrase>
A Transaction <phrase>Model</phrase> for an <phrase>Open</phrase> Publication Environment
A <phrase>Cooperative</phrase> Transaction <phrase>Model</phrase> for <phrase>Design</phrase> <phrase>Databases</phrase>
Using Polytransactions to Manage Interdependent <phrase>Data</phrase>
Facility for <phrase>Non Standard</phrase> <phrase>Database Systems</phrase>
The <phrase>S</phrase>-transaction <phrase>Model</phrase>
The <phrase>ConTract</phrase> <phrase>Model</phrase>
Concepts and Applications of <phrase>Multilevel</phrase> Transactions and <phrase>Open Nested Transactions</phrase>
An Analysis of a <phrase>Dynamic</phrase> <phrase>Query Optimization</phrase> Scheme for Different <phrase>Data</phrase> <phrase>Distributions</phrase>.
<phrase>A Survey</phrase> of <phrase>Indexing</phrase> Techniques for <phrase>Object-Oriented</phrase> <phrase>Database Management Systems</phrase>.
Towards a <phrase>Unification</phrase> of <phrase>Rewrite-Based</phrase> <phrase>Optimization Techniques</phrase> for <phrase>Object-Oriented</phrase> Queries.
<phrase>Algebraic</phrase> <phrase>Query Optimization</phrase> in the CoOMS <phrase>Structurally</phrase> <phrase>Object-Oriented</phrase> <phrase>Database</phrase> System.
<phrase>Extensible</phrase> <phrase>Query Optimization</phrase> and <phrase>Parallel</phrase> Execution in <phrase>Volcano</phrase>.
<phrase>Tagging</phrase> as an <phrase>Alternative</phrase> to <phrase>Object Creation</phrase>.
<phrase>Query Optimization</phrase> in <phrase>Deductive</phrase> <phrase>Object Bases</phrase>.
<phrase>Query Optimization</phrase> in <phrase>Object Bases</phrase>: <phrase>Exploiting</phrase> <phrase>Relational</phrase> Techniques.
<phrase>ADT</phrase>-based Type System for <phrase>SQL</phrase>.
Evaluation Aspects of <phrase>an Object-oriented</phrase> <phrase>Deductive</phrase> <phrase>Database</phrase> <phrase>Language</phrase>.
<phrase>Recently</phrase>, <phrase>F</phrase>-<phrase>logic</phrase> has been proposed as an attempt to extend <phrase>deductive</phrase> <phrase>databases</phrase> by typical concepts of <phrase>object-oriented</phrase> languages. Among these concepts are <phrase>complex objects</phrase>, (<phrase>term-based</phrase>) <phrase>object identity</phrase>, methods, classes, typing, <phrase>inheritance</phrase> and browsing. In Kifer <phrase>et al</phrase>. <phrase>syntax</phrase> and <phrase>model-theoretic semantics</phrase> is discussed; however many <phrase>algorithmic</phrase> aspects which arise when <phrase>computing</phrase> the corresponding models are <phrase>left open</phrase>. In this <phrase>paper</phrase> we start to <phrase>bridge</phrase> this <phrase>gap</phrase>. Several topics in the context of the evaluation of programs are discussed in detail; among these are <phrase>weak</phrase> <phrase>recursion</phrase>, <phrase>global</phrase> <phrase>stratification</phrase> and <phrase>dynamic type-checking</phrase>.
Challenges for <phrase>Query Processing</phrase> in <phrase>Object-Oriented</phrase> <phrase>Databases</phrase>.
<phrase>Integration</phrase> of <phrase>Composite</phrase> Objects into <phrase>Relational</phrase> <phrase>Query Processing</phrase>: The <phrase>SQL</phrase>/XNF Approach.
<phrase>Physical Database Design</phrase> for <phrase>an Object-Oriented Database</phrase> System.
Optimization of <phrase>Complex-Object</phrase> Queries in <phrase>PRIMA</phrase> - Statement of Problems.
Implementation of the <phrase>Object-Oriented</phrase> <phrase>Data Model</phrase> <phrase>TM</phrase>.
An <phrase>Engineering</phrase> <phrase>Database</phrase> benchmark.
The <phrase>Wisconsin</phrase> Benchmark: Past, Present, and Future.
Benchmark <phrase>Software</phrase> Distribution: Release 1.0.
<phrase>Introduction</phrase>.
Do we all look at <phrase>homeless</phrase> people in the same way? The <phrase>innocence</phrase> of <phrase>kids</phrase> can teach us how to look at the world in a different way.
The <phrase>Neal</phrase> <phrase>Nelson</phrase> <phrase>Database</phrase> Benchmark: A Benchmark Based on the <phrase>Realities</phrase> of <phrase>Business</phrase>.
The Set Query Benchmark.
Doing Your Own Benchmark.
The <phrase>History</phrase> of DebitCredit and the <phrase>TPC</phrase>.
<phrase>TPC</phrase> Benchmark A: Standard Specification.
<phrase>TPC</phrase> Benchmark <phrase>B</phrase>: Standard Specification.
<phrase>ASAP</phrase>: An <phrase>ANSI</phrase> <phrase>SQL</phrase> Standard <phrase>Scaleable</phrase> and Portable Benchmark for <phrase>Relational Database</phrase> Systems.
<phrase>TPC</phrase> Benchmark <phrase>B</phrase>: Standard Specification.
Doing Your Own Benchmark.
<phrase>TPC-D</phrase>: <phrase>Benchmarking</phrase> for <phrase>Decision Support</phrase>.
The <phrase>Engineering</phrase> <phrase>Database</phrase> Benchmark.
<phrase>Overview</phrase> of the <phrase>Full-Text Document Retrieval</phrase> Benchmark.
The <phrase>Wisconsin</phrase> Benchmark: Past, Present, and Future.
<phrase>Overview</phrase> of the <phrase>SPEC</phrase> Benchmarks.
<phrase>Database</phrase> and <phrase>Transaction Processing</phrase> Performance <phrase>Handbook</phrase>.
The Set Query Benchmark.
<phrase>TPC-C</phrase> - The <phrase>Standard Benchmark</phrase> for <phrase>Online transaction Processing</phrase> (<phrase>OLTP</phrase>).
The <phrase>History</phrase> of DebitCredit and the <phrase>TPC</phrase>.
<phrase>ASAP</phrase> - An <phrase>ANSI</phrase> <phrase>SQL</phrase> Standard <phrase>Scaleable</phrase> and Portable Benchmark for <phrase>Relational Database</phrase> Systems.
The <phrase>Neal</phrase> <phrase>Nelson</phrase> <phrase>Database</phrase> Benchmark: A Benchmark Based on the <phrase>Realities</phrase> of <phrase>Business</phrase>.
<phrase>TPC</phrase> Benchmark A: Standard Specification.
Towards a Theory of <phrase>Declarative Knowledge</phrase>.
<phrase>Performance Evaluation</phrase> of <phrase>Data</phrase> Intensive <phrase>Logic</phrase> Programs.
Foundations of <phrase>Semantic Query Optimization</phrase> for <phrase>Deductive</phrase> <phrase>Databases</phrase>
<phrase>Converting</phrase> AND-Control to OR-Control by <phrase>Program Transformation</phrase>.
<phrase>Negation</phrase> as Failure Using Tight Derivations for <phrase>General</phrase> <phrase>Logic</phrase> Programs.
<phrase>Compiling</phrase> the GCWA in <phrase>Indefinite Deductive Databases</phrase>.
<phrase>Intelligent Query Answering</phrase> in <phrase>Rule Based</phrase> Systems
<phrase>Logic Programming</phrase> and <phrase>Parallel</phrase> Complexity
<phrase>Unification</phrase> <phrase>Revisited</phrase>
On the <phrase>Declarative Semantics</phrase> of <phrase>Logic</phrase> Programs with <phrase>Negation</phrase>.
<phrase>Equivalences</phrase> of <phrase>Logic</phrase> Programs
A <phrase>Logic</phrase>-based <phrase>Language</phrase> for <phrase>Database</phrase> Updates.
<phrase>Introduction</phrase>
<phrase>UML</phrase> is at a <phrase>crossroads</phrase>. Which of the proposed revisions will bring it closer to meeting <phrase>user needs</phrase> and <phrase>winning</phrase> tool-vendor commitment? What if <phrase>UML2</phrase> <phrase>instead</phrase> combined the best features of each proposal?
On the <phrase>Declarative Semantics</phrase> of <phrase>Deductive</phrase> <phrase>Databases</phrase> and <phrase>Logic</phrase> Programs.
A <phrase>Theorem-Proving</phrase> Approach to <phrase>Database</phrase> Integrity.
<phrase>Optimizing</phrase> <phrase>Datalog</phrase> Programs.
<phrase>Datalog</phrase> programs, i.e., <phrase>Prolog</phrase> programs without <phrase>function</phrase> symbols, are considered It is assumed that a <phrase>variable</phrase> appearing in the <phrase>head</phrase> of a rule must also appear in the body of the rule. The input of a program is a set of <phrase>ground</phrase> <phrase>atoms</phrase> (which are given in addition to the program's rules) and, therefore, can be viewed as an assignment of relations to some of the program's predicates. Two programs are equivalent if they produce the same result for all possible assignments of relations to the <phrase>extensional</phrase> predicates (i.e., the predicates that do not appear as <phrase>heads</phrase> of rules). Two programs are uniformly equivalent if they produce the same result for all possible assignments of initial relations to all the predicates (i.e., both <phrase>extensional</phrase> and <phrase>intentional</phrase>). The <phrase>equivalence</phrase> problem for <phrase>Datalog</phrase> programs is known to be <phrase>undecidable</phrase>. It is shown that <phrase>uniform equivalence</phrase> is <phrase>decidable</phrase>, and an <phrase>algorithm</phrase> is given for <phrase>minimizing</phrase> a <phrase>Datalog</phrase> program under <phrase>uniform equivalence</phrase>. A technique for removing parts of a program that are redundant under <phrase>equivalence</phrase> (but not under <phrase>uniform equivalence</phrase>) is developed. A procedure for testing <phrase>uniform equivalence</phrase> is also developed for the case in which the <phrase>database</phrase> satisfies some constraints.
<phrase>Negation</phrase> in <phrase>Logic Programming</phrase>.
A Superjoin <phrase>Algorithm</phrase> for <phrase>Deductive</phrase> <phrase>Databases</phrase>.
On <phrase>Domain Independent</phrase> <phrase>Databases</phrase>.
<phrase>Middleware</phrase> for <phrase>Location-Based Services</phrase>.
<phrase>Database</phrase> Aspects of <phrase>Location-Based Services</phrase>.
<phrase>Data Transmission</phrase> in <phrase>Mobile</phrase> <phrase>Communication</phrase> Systems.
<phrase>LBS</phrase> <phrase>Interoperability</phrase> Through Standards.
<phrase>Data</phrase> Collection.
<phrase>Introduction</phrase>.
<phrase>Navigation</phrase> Systems: A <phrase>Spatial</phrase> <phrase>Database</phrase> <phrase>Perspective</phrase>.
<phrase>General</phrase> Aspects of <phrase>Location Based Services</phrase>.
<phrase>Case Study</phrase>: The Development of the Find <phrase>Friends</phrase> Application.
<phrase>Active Rule</phrase> <phrase>Management</phrase> in <phrase>Chimera</phrase>
The HiPAC <phrase>Project</phrase>
<phrase>Active</phrase> <phrase>Database</phrase> Facilities in <phrase>Ode</phrase>
The Ariel <phrase>Project</phrase>
The <phrase>POSTGRES</phrase> Rules System
The A-<phrase>RDL</phrase> System
The <phrase>Starburst</phrase> Rule System
<phrase>Introduction</phrase> to <phrase>Active</phrase> <phrase>Database Systems</phrase>
Standards and <phrase>Commercial Systems</phrase>
Applications of <phrase>Active Databases</phrase>
Conclusions and <phrase>Future Directions</phrase>
<phrase>Introduction</phrase> to <phrase>Spatial Databases</phrase>: Applications to <phrase>GIS</phrase>
<phrase>Optimizing</phrase> Compilers for <phrase>Modern Architectures</phrase>: A <phrase>Dependence-based</phrase> Approach
<phrase>Universal</phrase> <phrase>Database Management</phrase>: A Guide to <phrase>Object/Relational</phrase> <phrase>Technology</phrase>
<phrase>Building</phrase> <phrase>an Object-Oriented Database</phrase> System, The <phrase>Story</phrase> of <phrase>O2</phrase>
<phrase>Transactional</phrase> <phrase>Information</phrase> Systems: Theory, <phrase>Algorithms</phrase>, and the Practice of <phrase>Concurrency Control</phrase> and Recovery
Principles of <phrase>Transaction Processing</phrase> for Systems Professionals.
<phrase>Computer Systems</phrase> That Learn: Classification and <phrase>Prediction Methods</phrase> from <phrase>Statistics</phrase>, <phrase>Neural Nets</phrase>, <phrase>Machine Learning</phrase> and <phrase>Expert Systems</phrase>
<phrase>Migrating Legacy Systems</phrase>: <phrase>Gateways</phrase>, Interfaces, and the <phrase>Incremental</phrase> Approach
<phrase>Data Warehousing</phrase>: Using the <phrase>Wal-Mart</phrase> <phrase>Model</phrase>
<phrase>Data</phrase> on the <phrase>Web</phrase>: From Relations to <phrase>Semistructured Data</phrase> and <phrase>XML</phrase>
<phrase>Stochastic</phrase> <phrase>Local</phrase> Search: Foundations & Applications
The Object <phrase>Data</phrase> Standard: <phrase>ODMG</phrase> 3.0
How to Build a <phrase>Digital</phrase> Libary
:Given modern <phrase>society's</phrase> need to control its <phrase>ever-increasing</phrase> body of <phrase>information</phrase>, <phrase>digital libraries</phrase> will be among the most important and influential institutions of this <phrase>century</phrase>. With their versatility, accessibility, and <phrase>economy</phrase>, these focused collections of everything <phrase>digital</phrase> are <phrase>fast</phrase> becoming the "<phrase>banks</phrase>" in which the <phrase>world's</phrase> wealth of <phrase>information</phrase> is stored. How to Build a <phrase>Digital Library</phrase> is the only <phrase>book</phrase> that offers all the <phrase>knowledge</phrase> and tools needed to construct and maintain a <phrase>digital library</phrase>-no <phrase>matter</phrase> how large or small. Two <phrase>internationally recognized</phrase> experts provide a <phrase>fully developed</phrase>, <phrase>step-by-step</phrase> method, as well as the <phrase>software</phrase> that makes it all possible. How to Build a <phrase>Digital Library</phrase> is the perfectly <phrase>self-contained</phrase> resource for individuals, agencies, and institutions wishing to put this <phrase>powerful tool</phrase> to work in their burgeoning <phrase>information</phrase> treasuries. Features Sketches the <phrase>history</phrase> of <phrase>libraries</phrase>-both traditional and <phrase>digital</phrase>-and their impact on present practices and <phrase>future directions</phrase> Offers in-depth coverage of today's practical standards used to represent and store <phrase>information</phrase> digitally Uses <phrase>Greenstone</phrase>, <phrase>freely accessible</phrase> <phrase>open-source software</phrase>-available with interfaces in the <phrase>world's</phrase> <phrase>major</phrase> languages (including <phrase>Spanish</phrase>, <phrase>Chinese</phrase>, and <phrase>Arabic</phrase>) Written for both technical and non-technical audiences <phrase>Web</phrase>-<phrase>enhanced</phrase> with <phrase>software</phrase> documentation, <phrase>color</phrase> illustrations, <phrase>full-text</phrase> <phrase>index</phrase>, <phrase>source code</phrase>, and more <phrase>Author</phrase> <phrase>Biography</phrase>: <phrase>Ian</phrase> <phrase>H</phrase>. <phrase>Witten</phrase> is a <phrase>professor</phrase> of <phrase>computer science</phrase> at the <phrase>University</phrase> of <phrase>Waikato</phrase> in <phrase>New Zealand</phrase>. He directs the <phrase>New Zealand</phrase> <phrase>Digital Library</phrase> <phrase>research project</phrase>. His <phrase>research</phrase> interests include <phrase>information retrieval</phrase>, <phrase>machine learning</phrase>, <phrase>text compression</phrase>, and <phrase>programming by demonstration</phrase>. He received an <phrase>MA</phrase> in <phrase>Mathematics</phrase> from <phrase>Cambridge University</phrase>, <phrase>England</phrase>; an <phrase>MSc</phrase> in <phrase>Computer Science</phrase> from the <phrase>University</phrase> of <phrase>Calgary</phrase>, <phrase>Canada</phrase>; and a <phrase>PhD</phrase> in <phrase>Electrical Engineering</phrase> from <phrase>Essex University</phrase>, <phrase>England</phrase>. He is a <phrase>fellow</phrase> of the <phrase>ACM</phrase> and of the <phrase>Royal Society</phrase> of <phrase>New Zealand</phrase>. He has published widely on <phrase>digital libraries</phrase>, <phrase>machine learning</phrase>, <phrase>text compression</phrase>, <phrase>hypertext</phrase>, <phrase>speech synthesis</phrase> and <phrase>signal processing</phrase>, and computer <phrase>typography</phrase>. He has written several <phrase>books</phrase>, the latest being <phrase>Managing</phrase> <phrase>Gigabytes</phrase> (1999) and <phrase>Data Mining</phrase> (2000), both from <phrase>Morgan Kaufmann</phrase>. <phrase>David</phrase> Bainbridge is a <phrase>senior</phrase> <phrase>lecturer</phrase> in <phrase>Computer Science</phrase> at the <phrase>University</phrase> of <phrase>Waikato</phrase>, <phrase>New Zealand</phrase>. He holds a <phrase>PhD</phrase> in <phrase>Optical Music Recognition</phrase> from the <phrase>University</phrase> of <phrase>Canterbury</phrase>, <phrase>New Zealand</phrase> where he studied as a <phrase>Commonwealth</phrase> <phrase>Scholar</phrase>. Since moving to <phrase>Waikato</phrase> in 1996 he has continued to broadened his interest in <phrase>digital media</phrase>, while retaining a particular <phrase>emphasis</phrase> on <phrase>music</phrase>. An <phrase>active</phrase> <phrase>member</phrase> of the <phrase>New Zealand</phrase> <phrase>Digital Library</phrase> <phrase>project</phrase>, he manages the <phrase>group's</phrase> <phrase>digital</phrase> <phrase>music</phrase> <phrase>library</phrase>, Meldex, and has collaborated with several <phrase>United Nations</phrase> Agencies, the <phrase>BBC</phrase> and various <phrase>public libraries</phrase>. <phrase>David</phrase> has also worked as a <phrase>research</phrase> <phrase>engineer</phrase> for <phrase>Thorn EMI</phrase> in the <phrase>area</phrase> of <phrase>photo</phrase>-realistic <phrase>imaging</phrase> and <phrase>graduated</phrase> from the <phrase>University</phrase> of <phrase>Edinburgh</phrase> in 1991 as the class medalist in <phrase>Computer Science</phrase>.
The <phrase>Object Database</phrase> Standard: <phrase>ODMG</phrase>-93
<phrase>Data Mining</phrase>: Practical <phrase>Machine Learning</phrase> Tools and Techniques with <phrase>Java</phrase> Implementations
The <phrase>Object Database</phrase> Standard: <phrase>ODMG</phrase>-93 (Release 1.1)
<phrase>Managing</phrase> <phrase>Gigabytes</phrase>: <phrase>Compressing</phrase> and <phrase>Indexing</phrase> Documents and Images, <phrase>Second Edition</phrase>
The <phrase>Object Database</phrase> Standard: <phrase>ODMG</phrase>-93 (Release 1.2)
Priniples of <phrase>Database</phrase> <phrase>Query Processing</phrase> for <phrase>Advanced</phrase> Applications
The <phrase>Object Database</phrase> Standard: <phrase>ODMG</phrase> 2.0
<phrase>Advanced</phrase> <phrase>Database Systems</phrase>.
<phrase>SQL</phrase> for <phrase>Smarties</phrase>: <phrase>Advanced</phrase> <phrase>SQL</phrase> <phrase>Programming</phrase>
Readings in <phrase>Object-Oriented</phrase> <phrase>Database Systems</phrase>
<phrase>Joe</phrase> Celko's <phrase>SQL</phrase> <phrase>Puzzles</phrase> & Answers
<phrase>Active</phrase> <phrase>Database Systems</phrase>: Triggers and Rules For <phrase>Advanced</phrase> <phrase>Database</phrase> Processing.
<phrase>SQL</phrase> for <phrase>Smarties</phrase>: <phrase>Advanced</phrase> <phrase>SQL</phrase> <phrase>Programming</phrase>, <phrase>Second Edition</phrase>
Practical <phrase>File System</phrase> <phrase>Design</phrase> with the Be <phrase>File System</phrase>
<phrase>Joe</phrase> Celko's <phrase>Data</phrase> and <phrase>Databases</phrase>: Concepts in Practice
Unleashing <phrase>Web 2.0</phrase>: From Concepts to <phrase>Creativity</phrase>
Vossen is both an IS & <phrase>CS</phrase> <phrase>Professor</phrase> at the <phrase>University</phrase> of Muenster, and also served as <phrase>European</phrase> <phrase>Editor-in-Chief</phrase> for Elseviers international <phrase>information</phrase> systems <phrase>journal</phrase>. Hagemann is his <phrase>PhD</phrase> <phrase>student</phrase> whose <phrase>area</phrase> of <phrase>research</phrase> is <phrase>Web</phrase> <phrase>technology</phrase>.
Using the New <phrase>DB2</phrase>: <phrase>IBM's</phrase> <phrase>Object-Relational Database</phrase> System.
A Complete Guide to <phrase>DB2</phrase> <phrase>Universal</phrase> <phrase>Database</phrase>
<phrase>Engineering</phrase> a <phrase>Compiler</phrase>
<phrase>Fuzzy Modeling</phrase> Tools for <phrase>Data Mining</phrase> and <phrase>Knowledge</phrase> Discovery: <phrase>Knowledge</phrase> Discovery, <phrase>Fuzzy Rule Induction</phrase>, and <phrase>Autonomous Agents</phrase> for <phrase>Databases</phrase> and <phrase>Spreadsheets</phrase>
Component <phrase>Database Systems</phrase>
<phrase>Database Transaction</phrase> Models for <phrase>Advanced</phrase> Applications.
<phrase>Camelot</phrase> and <phrase>Avalon</phrase>: A Distributed Transaction Facility
<phrase>Information Visualization</phrase> in <phrase>Data Mining</phrase> and <phrase>Knowledge</phrase> Discovery
<phrase>Information Visualization</phrase> in <phrase>Data Mining</phrase> and <phrase>Knowledge</phrase> Discovery
<phrase>Database</phrase>-Driven <phrase>Web Sites</phrase>
<phrase>Query Processing</phrase> for <phrase>Advanced</phrase> <phrase>Database Systems</phrase>, Selected Contributions from a <phrase>Workshop</phrase> on "<phrase>Query Processing</phrase> in <phrase>Object-Oriented</phrase>, <phrase>Complex-Object</phrase> and <phrase>Nested</phrase> Relation <phrase>Databases</phrase>", Interationales Begegnungs- und <phrase>Forschungszentrum</phrase> <phrase>für Informatik</phrase>, <phrase>Schloss Dagstuhl</phrase>, <phrase>Germany</phrase>, <phrase>June</phrase> 1991
<phrase>Essentials</phrase> of <phrase>Artificial Intelligence</phrase>
The Benchmark <phrase>Handbook</phrase> for <phrase>Database</phrase> and Transaction Systems (<phrase>1st Edition</phrase>).
The Benchmark <phrase>Handbook</phrase> for <phrase>Database</phrase> and Transaction Systems (<phrase>2nd Edition</phrase>).
<phrase>Transaction Processing</phrase>: Concepts and Techniques
<phrase>Moving Objects</phrase> <phrase>Databases</phrase>
<phrase>Web</phrase> <phrase>Farming</phrase> for the <phrase>Data Warehouse</phrase>
<phrase>Data Mining</phrase>: Concepts and Techniques
<phrase>Computer Architecture</phrase>: A <phrase>Quantitative</phrase> Approach, <phrase>2nd Edition</phrase>
Recovery in <phrase>Parallel</phrase> <phrase>Database Systems</phrase>, <phrase>Second Edition</phrase>
<phrase>Web</phrase> <phrase>Dragons</phrase>: Inside the <phrase>Myths</phrase> of <phrase>Search Engine</phrase> <phrase>Technology</phrase>
A Guide to <phrase>Developing</phrase> <phrase>Client/Server</phrase> <phrase>SQL</phrase> Applications
The <phrase>Jasmine</phrase> <phrase>Object Database</phrase>: <phrase>Multimedia</phrase> Applications for the <phrase>Web</phrase>
Elements of <phrase>Machine Learning</phrase>.
Practical <phrase>Digital Libraries</phrase>: <phrase>Books</phrase>, <phrase>Bytes</phrase>, and <phrase>Bucks</phrase>
<phrase>Distributed Algorithms</phrase>
:In <phrase>Distributed Algorithms</phrase>, <phrase>Nancy</phrase> <phrase>Lynch</phrase> provides a <phrase>blueprint</phrase> for <phrase>designing</phrase>, <phrase>implementing</phrase>, and <phrase>analyzing</phrase> <phrase>distributed algorithms</phrase>. She directs her <phrase>book</phrase> at a <phrase>wide audience</phrase>, including students, programmers, system designers and researchers. <phrase>Distributed Algorithms</phrase> contains the most significant <phrase>algorithms</phrase> and <phrase>impossibility results</phrase> in the <phrase>area</phrase>, all in a simple <phrase>automata</phrase>-theoretic setting. The <phrase>algorithms</phrase> are <phrase>proved correct</phrase>, and their complexity is analyzed according to <phrase>precisely defined</phrase> <phrase>complexity measures</phrase>. The problems <phrase>covered</phrase> include <phrase>resource allocation</phrase>, <phrase>communication</phrase>, <phrase>consensus</phrase> among <phrase>distributed processes</phrase>, <phrase>data</phrase> consistency, <phrase>deadlock</phrase> detection, <phrase>leader election</phrase>, <phrase>global</phrase> snapshots, and many others. The material is organized according to the system <phrase>model</phrase> - first by the <phrase>timing model</phrase> and then by the <phrase>interprocess communication</phrase> mechanism. The material on system models is isolated in separate chapters for easy reference. The presentation is completely rigorous, yet is intuitive enough for immediate <phrase>comprehension</phrase>. This <phrase>book</phrase> familiarizes readers with important problems, <phrase>algorithms</phrase>, and <phrase>impossibility results</phrase> in the <phrase>area</phrase>: readers can then recognize the problems when they arise in practice, apply the <phrase>algorithms</phrase> to solve them, and use the <phrase>impossibility results</phrase> to determine whether problems are unsolvable. The <phrase>book</phrase> also provides readers with the <phrase>basic</phrase> <phrase>mathematical</phrase> tools for <phrase>designing</phrase> new <phrase>algorithms</phrase> and proving new <phrase>impossibility results</phrase>. In addition, it teaches readers how to reason carefully about <phrase>distributed algorithms</phrase> - to <phrase>model</phrase> them formally, devise <phrase>precise specifications</phrase> for their required behavior, prove their correctness, and evaluate their performance with realistic measures.
<phrase>Atomic</phrase> Transactions
<phrase>Understanding</phrase> <phrase>SQL</phrase> and <phrase>Java</phrase> Together: A Guide to SGLJ, <phrase>JDBC</phrase>, and <phrase>Related Technologies</phrase>
<phrase>Understanding</phrase> the New <phrase>SQL</phrase>: A Complete Guide, <phrase>Second Edition</phrase>, Volume <phrase>I</phrase>
<phrase>Understanding</phrase> <phrase>SQL</phrase> <phrase>Stored Procedures</phrase>: A Complete Guide to <phrase>SQL</phrase>/<phrase>PSM</phrase>
<phrase>Understanding</phrase> the New <phrase>SQL</phrase>: A Complete Guide
Foundations of <phrase>Deductive</phrase> <phrase>Databases</phrase> and <phrase>Logic Programming</phrase>
<phrase>Advanced</phrase> <phrase>Compiler</phrase> <phrase>Design</phrase> and Implementation
<phrase>Commonsense Reasoning</phrase>
<phrase>Database Design</phrase> for <phrase>Smarties</phrase>: Using <phrase>UML</phrase> for <phrase>Data Modeling</phrase>
<phrase>Machine Learning</phrase>: A <phrase>Theoretical Approach</phrase>.
<phrase>Database</phrase> Principles, <phrase>Programming</phrase>, Performance
<phrase>Database</phrase>: Principles, <phrase>Programming</phrase>, and Performance, <phrase>Second Edition</phrase>
<phrase>Data Quality</phrase>: The Accuracy <phrase>Dimension</phrase>
<phrase>Computer Architecture</phrase>: A <phrase>Quantitative</phrase> Approach.
<phrase>Computer Organization</phrase> & <phrase>Design</phrase>: The <phrase>Hardware/Software</phrase> Interface
<phrase>Computer Organization</phrase> & <phrase>Design</phrase>: The <phrase>Hardware/Software</phrase> Interface, <phrase>Second Edition</phrase>
MICO: <phrase>An Open Source</phrase> <phrase>CORBA</phrase> Implementation
<phrase>Data Preparation</phrase> for <phrase>Data Mining</phrase>
<phrase>C4.5</phrase>: Programs for <phrase>Machine Learning</phrase>
:<phrase>Classifier systems</phrase> <phrase>play</phrase> a <phrase>major</phrase> role in <phrase>machine learning</phrase> and <phrase>knowledge-based systems</phrase>, and <phrase>Ross</phrase> Quinlan's work on <phrase>ID3</phrase> and <phrase>C4.5</phrase> is <phrase>widely acknowledged</phrase> to have made some of the most <phrase>significant contributions</phrase> to their development. This <phrase>book</phrase> is a complete guide to the <phrase>C4.5</phrase> system as implemented in <phrase>C</phrase> for the <phrase>UNIX</phrase> environment. It contains a <phrase>comprehensive</phrase> guide to the system's use , the <phrase>source code</phrase> (about 8,800 lines), and implementation <phrase>notes</phrase>. The <phrase>source code</phrase> and <phrase>sample datasets</phrase> are also available on a 3.5-inch <phrase>floppy</phrase> <phrase>diskette</phrase> for a <phrase>Sun</phrase> <phrase>workstation</phrase>. <phrase>C4.5</phrase> starts with <phrase>large sets</phrase> of cases belonging to known classes. The cases, described by any mixture of <phrase>nominal</phrase> and <phrase>numeric</phrase> properties, are scrutinized for patterns that allow the classes to be reliably discriminated. These patterns are then expressed as models, in the form of <phrase>decision trees</phrase> or sets of <phrase>if-then rules</phrase>, that can be used to classify new cases, with <phrase>emphasis</phrase> on making the models understandable as well as accurate. The system has been <phrase>applied successfully</phrase> to <phrase>tasks involving</phrase> <phrase>tens of thousands</phrase> of cases described by hundreds of properties. The <phrase>book</phrase> starts from simple core <phrase>learning</phrase> methods and shows how they can be elaborated and extended to deal with <phrase>typical problems</phrase> such as <phrase>missing data</phrase> and over <phrase>hitting</phrase>. <phrase>Advantages and disadvantages</phrase> of the <phrase>C4.5</phrase> approach are discussed and illustrated with several <phrase>case studies</phrase>. This <phrase>book</phrase> and <phrase>software</phrase> should be of interest to developers of <phrase>classification-based</phrase> <phrase>intelligent systems</phrase> and to students in <phrase>machine learning</phrase> and <phrase>expert systems</phrase> courses.
<phrase>Introduction</phrase> to <phrase>Data Compression</phrase>
<phrase>Location-Based Services</phrase>
<phrase>Developing</phrase> Time-<phrase>Oriented Database</phrase> Applications in <phrase>SQL</phrase>
Readings in <phrase>Database Systems</phrase>, First <phrase>Edition</phrase>
Readings in <phrase>Database Systems</phrase>, <phrase>Second Edition</phrase>
<phrase>Object-Relational DBMSs</phrase>: The <phrase>Next</phrase> Great <phrase>Wave</phrase>
:Discover why <phrase>object-relational</phrase> <phrase>technology</phrase> is ideal for <phrase>supporting</phrase> a <phrase>broad spectrum</phrase> of <phrase>data</phrase> types and <phrase>application areas</phrase>, from <phrase>financial services</phrase> to <phrase>multimedia</phrase> <phrase>data</phrase>. In this completely <phrase>revised</phrase> and updated <phrase>edition</phrase>, <phrase>database</phrase> experts <phrase>Michael Stonebraker</phrase> and <phrase>Paul Brown</phrase> explore the <phrase>object-relational</phrase> <phrase>paradigm</phrase> and examine the most <phrase>recent developments</phrase> in the field. Specially written for <phrase>database application</phrase> programmers, <phrase>database</phrase> analysts, and IT managers, this <phrase>book</phrase> includes <phrase>detailed information</phrase> on how to classify <phrase>DBMS</phrase> applications, where <phrase>object-relational DBMSs</phrase> fit in the <phrase>database</phrase> world, and what mechanisms are required to support such an <phrase>engine</phrase>.
Readings in <phrase>Database Systems</phrase>, <phrase>Third Edition</phrase>
The <phrase>Mathematics</phrase> of <phrase>Inheritance</phrase> Systems
<phrase>Object-Relational DBMSs</phrase>, <phrase>Second Edition</phrase>
A <phrase>Many-Sorted Calculus</phrase> Based on Resolution and <phrase>Paramodulation</phrase>.
The <phrase>first-order</phrase> <phrase>calculus</phrase> whose <phrase>well formed</phrase> formulas are clauses and whose <phrase>sole</phrase> <phrase>inference rules</phrase> are factorization, resolution and <phrase>paramodulation</phrase> is extended to a <phrase>many-sorted calculus</phrase>. As a basis for <phrase>Automated Theorem Proving</phrase>, this <phrase>many-sorted calculus</phrase> leads to a remarkable reduction of the <phrase>search space</phrase> and also to <phrase>simpler proofs</phrase>. The <phrase>soundness and completeness</phrase> of the new <phrase>calculus</phrase> and the <phrase>Sort</phrase>-Theorem, which relates the <phrase>many-sorted calculus</phrase> to its one-sorted counterpart, are shown. In addition <phrase>results</phrase> about <phrase>term rewriting</phrase> and <phrase>unification</phrase> in a <phrase>many-sorted calculus</phrase> are obtained. <phrase>Practical examples</phrase> and a proof protocol of <phrase>an automated theorem prover</phrase> based on the <phrase>many-sorted calculus</phrase> are presented.
Principles of <phrase>Multimedia</phrase> <phrase>Database Systems</phrase>
<phrase>Database</phrase> Modeling & <phrase>Design</phrase>, <phrase>Third Edition</phrase>
Inside <phrase>ODBC</phrase>.
Inside <phrase>COM</phrase>.
The <phrase>Data Compression</phrase> <phrase>Book</phrase>, <phrase>2nd Edition</phrase>
<phrase>Managing</phrase> <phrase>Gigabytes</phrase>: <phrase>Compressing</phrase> and <phrase>Indexing</phrase> Documents and Images.
Plattformen.
<phrase>CSCL</phrase> <phrase>im</phrase> Fernstudium.
Selbst organisierte Szenarien.
<phrase>CSCL</phrase> in Hochschulseminaren: Zwei Beispielszenarien <phrase>aus der Praxis</phrase>.
<phrase>Virtuelle</phrase> kooperative Lernräume.
<phrase>Kooperation</phrase> in größeren Lerngruppen.
<phrase>CSCL</phrase> <phrase>als Herausforderung</phrase> an <phrase>die</phrase> Lehrerbildung.
Kollaboratives <phrase>Lernen</phrase> Studierender <phrase>mit</phrase> Hilfe von <phrase>Knowledge</phrase> <phrase>Forum</phrase>.
Pädagogische und didaktische <phrase>Grundlagen</phrase>.
Einleitung und Begriffe.
Entwicklungsprozess.
Kooperative Lernräume.
<phrase>Software</phrase>- und <phrase>Systementwicklung</phrase>.
Informatikgrundlagen und <phrase>Mensch-Computer</phrase>-<phrase>Kommunikation</phrase>.
Problemorientiertes <phrase>Lernen</phrase>.
<phrase>Kooperation</phrase> in kleineren Lerngruppen.
<phrase>Einführung</phrase> und <phrase>Bereitstellung</phrase>.
<phrase>Lern- und</phrase> kommunikationspsychologische <phrase>Grundlagen</phrase>.
Projektorientierung.
Gruppen und Gruppenarbeit.
Mediendidaktische <phrase>Konzeption</phrase>.
<phrase>Konzepte für die</phrase> Lerngruppe.
<phrase>Qualitätssicherung</phrase>.
Spezifikationen, Normen und Standards für Lernmaterialien.
<phrase>Kooperatives Lernen</phrase> in Organisationen.
<phrase>CSCL</phrase> in <phrase>der betrieblichen</phrase> <phrase>Weiterbildung</phrase>.
<phrase>Neue</phrase> Lernformen in der Berufsausbildung: <phrase>Eine Fallstudie</phrase>.
<phrase>CSCL</phrase> in <phrase>der Schule</phrase>.
Forschungsmethoden.
Koordinationswerkzeuge zur <phrase>Bildung</phrase> von Lerngruppen.
Moderation.
<phrase>Coaching</phrase>.
<phrase>Konzepte</phrase> zur <phrase>Administration</phrase>.
<phrase>Kommunikation</phrase>.
Medienwahl.
The <phrase>Software</phrase> <phrase>Abstract</phrase> is intended to <phrase>tell</phrase> its <phrase>reader</phrase> enough about the <phrase>software</phrase> to know where to find all the other <phrase>information</phrase> that exists about it, anywhere. A copy of the <phrase>Abstract</phrase> opens every document about the <phrase>software</phrase>. It has a fairly rigid format, so a <phrase>sequence</phrase> of <phrase>Abstracts</phrase> can be scanned swiftly, the same <phrase>information</phrase> always being found at the same place. The format of the <phrase>Software</phrase> <phrase>Abstract</phrase> is defined in <phrase>Figure</phrase> 1. Although most <phrase>Software</phrase> <phrase>Abstracts</phrase> are written to define individual programs, the format is also an effective tool for describing any <phrase>software</phrase> entity: <phrase>subroutine</phrase>, program, <phrase>software</phrase> system or subsystem, <phrase>data</phrase> file, or <phrase>library</phrase>. It has even been used successfully to document <phrase>books</phrase> and articles about documenting (<phrase>Schneider</phrase>, <phrase>French</phrase>, <phrase>Lucas</phrase> 77). The <phrase>Abstract</phrase> is constrained to fit on one side of one <phrase>sheet</phrase> of <phrase>paper</phrase>. This is the reason that certain sections of the <phrase>Abstract</phrase> are considered optional.An Example of <phrase>Software</phrase> <phrase>Abstract</phrase> is shown in <phrase>Figure</phrase> 2. The example demonstrates the considerable <phrase>informational</phrase> <phrase>latitude</phrase> that can be incorporated into a <phrase>Software</phrase> <phrase>Abstract</phrase> <phrase>without violating</phrase> the <phrase>strict</phrase> format guidelines. <phrase>The ACM Portal</phrase> is published by the <phrase>Association for Computing Machinery</phrase>. <phrase>Copyright © 2010 ACM</phrase>, Inc. <phrase>Terms of Usage Privacy Policy Code</phrase> of <phrase>Ethics</phrase> <phrase>Contact</phrase> Us Useful downloads: <phrase>Adobe Acrobat</phrase> <phrase>QuickTime</phrase> <phrase>Windows Media Player</phrase> Real Player
Adaptivität für individuelles <phrase>Lernen</phrase>.
<phrase>Werkzeuge</phrase> für spezielle Lernmethoden.
Kommunikationskonzepte.
<phrase>CSCL</phrase> für Lernbehinderte und Hochbegabte.
<phrase>Motivation</phrase>.
Lerngruppen.
<phrase>Perspektiven</phrase>.
<phrase>Konzepte für</phrase> den Lehrenden.
Bedarfsanalysen.
<phrase>Sicherheit</phrase>: Gewährleistung und Begrenzung <phrase>des</phrase> Informationsflusses.
Logikorientierte <phrase>Datenbanken</phrase> - <phrase>eine Einführung</phrase>.
<phrase>Konzepte</phrase> objektorientierter Datenmodelle.
<phrase>Eine Einführung</phrase> in Frame-<phrase>Logik</phrase>.
Natürlichsprachliche <phrase>Interaktion mit</phrase> <phrase>Datenbanken</phrase>.
<phrase>Konzepte</phrase> <phrase>des</phrase> <phrase>Datenbank</phrase>-<phrase>Entwurfs</phrase>.
<phrase>Modellbildung</phrase> für <phrase>Datenbank</phrase>-<phrase>Transaktionen</phrase>.
Datenbankkonzepte <phrase>für wissensbasierte</phrase> <phrase>Systeme</phrase>.
<phrase>Datenstrukturen</phrase> für Geodatenbanken.
Dieser <phrase>Bericht</phrase> gibt <phrase>eine</phrase> Uebersicht ueber den gegenwaertigen Stand <phrase>des</phrase> <phrase>Entwurfs</phrase> effizienter Zugriffsstrukturen <phrase>fur</phrase> geometrische <phrase>Objekte</phrase> in <phrase>Datenbanken</phrase>.
Operationen und Kalküle für komplex strukturierte Werte und <phrase>Objekte</phrase>.
Studien- und Forschungsführer <phrase>Informatik der</phrase> neuen Bundesländer (Fakultätentag <phrase>Informatik</phrase>, Arbeitskreis "<phrase>Informatik</phrase> an Deutschen <phrase>Universitäten</phrase> und Wissenschaftlichen <phrase>Hochschulen</phrase>"), 2. Aufl.
<phrase>Theoretische Informatik</phrase>: <phrase>Eine</phrase> anwendungsorientierte <phrase>Einführung</phrase>, 2. Auflage
<phrase>Java</phrase> 2, <phrase>Von den</phrase> <phrase>Grundlagen</phrase> <phrase>bis</phrase> zu Threads und <phrase>Netzen</phrase>, 2. Auflage
<phrase>Einführung in die</phrase> <phrase>objektorientierte Programmierung</phrase> <phrase>mit</phrase> <phrase>Java</phrase>, 2. Auflage
<phrase>Einführung in die</phrase> <phrase>objektorientierte Programmierung</phrase> <phrase>mit</phrase> <phrase>Java</phrase>, 1. Auflage
<phrase>Einführung in die</phrase> <phrase>Theoretische Informatik</phrase>: <phrase>Formale Sprachen</phrase> und Automatentheorie
Übersetzerbau
<phrase>Datenbanksysteme</phrase> - <phrase>Eine Einführung</phrase>, 4. Auflage
<phrase>Datenbanksysteme</phrase> - <phrase>Eine Einführung</phrase>, 5. Auflage
<phrase>Datenbanksysteme</phrase> - <phrase>Eine Einführung</phrase>, 6. Auflage
<phrase>Algorithmen</phrase> in <phrase>Java</phrase>
Rechneraufbau und Rechnerstrukturen, 9. Auflage
<phrase>Datenbanken</phrase> <phrase>im Unternehmen</phrase>: Analyse, <phrase>Modellbildung</phrase> und <phrase>Einsatz</phrase>
Ähnlichkeitssuche in <phrase>Multimedia</phrase>-<phrase>Datenbanken</phrase> - Retrieval, Suchalgorithmen und Anfragebehandlung
Ideen <phrase>der Informatik</phrase>: Grundlegende <phrase>Modelle und</phrase> <phrase>Konzepte</phrase>
Datenmodelle, Datenbanksprachen und Datenbankmanagementsysteme, 4. Auflage
<phrase>CSCL</phrase>-Kompendium. <phrase>Lehr- und</phrase> <phrase>Handbuch</phrase> zum computerunterstützten kooperativen <phrase>Lernen</phrase>
Datenmodelle, Datenbanksprachen und Datenbankmanagementsysteme, 5. Auflage
<phrase>Datenbanksysteme</phrase> - <phrase>Eine Einführung</phrase>, 7. Auflage
Übungsbuch <phrase>Datenbanksysteme</phrase>, 2. Auflage
<phrase>JavaServer Pages</phrase>
:<phrase>JavaServer Pages</phrase> (<phrase>JSP</phrase>) <phrase>technology</phrase> provides an easy way to create <phrase>dynamic web pages</phrase>. <phrase>JSP</phrase> uses a <phrase>component-based</phrase> approach that allows <phrase>web</phrase> developers to easily combine static <phrase>HTML</phrase> for <phrase>look-and-feel</phrase> with <phrase>Java</phrase> components for <phrase>dynamic</phrase> features. The simplicity of this <phrase>component-based</phrase> <phrase>model</phrase>, combined with the <phrase>cross-platform</phrase> power of <phrase>Java</phrase>, allows a <phrase>web development</phrase> environment with <phrase>enormous potential</phrase>. <phrase>JavaServer Pages</phrase> shows how to develop <phrase>Java</phrase>-based <phrase>web applications</phrase> without having to be a <phrase>hardcore</phrase> <phrase>programmer</phrase>. The <phrase>author</phrase> provides <phrase>an overview</phrase> of <phrase>JSP</phrase> concepts and discusses how <phrase>JSP</phrase> fits into the larger <phrase>picture</phrase> of <phrase>web applications</phrase>. <phrase>Web</phrase> page authors will benefit from the chapters on <phrase>generating</phrase> <phrase>dynamic</phrase> content, handling <phrase>session</phrase> <phrase>information</phrase>, <phrase>accessing databases</phrase>, <phrase>authenticating</phrase> users, and <phrase>personalizing</phrase> content. In the <phrase>programming</phrase>-oriented chapters, <phrase>Java</phrase> programmers learn how to create <phrase>Java</phrase> components and custom <phrase>JSP</phrase> tags for <phrase>web</phrase> authors to use in <phrase>JSP</phrase> pages. About the <phrase>Author</phrase>: <phrase>Hans</phrase> Bergsten is the <phrase>founder</phrase> of Gefion <phrase>Software</phrase>, whose main product is a <phrase>servlet</phrase>-based component <phrase>suite</phrase> for <phrase>developing</phrase> <phrase>web applications</phrase>. <phrase>Hans</phrase> is also an <phrase>active</phrase> participant in the development of the <phrase>JSP</phrase> specification.
<phrase>Java</phrase> <phrase>Cookbook</phrase>
<phrase>Java</phrase> Examples in a Nutshell
:This <phrase>book</phrase> is a <phrase>companion</phrase> volume to <phrase>Java</phrase> in a Nutshell. While <phrase>Java</phrase> in a Nutshell is a <phrase>quick</phrase>-reference at <phrase>heart</phrase>, it also includes an <phrase>accelerated</phrase> <phrase>introduction</phrase> to <phrase>Java</phrase> <phrase>programming</phrase>. <phrase>Java</phrase> Examples in a Nutshell picks up where that <phrase>book</phrase> <phrase>leaves</phrase> off, providing a <phrase>suite</phrase> of example programs for <phrase>novice</phrase> <phrase>Java</phrase> programmers and experts alike. This <phrase>book</phrase> doesn't hold your hand or supply detailed explanations of <phrase>Java</phrase> <phrase>syntax</phrase> or <phrase>method calls</phrase>; it simply delivers well-commented, <phrase>working examples</phrase> that explore the <phrase>wide range</phrase> of what is possible with <phrase>Java</phrase> 1.1. Each <phrase>chapter</phrase> concludes with <phrase>programming</phrase> exercises that suggest further avenues for <phrase>building</phrase> on what you have learned.
<phrase>Java</phrase> in a Nutshell - <phrase>A Desktop Quick Reference</phrase> for <phrase>Java</phrase> Programmers, Covers <phrase>Java</phrase> 1.0
<phrase>Java</phrase> Power Reference
<phrase>Java</phrase> <phrase>Foundation</phrase> Classes in a Nutshell
<phrase>Java</phrase> Fundamental Classes Reference
<phrase>XML</phrase> in a Nutshell
This authoritative new <phrase>edition</phrase> of <phrase>XML</phrase> in a Nutshell provides developers with a complete guide to the <phrase>rapidly evolving</phrase> <phrase>XML</phrase> space. Serious users of <phrase>XML</phrase> will find topics on just about everything they need, including fundamental <phrase>syntax</phrase> rules, details of <phrase>DTD</phrase> and <phrase>XML Schema</phrase> creation, <phrase>XSLT</phrase> transformations, and <phrase>APIs</phrase> used for processing <phrase>XML</phrase> documents. Simply put, this is the only reference of its kind among <phrase>XML</phrase> <phrase>books</phrase>.
<phrase>Java</phrase> 2D Graphics
One weakness of <phrase>Java</phrase> has been its <phrase>graphics capabilities</phrase>. <phrase>Java</phrase> 1.0 and 1.1 only included simple primitives for <phrase>line drawing</phrase>: lines could only be one <phrase>pixel</phrase> wide, they could only be solid, and there wasn't any good way to draw curves. <phrase>Font</phrase> <phrase>management</phrase> and <phrase>color management</phrase> were also <phrase>weak</phrase>. <phrase>Java</phrase> 2D (<phrase>collectively called</phrase> the "2D <phrase>API</phrase>") signals a <phrase>major</phrase> improvement in <phrase>Java's</phrase> <phrase>graphics capabilities</phrase>. It covers many of the classes in <phrase>Java</phrase> 1.2 that address graphics handling and improves on many weaknesses that were present in the <phrase>previous versions</phrase> of <phrase>Java</phrase>. The 2D <phrase>API</phrase> allows you to <phrase>produce high-quality</phrase>, <phrase>professional</phrase> images on a screen or <phrase>printer</phrase>. <phrase>Java</phrase> 2D Graphics describes the 2D <phrase>API</phrase> from <phrase>top</phrase> to bottom, demonstrating how to set line styles and pattern fills as well as more <phrase>advanced</phrase> techniques of <phrase>image processing</phrase> and <phrase>font</phrase> handling. You'll see how to create and manipulate the three types of graphics objects: shapes, text, and images. Other <phrase>topics include</phrase> <phrase>image data</phrase> storage, <phrase>color management</phrase>, <phrase>font</phrase> <phrase>glyphs</phrase>, and <phrase>printing</phrase>. <phrase>Java</phrase> 2D Graphics assumes no <phrase>prior knowledge</phrase> of graphics. Chock full of detailed explanations and examples, this <phrase>book</phrase> provides beginning <phrase>Java</phrase> programmers with a <phrase>solid foundation</phrase> in 2D graphics and helps more <phrase>advanced</phrase> programmers create and use <phrase>high</phrase>-quality images in their applications. Topics <phrase>covered</phrase> in the <phrase>book</phrase> include: The rendering pipelineShapes and pathsGeometryPainting with solid colors, gradients, and texturesStroking paths, including dashed linesTransformations: <phrase>translation</phrase>, rotation, shearing, and scalingAlpha compositingClippingRasterizing and antialiasingFonts and textFont metricsGlyphsColors and <phrase>color</phrase> spacessRGB and CIEXYZICC <phrase>color</phrase> profilesImages, <phrase>image color</phrase> models, and image dataImage processingImage <phrase>data</phrase> storageGraphics devicesPrinting
<phrase>Java</phrase> and <phrase>XML</phrase>
<phrase>Java</phrase> revolutionized the <phrase>programming</phrase> world by providing a <phrase>platform-independent</phrase> <phrase>programming language</phrase>. <phrase>XML</phrase> takes the <phrase>revolution</phrase> a step further with a <phrase>platform-independent</phrase> <phrase>language</phrase> for <phrase>interchanging</phrase> <phrase>data</phrase>. <phrase>Java</phrase> and <phrase>XML</phrase> shows how to put the two together, <phrase>building</phrase> <phrase>real-world</phrase> applications in which both the code and the <phrase>data</phrase> are truly portable.
<phrase>Java Virtual Machine</phrase>
<phrase>Windows</phrase> 98 in a Nutshell
<phrase>Database</phrase> <phrase>Programming</phrase> with <phrase>JDBC</phrase> and <phrase>Java</phrase>
<phrase>Java</phrase> <phrase>Performance Tuning</phrase>
CJKV <phrase>Information Processing</phrase>: <phrase>Chinese</phrase>, <phrase>Japanese</phrase>, <phrase>Korean</phrase> & <phrase>Vietnamese</phrase> <phrase>Computing</phrase>
<phrase>CGI</phrase> <phrase>Programming</phrase> on <phrase>the World Wide Web</phrase>, <phrase>1st Edition</phrase>
<phrase>Programming</phrase> the Be <phrase>Operating System</phrase>: <phrase>Writing Programs</phrase> for the Be <phrase>Operating System</phrase>
<phrase>Natural Language Processing</phrase> with Thought <phrase>Treasure</phrase>
<phrase>Tree</phrase> <phrase>Automata</phrase>
<phrase>Unification</phrase> theory.
<phrase>Classical</phrase> vs <phrase>non-classical logics</phrase> (the <phrase>universality</phrase> of <phrase>classical logic</phrase>).
<phrase>Higher order logic</phrase>.
<phrase>Meta</phrase>-languages, <phrase>reflection</phrase> principles, and <phrase>self-reference</phrase>.
<phrase>Mathematical induction</phrase>.
<phrase>Logical</phrase> basis for the <phrase>automation</phrase> of reasoning: <phrase>Case studies</phrase>.
<phrase>MEME</phrase>, <phrase>MAST</phrase>, and <phrase>Meta</phrase>-<phrase>MEME</phrase>: New Tools for <phrase>Motif Discovery</phrase> in <phrase>Protein</phrase> Sequences.
<phrase>Discovering</phrase> Concepts in <phrase>Structural</phrase> <phrase>Data</phrase>.
<phrase>Motif Discovery</phrase> in <phrase>Protein Structure</phrase> <phrase>Databases</phrase>.
<phrase>Assembling</phrase> Blocks.
A Framework for Biological <phrase>Pattern Discovery</phrase> on <phrase>Networks of Workstations</phrase>.
<phrase>Discovering</phrase> Patterns in <phrase>DNA</phrase> Sequences by the <phrase>Algorithmic</phrase> Significance Method.
<phrase>RNA Structure</phrase> Analysis: A <phrase>Multifaceted</phrase> Approach.
<phrase>Systematic</phrase> Detection of <phrase>Protein</phrase> <phrase>Structural</phrase> Motifs.
<phrase>Pattern Discovery</phrase> and Classification in <phrase>Biosequences</phrase>.
<phrase>Overview</phrase>: A System for Tracking and <phrase>Managing</phrase> the <phrase>Results</phrase> from <phrase>Sequence</phrase> Comparison Programs.
Representation and Matching of Small <phrase>Flexible Molecules</phrase> in <phrase>Large Databases</phrase> of 3D Molecular <phrase>Information</phrase>.
Text <phrase>Algorithms</phrase>
<phrase>Handbook</phrase> of <phrase>Logic</phrase> in <phrase>Artificial Intelligence</phrase> and <phrase>Logic Programming</phrase>, Volume2, <phrase>Deduction</phrase> Methodologies
<phrase>Pattern Discovery</phrase> in <phrase>Biomolecular Data</phrase>: Tools, Techniques and Applications
The Vbase <phrase>Object Database</phrase> Environment.
CommonLoops: <phrase>Merging</phrase> <phrase>Lisp</phrase> and <phrase>Object-Oriented Programming</phrase>.
CommonLoops blends <phrase>object-oriented programming</phrase> smoothly and tightly with the procedure-<phrase>oriented design</phrase> of <phrase>Lisp</phrase>. Functions and methods are combined in a more <phrase>general</phrase> abstraction. <phrase>Message passing</phrase> is invoked via normal <phrase>Lisp</phrase> <phrase>function</phrase> call. Methods are viewed as <phrase>partial</phrase> descriptions of procedures. <phrase>Lisp</phrase> <phrase>data</phrase> types are integrated with <phrase>object classes</phrase>. With these integrations, it is easy to incrementally move a program between the procedure and <phrase>object-oriented</phrase> styles.One of the most <phrase>important properties</phrase> of CommonLoops is its extensive use of <phrase>meta</phrase>-objects. We discuss three kinds of <phrase>meta</phrase>-objects: objects for classes, objects for methods, and objects for discriminators. We argue that these <phrase>meta</phrase>-objects make practical both <phrase>efficient</phrase> implementation and <phrase>experimentation</phrase> with new ideas for <phrase>object-oriented</phrase> programming.CommonLoops' small <phrase>kernel</phrase> is powerful enough to implement the <phrase>major</phrase> <phrase>object-oriented</phrase> systems in use today.
Complex Entities for <phrase>Engineering</phrase> Applications.
<phrase>Overview</phrase> of the <phrase>Iris</phrase> <phrase>DBMS</phrase>.
<phrase>Database</phrase> Description with <phrase>SDM</phrase>: A <phrase>Semantic</phrase> <phrase>Database</phrase> <phrase>Model</phrase>
A <phrase>Tutorial</phrase> on <phrase>Semantic</phrase> <phrase>Database</phrase> Modeling
<phrase>SIM</phrase>: A <phrase>Database</phrase> System Based on the <phrase>Semantic</phrase> <phrase>Data Model</phrase>.
PICQUERY: A <phrase>High</phrase> Level <phrase>Query Language</phrase> for <phrase>Pictorial</phrase> <phrase>Database Management</phrase>.
A reasonably <phrase>comprehensive</phrase> set of <phrase>data</phrase> accessing and <phrase>manipulation operations</phrase> that should be supported by a <phrase>generalized</phrase> <phrase>pictorial</phrase> <phrase>database management</phrase> system (PDBMS) is proposed. A corresponding <phrase>high</phrase>-level <phrase>query language</phrase>, PICQUERY, is presented and illustrated through examples. PICQUERY has been designed with a flavor similar to QBE as the highly nonprocedural and conservational <phrase>language</phrase> for the <phrase>pictorial</phrase> <phrase>database management</phrase> system PICDMS. PICQUERY and a <phrase>relational</phrase> QBE-like <phrase>language</phrase> would form the <phrase>language</phrase> by which a user could access conventional <phrase>relational databases</phrase> and at the same time <phrase>pictorial databases</phrase> managed by PICDMS or other <phrase>robust</phrase> PDBMS. This languageinterface is part of an <phrase>architecture</phrase> aimed <phrase>toward</phrase> <phrase>data</phrase> heterogeneity transparency over <phrase>pictorial</phrase> and nonpictorial <phrase>databases</phrase>.
<phrase>Managing</phrase> Change in a <phrase>Computer-Aided Design</phrase> <phrase>Database</phrase>.
<phrase>Object-oriented</phrase> concepts can make a <phrase>design</phrase> <phrase>database</phrase> more <phrase>reactive</phrase> to changes in its contents. By <phrase>embedding</phrase> change <phrase>semantics</phrase> in the <phrase>database</phrase> <phrase>model</phrase>, the <phrase>design engineer</phrase> can be relieved of <phrase>managing</phrase> the detailed effects of changes. However, mechanisms are needed to limit the scope of <phrase>change propagation</phrase> and to unambiguously identify the objects to which propagated changes should apply. We propose new mechanisms based on <phrase>group</phrase> check-in/check-out, <phrase>browser</phrase> contexts and paths, configuration constraints, and rules, to support a powerful <phrase>automatic</phrase> change capability within a <phrase>design</phrase> <phrase>database</phrase>.
<phrase>Integrating</phrase> <phrase>an Object-Oriented</phrase> <phrase>Programming</phrase> System with a <phrase>Database</phrase> System.
There are two <phrase>major</phrase> issues to address to achieve <phrase>integration</phrase> of <phrase>an object-oriented</phrase> <phrase>programming</phrase> system with a <phrase>database</phrase> system. One is the <phrase>language</phrase> issue: <phrase>an object-oriented</phrase> <phrase>programming language</phrase> must be <phrase>augmented</phrase> with <phrase>semantic</phrase> <phrase>data modeling</phrase> concepts to provide a <phrase>robust</phrase> set of <phrase>data modeling</phrase> concepts to allow modeling of entities for important <phrase>real-world</phrase> applications. Another is the <phrase>computational-model</phrase> issue: <phrase>application programmers</phrase> should be able to access and <phrase>manipulate objects</phrase> as <phrase>though</phrase> the objects are in an <phrase>infinite</phrase> <phrase>virtual memory</phrase>; in other words, they should not have to be aware of the <phrase>existence</phrase> of a <phrase>database</phrase> system in their computations with the <phrase>data</phrase> structures the <phrase>programming language</phrase> allows. This <phrase>paper</phrase> discusses these issues and presents the solutions which we have incorporated into the <phrase>ORION</phrase> <phrase>object-oriented</phrase> <phrase>database</phrase> system at <phrase>MCC</phrase>.
<phrase>Object Management</phrase> in <phrase>Distributed Information Systems</phrase>.
Development of <phrase>an Object-Oriented</phrase> <phrase>DBMS</phrase>.
We describe the <phrase>results</phrase> of <phrase>developing</phrase> the <phrase>GemStone</phrase> <phrase>object-oriented</phrase> <phrase>database server</phrase>, which supports a <phrase>model</phrase> of objects similar to that of <phrase>Smalltalk</phrase>-80. We begin with a <phrase>summary</phrase> of the goals and requirements for the system: <phrase>an extensible</phrase> <phrase>data model</phrase> that captures <phrase>behavioral semantics</phrase>, no <phrase>artificial</phrase> bounds on the number or size of <phrase>database</phrase> objects, <phrase>database</phrase> amenities (<phrase>concurrency</phrase>, transactions, recovery, <phrase>associative</phrase> access, <phrase>authorization</phrase>) and <phrase>an interactive</phrase> <phrase>development environment</phrase>. <phrase>Object-oriented</phrase> languages, <phrase>Smalltalk</phrase> in particular, answer some of these requirements. We discuss satisfying the remaining requirements in <phrase>an object oriented</phrase> context, and <phrase>report</phrase> briefly on the status of the <phrase>development efforts</phrase>. This <phrase>paper</phrase> is <phrase>directed</phrase> at an audience familiar with <phrase>object-oriented</phrase> languages and their implementation, but perhaps unacquainted with the difficulties and techniques of <phrase>database</phrase> system development. It updates the original <phrase>report</phrase> on the <phrase>project</phrase> [<phrase>CM</phrase>], and expands upon a more recent article [<phrase>MDP</phrase>].
The <phrase>POSTGRES</phrase> <phrase>Data Model</phrase>.
Type <phrase>Evolution</phrase> in <phrase>an Object-Oriented Database</phrase>.
A Prological Definition of HASL: A <phrase>Purely Functional</phrase> <phrase>Language</phrase> with <phrase>Unification</phrase>-Based <phrase>Conditional</phrase> Binding Expressions.
Constraining-<phrase>Unification</phrase> and the <phrase>Programming Language</phrase> <phrase>UNICORN</phrase>.
Up to this point <phrase>direct</phrase> implementations of <phrase>axiomatic</phrase> or <phrase>equational</phrase> specifications have been limited because the implementation mechanisms used are incapable of capturing the full <phrase>semantics</phrase> of the specifications. The <phrase>programming language</phrase> <phrase>Unicorn</phrase> was designed and implemented with the <phrase>intention</phrase> of <phrase>exploring</phrase> the full potential of <phrase>programming</phrase> with equations. <phrase>Unicorn</phrase> introduces a new <phrase>language</phrase> mechanism, called constraining-<phrase>unification</phrase>. When <phrase>coupled</phrase> with <phrase>semantic</phrase> <phrase>unification</phrase>, constraining-<phrase>unification</phrase> closely models the <phrase>semantics</phrase> of <phrase>equational</phrase> specifications thereby allowing for the implementation of a wider class of specifications. <phrase>Unlike</phrase> the <phrase>language</phrase> mechanisms of <phrase>rewrite-rule</phrase> and <phrase>logic programming</phrase>, constraining-<phrase>unification</phrase> is <phrase>free</phrase> of <phrase>order</phrase> dependencies. The same <phrase>results</phrase> are <phrase>produced</phrase> regardless of the <phrase>order</phrase> in which the <phrase>axioms</phrase> are stated. The use of viewpoints contributes to the flexibility of the <phrase>Unicorn</phrase> <phrase>language</phrase>. Preconditions for <phrase>partial</phrase> operations can be specified without added machinery.
<phrase>LEAF</phrase>: A <phrase>Language</phrase> which Integrates <phrase>Logic</phrase>, Equations and Functions.
The APPLOG <phrase>Language</phrase>.
The <phrase>Unification</phrase> of <phrase>Functional</phrase> and <phrase>Logic</phrase> Languages.
EQLOG: <phrase>Equality</phrase>, Types, and <phrase>Generic</phrase> Modules For <phrase>Logic Programming</phrase>.
<phrase>Logic Programming</phrase> <phrase>Language</phrase> Scheme.
<phrase>UNIFORM</phrase> - A <phrase>Language</phrase> Based Upon <phrase>Unification</phrase> Which Unifies (much of) <phrase>LISP</phrase>, <phrase>PROLOG</phrase>, and <phrase>ACT</phrase> 1.
<phrase>Uniform</phrase> is an <phrase>AI</phrase> <phrase>programming language</phrase> under development based upon <phrase>augmented</phrase> <phrase>unification</phrase>. It is an attempt to combine, in a simple <phrase>coherent</phrase>-framework, the most <phrase>important features</phrase> of <phrase>Lisp</phrase>, <phrase>actor</phrase> languages such as <phrase>Act</phrase> 1 and <phrase>SmallTalk</phrase>, and <phrase>logic programming</phrase> languages such as <phrase>Prolog</phrase>. Among the unusual abilities of the <phrase>language</phrase> is its ability to use the same program as a <phrase>function</phrase>, an <phrase>inverse function</phrase>, a predicate, a pattern, or a generator. All of these uses can be performed upon <phrase>concrete</phrase>, <phrase>symbolic</phrase>, and <phrase>partially instantiated</phrase> <phrase>data</phrase>. <phrase>Uniform</phrase> features <phrase>automatic</phrase> <phrase>inheritance</phrase> from multiple <phrase>super</phrase> classes, facilities for manipulation of programs, a limited ability to determine <phrase>program equivalence</phrase>, and a <phrase>unification</phrase>-<phrase>oriented database</phrase>.
<phrase>Equality</phrase> For <phrase>Prolog</phrase>.
The <phrase>language</phrase> <phrase>Prolog</phrase> has been extended by allowing the inclusion of assertions about <phrase>equality</phrase>. When a <phrase>unification</phrase> of two terms that do not unify <phrase>syntactically</phrase> is attempted, an <phrase>equality</phrase> theorem may be used to prove the two terms equal. If it is possible to prove that the two terms are equal the <phrase>unification</phrase> succeeds with the <phrase>variable</phrase> bindings introduced by the <phrase>equality</phrase> proof. It is shown that this mechanism <phrase>significantly improves</phrase> the power of <phrase>Prolog</phrase>. Sophisticated <phrase>data</phrase> abstraction with all the advantages of <phrase>object-oriented programming</phrase> is available. Techniques for passing <phrase>partially instantiated</phrase> <phrase>data</phrase> are described that extends the "multiuse" capabilities of the <phrase>language</phrase>, improve the efficiency of some programs, and allow the implementation of <phrase>arithmetic</phrase> relations that are both <phrase>general</phrase> and <phrase>efficient</phrase>. The modifications to <phrase>standard Prolog</phrase> are simple and straightforward and in addition the <phrase>computational overhead</phrase> for the <phrase>extra linguistic</phrase> power is not significant. <phrase>Equality</phrase> theorems will probably <phrase>play</phrase> an <phrase>important role</phrase> in future <phrase>logic programming</phrase> systems.
TABLOG: A New Approach To <phrase>Logic Programming</phrase>.
On the Relationship Between <phrase>Logic</phrase> and <phrase>Functional</phrase> Languages.
QUTE: A <phrase>Functional Language</phrase> Based on <phrase>Unification</phrase>.
FRESH: A <phrase>Higher-Order</phrase> <phrase>Language</phrase> With <phrase>Unification</phrase> and Multiple <phrase>Results</phrase>.
FUNLOG: A <phrase>Computational Model</phrase> <phrase>Integrating</phrase> <phrase>Logic Programming</phrase> and <phrase>Functional Programming</phrase>.
<phrase>Introduction</phrase> to <phrase>Data Structures</phrase> and <phrase>Algorithms</phrase> Related to <phrase>Information Retrieval</phrase>.
<phrase>String Searching Algorithms</phrase>.
<phrase>Signature Files</phrase>.
The <phrase>Student</phrase> <phrase>Forum</phrase> will provide an <phrase>opportunity</phrase> for students working in the <phrase>area</phrase> of <phrase>dependable computing</phrase> to present and discuss their <phrase>research</phrase> objectives, approaches and <phrase>preliminary results</phrase>. The <phrase>Forum</phrase> is <phrase>centered around</phrase> a conference <phrase>track</phrase> during which the selected "<phrase>student</phrase> <phrase>research</phrase> papers" are presented.
<phrase>File Organizations</phrase> for <phrase>Optical Disks</phrase>.
<phrase>Lexical Analysis</phrase> and Stoplists.
<phrase>Extended Boolean</phrase> Models.
<phrase>Introduction</phrase> to <phrase>Information</phrase> Storage and <phrase>Retrieval Systems</phrase>.
<phrase>Stemming</phrase> <phrase>Algorithms</phrase>.
New Indices for Text: <phrase>Pat</phrase> <phrase>Trees</phrase> and <phrase>Pat</phrase> Arrays.
<phrase>Relevance Feedback</phrase> and Other <phrase>Query Modification</phrase> Techniques.
<phrase>Ranking Algorithms</phrase>.
<phrase>Inverted</phrase> Files.
<phrase>Special-Purpose</phrase> Hardware for <phrase>Information Retrieval</phrase>.
<phrase>Clustering Algorithms</phrase>.
<phrase>Thesaurus</phrase> <phrase>Construction</phrase>.
<phrase>Parallel</phrase> <phrase>Information Retrieval</phrase> <phrase>Algorithms</phrase>.
<phrase>Boolean</phrase> Operations.
<phrase>Hashing</phrase> <phrase>Algorithms</phrase>.
<phrase>Multimedia</phrase> Communications - Synchronization.
<phrase>Design</phrase> of <phrase>Large-Scale</phrase> <phrase>Multimedia</phrase>-<phrase>on-Demand</phrase> <phrase>Storage Servers</phrase> and <phrase>Storage Hierarchies</phrase>.
<phrase>Third-Generation</phrase> <phrase>Distributed Hypermedia</phrase> Systems.
<phrase>Visual</phrase> Interfaces to <phrase>Multimedia</phrase> <phrase>Databases</phrase>.
<phrase>Video</phrase> and <phrase>Image Content</phrase> Representation and Retrieval.
Modeling Time-Based <phrase>Media</phrase>.
<phrase>Image Database</phrase> <phrase>Prototypes</phrase>.
<phrase>Composite</phrase> Models.
<phrase>Document Model</phrase> Issues for <phrase>Hypermedia</phrase>.
<phrase>Content-Based Indexing</phrase> and Retrieval.
<phrase>Video</phrase> <phrase>Database Systems</phrase> - <phrase>Recent Trends</phrase> in <phrase>Research</phrase> and <phrase>Development Activities</phrase>.
<phrase>Video</phrase> Segmentation for <phrase>Video</phrase> <phrase>Data Management</phrase>.
<phrase>Multimedia</phrase> Interfaces - <phrase>Multimedia</phrase> Content Indication.
<phrase>Memory Management</phrase>: <phrase>Codecs</phrase>.
<phrase>Concurrency Control</phrase> <phrase>Performance Modeling</phrase>: Alternatives and Implications.
A number of <phrase>recent studies</phrase> have examined the performance of <phrase>concurrency control</phrase> <phrase>algorithms</phrase> for <phrase>database management systems</phrase>. The <phrase>results</phrase> reported to date, rather than being definitive, have tended to be contradictory. In this <phrase>paper</phrase>, rather than presenting &ldquo;yet another <phrase>algorithm</phrase> <phrase>performance study</phrase>,&rdquo; we critically investigate the assumptions made in the models used in <phrase>past studies</phrase> and their implications. We employ a fairly complete <phrase>model</phrase> of a <phrase>database</phrase> environment for studying the <phrase>relative performance</phrase> of three different approaches to the <phrase>concurrency control</phrase> problem under a <phrase>variety</phrase> of <phrase>modeling assumptions</phrase>. The three approaches studied represent different extremes in how transaction conflicts are dealt with, and the assumptions addressed pertain to the <phrase>nature</phrase> of the <phrase>database</phrase> system's resources, how <phrase>transaction restarts</phrase> are modeled, and the amount of <phrase>information</phrase> available to the <phrase>concurrency control</phrase> <phrase>algorithm</phrase> about transactions' <phrase>reference strings</phrase>. We show that differences in the <phrase>underlying assumptions</phrase> explain the <phrase>seemingly contradictory</phrase> <phrase>performance results</phrase>. We also address the question of how realistic the various assumptions are for actual <phrase>database systems</phrase>.
On <phrase>Mixing</phrase> Queries and Transactions via <phrase>Multiversion</phrase> <phrase>Locking</phrase>.
<phrase>Conflict Detection</phrase> Tradeoffs for <phrase>Replicated Data</phrase>.
<phrase>Serializability</phrase>-Based <phrase>Correctness Criteria</phrase>.
<phrase>Database</phrase> <phrase>Concurrency Control</phrase> Using <phrase>Data Flow Graphs</phrase>.
A specialized <phrase>data flow graph</phrase>, <phrase>Database</phrase> <phrase>Flow Graph</phrase> (DBFG) is introduced. DBFGs may be used for scheduling <phrase>database</phrase> operations, particularly in an <phrase>MIMD</phrase> <phrase>database</phrase> machine environment. A DBFG explicitly maintains intertransaction and intratransaction dependencies, and is constructed from the Transaction <phrase>Flow Graphs</phrase> (TFG) of <phrase>active</phrase> transactions. A TFG, in turn, is the <phrase>generalization</phrase> of a <phrase>query tree</phrase> used, for example, in <phrase>DIRECT</phrase> [15]. All DBFG schedules are serializable and <phrase>deadlock</phrase> <phrase>free</phrase>. Operations needed to create and maintain the DBFG structure as transactions are <phrase>added or removed</phrase> from the system are discussed. <phrase>Simulation</phrase> <phrase>results</phrase> show that DBFG scheduling performs as well as <phrase>two-phase locking</phrase>.
<phrase>Firm</phrase> <phrase>Real-Time</phrase> <phrase>Concurrency Control</phrase>.
Reduction in Transaction Conflicts Using <phrase>Semantics</phrase>-Based <phrase>Concurrency Control</phrase>.
In this <phrase>chapter</phrase>, we consider <phrase>algorithms</phrase> that <phrase>permit</phrase> every site in a <phrase>partitioned</phrase> <phrase>database</phrase> system to perform new updates. Since this may result in <phrase>independent</phrase> updates to items in different <phrase>partitions</phrase>, conflicts among transactions are bound to occur. <phrase>Commutative</phrase> transactions can be used to reduce the number of these conflicts. We develop a <phrase>probabilistic model</phrase> to estimate the possible reduction in conflicts if we incorporate this notion of <phrase>commutativity</phrase>. The <phrase>results</phrase> show that the additional efforts to recognize this <phrase>commutativity</phrase> is not beneficial unless the number of transactions that commute with each other is significantly large.
<phrase>Concurrency Control</phrase> Mechanisms and Their <phrase>Taxonomy</phrase>.
Transactions and <phrase>Database</phrase> Processing.
<phrase>Extensibility</phrase> and <phrase>Asynchrony</phrase> in the <phrase>Brown</phrase>-<phrase>Object Storage</phrase> System.
Performance of <phrase>Concurrency Control</phrase> <phrase>Algorithms</phrase> for <phrase>Real-Time Database Systems</phrase>.
The <phrase>Design</phrase> and <phrase>Performance Evaluation</phrase> of a <phrase>Lock Manager</phrase> for a <phrase>Memory</phrase>-Resident <phrase>Database</phrase> System.
<phrase>Concurrency Control</phrase> and Recovery Methods for <phrase>B+-Tree</phrase> Indexes: <phrase>ARIES</phrase>/KVL and <phrase>ARIES/IM</phrase>.
Commit_LSN: A Novel and Simple Method for <phrase>Reducing</phrase> <phrase>Locking</phrase> and Latching in <phrase>Transaction Processing</phrase> Systems.
A <phrase>Two-Phase</phrase> Approach to Predictably Scheduling <phrase>Real-Time</phrase> Transactions.
An <phrase>Analytic</phrase> <phrase>Model</phrase> of Transaction Interference.
<phrase>Synchronizing</phrase> <phrase>Long</phrase>-Lived Computations.
<phrase>Two-Phase Locking</phrase> Performance and Its <phrase>Thrashing</phrase> Behavior.
<phrase>Implementation Considerations</phrase> and <phrase>Performance Evaluation</phrase> of <phrase>Object-Based</phrase> <phrase>Concurrency Control</phrase> Protocols.
Modeling and Analysis of <phrase>Concurrency Control</phrase> Schemes.
Modeling <phrase>Performance Impact</phrase> of <phrase>Hot Spots</phrase>.
<phrase>Database Design</phrase> Based on Entity and Realtionship.
<phrase>Data</phrase> Models and the <phrase>ANSI</phrase>/<phrase>SPARC</phrase> <phrase>Architecture</phrase>.
Network <phrase>Database Design</phrase> Methods.
Compter-Assisted <phrase>Hierarchical</phrase> <phrase>Database Design</phrase>.
<phrase>Requirement Specification</phrase> Techniques.
<phrase>Semantic</phrase> <phrase>Data</phrase> Models.
<phrase>Relational</phrase> <phrase>Database Design</phrase>.
Schema Implemetation and <phrase>Restructuring</phrase>.
<phrase>Processing-Requirement</phrase> Modeling and Its Applications in <phrase>Logical</phrase> <phrase>Database Design</phrase>.
<phrase>An Interactive</phrase> System for <phrase>Database Design</phrase> and <phrase>Integration</phrase>.
The <phrase>Design</phrase> of the <phrase>UNIX</phrase> <phrase>Operating System</phrase>.
<phrase>Syntax</phrase> of <phrase>Programming Languages</phrase>: Theory and Practice
<phrase>Graph Drawing</phrase>: <phrase>Algorithms</phrase> for the Visualization of <phrase>Graphs</phrase>
<phrase>Linear Programming</phrase>: <phrase>Active</phrase> Set Analysis and <phrase>Computer Programs</phrase>.
<phrase>Object-Oriented</phrase> <phrase>Multidatabase Systems</phrase>: A <phrase>Solution</phrase> for <phrase>Advanced</phrase> Applications
<phrase>Research</phrase> Foundations in <phrase>Object-Oriented</phrase> and <phrase>Semantic</phrase> <phrase>Database</phrase> System
<phrase>Operating Systems</phrase> Theory
<phrase>Internetworking</phrase> with <phrase>TCP/IP</phrase> - Principles, Protocols, and Architectures, <phrase>Fourth Edition</phrase>
How to Program <phrase>Advanced</phrase> <phrase>Java</phrase>
A Discipline of <phrase>Programming</phrase>.
<phrase>Data Mining</phrase>: <phrase>Introductory</phrase> and <phrase>Advanced</phrase> Topics
<phrase>Information Retrieval</phrase>: <phrase>Data</phrase> Structures & <phrase>Algorithms</phrase>
<phrase>Database</phrase> System Implementation
<phrase>Graphic</phrase> <phrase>Java</phrase> 2, <phrase>Mastering</phrase> the JFC: <phrase>Volume II</phrase>: <phrase>Swing</phrase>, <phrase>3rd Edition</phrase>
<phrase>Handbook</phrase> of <phrase>Multimedia</phrase> <phrase>Information Management</phrase>.
<phrase>Brinch Hansen</phrase> on <phrase>Pascal</phrase> Compilers
<phrase>Communicating Sequential Processes</phrase>
This <phrase>paper</phrase> suggests that <phrase>input and output</phrase> are <phrase>basic</phrase> primitives of <phrase>programming</phrase> and that <phrase>parallel</phrase> composition of <phrase>communicating sequential processes</phrase> is a fundamental <phrase>program structuring</phrase> method. When combined with a development of <phrase>Dijkstra's guarded</phrase> command, these concepts are <phrase>surprisingly</phrase> <phrase>versatile</phrase>. Their use is illustrated by sample solutions of a <phrase>variety</phrase> of familiar <phrase>programming</phrase> exercises.
<phrase>Algorithms</phrase> for <phrase>Clustering</phrase> <phrase>Data</phrase>
The Implementation of <phrase>Functional Programming Languages</phrase>.
<phrase>Object-Oriented</phrase> <phrase>Database Management</phrase>: Applications in <phrase>Engineering</phrase> and <phrase>Computer Science</phrase>
The <phrase>C</phrase> <phrase>Programming Language</phrase>
The <phrase>C</phrase> <phrase>Programming Language</phrase>, <phrase>Second Edition</phrase>
Elements of the Theory of Computation
<phrase>Object Databases</phrase> in Practice.
The .<phrase>NET</phrase> Training Course
<phrase>Object-Oriented</phrase> <phrase>Software</phrase> <phrase>Construction</phrase>, 1st editon
:<phrase>Object-Oriented</phrase> <phrase>Software</phrase> <phrase>Construction</phrase>, <phrase>second edition</phrase> is the <phrase>comprehensive</phrase> reference on all aspects of <phrase>object technology</phrase>, from <phrase>design</phrase> principles to <phrase>Object-Oriented</phrase> techniques, <phrase>Design</phrase> by <phrase>Contract</phrase>, <phrase>Object-Oriented</phrase> analysis, <phrase>concurrency</phrase>, <phrase>persistence</phrase>, <phrase>abstract data types</phrase> and many more. Written by a <phrase>pioneer</phrase> in the field, contains an in-depth analysis of both methodological and technical issues.Two-<phrase>color printing</phrase> provides for clear figures and readable <phrase>software</phrase> extracts. Comes with a <phrase>CD-ROM</phrase> containing: the complete hyperlinked text, for easy reference; <phrase>software</phrase> to read the text on <phrase>major</phrase> <phrase>industry</phrase> platforms; <phrase>supplementary material</phrase> (<phrase>reusable components</phrase>, <phrase>mathematical</phrase> complements); and a complete <phrase>graphical</phrase> <phrase>Object-Oriented</phrase> <phrase>development environment</phrase> <phrase>supporting</phrase> the concepts of the <phrase>book</phrase>.
<phrase>Introduction</phrase> to the Theory of <phrase>Programming Languages</phrase>
<phrase>Eiffel</phrase>: The <phrase>Language</phrase>
<phrase>An Object-Oriented</phrase> Environment: Principles and Applications
<phrase>Reusable Software</phrase>: The Base <phrase>Object-Oriented</phrase> <phrase>Component Libraries</phrase>
Object Success
<phrase>Object-Oriented</phrase> <phrase>Software</phrase> <phrase>Construction</phrase>, <phrase>2nd Edition</phrase>
<phrase>Object-Oriented</phrase> Applications
Principles of <phrase>Distributed Database</phrase> Systems.
Principles of <phrase>Distributed Database</phrase> Systems, <phrase>Second Edition</phrase>
<phrase>Combinatorial</phrase> Optimization: <phrase>Algorithms</phrase> and Complexity
The <phrase>Art</phrase> of <phrase>Compiler</phrase> <phrase>Design</phrase>: Theory and Practice
<phrase>UNIX</phrase> <phrase>Database Management Systems</phrase>
<phrase>Object-Oriented</phrase> Modeling and <phrase>Design</phrase>
<phrase>File Structures</phrase>: An <phrase>Analytic</phrase> Approach.
<phrase>Database</phrase> Tuning - A <phrase>Principled</phrase> Approach
<phrase>Computer Networks</phrase>
From the Book:This <phrase>book</phrase> is now in its <phrase>third edition</phrase>. Each <phrase>edition</phrase> has corresponded to a different phase in the way <phrase>computer networks</phrase> were used. When the first <phrase>edition</phrase> appeared in 1980, networks were an <phrase>academic</phrase> curiosity. When the <phrase>second edition</phrase> appeared in 1988, networks were used by <phrase>universities</phrase> and large businesses. When the <phrase>third edition</phrase> appeared in 1996, <phrase>computer networks</phrase>, especially the worldwide <phrase>Internet</phrase>, had become a <phrase>daily</phrase> <phrase>reality</phrase> for millions of people. Furthermore, the <phrase>networking</phrase> hardware and <phrase>software</phrase> have completely changed since the <phrase>second edition</phrase> appeared In 1988, nearly all networks were based on <phrase>copper</phrase> <phrase>wire</phrase>. Now, many are based on <phrase>fiber optics</phrase> or <phrase>wireless communication</phrase>. Proprietary networks, such as <phrase>SNA</phrase> have become far less important than <phrase>public</phrase> networks, especially the <phrase>Internet</phrase>. The <phrase>OSI</phrase> protocols have quietly vanished,, and the <phrase>TCP/IP protocol suite</phrase> has become dominant. In fact, so much has changed, the <phrase>book</phrase> has almost been rewritten <phrase>from scratch</phrase>. Although Chap. 1 has the same <phrase>introductory</phrase> <phrase>function</phrase> as it did in the <phrase>second edition</phrase>, the contents have been completely <phrase>revised</phrase> and brought <phrase>up to date</phrase>. For example, <phrase>instead</phrase> of <phrase>basing</phrase> the <phrase>hook</phrase> on the seven-layer <phrase>OSI model</phrase>. a five-layer <phrase>hybrid</phrase> <phrase>model</phrase> (<phrase>shown in Fig</phrase>. 1-21) is now used and introduced in Chap. 1. While not exactly identical to the <phrase>TCP/IP</phrase> <phrase>model</phrase>, it is much closer to the <phrase>TCP/IP</phrase> <phrase>model</phrase> in <phrase>spirit</phrase> than it is to the <phrase>OSI model</phrase> used in the <phrase>second edition</phrase>. Also, the new running examples used throughout the <phrase>book</phrase> - the <phrase>Internet</phrase> and <phrase>Al</phrase> <phrase>M</phrase> networks are introduced here, along with some <phrase>gigabit</phrase> networks and other popular networks. In Chap. 2, the focus has moved from <phrase>copper</phrase> <phrase>wire</phrase> to <phrase>fiber optics</phrase> and <phrase>wireless communication</phrase>,since these <phrase>arc</phrase> the technologies of the future. The <phrase>telephone</phrase> system has become almost entirely <phrase>digital</phrase> in the <phrase>past decade</phrase>, so the material on it has been largely rewritten, with new material on <phrase>broadband</phrase> <phrase>ISDN</phrase> added. The material on <phrase>cellular radio</phrase> has been <phrase>greatly expanded</phrase>, and new material on low-<phrase>orbit</phrase> <phrase>satellites</phrase> has been added to the <phrase>chapter</phrase>. The <phrase>order</phrase> of discussion of the <phrase>data link layer</phrase> and the <phrase>MAC</phrase> sublayer has been reversed, since experience with students shows that they understand the <phrase>MAC</phrase> sublayer better after they have studied the <phrase>data link layer</phrase>. The example protocols there have been kept, as they have <phrase>proven</phrase> very popular, but they have been rewritten in <phrase>C</phrase>. New material on the <phrase>Internet</phrase> and <phrase>ATM</phrase> <phrase>data link</phrase> layers has been added. The <phrase>MAC</phrase> sublayer principles of Chap. 4. have been <phrase>revised</phrase> to reflect new protocols, including <phrase>wavelength division multiplexing</phrase>, <phrase>wireless</phrase> <phrase>LANs</phrase>, and <phrase>digital radio</phrase>. The discussion of bridges has been <phrase>revised</phrase>, and new material has been added on <phrase>high</phrase>-speed <phrase>LANs</phrase>. Most of the <phrase>routing algorithms</phrase> of Chap. 5 have been replaced by more modern ones, including <phrase>distance vector</phrase> and <phrase>link state routing</phrase>. The sections on <phrase>congestion control</phrase> have been completely <phrase>redone</phrase>, and material on the running examples, the <phrase>Internet</phrase> and <phrase>ATM</phrase> is all new. Chap. 6 is still about the <phrase>transport</phrase> layer, but here, too, <phrase>major</phrase> changes have occurred, primarily, the addition of a large amount of new material about the <phrase>Internet</phrase>, <phrase>ATM</phrase>, and <phrase>network performance</phrase>. Chap. 7, on the <phrase>application layer</phrase>, is now the <phrase>longest</phrase> <phrase>chapter</phrase> in the <phrase>book</phrase>. The material on <phrase>network security</phrase> has been doubled in length, and new material has been added on <phrase>DNS</phrase>, <phrase>SNMP</phrase>, <phrase>email</phrase>, <phrase>USENET</phrase>, <phrase>the World Wide Web</phrase>, <phrase>HTML</phrase>, <phrase>Java</phrase>, <phrase>multimedia</phrase>, <phrase>video on demand</phrase>, and the <phrase>MBone</phrase>. Of the 395 figures in the <phrase>third edition</phrase>, 276 (<phrase>70 percent</phrase>) are completely new and some of the others have been <phrase>revised</phrase>. Of the 371 references to the <phrase>literature</phrase>, 282 (76 percent) are to <phrase>books</phrase> and papers that have appeared since the <phrase>second edition</phrase> was published. Of these, over 100 are to works published in 1995 and 1996 alone. All in all, probably 75 percent of the entire <phrase>book</phrase> is <phrase>brand</phrase> new, and parts of the remaining 25 percent have been heavily <phrase>revised</phrase>. Since this is effectively a new <phrase>book</phrase>, the <phrase>cover</phrase> was redesigned to avoid confusion with the <phrase>second edition</phrase>. Computer <phrase>books</phrase> are full of <phrase>acronyms</phrase>. This one is no exception. By the time you are finished <phrase>reading</phrase> this one, all of the following should <phrase>ring</phrase> a <phrase>bell</phrase>: <phrase>AAL</phrase>, <phrase>AMPS</phrase>, <phrase>ARP</phrase>, <phrase>ASN</phrase>, <phrase>ATM</phrase>, <phrase>BGP</phrase>, <phrase>CDMA</phrase>, CDPD, <phrase>CSMA</phrase>, <phrase>DQDB</phrase>, <phrase>DNS</phrase>, <phrase>FAQ</phrase>, <phrase>FDM</phrase>, <phrase>FTP</phrase>, FTTC, FTTH, <phrase>GSM</phrase>, <phrase>HDLC</phrase>, <phrase>HEC</phrase>, HlPPl, <phrase>TAB</phrase>, lCMP, IDEA, <phrase>IETF</phrase>, 1Pv6, <phrase>ISO</phrase>, <phrase>ITU</phrase>, <phrase>LATA</phrase>, <phrase>MAC</phrase>, MACA, <phrase>MAN</phrase>, <phrase>MIB</phrase>, <phrase>MIME</phrase>, <phrase>NAP</phrase>, <phrase>NNTP</phrase>, <phrase>NSA</phrase>, NSAP, <phrase>OSI</phrase>, <phrase>OSPF</phrase>, <phrase>PCM</phrase>, <phrase>PCN</phrase>, <phrase>PCS</phrase>, <phrase>PEM</phrase>, <phrase>PGP</phrase>, <phrase>PPP</phrase>, <phrase>PSTN</phrase>, PTT, <phrase>PVC</phrase>, <phrase>QAM</phrase>, RARP, <phrase>RFC</phrase>, <phrase>RSA</phrase>, SABME, <phrase>SAP</phrase>, <phrase>SAR</phrase>, <phrase>SDH</phrase>, <phrase>SDLC</phrase>, <phrase>SHA</phrase>, <phrase>SMI</phrase>, <phrase>SNA</phrase>, <phrase>SNMP</phrase>, SNRME, SPX, <phrase>TCP</phrase>, <phrase>UDP</phrase>, <phrase>VHF</phrase>, <phrase>VLF</phrase>, <phrase>VSAT</phrase>, WARC, <phrase>WDM</phrase>, WWV, and <phrase>WWW</phrase>. But <phrase>don't</phrase> worry. Each one will be <phrase>carefully defined</phrase> before it is used. To help instructors using this <phrase>book</phrase> as a text for course, the <phrase>author</phrase> has prepared three <phrase>teaching</phrase> <phrase>aids</phrase>: A problem solutions manual. <phrase>PostScript</phrase> files containing all the figures (for making overhead sheets). A simulator (written in <phrase>C</phrase>) for the example protocols of Chap. 3. The solutions manual is available from <phrase>Prentice Hall</phrase> (but only to instructors). The file with the figures and the simulator are available via <phrase>the World Wide Web</phrase>. To get them, <phrase>please</phrase> see the <phrase>author's</phrase> <phrase>home</phrase> page: <phrase>http</phrase>://www.cs.vu.nl/~<phrase>ast</phrase>/. The <phrase>book</phrase> was typeset in Times <phrase>Roman</phrase> using <phrase>Troff</phrase>, which, after all these years, is still the only way to <phrase>go</phrase>. While <phrase>Troff</phrase> is not as trendy as <phrase>WYSIWYG</phrase> systems, the <phrase>reader</phrase> is invited to compare the <phrase>typesetting</phrase> quality of this <phrase>book</phrase> with <phrase>books</phrase> <phrase>produced</phrase> by <phrase>WYSIWYG</phrase> systems. My only <phrase>concession</phrase> to <phrase>PCs</phrase> and <phrase>desktop publishing</phrase> is that for the first time, the <phrase>art</phrase> was <phrase>produced</phrase> using <phrase>Adobe Illustrator</phrase>, <phrase>instead</phrase> of being drawn on <phrase>paper</phrase>. Also for the first time, the <phrase>book</phrase> was <phrase>produced</phrase> entirely electronically. The <phrase>PostScript</phrase> output from <phrase>Troff</phrase> was sent over the <phrase>Internet</phrase> to the <phrase>printer</phrase>, where the <phrase>film</phrase> for making the offset plates was <phrase>produced</phrase>. No intermediate <phrase>paper</phrase> copy was printed and photographed, as is normally done. <phrase>Andrew</phrase> <phrase>S</phrase>. Tanenbaum
<phrase>Modern Operating Systems</phrase>
<phrase>Design</phrase> of <phrase>Database</phrase> Structures
<phrase>Geographic Information Systems</phrase> and <phrase>Cartographic</phrase> Modelling.
Core <phrase>Swing</phrase>: <phrase>Advanced</phrase> <phrase>Programming</phrase>
A First Course in <phrase>Database Systems</phrase>.
<phrase>PCTE</phrase> - The Standard for <phrase>Open</phrase> Repositories.
<phrase>Seamless</phrase> <phrase>Object-Oriented</phrase> <phrase>Software Architecture</phrase> - Analysis and <phrase>Design</phrase> of <phrase>Reliable</phrase> Systems
A <phrase>Model</phrase> Implementation of <phrase>Standard Pascal</phrase>
Principles of <phrase>Database Design</phrase>, Volume <phrase>I</phrase>: <phrase>Logical</phrase> Organizations
<phrase>Konstruktion von</phrase> Anfrageoptimierern für Objektbanken.
On the Complexity of <phrase>Broadcast</phrase> and <phrase>Gossip</phrase> in Different <phrase>Communication</phrase> Modes.
<phrase>Branching</phrase> Programs and <phrase>Binary Decision Diagrams</phrase>
<phrase>Topological</phrase> Concepts for <phrase>Hierarchies</phrase> of variables, Types and Controls.
Modifications of the Oettli-Prager Theorem with Application to the <phrase>Eigenvalue</phrase> Problem.
<phrase>Introduction</phrase>: <phrase>Symbolic</phrase> <phrase>Algebraic</phrase> Methods and <phrase>Verification Methods</phrase>.
<phrase>Symbolic-Numeric</phrase> <phrase>Algorithms</phrase> for <phrase>Polynomials</phrase>: Some <phrase>recent Results</phrase>.
On the <phrase>Isoefficiency</phrase> of the <phrase>Parallel</phrase> <phrase>Descartes</phrase> Method.
Matrix Methods for Solving <phrase>Algebraic</phrase> Systems.
A Feasibility Result for <phrase>Interval</phrase> <phrase>Gaussian Elimination</phrase> Relying on <phrase>Graph</phrase> Structure.
<phrase>Solution</phrase> of Systems of <phrase>Polynomial</phrase> Equation by Using <phrase>Bernstein</phrase> <phrase>Expansion</phrase>.
<phrase>Symbolic</phrase>-<phrase>Algebraic</phrase> Computations in <phrase>Modeling Language</phrase> for <phrase>Mathematical</phrase> <phrase>Programming</phrase>.
<phrase>Translation</phrase> of <phrase>Taylor Series</phrase> into LFT Expansions.
<phrase>Quasi Convex</phrase>-Concave Extension.
<phrase>Rewriting</phrase>, <phrase>Induction</phrase> and <phrase>Decision Procedures</phrase>: <phrase>A Case Study</phrase> of <phrase>Presburger Arithmetic</phrase>.
<phrase>Derivative</phrase>-Based Subdivision in <phrase>Multi-dimensional</phrase> Verified <phrase>Gaussian Quadrature</phrase>.
On the Shape of the <phrase>Fixed Points</phrase> of [<phrase>f</phrase>]([<phrase>c</phrase>])=[A][<phrase>x</phrase>]+[<phrase>b</phrase>].
<phrase>Exact</phrase> Computation with leda_real - Theory and <phrase>geometric</phrase> Applications.
<phrase>Numerical Verification</phrase> Method for Solutions of <phrase>Nonlinear Hyperbolic Equations</phrase>.
<phrase>Geometric Series</phrase> Bounds for the <phrase>Local</phrase> errors of <phrase>Taylor</phrase> Methods for Linear n-<phrase>th</phrase>-<phrase>Order</phrase> <phrase>ODEs</phrase>.
<phrase>Safe</phrase> <phrase>Numerical Error</phrase> Bounds for Solutions of <phrase>Nonlinear</phrase> <phrase>Elliptic Boundary Value Problems</phrase>.
<phrase>Fast</phrase> <phrase>Verification Algorithms</phrase> in <phrase>MATLAB</phrase>.
The <phrase>Linear Complementarity Problem</phrase> with <phrase>Interval Data</phrase>.
Some <phrase>Numerical Methods</phrase> for <phrase>Nonlinear Least Squares Problems</phrase>.
A New Insight of the Shortley-Weller Approximation for <phrase>Dirichlet</phrase> Problems.
How <phrase>Orthogonality</phrase> is <phrase>Lost</phrase> in <phrase>Krylov</phrase> Methods.
<phrase>Symbolic-Numeric</phrase> <phrase>QD</phrase>-<phrase>Algorithms</phrase> with Application in <phrase>Function</phrase> Theory and <phrase>Linear Algebra</phrase>.
<phrase>Content-Based</phrase> <phrase>Querying</phrase>.
Searching <phrase>Distributed Hypermedia</phrase>.
<phrase>Query Processing</phrase>.
<phrase>Introduction</phrase> [Requirements for a <phrase>Multimedia</phrase> <phrase>Database</phrase>].
<phrase>User Interaction</phrase> in a <phrase>Virtual World</phrase> Environment.
<phrase>Operating System</phrase> Support [for <phrase>Multimedia</phrase> <phrase>Databases</phrase>].
<phrase>Communication</phrase> Support [for <phrase>Multimedia</phrase> <phrase>Databases</phrase>].
<phrase>Indexing</phrase> of <phrase>Multimedia</phrase> <phrase>Data</phrase>.
<phrase>Critical Success Factors</phrase> [for <phrase>Multimedia</phrase> <phrase>Databases</phrase>].
<phrase>Multimedia</phrase> and its Impact on <phrase>Database</phrase> System Architectures.
Current and <phrase>Emerging Applications</phrase> [Requirements for a <phrase>Multimedia</phrase> <phrase>Database</phrase>].
The SQL3 Server Interface.
The <phrase>SGML</phrase>/HyTime Server Interface.
An <phrase>Expert</phrase> Interface for Effective <phrase>Man-Machine Interaction</phrase>.
<phrase>An Interactive</phrase> Customization Program for a <phrase>Natural Language</phrase> <phrase>Database</phrase> Query System.
<phrase>Talking</phrase> it Over: The <phrase>Natural Language Dialog</phrase> System <phrase>HAM-ANS</phrase>.
The <phrase>Semantic</phrase>-Based <phrase>Natural Language</phrase> Interface to <phrase>Relational Databases</phrase>.
Studies in the Evaluation of a <phrase>Domain-Independent</phrase> <phrase>Natural Language</phrase> Query System.
<phrase>DIAGRAM</phrase>: A <phrase>Grammar</phrase> for <phrase>Dialogues</phrase>.
An <phrase>explanatory</phrase> <phrase>overview</phrase> is given of <phrase>DIAGRAM</phrase>, a large and complex <phrase>grammar</phrase> used in an <phrase>artificial intelligence</phrase> system for <phrase>interpreting</phrase> <phrase>English</phrase> <phrase>dialogue</phrase>. <phrase>DIAGRAM</phrase> is an <phrase>augmented</phrase> <phrase>phrase-structure grammar</phrase> with rule procedures that allow phrases to inherit attributes from their constituents and to acquire attributes from the larger phrases in which they themselves are constituents. These attributes are used to set <phrase>context-sensitive</phrase> constraints on the acceptance of an analysis. Constraints can be imposed by conditions on <phrase>dominance</phrase> as well as by conditions on <phrase>constituency</phrase>. Rule procedures can also <phrase>assign scores</phrase> to an analysis to rate it as probable or unlikely. Less likely analyses can be ignored by the procedures that interpret the <phrase>utterance</phrase>. For every expression it analyzes, <phrase>DIAGRAM</phrase> provides an annotated description of the structure. The annotations supply <phrase>important information</phrase> for other parts of the system that interpret the expression in the context of a <phrase>dialogue</phrase>. <phrase>Major</phrase> <phrase>design</phrase> decisions are explained and illustrated. Some contrasts with <phrase>transformational grammars</phrase> are <phrase>pointed out</phrase> and problems that motivate a plan to use metarules in the future are discussed. (Metarules derive new rules from a set of base rules to achieve the kind of generality <phrase>previously captured</phrase> by <phrase>transformational grammars</phrase> but without having to perform transformations on <phrase>syntactic</phrase> analyses.)
Considerations for the Development of <phrase>Natural-Language</phrase> Interfaces to <phrase>Database Management Systems</phrase>.
An <phrase>Engine</phrase> for Intelligent Graphics.
<phrase>Algorithmic</phrase> <phrase>Number Theory</phrase> and Its Relationship to <phrase>Computational Complexity</phrase>.
<phrase>Algorithmic</phrase> Techniques for <phrase>Geometric</phrase> Optimization.
<phrase>Programming</phrase> Satan's Computer.
Differential <phrase>BDDs</phrase>.
Templates for <phrase>Linear Algebra</phrase> Problems.
The <phrase>ART</phrase> behind IDEAS.
A <phrase>Quantum</phrase> <phrase>Jump</phrase> in <phrase>Computer Science</phrase>.
<phrase>Mathematical</phrase> System Models as a Basis of <phrase>Software Engineering</phrase>.
<phrase>Abstracting</phrase> <phrase>Unification</phrase>: A Key Step in the <phrase>Design</phrase> of <phrase>Logic Program</phrase> Analyses.
<phrase>Multimedia</phrase> <phrase>Authoring</phrase> Tools: <phrase>State</phrase> of the <phrase>Art</phrase> and <phrase>Research</phrase> Challenges.
<phrase>Symmetry</phrase> and <phrase>Induction</phrase> in <phrase>Model Checking</phrase>.
Trends in <phrase>Active</phrase> Vision.
Avoiding the Undefined by <phrase>Underspecification</phrase>.
We use the <phrase>appeal</phrase> of simplicity and an <phrase>aversion</phrase> to complexity in <phrase>selecting</phrase> a method for handling <phrase>partial</phrase> functions in <phrase>logic</phrase>. We conclude that avoiding the undefined by using <phrase>underspecification</phrase> is the preferred choice.
Towards a Computational Theory of <phrase>Genome</phrase> Rearrangements.
Towards a theory of <phrase>Recursive</phrase> Structures.
In <phrase>computer science</phrase>, one is interested mainly in finite objects. Insofar as <phrase>infinite</phrase> objects are of interest, they must be <phrase>computable</phrase>, i.e., <phrase>recursive</phrase>, thus admitting an effective finite representation. This leads to the notion of a <phrase>recursive</phrase> <phrase>graph</phrase>, or, more generally, a <phrase>recursive</phrase> structure or <phrase>data</phrase> base. In this <phrase>paper</phrase> we summarize our recent work on <phrase>recursive</phrase> structures and <phrase>data</phrase> bases, including (1) the <phrase>high</phrase> <phrase>undecidability</phrase> of many problems on <phrase>recursive</phrase> <phrase>graphs</phrase>, (<phrase>ii</phrase>) <phrase>somewhat surprising</phrase> ways of deducting <phrase>results</phrase> on the classification of <phrase>NP optimization problems</phrase> from <phrase>results</phrase> on the <phrase>degree</phrase> of <phrase>undecidability</phrase> of their <phrase>infinitary</phrase> <phrase>analogues</phrase>, and (<phrase>iii</phrase>) <phrase>completeness results</phrase> for <phrase>query languages</phrase> on <phrase>recursive</phrase> <phrase>data</phrase> bases. <phrase>The ACM Portal</phrase> is published by the <phrase>Association for Computing Machinery</phrase>. <phrase>Copyright © 2010 ACM</phrase>, Inc. <phrase>Terms of Usage Privacy Policy Code</phrase> of <phrase>Ethics</phrase> <phrase>Contact</phrase> Us Useful downloads: <phrase>Adobe Acrobat</phrase> <phrase>QuickTime</phrase> <phrase>Windows Media Player</phrase> Real Player
<phrase>Algebraic Topology</phrase> and <phrase>Distributed Computing</phrase>: A <phrase>Primer</phrase>.
<phrase>Computational Models</phrase> for <phrase>Distributed Multimedia Applications</phrase>.
Computational <phrase>Machine Learning</phrase> in Theory and <phrase>Praxis</phrase>.
<phrase>Hypermedia</phrase> Systems as <phrase>Internet</phrase> Tools.
<phrase>Scalable Computing</phrase>.
<phrase>Efficient</phrase> Use of <phrase>Parallel</phrase> & <phrase>Distributed Systems</phrase>: From Theory to Practice.
<phrase>Edge-Coloring</phrase> <phrase>Algorithms</phrase>.
All the Needles in a <phrase>Haystack</phrase>: Can <phrase>Exhaustive Search</phrase> Overcome <phrase>Combinatorial</phrase> <phrase>Chaos</phrase>?
<phrase>Chu Spaces</phrase> and Their Interpretation as <phrase>Concurrent</phrase> Objects.
<phrase>Fundamental Limitations</phrase> on <phrase>Search Algorithms</phrase>: <phrase>Evolutionary</phrase> <phrase>Computing</phrase> in <phrase>Perspective</phrase>.
<phrase>Petri Net</phrase> Models of <phrase>Distributed Algorithms</phrase>.
<phrase>Information Retrieval</phrase> and <phrase>Information</phrase> Reasoning.
<phrase>Reasoning about</phrase> Actions and Change with <phrase>Ramification</phrase>.
Formulations and Formalisms in <phrase>Software Architecture</phrase>.
<phrase>Recurrent Neural Networks</phrase>.
The <phrase>Oz</phrase> <phrase>Programming</phrase> <phrase>Model</phrase>.
<phrase>Experimental</phrase> Validation of Models of <phrase>Parallel</phrase> Computation.
<phrase>Artificial Life</phrase> and <phrase>Real World</phrase> <phrase>Computing</phrase>.
<phrase>Alternating Automata</phrase> and <phrase>Program Verification</phrase>.
<phrase>Database Transaction</phrase> Models.
Quo Vadetis, <phrase>Parallel Machine</phrase> Models?
<phrase>Standard Generalized Markup Language</phrase>: <phrase>Mathematical</phrase> and <phrase>Philosophical</phrase> Issues.
<phrase>Fuzzy Sets</phrase> as a Tool for Modeling.
<phrase>Data Mining</phrase> for Selection of <phrase>Manufacturing</phrase> Processes.
<phrase>Fractal</phrase> <phrase>Mining</phrase> - <phrase>Self Similarity</phrase>-<phrase>based Clustering</phrase> and its Applications.
<phrase>Text Mining</phrase> and <phrase>Information Extraction</phrase>.
<phrase>Outlier</phrase> Detection.
<phrase>Statistical Methods</phrase> for <phrase>Data Mining</phrase>.
<phrase>Data Mining</phrase> within a <phrase>Regression</phrase> Framework.
<phrase>Constraint-Based</phrase> <phrase>Data Mining</phrase>.
<phrase>Data Mining</phrase> <phrase>Query Languages</phrase>.
<phrase>Geometric</phrase> Methods for <phrase>Feature Extraction</phrase> and <phrase>Dimensional Reduction</phrase> - <phrase>A Guided Tour</phrase>.
<phrase>Data Mining</phrase> for <phrase>Imbalanced Datasets</phrase>: <phrase>An Overview</phrase>.
<phrase>Dimension</phrase> Reduction and <phrase>Feature Selection</phrase>.
<phrase>Reinforcement-Learning</phrase>: <phrase>An Overview</phrase> from <phrase>a Data Mining Perspective</phrase>.
<phrase>Parallel</phrase> and <phrase>Grid</phrase>-Based <phrase>Data Mining</phrase> - <phrase>Algorithms</phrase>, Models and Systems for <phrase>High</phrase>-Performance <phrase>KDD</phrase>.
<phrase>Link Analysis</phrase>.
<phrase>Relational</phrase> <phrase>Data Mining</phrase>.
<phrase>WEKA</phrase> - A <phrase>Machine Learning</phrase> <phrase>Workbench</phrase> for <phrase>Data Mining</phrase>.
<phrase>Evolutionary Algorithms</phrase> for <phrase>Data Mining</phrase>.
<phrase>Web Mining</phrase>.
Bias vs. <phrase>Variance</phrase> Decomposition for <phrase>Regression</phrase> and Classification.
<phrase>Data Mining</phrase> <phrase>Model</phrase> Comparison.
<phrase>Frequent Set Mining</phrase>.
<phrase>Meta-Learning</phrase>.
<phrase>Rule Induction</phrase>.
<phrase>Mining</phrase> <phrase>High-Dimensional Data</phrase>.
LERS - A <phrase>Data Mining</phrase> System.
<phrase>Mining</phrase> <phrase>Data</phrase> Streams.
Handling <phrase>Missing Attribute Values</phrase>.
Logics for <phrase>Data Mining</phrase>.
<phrase>Quality Assessment</phrase> Approaches in <phrase>Data Mining</phrase>.
<phrase>Association Rules</phrase>.
Visualization and <phrase>Data Mining</phrase> for <phrase>High Dimensional</phrase> Datasets.
On the Use of <phrase>Fuzzy Logic</phrase> in <phrase>Data Mining</phrase>.
DataEngine - Tools for <phrase>Intelligent Data Analysis</phrase> and Control.
<phrase>Mining</phrase> with <phrase>Rare Cases</phrase>.
<phrase>Data Mining</phrase> for <phrase>Financial Applications</phrase>.
<phrase>Data Mining</phrase> for <phrase>Software Testing</phrase>.
<phrase>Data Mining</phrase> in <phrase>Medicine</phrase>.
<phrase>Data Mining</phrase> for <phrase>Target</phrase> <phrase>Marketing</phrase>.
GainSmarts <phrase>Data Mining</phrase> System for <phrase>Marketing</phrase>.
<phrase>Wavelet</phrase> Methods in <phrase>Data Mining</phrase>.
<phrase>Granular Computing</phrase> and <phrase>Rough</phrase> Sets.
<phrase>Introduction</phrase> to <phrase>Knowledge</phrase> Discovery in <phrase>Databases</phrase>.
<phrase>Introduction</phrase> to <phrase>Supervised</phrase> Methods.
Decomposition Methodology for <phrase>Knowledge</phrase> Discovery and <phrase>Data Mining</phrase>.
<phrase>Data Cleansing</phrase> - A <phrase>Prelude</phrase> to <phrase>Knowledge</phrase> Discovery.
Wizsoft's WizWhy.
Collaborative <phrase>Data Mining</phrase>.
Organizational <phrase>Data Mining</phrase>.
A Review of <phrase>Web Document Clustering</phrase> Approaches.
<phrase>Mining</phrase> <phrase>Time Series Data</phrase>.
<phrase>Data Mining</phrase> of <phrase>Design</phrase> <phrase>Products</phrase> and Processes.
<phrase>Ensemble</phrase> Methods for Classifiers.
<phrase>Decision Trees</phrase>.
<phrase>Clustering</phrase> Methods.
<phrase>Interestingness Measures</phrase> - On <phrase>Determining</phrase> What Is Interesting.
<phrase>Spatial Data Mining</phrase>.
<phrase>Support Vector Machines</phrase>.
<phrase>Learning</phrase> <phrase>Information</phrase> Patterns in <phrase>Biological Databases</phrase>.
<phrase>Data Mining</phrase> for <phrase>Intrusion Detection</phrase>.
<phrase>Oracle</phrase> <phrase>Data Mining</phrase> - <phrase>Data Mining</phrase> in the <phrase>Database</phrase> Environment.
<phrase>Building</phrase> <phrase>Data Mining</phrase> Solutions with <phrase>OLE DB</phrase> for <phrase>DM</phrase> and <phrase>XML</phrase> for Analysis.
A <phrase>data mining</phrase> component is included in <phrase>Microsoft SQL Server</phrase> 2000 and <phrase>SQL Server</phrase> 2005, one of the most popular <phrase>DBMSs</phrase>. This gives a <phrase>push</phrase> for <phrase>data mining</phrase> technologies to move from a <phrase>niche</phrase> towards the mainstream. Apart from a few <phrase>algorithms</phrase>, the <phrase>main contribution</phrase> of <phrase>SQL Server</phrase> <phrase>Data Mining</phrase> is the implementation of <phrase>OLE DB</phrase> for <phrase>Data Mining</phrase>. <phrase>OLE DB</phrase> for <phrase>Data mining</phrase> is an <phrase>industrial</phrase> standard <phrase>led</phrase> by <phrase>Microsoft</phrase> and supported by a number of ISVs. It leverages two existing <phrase>relational</phrase> technologies: <phrase>SQL</phrase> and <phrase>OLE DB</phrase>. It defines a <phrase>SQL</phrase> <phrase>language</phrase> for <phrase>data mining</phrase> based on a <phrase>relational</phrase> concept. More <phrase>recently</phrase>, <phrase>Microsoft</phrase>, <phrase>Hyperion</phrase>, <phrase>SAS</phrase> and a few other <phrase>BI</phrase> vendors formed the <phrase>XML</phrase> for Analysis <phrase>Council</phrase>. <phrase>XML</phrase> for Analysis covers both <phrase>OLAP</phrase> and <phrase>Data Mining</phrase>. The goal is to allow <phrase>consumer</phrase> applications to query various <phrase>BI</phrase> packages from different platforms. This <phrase>paper</phrase> gives <phrase>an overview</phrase> of <phrase>OLE DB</phrase> for <phrase>Data Mining</phrase> and <phrase>XML</phrase> for Analysis. It also shows how to build <phrase>data mining</phrase> application using these <phrase>APIs</phrase>.
<phrase>Data Mining</phrase> for <phrase>CRM</phrase>.
<phrase>Information</phrase> <phrase>Fusion</phrase> - Methods and <phrase>Aggregation Operators</phrase>.
<phrase>Data Mining</phrase> in <phrase>Telecommunications</phrase>.
<phrase>Discretization</phrase> Methods.
<phrase>Causal</phrase> Discovery.
<phrase>Neural Networks</phrase>.
<phrase>Bayesian</phrase> Networks.
<phrase>Object-Oriented</phrase> <phrase>Galileo</phrase>.
<phrase>Proteus</phrase>: The <phrase>DBMS</phrase> <phrase>User Interface</phrase> as an Object.
<phrase>Handling Constraints</phrase> and their Exceptions: An Attached Constraint <phrase>Handler</phrase> for <phrase>Object-Oriented</phrase> <phrase>CAD</phrase> <phrase>Databases</phrase>.
The <phrase>Architecture</phrase> of the <phrase>EXODUS</phrase> <phrase>Extensible</phrase> <phrase>DBMS</phrase>.
<phrase>Summary</phrase>.
<phrase>Managing Complex</phrase> Objects in the <phrase>Darmstadt</phrase> <phrase>Database</phrase> <phrase>Kernel</phrase> System.
<phrase>Object-Oriented</phrase> <phrase>Database Systems</phrase>: The Notion and the Issues.
The <phrase>Efficient</phrase> Support of <phrase>Functionally-Defined</phrase> <phrase>Data</phrase> in Cactis.
<phrase>Inheritance</phrase> Issues in <phrase>Computer-Aided Design</phrase> <phrase>Databases</phrase>.
Godal: An <phrase>Object-Centered</phrase> <phrase>Database</phrase> <phrase>Language</phrase>.
<phrase>An Object-Oriented</phrase> Interface to a <phrase>Relational Database</phrase>.
A <phrase>Data Modeling</phrase> Methodology for the <phrase>Design</phrase> and Implementation of <phrase>Information</phrase> Systems.
<phrase>Formal specifications</phrase> that precisely and correctly define the <phrase>semantics</phrase> of <phrase>software</phrase> systems become <phrase>increasingly important</phrase> as the complexity of such systems increase. The emerging set of <phrase>semantic</phrase> <phrase>data</phrase> models which support both <phrase>structural</phrase> and operational abstractions are excellent tools for <phrase>formal specifications</phrase>. In this <phrase>paper</phrase> we introduce a methodology, based on <phrase>an object-oriented data model</phrase>, for the <phrase>design</phrase> and development of <phrase>large software systems</phrase>. The methodology is demonstrated by <phrase>applying</phrase> the <phrase>object-oriented</phrase> <phrase>data model</phrase> to the specification of a <phrase>database</phrase> system which implements the given <phrase>model</phrase>. The specification serves several purposes: it <phrase>formally defines</phrase> the <phrase>precise semantics</phrase> of the operations of the <phrase>data model</phrase>, it provides a basis from which the corresponding <phrase>database</phrase> system <phrase>software</phrase> can be <phrase>systematically derived</phrase>, and it <phrase>tests</phrase> and demonstrates the <phrase>adequacy</phrase> of such a <phrase>model</phrase> for defining <phrase>software</phrase> systems in <phrase>general</phrase>. The <phrase>design</phrase> methodology introduced combines techniques from <phrase>data</phrase> modeling, <phrase>formal specifications</phrase>, and <phrase>software engineering</phrase>.
<phrase>An Overview</phrase> of <phrase>PDM</phrase>: <phrase>An Object-Oriented Data Model</phrase>.
<phrase>Generating</phrase> <phrase>Object-Oriented</phrase> <phrase>Database Systems</phrase> with the <phrase>Data Model</phrase> <phrase>Compiler</phrase>.
<phrase>An Object-Oriented Database</phrase> for <phrase>Trellis</phrase>.
<phrase>Design</phrase> Issues for <phrase>Object-Oriented</phrase> <phrase>Database Systems</phrase>.
A <phrase>Shared Object</phrase> Hierarchy.
This <phrase>paper</phrase> describes the <phrase>design</phrase> and proposed implementation of a <phrase>shared object</phrase> hierarchy. The object hierarchy is stored in a <phrase>relational database</phrase> and objects referenced by an <phrase>application program</phrase> are cached in the program's <phrase>address space</phrase>. The <phrase>paper</phrase> describes the <phrase>database</phrase> representation for the object hierarchy and the use of <phrase>POSTGRES</phrase>, a <phrase>next</phrase>-generation <phrase>relational database management system</phrase>, to implement <phrase>object referencing</phrase> efficiently. The <phrase>shared object</phrase> hierarchy system will be used to implement Object <phrase>FADS</phrase>, <phrase>an object-oriented</phrase> <phrase>programming</phrase> environment for interactive <phrase>database</phrase> applications that will be the main <phrase>programming</phrase> interface to <phrase>POSTGRES</phrase>.
<phrase>ObServer</phrase>: An <phrase>Object Server</phrase> for <phrase>an Object-Oriented Database</phrase> System.
Towards on <phrase>Object-Oriented</phrase> <phrase>Data Model</phrase> for a <phrase>Mechanical CAD</phrase> <phrase>Database</phrase> System.
Associate Access Support in <phrase>GemStone</phrase>.
<phrase>Object Management</phrase> in <phrase>Postgres</phrase> using Procedures.
This <phrase>paper</phrase> presents the <phrase>object management</phrase> facilities being designed into a <phrase>next</phrase>-generation <phrase>data</phrase> <phrase>manager</phrase>, <phrase>POSTGRES</phrase>. This system is unique in that it does not invent a new <phrase>data model</phrase> for support of objects but chooses <phrase>instead</phrase> to extend the <phrase>relational model</phrase> with a powerful <phrase>abstract</phrase> <phrase>data</phrase> typing capability and procedures as <phrase>full-fledged</phrase> <phrase>data</phrase> base objects. The reasons to remain with the <phrase>relational model</phrase> are indicated in this <phrase>paper</phrase> along with the <phrase>POSTGRES</phrase> <phrase>relational</phrase> extensions.
<phrase>Persistent</phrase> <phrase>Memory</phrase>: A <phrase>Storage System</phrase> for <phrase>Object-Oriented</phrase> <phrase>Databases</phrase>.
Views, Objects, and <phrase>Databases</phrase>.
Using <phrase>Adaptive</phrase> <phrase>Information Extraction</phrase> for Effective <phrase>Human</phrase>-Centred <phrase>Document Annotation</phrase>.
<phrase>XML</phrase> <phrase>Information Retrieval</phrase> and <phrase>Information Extraction</phrase>.
On <phrase>Knowledgeable</phrase> <phrase>Unsupervised</phrase> <phrase>Text Mining</phrase>.
Towards <phrase>Collaborative Information Retrieval</phrase>: Three Approaches.
<phrase>Evaluating</phrase> <phrase>Retrieval Performance</phrase> Using <phrase>Clickthrough Data</phrase>.
<phrase>Concept Drift</phrase> and the Importance of Example.
<phrase>Text Mining</phrase>.
The XDOC Document <phrase>Suite</phrase> - a <phrase>Workbench</phrase> for <phrase>Document Mining</phrase>.
<phrase>Feature-Rich</phrase> <phrase>Memory-Based</phrase> Classification for <phrase>Shallow</phrase> <phrase>NLP</phrase> and <phrase>Information Extraction</phrase>.
<phrase>Visual</phrase> Interfaces for <phrase>Semantic</phrase> <phrase>Information Retrieval</phrase> and Browsing.
<phrase>Information Visualization</phrase> Versus the <phrase>Semantic Web</phrase>.
<phrase>Ontology</phrase>-based <phrase>Information Visualization</phrase>.
The <phrase>XML</phrase> <phrase>Revolution</phrase> and the <phrase>Semantic Web</phrase>.
<phrase>Concluding Remarks</phrase>: Today's Vision of Envisioning the <phrase>Semantic</phrase> Future.
<phrase>SVG</phrase> and <phrase>X3D</phrase>: New <phrase>XML</phrase> Technologies for 2D and 3D Visualization.
<phrase>Interactive Interfaces</phrase> for Mapping <phrase>E-commerce</phrase> <phrase>Ontologies</phrase>.
Using <phrase>Scalable Vector Graphics</phrase> and Georgraphical <phrase>Information</phrase> Systems in a <phrase>Back Pain</phrase> Study.
<phrase>Topic Maps</phrase> Visualization.
<phrase>Web</phrase> Rendering Systems: Techniques, <phrase>Classification Criteria</phrase> and Challenges.
<phrase>Recommender Systems</phrase> for the <phrase>Web</phrase>.
<phrase>Web Services</phrase>: Description, Interfaces and <phrase>Ontology</phrase>.
<phrase>Interactive Visualization</phrase> of <phrase>Paragraph</phrase>-level <phrase>Metadata</phrase> to Support <phrase>Corporate</phrase> Document Use.
Informatikbetrachtungen.
Was <phrase>ist</phrase> <phrase>Informatik</phrase>?
<phrase>Informatik und</phrase> <phrase>Wirtschaftsinformatik</phrase>.
<phrase>Informatik</phrase> - Allgemeinbildung <phrase>für die</phrase> <phrase>Informationsgesellschaft</phrase>.
Computerunterstütztes problemorientiertes <phrase>Lernen</phrase>.
Was lehren wir eigentlich, wenn wir <phrase>Informatik</phrase> lehren?
<phrase>Software-Entwicklung</phrase> <phrase>im</phrase> industriellen Maßstab.
<phrase>Wissen und</phrase> <phrase>Lernen</phrase>.
Sind <phrase>Informatiker</phrase> <phrase>auch</phrase> gute <phrase>Software</phrase>-Ingenieuere?
Softwaresystemtechnik - <phrase>eine</phrase> <phrase>Informatik</phrase>-Ingenieurdisziplin.
<phrase>Progress Toward</phrase> <phrase>Automating</phrase> The Development of <phrase>Database</phrase> System <phrase>Software</phrase>.
<phrase>Query Processing</phrase> in a <phrase>Multidatabase</phrase> System
Updating <phrase>Relational</phrase> Views.
<phrase>Common Subexpression</phrase> Isolation in <phrase>Multiple Query Optimization</phrase>
<phrase>Introduction</phrase> to <phrase>Query Processing</phrase>
Processing <phrase>Cyclic</phrase> Queries.
<phrase>Query Processing</phrase> Using the Concecutive Retrieval <phrase>Property</phrase>.
<phrase>Global Optimization</phrase> of <phrase>Relational</phrase> Queries: A First Step
<phrase>Query Processing</phrase> in <phrase>R</phrase>*
<phrase>Supporting</phrase> <phrase>Complex Objects</phrase> in a <phrase>Relational</phrase> System for <phrase>Engineering</phrase> <phrase>Databases</phrase>.
<phrase>Physical Database Design</phrase>: Techniques for Improved <phrase>Database</phrase> Performance.
A <phrase>Query Language</phrase> for <phrase>Statistical Databases</phrase>
<phrase>Querying</phrase> <phrase>Relational</phrase> Views of Networks
<phrase>Relational</phrase> <phrase>Query Processing</phrase> on the Non-Von <phrase>Supercomputer</phrase>.
The Intelligent <phrase>Database</phrase> Machine (<phrase>IDM</phrase>).
<phrase>Database</phrase> Access Requirements of <phrase>Knowledge-Based Systems</phrase>.
The <phrase>Property</phrase> of <phrase>Separability</phrase> And Its Application to <phrase>Physical Database Design</phrase>.
<phrase>Distributed Database</phrase> <phrase>Query Processing</phrase>.
Datenbanksprachen und Datenbankbenutzung.
<phrase>Realisierung von</phrase> operationalen Schnittstellen.
<phrase>Architektur</phrase> <phrase>von Datenbanksystemen</phrase>.
Datenbankentwurf.
<phrase>Maßnahmen</phrase> zur Wahrung von <phrase>Sicherheits- und</phrase> Integritäsbedingungen.
Datenmodelle.
<phrase>JADE</phrase> - A <phrase>Java Agent Development Framework</phrase>.
<phrase>Jason</phrase> and the <phrase>Golden Fleece</phrase> of <phrase>Agent-Oriented Programming</phrase>.
<phrase>Programming</phrase> <phrase>Multi-Agent Systems</phrase> in 3APL.
IMPACT: A <phrase>Multi-Agent</phrase> Framework with <phrase>Declarative Semantics</phrase>.
<phrase>Jadex</phrase>: A <phrase>BDI</phrase> <phrase>Reasoning Engine</phrase>.
ARTIMIS <phrase>Rational</phrase> <phrase>Dialogue Agent</phrase> <phrase>Technology</phrase>: <phrase>An Overview</phrase>.
The <phrase>DEFACTO</phrase> System: <phrase>Coordinating</phrase> <phrase>Human-Agent Teams</phrase> for the Future of <phrase>Disaster</phrase> Response.
CLAIM and SyMPA: A <phrase>Programming</phrase> Environment for Intelligent and <phrase>Mobile</phrase> Agents.
<phrase>JACK</phrase> <phrase>Intelligent Agents</phrase>: An <phrase>Industrial</phrase> Strength Platform.
Implementation-Aware <phrase>Embedded Control Systems</phrase>.
Network <phrase>Fundamentals</phrase>.
<phrase>Microcontrollers</phrase>.
<phrase>Bluetooth</phrase> in Control.
<phrase>Introduction</phrase> to <phrase>Hybrid</phrase> Systems.
<phrase>Real-Time</phrase> Scheduling for <phrase>Embedded Systems</phrase>.
From <phrase>Control Loops</phrase> to <phrase>Real-Time</phrase> Programs.
<phrase>Discrete-Event Systems</phrase>.
<phrase>Basics</phrase> of <phrase>Data Acquisition</phrase> and Control.
<phrase>Temporal Logic</phrase> <phrase>Model Checking</phrase>.
The <phrase>Cornell</phrase> <phrase>RoboCup</phrase> <phrase>Robot Soccer Team</phrase>: 1999-2003.
Control of <phrase>Autonomous Mobile Robots</phrase>.
SOPCs: Systems on <phrase>Programmable</phrase> Chips.
<phrase>Embedded Sensor Networks</phrase>.
<phrase>Feedback</phrase> Control with <phrase>Communication</phrase> Constraints.
Control of <phrase>Single-Input Single-Output</phrase> Systems.
<phrase>Vehicle</phrase> Applications of <phrase>Controller Area Network</phrase>.
<phrase>Finite Automata</phrase>.
<phrase>Digital Signal Processors</phrase>.
<phrase>Fundamentals</phrase> of <phrase>Dynamical Systems</phrase>.
<phrase>Fundamentals</phrase> of <phrase>RTOS</phrase>-Based <phrase>Digital Controller</phrase> Implementation.
<phrase>Network Protocols</phrase> for <phrase>Networked Control Systems</phrase>.
<phrase>Switched</phrase> Systems.
<phrase>LabVIEW</phrase> <phrase>Real-Time</phrase> for <phrase>Networked/Embedded</phrase> Control.
<phrase>An Overview</phrase> of <phrase>Hybrid</phrase> Systems Control.
<phrase>Control Issues</phrase> in Systems with Loop Delays.
<phrase>Networked Control Systems</phrase>: <phrase>A Model-Based Approach</phrase>.
Embedded <phrase>Real-Time</phrase> Control via <phrase>MATLAB</phrase>, <phrase>Simulink</phrase>, and xPC <phrase>Target</phrase>.
<phrase>Programmable Logic Controllers</phrase>.
<phrase>An Introduction</phrase> to <phrase>Hybrid</phrase> <phrase>Automata</phrase>.
<phrase>Basics</phrase> of <phrase>Sampling</phrase> and Quantization.
<phrase>Basics</phrase> of <phrase>Computer Architecture</phrase>.
Control Using <phrase>Feedback</phrase> over <phrase>Wireless</phrase> <phrase>Ethernet</phrase> and <phrase>Bluetooth</phrase>.
<phrase>Wireless</phrase> Control with <phrase>Bluetooth</phrase>.
<phrase>Control Loops</phrase> in RTLinux.
<phrase>Abduction</phrase> and <phrase>Analogy</phrase> in <phrase>Chance Discovery</phrase>.
The PreparedMind: the Role of Representational Change in <phrase>Chance Discovery</phrase>.
Application to <phrase>Understanding</phrase> Consumers <phrase>Latent</phrase> Desires.
<phrase>Discovering</phrase> <phrase>Deep</phrase> <phrase>Building</phrase> Blocks for <phrase>Competent Genetic Algorithms</phrase> Using <phrase>Chance Discovery</phrase> via KeyGraphs.
<phrase>Anatomy</phrase> of <phrase>Rare Events</phrase> in a Complex <phrase>Adaptive</phrase> System.
<phrase>Self-organizing</phrase> <phrase>Complex Systems</phrase>.
Topic <phrase>Diffusion</phrase> in a <phrase>Community</phrase>.
<phrase>Chance</phrase> Discoveries from the <phrase>WWW</phrase>.
Prediction, <phrase>Forecasting</phrase>, and <phrase>Chance Discovery</phrase>.
<phrase>Dimensional Representations</phrase> of <phrase>Knowledge</phrase> in an <phrase>Online Community</phrase>.
<phrase>Agent Communications</phrase> for <phrase>Chance Discovery</phrase>.
<phrase>Chance Discovery</phrase> for Consumers.
Application to <phrase>Questionnaire Analysis</phrase>.
Modeling the Process of <phrase>Chance Discovery</phrase>.
KeyGraph: Visualized Structure Among Event Clusters.
Detection of <phrase>Earthquake</phrase> Risks with KeyGraph.
Logics of <phrase>Argumentation</phrase> for <phrase>Chance Discovery</phrase>.
The Storification of <phrase>Chances</phrase>.
<phrase>Human</phrase>-to-<phrase>Human</phrase> <phrase>Communication</phrase> for <phrase>Chance Discovery</phrase> in <phrase>Business</phrase>.
<phrase>Enhancing</phrase> <phrase>Daily</phrase> Conversations.
<phrase>Active</phrase> <phrase>Mining</phrase> with <phrase>Visual</phrase> <phrase>Human</phrase> Interface.
Awareness and <phrase>Imagination</phrase> of <phrase>Hidden</phrase> Factors and <phrase>Rare Events</phrase>.
Effects of <phrase>Scenic</phrase> <phrase>Information</phrase>.
Decisions by <phrase>Chance</phrase> and on <phrase>Chance</phrase>: Meanings of <phrase>Chance</phrase> in Recent <phrase>News Stories</phrase>.
Agent <phrase>Naming</phrase> and <phrase>Coordination</phrase>: <phrase>Actor Based</phrase> Models and Infrastructures.
<phrase>Middleware</phrase> Technologies: <phrase>CORBA</phrase> and <phrase>Mobile</phrase> Agents.
A <phrase>Market-Based</phrase> <phrase>Model</phrase> for <phrase>Resource Allocation</phrase> in <phrase>Agent Systems</phrase>.
<phrase>Coordination</phrase> and <phrase>Security</phrase> on the <phrase>Internet</phrase>.
<phrase>Coordination</phrase> Models: <phrase>A Guided Tour</phrase>.
<phrase>Coordinating</phrase> Agents using <phrase>Agent Communication Languages</phrase> Conversations.
Reusable Patterns for <phrase>Agent Coordination</phrase>.
<phrase>Inter-Organizational Workflows</phrase> for Enterprise <phrase>Coordination</phrase>.
<phrase>Coordination</phrase> and Control in Computational <phrase>Ecosystems</phrase>: A Vision of the Future.
<phrase>High</phrase>-Level Enabling <phrase>Coordination</phrase> Technologies, <phrase>Introduction</phrase>.
<phrase>Brokering</phrase> and <phrase>Matchmaking</phrase> for <phrase>Coordination</phrase> of <phrase>Agent Societies</phrase>: <phrase>A Survey</phrase>.
<phrase>Scalability</phrase> in <phrase>Linda</phrase>-like <phrase>Coordination</phrase> Systems.
Constraints Solving as the <phrase>Coordination</phrase> of <phrase>Inference Engines</phrase>.
<phrase>Coordination</phrase> Models and Languages: <phrase>State</phrase> of the <phrase>Art</phrase>, <phrase>Introduction</phrase>.
<phrase>Basic</phrase> <phrase>Enabling Technologies</phrase>, <phrase>Introduction</phrase>.
<phrase>Preface</phrase>: <phrase>Coordination</phrase> of <phrase>Internet</phrase> Agents.
Models and Technologies for the <phrase>Coordination</phrase> of <phrase>Internet</phrase> Agents: <phrase>A Survey</phrase>.
<phrase>Coordination</phrase> and Mobility.
<phrase>Tuple</phrase>-based Technologies for <phrase>Coordination</phrase>.
<phrase>Run-Time</phrase> Systems for <phrase>Coordination</phrase>.
<phrase>Agent Coordination</phrase> via <phrase>Scripting</phrase> Languages.
<phrase>Foreword</phrase>: <phrase>Coordination</phrase> and the <phrase>Internet</phrase>.
Applications of <phrase>Coordination</phrase> <phrase>Technology</phrase>, <phrase>Introduction</phrase>.
<phrase>Emerging Issues</phrase> of <phrase>Coordination</phrase>, <phrase>Introduction</phrase>.
<phrase>Visions</phrase>, <phrase>Introduction</phrase>.
<phrase>Agent-Oriented Software Engineering</phrase> for <phrase>Internet</phrase> Applications.
<phrase>Grid Computing</phrase>-<phrase>Ansätze</phrase> für <phrase>verteiltes</phrase> <phrase>virtuelles</phrase> <phrase>Prototyping</phrase>.
<phrase>Bedeutung von</phrase> <phrase>Peer-to-Peer</phrase> <phrase>Technologien</phrase> <phrase>für die</phrase> Distribution von Medienprodukten <phrase>im</phrase> <phrase>Internet</phrase>.
<phrase>Peer-to-Peer</phrase>-<phrase>Computing</phrase> - Wettbewerbsvorteil für <phrase>Intel</phrase>.
Sicherheitsaspekte von <phrase>P2P</phrase> <phrase>Anwendungen</phrase> in <phrase>Unternehmen</phrase>.
Vertrauen und <phrase>Reputation</phrase> in <phrase>P2P</phrase>-<phrase>Netzwerken</phrase>.
<phrase>Die</phrase> Anatomie <phrase>des</phrase> <phrase>Grid</phrase>.
<phrase>Project</phrase> <phrase>JXTA</phrase>.
<phrase>Napster</phrase> in der Videobranche?
Urheberrecht und <phrase>Peer-to-Peer</phrase>-<phrase>Dienste</phrase>.
<phrase>Instant Messaging</phrase> - Nutzenpotentiale <phrase>und Herausforderungen</phrase>.
<phrase>Gnutella</phrase>.
Moneybee - <phrase>Vernetzung</phrase> <phrase>künstlicher Intelligenz</phrase>.
<phrase>Peer-to-Peer</phrase> Anwendungsbereiche <phrase>und Herausforderungen</phrase>.
ZetaGrid.
<phrase>Web Services</phrase> und <phrase>Peer-to-Peer</phrase>-<phrase>Netzwerke</phrase>.
Rule Analysis
<phrase>Architecture</phrase> of <phrase>Active</phrase> <phrase>Database Systems</phrase>
<phrase>ECA</phrase> Functionality in a <phrase>Distributed Environment</phrase>.
<phrase>NAOS</phrase>.
<phrase>Tool Support</phrase>.
<phrase>EXACT</phrase>: An Approach to <phrase>Coping</phrase> with Heterogeneous <phrase>Rule Execution</phrase> Models.
<phrase>RAP</phrase>: The <phrase>ROCK</phrase> & <phrase>ROLL</phrase> <phrase>Active</phrase> <phrase>Programming</phrase> System.
<phrase>Active</phrase> <phrase>Database Systems</phrase>: Expectations, Commercial Experience, and Beyond.
<phrase>Database</phrase> Internal Applications.
<phrase>Comparing</phrase> <phrase>Deductive</phrase> and <phrase>Active Databases</phrase>.
<phrase>Chimera</phrase>: A <phrase>Language</phrase> for <phrase>Designing</phrase> Rule Applications.
<phrase>SAMOS</phrase>.
<phrase>Performance Assessment</phrase>.
Ariel.
<phrase>Active</phrase> <phrase>Real-Time Database Systems</phrase>.
<phrase>Active</phrase> <phrase>Database</phrase> Features in SQL3.
<phrase>Summary</phrase>.
Optimization
<phrase>Introduction</phrase>
<phrase>PFL</phrase>: An <phrase>Active</phrase> <phrase>Functional</phrase> DBPL.
Monitoring Complex <phrase>Rule Conditions</phrase>
REACH.
<phrase>Ontologies</phrase> for <phrase>Knowledge Management</phrase>.
<phrase>Ontologies</phrase> in <phrase>F</phrase>-<phrase>logic</phrase>.
<phrase>Web Ontology Language</phrase>: <phrase>OWL</phrase>.
<phrase>Description Logics</phrase>.
<phrase>Ontologies</phrase> and <phrase>Metadata</phrase> for eLearning.
<phrase>Ontologies</phrase> and <phrase>Hypertext</phrase>.
<phrase>Knowledge</phrase> Patterns.
<phrase>Ontologies</phrase> in Support of <phrase>Problem Solving</phrase>.
The Role of <phrase>Ontologies</phrase> in <phrase>eCommerce</phrase>.
<phrase>Ontology</phrase> Matching: <phrase>A Machine Learning Approach</phrase>.
<phrase>Semantic</phrase> <phrase>Layering</phrase> with <phrase>Magpie</phrase>.
<phrase>Retrieving</phrase> and <phrase>Exploring</phrase> <phrase>Ontology</phrase>-based <phrase>Information</phrase>.
<phrase>Supporting User</phrase> Tasks through <phrase>Visualisation</phrase> of <phrase>Light</phrase>-weight <phrase>Ontologies</phrase>.
<phrase>Ontology</phrase> Evaluation.
<phrase>Ontology</phrase> of the <phrase>Process Specification Language</phrase>.
<phrase>An Overview</phrase> of OntoClean.
<phrase>Building</phrase> a <phrase>Very Large</phrase> <phrase>Ontology</phrase> from <phrase>Medical</phrase> <phrase>Thesauri</phrase>.
<phrase>Ontology</phrase> <phrase>Reconciliation</phrase>.
<phrase>Ontology</phrase> and the <phrase>Lexicon</phrase>.
<phrase>Ontology</phrase> <phrase>Learning</phrase>.
The <phrase>Resource Description Framework</phrase> (<phrase>RDF</phrase>) and its <phrase>Vocabulary</phrase> <phrase>Description Language</phrase> <phrase>RDFS</phrase>.
<phrase>Ontology</phrase>-<phrase>based Recommender Systems</phrase>.
<phrase>Ontology</phrase>-based <phrase>Content Management</phrase> in a <phrase>Virtual</phrase> <phrase>Organization</phrase>.
<phrase>An Ontology-based</phrase> Platform for <phrase>Semantic</phrase> <phrase>Interoperability</phrase>.
An <phrase>Ontology</phrase>-<phrase>Composition Algebra</phrase>.
<phrase>Ontology Engineering</phrase> Environments.
Tools for Mapping and <phrase>Merging</phrase> <phrase>Ontologies</phrase>.
The <phrase>Knowledge Portal</phrase> "OntoWeb".
<phrase>An Extensible</phrase> <phrase>Ontology</phrase> <phrase>Software</phrase> Environment.
<phrase>Ontologies</phrase> in <phrase>Bioinformatics</phrase>.
On-To-<phrase>Knowledge</phrase> Methodology (OTKM).
<phrase>Ontologies</phrase> in <phrase>Agent Architectures</phrase>.
<phrase>Ink</phrase> as a <phrase>First-Class</phrase> <phrase>Datatype</phrase> in <phrase>Multimedia</phrase> <phrase>Databases</phrase>.
A <phrase>Data Access</phrase> Structure for Filtering <phrase>Distance Queries</phrase> in <phrase>Image Retrieval</phrase>.
<phrase>Multimedia</phrase> Athoring Systems.
<phrase>Stream-based</phrase> Versus Structured <phrase>Video</phrase> Objects: Issues, Solutions, and Challenges.
<phrase>A Unified</phrase> Approach to <phrase>Data Modeling</phrase> and Retrieval for a Class of <phrase>Image Database</phrase> Applications.
<phrase>Indexing</phrase> for Retrieval by Similarity.
<phrase>Metadata</phrase> for <phrase>Building</phrase> the <phrase>MultiMedia</phrase> Patch <phrase>Quilt</phrase>.
<phrase>Querying</phrase> <phrase>Multimedia</phrase> <phrase>Databases</phrase> in <phrase>SQL</phrase>.
Towards a Theory of <phrase>Multimedia</phrase> <phrase>Database Systems</phrase>.
The Storage and Retrieval of <phrase>Continuous Media Data</phrase>.
Retrieval of Pictures Using <phrase>Approximate</phrase> Matching.
<phrase>Design</phrase> and Implementation of QBISM, a 3D <phrase>Medical</phrase> <phrase>Image Database</phrase> System.
<phrase>Dataflow</phrase> and <phrase>Education</phrase>: <phrase>Data</phrase>-driven and <phrase>Demand-driven</phrase> <phrase>Distributed Computation</phrase>.
<phrase>Contrasting</phrase> Themes in the <phrase>Semantics</phrase> of Imperative <phrase>Concurrency</phrase>.
<phrase>Functional Programming</phrase> and the <phrase>Language</phrase> <phrase>TALE</phrase>.
<phrase>Design</phrase>, Specification and Validation of <phrase>Hierarchies</phrase> of Protocols in <phrase>Distributed Systems</phrase>.
<phrase>Infinitary</phrase> Languages: <phrase>Basic</phrase> Theory an Applications to <phrase>Concurrent Systems</phrase>.
The <phrase>Quest</phrase> Goes on: <phrase>A Survey</phrase> of Proofsystems for <phrase>Partial</phrase> Correctness of <phrase>CSP</phrase>.
<phrase>Logic Programming</phrase>: The Foundations, the Approach and the Role of <phrase>Concurrency</phrase>.
Process Theory: <phrase>Semantics</phrase>, Specification and Verification.
Applications of <phrase>Temporal Logic</phrase> to the Specification and Verification of <phrase>Reactive Systems</phrase>: <phrase>A Survey</phrase> of <phrase>Current Trends</phrase>.
<phrase>Petri Nets</phrase>: <phrase>Basic</phrase> Notions, Structure, Behaviour.
Concepts for <phrase>Concurrent Programming</phrase>.
Survey of Biodata Analysis from <phrase>a Data Mining Perspective</phrase>.
<phrase>Mining</phrase> <phrase>Chemical Compounds</phrase>.
<phrase>Data Mining</phrase> Methods for a <phrase>Systematics</phrase> of <phrase>Protein Subcellular Location</phrase>.
Phyloinformatics: <phrase>Toward</phrase> a <phrase>Phylogenetic</phrase> <phrase>Database</phrase>.
<phrase>Declarative</phrase> and <phrase>Efficient Querying</phrase> on <phrase>Protein</phrase> <phrase>Secondary</phrase> Structures.
AntiClustAl: <phrase>Multiple Sequence Alignment</phrase> by Antipole <phrase>Clustering</phrase>.
<phrase>Piecewise</phrase> Constant Modeling of <phrase>Sequential Data</phrase> Using <phrase>Reversible Jump Markov Chain Monte Carlo</phrase>.
<phrase>Gene Mapping</phrase> by <phrase>Pattern Discovery</phrase>.
Scalable <phrase>Index</phrase> Structures for <phrase>Biological Data</phrase>.
<phrase>Introduction</phrase> to <phrase>Data Mining</phrase> in <phrase>Bioinformatics</phrase>.
<phrase>Predicting</phrase> <phrase>Protein Folding</phrase> Pathways.
<phrase>Summary</phrase>: A structured <phrase>folding</phrase> pathway, which is a time <phrase>ordered</phrase> <phrase>sequence</phrase> of <phrase>folding</phrase> events, plays an <phrase>important role</phrase> in the <phrase>protein folding</phrase> process and <phrase>hence</phrase>, in the <phrase>conformational</phrase> search. <phrase>Pathway prediction</phrase>, thus gives more insight into the <phrase>folding</phrase> process and is a valuable guiding tool to search the <phrase>conformation</phrase> space. In this <phrase>paper</phrase>, we propose a novel '<phrase>unfolding</phrase>' approach to predict the <phrase>folding</phrase> pathway. We apply <phrase>graph-based</phrase> methods on a <phrase>weighted</phrase> <phrase>secondary</phrase> structure <phrase>graph</phrase> of a <phrase>protein</phrase> to predict the <phrase>sequence</phrase> of <phrase>unfolding</phrase> events. When viewed in <phrase>reverse</phrase> this yields the <phrase>folding</phrase> pathway. We demonstrate the success of our approach on several <phrase>proteins</phrase> whose pathway is <phrase>partially known</phrase>.
<phrase>RNA Structure</phrase> Comparison and Alignment.
<phrase>Active</phrase> <phrase>XML</phrase>: A <phrase>Data</phrase>-<phrase>Centric Perspective</phrase> on <phrase>Web Services</phrase>.
<phrase>Web</phrase> Dynamics, Structure, and <phrase>Page Quality</phrase>.
An <phrase>Event-Condition-Action</phrase> <phrase>Language</phrase> for <phrase>XML</phrase>.
<phrase>Search Engine</phrase> Ability to <phrase>Cope</phrase> With the Changing <phrase>Web</phrase>.
<phrase>Active</phrase> <phrase>XQuery</phrase>.
<phrase>Adaptive</phrase> <phrase>Web-Based Educational</phrase> <phrase>Hypermedia</phrase>.
<phrase>DREAM</phrase>: Distributed <phrase>Reliable</phrase> <phrase>Event-Based</phrase> <phrase>Application Management</phrase>.
<phrase>A Survey</phrase> of Architectures for <phrase>Adaptive</phrase> <phrase>Hypermedia</phrase>.
<phrase>Learning</phrase> <phrase>Web</phrase> <phrase>Request Patterns</phrase>.
How Large Is the WorldWide <phrase>Web</phrase>?
Methods for MiningWeb Communities: <phrase>Bibliometric</phrase>, Spectral, and Flow.
WebVigiL: An Approach to <phrase>Just-In-Time</phrase> <phrase>Information</phrase> Propagation in Large <phrase>Network-Centric</phrase> Environments.
<phrase>Web</phrase> Dynamics - Setting the Scene.
<phrase>Navigating</phrase> <phrase>the World Wide Web</phrase>.
Theory of <phrase>Random</phrase> Networks and Their Role in <phrase>Communications Networks</phrase>.
<phrase>Crawling</phrase> the <phrase>Web</phrase>.
<phrase>Combining</phrase> Link and Content <phrase>Information</phrase> in <phrase>Web Search</phrase>.
<phrase>MP</phrase> - <phrase>Mobile</phrase> <phrase>Portals</phrase>, Profiles and <phrase>Personalization</phrase>.
<phrase>Evolution</phrase> of <phrase>Web</phrase> Structure and Content - <phrase>Introduction</phrase>.
Searching and <phrase>Navigating</phrase> the <phrase>Web</phrase> - <phrase>Introduction</phrase>.
Events and Change on the <phrase>Web</phrase> - <phrase>Introduction</phrase>.
<phrase>Personalized</phrase> Access to the <phrase>Web</phrase> - <phrase>Introduction</phrase>.
<phrase>Behavioural</phrase> <phrase>Virtual</phrase> Agents.
We discuss the application of <phrase>behavioural</phrase> architectures, in the <phrase>robotic</phrase> sense, to <phrase>virtual</phrase> agents. '<phrase>Virtual</phrase> <phrase>Teletubbies</phrase>' are used as an example of the <phrase>issues involved</phrase>. we conclude that the use of such architectures has implications for the whole style in which a <phrase>virtual world</phrase> is modelled.
<phrase>Logic</phrase>-Based <phrase>Knowledge Representation</phrase>.
After a <phrase>short</phrase> analysis of the requirements that a <phrase>knowledge representation</phrase> <phrase>language</phrase> must satisfy, we introduce <phrase>Description Logics</phrase>, <phrase>Modal Logics</phrase>, and <phrase>Nonmonotonic Logics</phrase> as formalisms for representing <phrase>terminological knowledge</phrase>, <phrase>time-dependent</phrase> or <phrase>subjective knowledge</phrase>, and <phrase>incomplete knowledge</phrase> respectively. At the end of each section, we briefly <phrase>comment</phrase> on the connection to <phrase>Logic Programming</phrase>.
<phrase>An Overview</phrase> of <phrase>Planning</phrase> Under <phrase>Certainty</phrase>.
A <phrase>Taxonomy</phrase> of <phrase>Theorem-Proving</phrase> Strategies.
This <phrase>article presents</phrase> a <phrase>taxonomy</phrase> of strategies for <phrase>fully-automated</phrase> <phrase>general</phrase>-purpose <phrase>first-order theorem proving</phrase>. It covers <phrase>forward</phrase>-reasoning ordering-based strategies and <phrase>backward</phrase>-reasoning <phrase>subgoal</phrase>-<phrase>reduction strategies</phrase>, which do not appear together often. <phrase>Unlike</phrase> traditional presentations that emphasize <phrase>logical</phrase> inferences, this classification strives to give <phrase>equal weight</phrase> to the inference and search components of <phrase>theorem proving</phrase>, which are <phrase>equally important</phrase> in practice. For this purpose, a formal notion of search plan is given and shown to apply to all classes of strategies. For each class, the form of <phrase>derivation</phrase> is specified, and it is shown how inference system and search plan cooperate to generate it.
<phrase>Knowledge Representation</phrase> for <phrase>Stochastic</phrase> <phrase>Decision Process</phrase>.
<phrase>Reasoning about</phrase> <phrase>stochastic</phrase> <phrase>dynamical systems</phrase> and <phrase>planning under uncertainty</phrase> has come to <phrase>play</phrase> a fundamental role in <phrase>AI</phrase> <phrase>research</phrase> and applications. The representation of such systems, in particular, of actions with <phrase>stochastic</phrase> effects, has accordingly been given <phrase>increasing attention</phrase> in <phrase>recent years</phrase>. In this article, we survey a number of techniques for representing <phrase>stochastic processes</phrase> and actions with <phrase>stochastic</phrase> effects using <phrase>dynamic</phrase> <phrase>Bayesian</phrase> networks and <phrase>influence diagrams</phrase>, and briefly describe how these support effective inference for tasks such as monitoring, <phrase>forecasting</phrase>, <phrase>explanation</phrase> and <phrase>decision making</phrase>. We also compare these techniques to several <phrase>action</phrase> representations adopted in the <phrase>classical</phrase> <phrase>reasoning about</phrase> <phrase>action</phrase> and <phrase>planning</phrase> communities, describing how traditional problems such as the frame and <phrase>ramification</phrase> problems are dealt with in <phrase>stochastic</phrase> settings, and how these solutions compare to <phrase>recent approaches</phrase> to this problem in the <phrase>classical</phrase> (<phrase>deterministic</phrase>) <phrase>literature</phrase>. We argue that while <phrase>stochastic</phrase> dynamics introduce certain complications when it comes to such issues, for the most part, intuitions underlying <phrase>classical</phrase> models can be extended to the <phrase>stochastic</phrase> setting.
<phrase>A Survey</phrase> of <phrase>Automated Deduction</phrase>.
We <phrase>survey research</phrase> in the <phrase>automation</phrase> of <phrase>deductive</phrase> inference, from its beginnings in the <phrase>early history</phrase> of <phrase>computing</phrase> to the present day. We identify and describe the <phrase>major</phrase> areas of <phrase>research</phrase> interest and their applications. The <phrase>area</phrase> is characterised by its wide <phrase>variety</phrase> of <phrase>proof methods</phrase>, forms of <phrase>automated deduction</phrase> and applications.
<phrase>The World Wide Web</phrase> as a Place for Agents.
The Word <phrase>Wide Web</phrase> was born as an <phrase>Internet service</phrase> <phrase>supporting</phrase> a simple distributed <phrase>hypertext</phrase> <phrase>management</phrase> system. Since its start a number of technologies have been proposed to enhance its capabilities. In this <phrase>paper</phrase> we describe our concept of an <phrase>active</phrase> <phrase>Web</phrase>, namely how we <phrase>design</phrase> the <phrase>software architecture</phrase> of interactive <phrase>cooperative</phrase> applications based on the Word <phrase>Wide web</phrase>. An <phrase>active</phrase> <phrase>Web</phrase> includes agents able to use the <phrase>services offered</phrase> by Word <phrase>Wide web</phrase> <phrase>clients and servers</phrase>. In an <phrase>active</phrase> <phrase>Web</phrase> both users and agents can interoperate using a set of <phrase>basic</phrase> mechanisms for <phrase>communication</phrase> and synchronization. The <phrase>active</phrase> <phrase>Web</phrase> we describe here is based on <phrase>coordination</phrase> <phrase>technology</phrase>: we explore two <phrase>alternative</phrase> implementations, both based on <phrase>Java</phrase> <phrase>enriched</phrase> with <phrase>alternative</phrase> <phrase>coordination</phrase> kernels.
<phrase>Lifelike</phrase> <phrase>Pedagogical</phrase> Agents and <phrase>Affective Computing</phrase>: <phrase>An Exploratory</phrase> <phrase>Synthesis</phrase>.
<phrase>OBDD</phrase>-based <phrase>Universal</phrase> <phrase>Planning</phrase>: Specifying and <phrase>Solving Planning Problems</phrase> for Synchronized Agents in <phrase>Non-deterministic</phrase> Domains.
<phrase>Recently</phrase> <phrase>model</phrase> checking representation and <phrase>search techniques</phrase> were shown to be efficiently applicable to <phrase>planning</phrase>, in particular to <phrase>non-deterministic</phrase> <phrase>planning</phrase>. Such <phrase>planning</phrase> approaches use <phrase>Ordered Binary Decision Diagrams</phrase> (OBDDS) to encode a <phrase>planning</phrase> domain as a <phrase>non-deterministic</phrase> <phrase>finite automaton</phrase> (<phrase>NFA</phrase>) and then apply <phrase>fast</phrase> <phrase>algorithms</phrase> from <phrase>model checking</phrase> to search for a <phrase>solution</phrase>. OBDDS can effectively scale and can provide <phrase>universal</phrase> plans for complex <phrase>planning</phrase> domains. We are particularly interested in addressing the complexities arising in <phrase>non-deterministic</phrase>, <phrase>multi-agent</phrase> domains. In this <phrase>chapter</phrase>, we present UMOP,1 a new <phrase>universal</phrase> <phrase>OBDD-based</phrase> <phrase>planning</phrase> framework for <phrase>non-deterministic</phrase>, <phrase>multi-agent</phrase> domains, which is also applicable to <phrase>deterministic</phrase> singleagent domains as a <phrase>special case</phrase>. We introduce a new <phrase>planning domain</phrase> <phrase>description language</phrase>, NADL,2 to specify <phrase>non-deterministic</phrase> <phrase>multi-agent</phrase> domains. The <phrase>language</phrase> contributes the explicit definition of <phrase>controllable</phrase> agents and uncontrollable environment agents. We describe the <phrase>syntax</phrase> and <phrase>semantics</phrase> of NADL and show how to build <phrase>an efficient</phrase> <phrase>OBDD-based</phrase> representation of an NADL description. The UMOP <phrase>planning</phrase> system uses NADL and different <phrase>OBDD</phrase>-based <phrase>universal</phrase> <phrase>planning</phrase> <phrase>algorithms</phrase>. It includes the <phrase>previously developed</phrase> strong and <phrase>strong cyclic planning</phrase> <phrase>algorithms</phrase> [9,10]. In addition, we introduce our new <phrase>optimistic</phrase> <phrase>planning</phrase> <phrase>algorithm</phrase>, which relaxes <phrase>optimality guarantees</phrase> and generates plausible <phrase>universal</phrase> plans in some domains where no strong or <phrase>strong cyclic</phrase> <phrase>solution</phrase> exist. We present <phrase>empirical results</phrase> from domains ranging from <phrase>deterministic</phrase> and <phrase>single</phrase>-agent with no environment actions to <phrase>nondeterministic</phrase> and <phrase>multi-agent</phrase> with <phrase>complex environment</phrase> actions. UMOP is shown to be a rich and <phrase>efficient</phrase> <phrase>planning</phrase> system.
Combibining <phrase>Artificial Intelligence</phrase> and <phrase>Databases</phrase> for <phrase>Data Integration</phrase>.
<phrase>Data integration</phrase> is a problem at the <phrase>intersection</phrase> of the fields of <phrase>Artificial Intelligence</phrase> and <phrase>Database Systems</phrase>. The goal of a <phrase>data integration</phrase> system is to provide a <phrase>uniform</phrase> interfacc to a multitude of <phrase>data</phrase> sources, whether they are within one enterprise or on <phrase>the World-Wide Web</phrase>. The <phrase>key challenges</phrase> in <phrase>data integration</phrase> arise because the <phrase>data</phrase> sources being integrated have been designed independently for <phrase>autonomous</phrase> applications, and their contents are related in <phrase>subtle ways</phrase>. As a result, a <phrase>data integration</phrase> system requires rich formalisms for describing contents of <phrase>data</phrase> sources and relating between contents of different sources. This <phrase>paper</phrase> discusses works aimed at <phrase>applying</phrase> techniques from <phrase>Artificial Intelligence</phrase> to the problem of <phrase>data integration</phrase>. In addition to employing <phrase>Knowledge Representation</phrase> techniques for describing contents of <phrase>information</phrase> sources, projects have also made use of <phrase>Machine Learning</phrase> techniques for <phrase>extracting</phrase> <phrase>data</phrase> from sources and <phrase>planning</phrase> techniques for <phrase>query optimization</phrase>. The <phrase>paper</phrase> also outlines future opportunities for <phrase>applying</phrase> <phrase>AI</phrase> techniques in the context of <phrase>data integration</phrase>.
<phrase>``</phrase><phrase>Underwater</phrase> <phrase>Love</phrase>'': <phrase>Building</phrase> Tristão and Isolda`<phrase>s</phrase> Personalities.
An <phrase>Oz</phrase>-Centric Review of <phrase>Interactive Drama</phrase> and <phrase>Believable Agents</phrase>.
<phrase>Believable agents</phrase> are <phrase>autonomous agents</phrase> that exhibit rich personalities. <phrase>Interactive dramas</phrase> <phrase>take place</phrase> in <phrase>virtual worlds</phrase> <phrase>inhabited</phrase> by <phrase>believable agents</phrase> with whom an audience interacts. In the course of this interaction, the audience experiences a <phrase>story</phrase>. This <phrase>paper</phrase> presents the <phrase>research</phrase> <phrase>philosophy</phrase> behind the <phrase>Oz</phrase> <phrase>Project</phrase>, a <phrase>research group</phrase> at <phrase>CMU</phrase> that has spent the <phrase>last</phrase> <phrase>ten years</phrase> studying <phrase>believable agents</phrase> and <phrase>interactive drama</phrase>. The <phrase>paper</phrase> then surveys current work from an <phrase>Oz</phrase> <phrase>perspective</phrase>.
<phrase>Robots</phrase> with the Best of Intentions.
<phrase>Intelligent mobile robots</phrase> need the ability to integrate <phrase>robust</phrase> <phrase>navigation</phrase> facilities with <phrase>higher level</phrase> reasoning. This <phrase>paper</phrase> is an attempt at <phrase>combining</phrase> <phrase>results</phrase> and techniques from the areas of <phrase>robot</phrase> <phrase>navigation</phrase> and of intelligent <phrase>agency</phrase>. We propose to integrate an existing <phrase>navigation</phrase> system based on <phrase>fuzzy logic</phrase> with a deliberator based on the so-called <phrase>BDI model</phrase>. We discuss some of the subtleties involved in this <phrase>integration</phrase>, and illustrate it on a simulated example. Experiments on a real <phrase>mobile robot</phrase> are under way.
<phrase>Agent-Based</phrase> <phrase>Project Management</phrase>.
<phrase>Integrated project</phrase> <phrase>management</phrase> means that <phrase>design</phrase> and <phrase>construction</phrase> <phrase>planning</phrase> are <phrase>interleaved</phrase> with <phrase>plan execution</phrase>, allowing both the <phrase>design</phrase> and plan to be changed as necessary. This requires that the right effects of change need to be propagated through the plan and <phrase>design</phrase>. When this is distributed among designers and planners, no one may have all of the <phrase>information</phrase> to perform such propagation and it is important to identify what effects should be propagated to whom, and when. We describe a set of dependencies among plan and <phrase>design</phrase> elements that allow such notification by a set of <phrase>message-passing</phrase> <phrase>software</phrase> agents. The result is to provide a novel level of computer support for <phrase>complex projects</phrase>.
A System for <phrase>Defeasible Argumentation</phrase>, with <phrase>Defeasible</phrase> Priorities.
Inspired by <phrase>legal</phrase> reasoning, this <phrase>paper</phrase> presents an <phrase>argument-based</phrase> system for <phrase>defeasible reasoning</phrase>, with a <phrase>logic-programming</phrase>-like <phrase>language</phrase>, and based on <phrase>Dung's argumentation</phrase>-<phrase>theoretic approach</phrase> to the <phrase>semantics</phrase> of <phrase>logic programming</phrase>. The <phrase>language</phrase> of the system has both <phrase>weak</phrase> and <phrase>explicit negation</phrase>, and conflicts between arguments are decided with the help of priorities on the rules. These priorities are not fixed, but are themselves defeasibly derived as conclusions within the system.
<phrase>Handling Uncertainty</phrase> in Control of <phrase>Autonomous Robots</phrase>.
<phrase>Autonomous robots</phrase> need the ability to move purposefully and without <phrase>human</phrase> intervention in <phrase>real-world</phrase> environments that have not been <phrase>specifically</phrase> engineered for them. These environments are characterized by the <phrase>pervasive</phrase> presence of uncertainty: the need to <phrase>cope</phrase> with this uncertainty constitutes a <phrase>major</phrase> <phrase>challenge</phrase> for <phrase>autonomous robots</phrase>. In this <phrase>note</phrase>, we discuss this <phrase>challenge</phrase>, and present some specific solutions based on our experience on the use of <phrase>fuzzy logic</phrase> in <phrase>mobile</phrase> <phrase>robots</phrase>. We focus on three issues: how to realize <phrase>robust</phrase> <phrase>motion control</phrase>; how to flexibly execute <phrase>navigation</phrase> plans; and how to approximately estimate the <phrase>robot's</phrase> location.
The <phrase>Event Calculus</phrase> Explained.
This <phrase>article presents</phrase> the <phrase>event calculus</phrase>, a <phrase>logic</phrase>-based formalism for representing actions and their effects. A <phrase>circumscriptive</phrase> <phrase>solution</phrase> to the <phrase>frame problem</phrase> is deployed which reduces to <phrase>monotonic</phrase> predicate completion. Using a number of <phrase>benchmark examples</phrase> from the <phrase>literature</phrase>, the formalism is shown to apply to a <phrase>variety</phrase> of domains, including those featuring actions with <phrase>indirect</phrase> effects, actions with <phrase>nondeterministic</phrase> effects, <phrase>concurrent</phrase> actions, and <phrase>continuous</phrase> change.
Towards a <phrase>Logic Programming</phrase> <phrase>Infrastructure</phrase> for <phrase>Internet</phrase> <phrase>Programming</phrase>.
After <phrase>reviewing</phrase> a number of <phrase>Internet</phrase> tools and technologies originating in the field of <phrase>logic programming</phrase> and discussing promissing directions of <phrase>ongoing research</phrase>, we describe a <phrase>logic programming</phrase> based <phrase>networking infrastructure</phrase> which combines reasoning and <phrase>knowledge</phrase> processing with flexible <phrase>coordination</phrase> of <phrase>dynamic</phrase> <phrase>state</phrase> changes and computation mobility, as well as and its use for the <phrase>design</phrase> of <phrase>intelligent mobile agent</phrase> programs. A <phrase>lightweight</phrase> <phrase>logic programming</phrase> <phrase>language</phrase>, Jinni, implemented in <phrase>Java</phrase> is introduced as a flexible <phrase>scripting</phrase> tool for gluing together <phrase>knowledge</phrase> processing components and <phrase>Java</phrase> objects in <phrase>networked</phrase> <phrase>client/server</phrase> applications and <phrase>thin client</phrase> environments as well as through applets over the <phrase>Web</phrase>. <phrase>Mobile</phrase> threads, implemented by capturing <phrase>first order</phrase> <phrase>continuations</phrase> in a <phrase>compact</phrase> <phrase>data structure</phrase> sent over the network, allow Jinni to interoperate with <phrase>remote</phrase> <phrase>high</phrase> performance BinProlog servers for <phrase>CPU</phrase>-intensive <phrase>knowledge</phrase> processing. A <phrase>Controlled Natural Language</phrase> to <phrase>Prolog</phrase> <phrase>translator</phrase> with support of <phrase>third party</phrase> <phrase>speech recognition</phrase> and <phrase>text-to-speech</phrase> <phrase>translation</phrase> allows interaction with users not familiar with <phrase>logic programming</phrase>.
Towards <phrase>Autonomous</phrase>, <phrase>Perceptive</phrase>, and <phrase>Intelligent Virtual</phrase> <phrase>Actors</phrase>.
This <phrase>paper</phrase> explains methods to provide <phrase>autonomous virtual humans</phrase> with the skills necessary to perform <phrase>stand-alone</phrase> role in <phrase>films</phrase>, <phrase>games</phrase> and interictive <phrase>television</phrase>. We present <phrase>current research</phrase> developments in the <phrase>Virtual</phrase> <phrase>Life</phrase> of <phrase>autonomous</phrase> <phrase>synthetic actors</phrase>. After a brief description of our <phrase>geometric</phrase>. physical, and <phrase>auditory</phrase> <phrase>Virtual</phrase> Environments, we introduce the <phrase>perception</phrase> <phrase>action</phrase> principles with a few <phrase>simple examples</phrase>. We emphasize the concept of <phrase>virtual</phrase> sensors for <phrase>virtual</phrase> humans. In particular, we describe our experiences in <phrase>implementing</phrase> <phrase>virtual</phrase> sensors such as <phrase>vision sensors</phrase>, <phrase>tactile</phrase> sensors, and <phrase>hearing</phrase> sensors. We then describe <phrase>knowledge-based</phrase> <phrase>navigation</phrase>. <phrase>knowledge</phrase>-based <phrase>locomotion</phrase> and in more details <phrase>sensor</phrase>-based <phrase>tennis</phrase>.
Temporally Invariant <phrase>Junction Tree</phrase> for Interference in <phrase>Dynamic</phrase> <phrase>Bayesian Network</phrase>.
<phrase>Dynamic</phrase> <phrase>Bayesian</phrase> networks (DBNs) extend <phrase>Bayesian</phrase> networks from static domains to <phrase>dynamic</phrase> domains. The only known <phrase>generic</phrase> method for <phrase>exact</phrase> inference in DBNs is based on <phrase>dynamic</phrase> <phrase>expansion</phrase> and reduction of <phrase>active</phrase> slices. It is effective when the domain evolves relatively slowly, but is reported to be "<phrase>too expensive</phrase>" for <phrase>fast evolving</phrase> domain where inference is under time <phrase>pressure</phrase>. This study explores the stationary feature of <phrase>problem domains</phrase> to improve the efficiency of <phrase>exact</phrase> inference in DBNs. We propose the <phrase>construction</phrase> of a temporally invariant template of a <phrase>DBN</phrase> directly <phrase>supporting</phrase> <phrase>exact</phrase> inference and discuss issues in the <phrase>construction</phrase>. This method eliminates the need for the computation associated with <phrase>dynamic</phrase> <phrase>expansion</phrase> and reduction of the existing method. The method is demonstrated by <phrase>experimental</phrase> result.
Termersetzungssysteme : <phrase>Grundlagen</phrase> der Prototyp-<phrase>Generierung</phrase> algebraischer Spezifikationen
The <phrase>Programming Language</phrase> <phrase>Ada</phrase> <phrase>Reference Manual</phrase>, Proposed Standard Document, <phrase>United States Department of Defense</phrase>
PREMO: A Framework for <phrase>Multimedia</phrase> <phrase>Middleware</phrase> - Specification, Rationale, and <phrase>Java</phrase> Binding
The <phrase>Programming Language</phrase> <phrase>Ada</phrase> <phrase>Reference Manual</phrase>, <phrase>American National Standards Institute</phrase>, Inc., <phrase>ANSI</phrase>/<phrase>MIL-STD</phrase>-1815A-1983
<phrase>Software-Architekturen</phrase> <phrase>für verteilte Systeme</phrase>
<phrase>Least Squares</phrase> <phrase>Orthogonal</phrase> Distance <phrase>Fitting</phrase> of Curves and Surfaces in Space
<phrase>Architecture</phrase> of <phrase>Distributed Computer Systems</phrase>
Unobstructed <phrase>Shortest Paths</phrase> in <phrase>Polyhedral</phrase> Environments
<phrase>Exploitation</phrase> of <phrase>Fine-Grain</phrase> Parallelism.
<phrase>Relational Database</phrase> <phrase>Technology</phrase>
Mikroarchitekturen und Mikroprogrammierung: <phrase>Formale Beschreibung</phrase> <phrase>und Optimierung</phrase>
<phrase>Object-Oriented</phrase> <phrase>Database</phrase> <phrase>Programming</phrase>
A Tight, Practical <phrase>Integration</phrase> of Relations and Functions.
The <phrase>Design</phrase> of <phrase>Well-Structured</phrase> and <phrase>Correct Programs</phrase>
<phrase>Cooperative</phrase> Interfaces to <phrase>Information</phrase> Systems
<phrase>Symbolic</phrase> <phrase>Algebraic</phrase> Methods and <phrase>Verification Methods</phrase>
The <phrase>Classical</phrase> <phrase>Decision Problem</phrase>
Reasoning with <phrase>Logic Programming</phrase>
<phrase>Abstract State Machines</phrase>. A Method for <phrase>High</phrase>-Level <phrase>System Design</phrase> and Analysis
<phrase>Incremental</phrase> <phrase>Speech Translation</phrase>.
A <phrase>Resolution Principle</phrase> for a <phrase>Logic</phrase> with <phrase>Restricted</phrase> <phrase>Quantifiers</phrase>
<phrase>Multimedia</phrase> <phrase>Databases</phrase> in <phrase>Perspective</phrase>
<phrase>Co-oP</phrase>, A <phrase>Group Decision Support System</phrase> for <phrase>Cooperative</phrase> <phrase>Multiple Criteria Group Decision Making</phrase>
<phrase>Propositional</phrase>, <phrase>Probabilistic</phrase> and <phrase>Evidential Reasoning</phrase>: <phrase>Integrating</phrase> Numerical and <phrase>Symbolic</phrase> Approaches
<phrase>Von Datenbanken</phrase> zu <phrase>Expertensystemen</phrase>
<phrase>Automatic</phrase> Verification of <phrase>Sequential</phrase> <phrase>Infinite-State</phrase> Processes
<phrase>R</phrase>/3 <phrase>Einführung</phrase>: <phrase>Methoden und Werkzeuge</phrase>
A Review of <phrase>Ada Tasking</phrase>
<phrase>SAP R/3</phrase> Implementation: Methods and Tools
<phrase>Generierung</phrase> <phrase>natürlicher Sprache</phrase> <phrase>mit</phrase> Generalisierten Phrasenstruktur-Grammatiken
This <phrase>dissertation</phrase> describes <phrase>NL</phrase> generation with <phrase>generalized</phrase> <phrase>phrase structure grammars</phrase> (GPSG). It thoroughly discusses the theory of GPSG and argues that it can, in its 1985 version, not efficiently be implemented. Therefore, some modifications are suggested that overcome this problem. Using the <phrase>modified</phrase> formalism, two different approaches to GPSG-based generation are presented. The <phrase>grammar</phrase>-<phrase>driven approach</phrase> is shown to suffer from <phrase>indeterminism</phrase>, whereas the <phrase>structure-driven</phrase> approach can be <phrase>efficiently implemented</phrase>. The latter method has been explored within the <phrase>Berlin</phrase> <phrase>machine translation</phrase> system, where the generator starts from sentence-<phrase>semantic</phrase> input structures designed for transfer. Since the <phrase>semantics</phrase> is not integrated into the <phrase>grammar</phrase>, an explicit mapping from <phrase>partial</phrase> <phrase>semantic</phrase> onto <phrase>syntactic</phrase> structures is necessary, which is accomplished by using techniques known from <phrase>AI</phrase> <phrase>production</phrase> systems. Both generators allow for <phrase>multilingual</phrase> generation, which is demonstrated for <phrase>English</phrase> and <phrase>German</phrase>.
<phrase>Querying</phrase> <phrase>Databases</phrase> Privately: A New Approach to <phrase>Private</phrase> <phrase>Information Retrieval</phrase>
<phrase>PORTAL</phrase> <phrase>Language</phrase> Description - Second, Extended <phrase>Edition</phrase>
<phrase>LOGIDATA+</phrase>: <phrase>Deductive</phrase> <phrase>Databases</phrase> with <phrase>Complex Objects</phrase>
<phrase>B2B</phrase> <phrase>Integration</phrase>: Concepts and <phrase>Architecture</phrase>
<phrase>Ada</phrase> 95 Quality and Style, Guideline for <phrase>Professional</phrase> Programmers
Fundamental <phrase>Algorithms</phrase> for <phrase>Permutation</phrase> Groups
Interactive <phrase>Relational Database</phrase> <phrase>design</phrase> - A <phrase>Logic Programming</phrase> Implementation
<phrase>Computer Science</phrase> Today: <phrase>Recent Trends</phrase> and Developments
The MOSIX Distributed <phrase>Operating System</phrase> - <phrase>Load Balancing</phrase> for <phrase>UNIX</phrase>
<phrase>Tractable Reasoning</phrase> in <phrase>Artificial Intelligence</phrase>
<phrase>Mental Representation</phrase> and Processing of <phrase>Geographic</phrase> <phrase>Knowledge</phrase> - A <phrase>Computational Approach</phrase>
The <phrase>Concurrency Control</phrase> Problem for <phrase>Database Systems</phrase>
<phrase>Ada</phrase> 95 Rationale, The <phrase>Language</phrase>, The <phrase>Standard Libraries</phrase>
<phrase>Logic Programming</phrase> and <phrase>Databases</phrase>
<phrase>A Survey</phrase> of <phrase>Verification Techniques</phrase> for <phrase>Parallel</phrase> Programs
<phrase>Time Series</phrase> Package (TSPACK)
Entzifferte Geheimnisse: <phrase>Methoden und</phrase> Maximen der Kryptologie, 3. Auflage
<phrase>Parallel</phrase> Execution of <phrase>Parlog</phrase>
Entzifferte Geheimnisse: <phrase>Methoden und</phrase> Maximen der Kryptologie, 2. Auflage
Mapping Scientific <phrase>Frontiers</phrase>: The <phrase>Quest</phrase> for <phrase>Knowledge</phrase> Visualization
The <phrase>Munich</phrase> <phrase>Project</phrase> <phrase>CIP</phrase>, Volume <phrase>I</phrase>: The <phrase>Wide Spectrum Language</phrase> <phrase>CIP</phrase>-<phrase>L</phrase>
<phrase>Information Visualisation</phrase> and <phrase>Virtual</phrase> Environments
The <phrase>Munich</phrase> <phrase>Project</phrase> <phrase>CIP</phrase>, <phrase>Volume II</phrase>: The <phrase>Program Transformation</phrase> System <phrase>CIP</phrase>-<phrase>S</phrase>
A Guide to <phrase>Modula</phrase>-2
<phrase>Mobile</phrase> Agents: <phrase>Control Algorithms</phrase>
Modelling in <phrase>Molecular Biology</phrase>
<phrase>Software</phrase>-Bewertung: <phrase>Ein</phrase> semantischer <phrase>Ansatz</phrase> für Infomationsmaße
<phrase>Active Visual</phrase> Inference of <phrase>Surface Shape</phrase>
Theory Reasoning in Connection <phrase>Calculi</phrase>
<phrase>Programming</phrase> in <phrase>Prolog</phrase>
Zur <phrase>Logik</phrase> der <phrase>Logik</phrase>-<phrase>Programmierung</phrase>: <phrase>Ein</phrase> konstruktiver <phrase>Ansatz</phrase>
<phrase>Programming</phrase> in <phrase>Prolog</phrase>, <phrase>2nd Edition</phrase>
Concepts in <phrase>User Interfaces</phrase>: A <phrase>Reference Model</phrase> for the Command and Response Languages (By Members of <phrase>IFIP</phrase> WG2.7)
<phrase>Programming</phrase> in <phrase>Prolog</phrase>, <phrase>3rd Edition</phrase>
Concepts, <phrase>Design</phrase>, and <phrase>Performance Analysis</phrase> of a <phrase>Parallel</phrase> <phrase>Prolog</phrase> Machine
<phrase>Prolog</phrase> by Example: How to Learn, Teach and Use It
<phrase>Concurrent</phrase> <phrase>Reactive</phrase> Plans, <phrase>Anticipation</phrase> and Forestalling <phrase>Execution Failures</phrase>
<phrase>Autonomous robots</phrase> that accomplish their jobs in partly unknown and <phrase>changing environments</phrase> often learn <phrase>important information</phrase> while <phrase>carrying out</phrase> their jobs. To be <phrase>reliable</phrase> and <phrase>effcient</phrase>, they have to <phrase>act</phrase> appropriately in novel situations and respond immediately to unpredicted events. They also have to reconsider their intended course of <phrase>action</phrase> when it is likely to have flaws. For example, whenever a <phrase>robot</phrase> detects another <phrase>robot</phrase>, it should predict that <phrase>robot's</phrase> effect on its plan and -- if necessary -- revise its plan to make it more <phrase>robust</phrase>. To accomplish these patterns of activity we equip <phrase>robots</phrase> with structured <phrase>reactive</phrase> plans (SRPs), <phrase>concurrent</phrase> <phrase>control programs</phrase> that can not only be interpreted but also reasoned about and manipulated. These plans specify how the <phrase>robot</phrase> is to respond to <phrase>sensory input</phrase> in <phrase>order</phrase> to accomplish its jobs. In this <phrase>book</phrase> we describe a <phrase>computational model</phrase> of forestalling common flaws in <phrase>autonomous robot</phrase> behavior. To this end, we develop a representation for SRPs in which <phrase>declarative</phrase> statements for goals, perceptions, and beliefs make the structure and purpose of SRPs explicit and thereby simplify and <phrase>speed up</phrase> <phrase>reasoning about</phrase> SRPs and their projections. We have also developed a notation for <phrase>transforming</phrase> SRPs, which does not only make the <phrase>physical effects</phrase> of <phrase>plan execution</phrase> explicit, but also the process of plan interpretation, as well as temporal, <phrase>causal</phrase>, and <phrase>teleological</phrase> relationships among plan interpretation, the world, and the physical behavior of the <phrase>robot</phrase>. Using this notation a <phrase>planning</phrase> system can diagnose and forestall common flaws in <phrase>robot</phrase> plans that cannot be dealt with in other <phrase>planning</phrase> representations. <phrase>Finally</phrase>, we have extended the <phrase>language</phrase> for writing SRPs with constructs that allow for a flexible <phrase>integration</phrase> of <phrase>planning</phrase> and execution and thereby turned it into a <phrase>single</phrase> <phrase>high</phrase>-level <phrase>language</phrase> that can handle both <phrase>planning</phrase> and execution actions. Experiments in a <phrase>simulated world</phrase> show that by simultaneously forestalling flaws and executing SRPs, the <phrase>robot</phrase> can perform its jobs more reliably than, and almost as effciently as, it could using fixed <phrase>control programs</phrase>.
<phrase>Large Sparse</phrase> <phrase>Numerical Optimization</phrase>
<phrase>Plan-Based</phrase> Control of <phrase>Robotic</phrase> Agents: <phrase>Improving</phrase> the Capabilities of <phrase>Autonomous Robots</phrase>
<phrase>An Introduction</phrase> to the <phrase>PL</phrase>/CV2 <phrase>Programming</phrase> <phrase>Logic</phrase>
<phrase>Hierarchical</phrase> <phrase>Neural Networks</phrase> for <phrase>Image Interpretation</phrase>
Erfahrung und <phrase>Berechnung</phrase>: Kritik der Expertensystemtechnik
Korrekte Zugriffe zu verteilten <phrase>Daten</phrase>
The <phrase>Data Mining</phrase> and <phrase>Knowledge</phrase> Discovery <phrase>Handbook</phrase>.
<phrase>Dynamische</phrase> nicht-normalisierte Relationen und symbolische Bildbeschreibung
Indexstrukturen in <phrase>Datenbanksystemen</phrase>
<phrase>Automatic</phrase> Generation of <phrase>Computer Animation</phrase>: Using <phrase>AI</phrase> for <phrase>Movie</phrase> <phrase>Animation</phrase>
Systems of Reductions
<phrase>Queueing Networks</phrase> with <phrase>Discrete Time</phrase> Scale - <phrase>Explicit Expressions</phrase> for the <phrase>Steady State</phrase> Behavior of <phrase>Discrete Time</phrase> <phrase>Stochastic</phrase> Networks
<phrase>Ray Shooting</phrase>, <phrase>Depth Orders</phrase> and <phrase>Hidden</phrase> Surface Removal
The <phrase>Design</phrase> of <phrase>Rijndael</phrase>: <phrase>AES</phrase> - The <phrase>Advanced Encryption Standard</phrase>
<phrase>Statistical Decision Theory</phrase> and <phrase>Bayesian Analysis</phrase>, <phrase>2nd Edition</phrase>.
<phrase>Entwurf</phrase> <phrase>und Verifikation</phrase> mikroprogrammierter Rechnerarchitekturen
<phrase>Experience Management</phrase>: Foundations, <phrase>Development Methodology</phrase>, and <phrase>Internet-Based</phrase> Applications
MetaSoft <phrase>Primer</phrase>, Towards a <phrase>Metalanguage</phrase> for Applied <phrase>Denotational Semantics</phrase>
<phrase>Efficient Query Processing</phrase> in <phrase>Geographic Information Systems</phrase>
<phrase>Developing</phrase> <phrase>Industrial</phrase> <phrase>Case-Based Reasoning</phrase> Applications: The INRECA-Methodology
The <phrase>Logic</phrase> System of <phrase>Concept Graphs</phrase> with <phrase>Negation</phrase> And Its Relationship to <phrase>Predicate Logic</phrase>
How to <phrase>Multiply</phrase> Matrices Faster
<phrase>Managing</phrase> <phrase>Information Highways</phrase> - The <phrase>PRISM</phrase> <phrase>Book</phrase>: Principles, Methods, and <phrase>Case Studies</phrase> for <phrase>Designing</phrase> <phrase>Telecommunications</phrase> <phrase>Management</phrase> Systems
On the <phrase>Integration</phrase> of <phrase>Algebraic</phrase> Functions
<phrase>Intelligent Data Analysis</phrase>, <phrase>An Introduction</phrase>, 2nd editon
The Adaptation of <phrase>Virtual</phrase> <phrase>Man</phrase>-Computer Interfaces to <phrase>User Requirements</phrase> in Dialogs
<phrase>Public-Key Cryptography</phrase>: <phrase>State</phrase> of the <phrase>Art</phrase> and <phrase>Future Directions</phrase>, E.I.S.S. <phrase>Workshop</phrase>, <phrase>Oberwolfach</phrase>, <phrase>Germany</phrase>, <phrase>July</phrase> 3-6, 1991, <phrase>Final Report</phrase>
<phrase>Introduction</phrase> to <phrase>Cryptography</phrase>: Principles and Applications
Due to the <phrase>rapid</phrase> growth of <phrase>digital</phrase> <phrase>communication</phrase> and <phrase>electronic</phrase> <phrase>data</phrase> exchange, <phrase>information security</phrase> has become a <phrase>crucial issue</phrase> in <phrase>industry</phrase>, <phrase>business</phrase>, and <phrase>administration</phrase>. <phrase>Modern cryptography</phrase> provides essential techniques for <phrase>securing</phrase> <phrase>information</phrase> and <phrase>protecting</phrase> <phrase>data</phrase>. In the first part, this <phrase>book</phrase> covers the <phrase>key concepts</phrase> of <phrase>cryptography</phrase> on an <phrase>undergraduate</phrase> level, from <phrase>encryption</phrase> and <phrase>digital signatures</phrase> to <phrase>cryptographic</phrase> protocols. Essential techniques are demonstrated in protocols for <phrase>key exchange</phrase>, <phrase>user identification</phrase>, <phrase>electronic elections</phrase> and <phrase>digital cash</phrase>. In the second part, more <phrase>advanced</phrase> topics are addressed, such as the <phrase>bit</phrase> <phrase>security</phrase> of <phrase>one-way functions</phrase> and computationally <phrase>perfect</phrase> <phrase>pseudo random bit</phrase> generators. The <phrase>security</phrase> of <phrase>cryptographic</phrase> schemes is a central topic. <phrase>Typical examples</phrase> of <phrase>provably secure</phrase> <phrase>encryption</phrase> and <phrase>signature schemes</phrase> and their <phrase>security</phrase> proofs are given. <phrase>Though</phrase> particular attention is given to the <phrase>mathematical</phrase> foundations, no special background in <phrase>mathematics</phrase> is presumed. The necessary <phrase>algebra</phrase>, <phrase>number theory</phrase> and <phrase>probability theory</phrase> are included in the <phrase>appendix</phrase>. Each <phrase>chapter</phrase> closes with a collection of exercises. Answers to the exercises are provided on the <phrase>Web</phrase> page for this <phrase>book</phrase>.
<phrase>Qualität</phrase> und Testbarkeit hochintegrierter <phrase>Schaltungen</phrase>: <phrase>Qualitätssicherung</phrase> durch regelbasierte <phrase>Systeme</phrase>
<phrase>Incomplete Information</phrase>: Structure, Inference, Complexity
:This <phrase>monograph</phrase> presents a <phrase>systematic</phrase>, exhaustive and <phrase>up-to-date</phrase> <phrase>overview</phrase> of <phrase>formal methods</phrase> and theories for <phrase>data analysis</phrase> and inference inspired by the concept of <phrase>rough set</phrase>. The <phrase>book</phrase> studies structures with <phrase>incomplete information</phrase> from the <phrase>logical</phrase>, <phrase>algebraic</phrase> and computational <phrase>perspective</phrase>. The formalisms developed are <phrase>non-invasive</phrase> in that only the actual <phrase>information</phrase> is needed in the process of analysis without <phrase>external sources</phrase> of <phrase>information</phrase> being required. The <phrase>book</phrase> is intended for researchers, <phrase>lecturers</phrase> and <phrase>graduate students</phrase> who wish to get acquainted with the <phrase>rough set</phrase> style approach to <phrase>information</phrase> systems with <phrase>incomplete information</phrase>.
<phrase>Algebraic</phrase> System Specification and Development - <phrase>A Survey</phrase> and <phrase>Annotated Bibliography</phrase>
<phrase>Attribute Grammars</phrase>: Definitions, Systems, and <phrase>Bibliography</phrase>.
<phrase>Casl</phrase> <phrase>User Manual</phrase> - <phrase>Introduction</phrase> to Using the <phrase>Common Algebraic Specification Language</phrase>
<phrase>Das</phrase> <phrase>ist</phrase> <phrase>Informatik</phrase>
<phrase>Semirings</phrase> for <phrase>Soft Constraint</phrase> Solving and <phrase>Programming</phrase>
<phrase>Combinatorics</phrase> on Traces
<phrase>Automatische</phrase> <phrase>Synthese</phrase> rekursiver <phrase>Programme</phrase> als Beweisverfahren
Flexible, realzeitfähige Kollisionsvermeidung in Mehrroboter-<phrase>Systemen</phrase>
<phrase>Ein</phrase> universelles <phrase>Konzept</phrase> zum flexiblen Informationsschutz in und <phrase>mit</phrase> <phrase>Rechensystemen</phrase>
Integrity Primitives for <phrase>Secure</phrase> <phrase>Information</phrase> Systems, <phrase>Final Report</phrase> of <phrase>RACE</phrase> Integrity Primitives Evaluation <phrase>RIPE</phrase>-<phrase>RACE</phrase> 1040
<phrase>Primality Testing</phrase> in <phrase>Polynomial</phrase> Time, From <phrase>Randomized</phrase> <phrase>Algorithms</phrase> to "<phrase>PRIMES</phrase> Is in <phrase>P</phrase>"
<phrase>Network Calculus</phrase>: A Theory of <phrase>Deterministic</phrase> <phrase>Queuing Systems</phrase> for the <phrase>Internet</phrase>
<phrase>Mathematik</phrase> <phrase>für Informatiker</phrase> <phrase>I</phrase>: <phrase>Die</phrase> <phrase>Methode der</phrase> <phrase>Mathematik</phrase>
Extensions of the <phrase>UNITY</phrase> Methodology - <phrase>Compositionality</phrase>, <phrase>Fairness</phrase> and <phrase>Probability</phrase> in Parallelism
<phrase>Embedded Systems</phrase> <phrase>Design</phrase>: The <phrase>ARTIST</phrase> <phrase>Roadmap</phrase> for <phrase>Research</phrase> and Development
The <phrase>Stability Theory</phrase> of <phrase>Stream Ciphers</phrase>
<phrase>Microcomputer</phrase> <phrase>Problem Solving</phrase> Using <phrase>Pascal</phrase>
<phrase>Die</phrase> strukturierte Analyse Markovscher <phrase>Modelle</phrase>
Featurebasierte <phrase>Integration</phrase> von <phrase>CAD/CAM</phrase>-<phrase>Systemen</phrase>
<phrase>An Optimized</phrase> <phrase>Translation</phrase> Process and Its Application to <phrase>ALGOL</phrase> 68
On <phrase>Object-Oriented</phrase> <phrase>Database Systems</phrase>
An Analytical Description of CHILL, the <phrase>CCITT</phrase> <phrase>High</phrase> Level <phrase>Language</phrase>
<phrase>Stochastic</phrase> <phrase>Automata</phrase>: Stability, <phrase>Nondeterminism</phrase>, and Prediction
Modern <phrase>Cryptology</phrase> - A <phrase>Tutorial</phrase>
Complementary Definitions of <phrase>Programming Language</phrase> <phrase>Semantics</phrase>
Massiv <phrase>parallele Programmierung</phrase> <phrase>mit dem</phrase> Parallaxis-<phrase>Modell</phrase>
<phrase>Error Detection</phrase> and Recovery in <phrase>Robotics</phrase>
<phrase>Algebraic Specification</phrase> Techniques in <phrase>Object Oriented Programming</phrase> Environments
<phrase>Efficient</phrase> <phrase>Graph Rewriting</phrase> and Its Implementation
<phrase>Input/Output</phrase> Intensive <phrase>Massively Parallel Computing</phrase> - <phrase>Language</phrase> Support, <phrase>Automatic Parallelization</phrase>, <phrase>Advanced</phrase> Optimization, and <phrase>Runtime Systems</phrase>
Resolution Methods for the <phrase>Decision Problem</phrase>
<phrase>Introduction</phrase> to <phrase>Cryptography</phrase>
<phrase>Artificial</phrase> Animals for <phrase>Computer Animation</phrase>, <phrase>Biomechanics</phrase>, <phrase>Locomotion</phrase>, <phrase>Perception</phrase>, and Behavior
Fehlermaskierung durch <phrase>verteilte Systeme</phrase>
Entwurfstransaktionen für modulare Objektsysteme: Synchronisierung in objektorientierten <phrase>Datenbanksystemen</phrase>
<phrase>Fundamentals</phrase> of <phrase>Algebraic</phrase> Specification 1: Equations und <phrase>Initial Semantics</phrase>
<phrase>Modellbildung</phrase>, Wissensrevision und <phrase>Wissensrepräsentation</phrase> <phrase>im</phrase> Maschinellen <phrase>Lernen</phrase>
Rechtsprechung und Computer in den neunziger Jahren: <phrase>Am</phrase> <phrase>Beispiel von</phrase> Begriff und Typologie der Körperschaft <phrase>des</phrase> Öffentlichen Rechts
Simple <phrase>Program Schemes</phrase> and <phrase>Formal Languages</phrase>
<phrase>Knowledge</phrase> Discovery in <phrase>Databases</phrase> - <phrase>Techniken und</phrase> <phrase>Anwendungen</phrase>
<phrase>Generierung</phrase> portabler <phrase>Compiler</phrase>: <phrase>Das</phrase> portable System <phrase>POCO</phrase>
Exercises in <phrase>Computer Systems</phrase> Analysis
<phrase>Advanced</phrase> <phrase>Symbolic</phrase> Analysis for Compilers: New Techniques and <phrase>Algorithms</phrase> for <phrase>Symbolic</phrase> <phrase>Program Analysis</phrase> and Optimization
Ausnahmebehandlung in objektorientierten <phrase>Programmiersprachen</phrase>
<phrase>Problem-Solving</phrase> Methods: <phrase>Understanding</phrase>, Description, Development, and Reuse
Foundations of <phrase>Equational Logic Programming</phrase>
<phrase>LUCAS</phrase> <phrase>Associative Array</phrase> Processor: <phrase>Design</phrase>., <phrase>Programming</phrase> and Application Studies
An <phrase>Attribute Grammar</phrase> for the <phrase>Semantic</phrase> Analysis of <phrase>Ada</phrase>
A <phrase>Systematic</phrase> <phrase>Catalogue</phrase> of Reusable <phrase>Abstract</phrase> <phrase>Data</phrase> Types
IT-<phrase>Security</phrase> and <phrase>Privacy</phrase> - <phrase>Design</phrase> and Use of <phrase>Privacy</phrase>-<phrase>Enhancing</phrase> <phrase>Security</phrase> Mechanisms
Specification and <phrase>Compositional</phrase> Verification of <phrase>Real-Time</phrase> Systems
<phrase>Datenbanksystem</phrase> für <phrase>CAD</phrase>-Arbeitsplätze
Kollisionsfreie Bahnen <phrase>für Industrieroboter</phrase>: <phrase>Ein</phrase> Planungsverfahren
A Collection of <phrase>Test</phrase> Problems for <phrase>Constrained Global Optimization</phrase> Problems
<phrase>Approximative</phrase> <phrase>Public</phrase>-Key-Kryptosysteme
<phrase>Text Mining</phrase>, <phrase>Theoretical Aspects</phrase> and Applications
<phrase>Parallele</phrase> <phrase>Algorithmen</phrase>
<phrase>Automatic</phrase> <phrase>Ambiguity Resolution</phrase> in <phrase>Natural Language Processing</phrase> - <phrase>An Empirical</phrase> Approach
:This <phrase>book</phrase> introduces a new approach to the important <phrase>NLP</phrase> issue of <phrase>automatic</phrase> <phrase>ambiguity resolution</phrase>, based on <phrase>statistical models</phrase> of text. This approach is compared with previous work and proved to yield <phrase>higher accuracy</phrase> for <phrase>natural language</phrase> analysis. At the same time, an effective <phrase>implementation strategy</phrase> is described, which is directly useful for <phrase>natural language</phrase> analysis. The <phrase>book</phrase> is noteworthy for demonstrating a new empirical approach to <phrase>NLP</phrase>; it is essential <phrase>reading</phrase> for researchers in <phrase>natural language processing</phrase> or <phrase>computational linguistics</phrase>.
<phrase>SIL</phrase> - a <phrase>Simulation</phrase> <phrase>Language</phrase>, <phrase>User's Guide</phrase>
<phrase>Mechanismen</phrase> zur <phrase>Synchronisation</phrase> paralleler <phrase>Prozesse</phrase>
Funktioneller <phrase>Test</phrase> der Auflösung von Zugriffskonflikten in Mehrrechnersystemen
<phrase>Translating</phrase> <phrase>Relational</phrase> Queries into <phrase>Iterative</phrase> Programs
FM8501: A Verified <phrase>Microprocessor</phrase>
VOCUS: A <phrase>Visual</phrase> Attention System for <phrase>Object Detection</phrase> and <phrase>Goal-Directed</phrase> Search
<phrase>Agent-Oriented Programming</phrase>, From <phrase>Prolog</phrase> to <phrase>Guarded</phrase> <phrase>Definite Clauses</phrase>.
<phrase>Ein</phrase> Roboteraktionsplanungssystem
<phrase>Formal Foundations</phrase> for <phrase>Software</phrase> Engineeing Methods
Analysis of <phrase>Drum</phrase> and <phrase>Disk Storage</phrase> Units
<phrase>Parallel</phrase>, Distributed and Multiagent <phrase>Production</phrase> Systems
<phrase>Datenverarbeitung</phrase> <phrase>im</phrase> Hochschulbereich der <phrase>USA</phrase>: <phrase>Stand und</phrase> <phrase>Entwicklungstendenzen</phrase>
Datenverwaltung in <phrase>verteilten Systemen</phrase>: <phrase>Grundlagen</phrase> und Lösungskonzepte
Matrix Eigensystem Routines - EISPACK Guide Extension
Conclog: A <phrase>Methodological Approach</phrase> to <phrase>Concurrent</phrase> <phrase>Logic Programming</phrase>
On the Shape of <phrase>Mathematical</phrase> Arguments
New Concepts for <phrase>Parallel</phrase> <phrase>Object-Relational</phrase> <phrase>Query Processing</phrase>
During the <phrase>last</phrase> few years <phrase>parallel</phrase> <phrase>object-relational database management systems</phrase> have emerged as the leading <phrase>data management</phrase> <phrase>technology</phrase> on the <phrase>market place</phrase>. These systems are <phrase>extensible</phrase> by <phrase>user-defined data types</phrase> and <phrase>user-defined</phrase> functionality for the <phrase>data</phrase>. This work focuses on the <phrase>efficient parallel</phrase> execution of <phrase>user-defined</phrase> functionality. The <phrase>main contributions</phrase> describe techniques to support <phrase>data</phrase> parallelism for <phrase>user-defined</phrase> scalar and <phrase>aggregate functions</phrase>, to support <phrase>intra</phrase>-<phrase>function</phrase> parallelism for the execution of a <phrase>scalar function</phrase> on a <phrase>large object</phrase>, and a new <phrase>technology</phrase> to provide <phrase>extensibility</phrase> with regard to new <phrase>set-oriented</phrase> <phrase>database</phrase> operations that can <phrase>efficiently implement</phrase> <phrase>user-defined</phrase> functionality in <phrase>parallel</phrase> <phrase>object-relational database management systems</phrase>. Some of these techniques have been implemented in the <phrase>MIDAS</phrase> <phrase>prototype</phrase> or on <phrase>top</phrase> of a commercial <phrase>object-relational</phrase> <phrase>database management</phrase> system.
<phrase>Mes</phrase> premières constructions de programmes
<phrase>Spatio-Temporal</phrase> <phrase>Image Processing</phrase>: Theory and <phrase>Scientific Applications</phrase>
<phrase>Modular</phrase> <phrase>Algorithms</phrase> in <phrase>Symbolic Summation</phrase> and <phrase>Symbolic Integration</phrase>
<phrase>Pascal</phrase> <phrase>User Manual</phrase> and <phrase>Report</phrase>, <phrase>Second Edition</phrase>
<phrase>Visualizing</phrase> the <phrase>Semantic Web</phrase>
<phrase>Pascal</phrase> <phrase>User Manual</phrase> and <phrase>Report</phrase>, <phrase>Second Edition</phrase>
<phrase>Abstract</phrase> <phrase>Compositional</phrase> Analysis of <phrase>Iterated</phrase> Relations, A <phrase>Structural</phrase> Approach to Complex <phrase>State Transition</phrase> Systems.
<phrase>Evaluating</phrase> <phrase>Natural Language Processing</phrase> Systems, An Analysis and Review
:This <phrase>comprehensive</phrase> <phrase>state</phrase>-of-the-<phrase>art</phrase> <phrase>book</phrase> is the first devoted to the important and timely issue of <phrase>evaluating</phrase> <phrase>NLP</phrase> systems. It addresses the whole <phrase>area</phrase> of <phrase>NLP</phrase> system evaluation, including aims and scope, problems and methodology. The authors provide a <phrase>wide-ranging</phrase> and careful analysis of evaluation concepts, <phrase>reinforced</phrase> with extensive illustrations; they relate systems to their environments and develop a framework for proper evaluation. The discussion of principles is completed by a detailed review of practice and strategies in the field, covering both systems for <phrase>specific tasks</phrase>, like <phrase>translation</phrase>, and <phrase>core language</phrase> processors. The methodology <phrase>lessons</phrase> drawn from the analysis and review are applied in a series of example cases. The <phrase>book</phrase> also refers <phrase>NLP</phrase> system evaluation to the neighbouring areas of <phrase>information</phrase> and <phrase>speech processing</phrase>, and addresses issues of tool and <phrase>data</phrase> provision for evaluation. A <phrase>comprehensive</phrase> <phrase>bibliography</phrase> and <phrase>subject index</phrase> are included as well as a term <phrase>glossary</phrase>. This <phrase>monograph</phrase> will be a valuable source of inspiration in <phrase>research</phrase>, practice, and <phrase>teaching</phrase>.
<phrase>Partial-Order</phrase> Methods for the Verification of <phrase>Concurrent</phrase> Systems - An Approach to the <phrase>State-Explosion</phrase> Problem
<phrase>TEMPO</phrase>: <phrase>A Unified</phrase> Treatment of Binding Time and <phrase>Parameter Passing</phrase> Concepts in <phrase>Programming Languages</phrase>
<phrase>An Extended Entity-Relationship Model</phrase> - <phrase>Fundamentals</phrase> and <phrase>Pragmatics</phrase>
<phrase>Index</phrase> Structures for <phrase>Data Warehouses</phrase>
<phrase>Data warehouses</phrase> <phrase>differ significantly</phrase> from traditional <phrase>transaction-oriented</phrase> operational <phrase>database</phrase> applications. <phrase>Indexing</phrase> techniques and <phrase>index</phrase> structures applied in the <phrase>transaction-oriented</phrase> context are not feasible for <phrase>data warehouses</phrase>. This work develops specific <phrase>heuristic</phrase> <phrase>indexing</phrase> techniques, which process <phrase>range</phrase> queries on <phrase>aggregated data</phrase> more efficiently than those traditionally used in <phrase>transaction-oriented</phrase> systems. The <phrase>book</phrase> presents chapters on: - the <phrase>state</phrase> of the <phrase>art</phrase> in <phrase>data warehouse</phrase> <phrase>research</phrase> - <phrase>data</phrase> storage and <phrase>index</phrase> structures - <phrase>finding optimal</phrase> <phrase>tree</phrase>-based <phrase>index</phrase> structures - <phrase>aggregated data</phrase> in <phrase>tree</phrase>-based <phrase>index</phrase> structures - <phrase>performance models</phrase> for <phrase>tree</phrase>-based <phrase>index</phrase> structures - and techniques for <phrase>comparing</phrase> <phrase>index</phrase> structures.
Axiomatising the <phrase>Logic</phrase> of <phrase>Computer Programming</phrase>
Sprecherunabhängigkeit und Sprecheradaption: <phrase>Lösungsansätze für</phrase> <phrase>das</phrase> Problem <phrase>des</phrase> Sprecherwechsels <phrase>bei der</phrase> <phrase>automatischen Spracherkennung</phrase>
<phrase>DIANA</phrase> - An <phrase>Intermediate Language</phrase> for <phrase>Ada</phrase>, <phrase>Revised</phrase> Version
GAG: A Practical <phrase>Compiler</phrase> Generator
<phrase>Edinburgh</phrase> <phrase>LCF</phrase>
<phrase>Zuverlässigkeit</phrase> und Leistungsfähigkeit <phrase>objekt</phrase>-orientierter <phrase>Datenbanksysteme</phrase>
<phrase>Robust</phrase> Adaptation to <phrase>Non-Native</phrase> Accents in <phrase>Automatic Speech Recognition</phrase>
Conditionals in <phrase>Nonmonotonic Reasoning</phrase> and <phrase>Belief Revision</phrase> - Considering Conditionals as Agents
<phrase>Datenbanksysteme</phrase> für <phrase>Software</phrase>-Produktionsumgebungen
Personalinformationssysteme in deutschen Großunternehmen: Ausbaustand und Rechtsprobleme
Graphgrammatiken in <phrase>der Softwaretechnik</phrase>: <phrase>Theorie und</phrase> <phrase>Anwendungen</phrase>
<phrase>Query Processing</phrase> in <phrase>Database Systems</phrase>
<phrase>Term Indexing</phrase>
<phrase>Disconnected Operation</phrase> in a <phrase>Distributed File System</phrase>
:The focus of this work is on the issue of <phrase>availability</phrase> in <phrase>distributed file systems</phrase>. It presents the important new <phrase>technique called</phrase> <phrase>disconnected operation</phrase>, in which clients mask failures and <phrase>voluntary</phrase> network detachments by <phrase>emulating</phrase> the functionality of servers where actual server-oriented solutions are inadequate. This permits client operation even under complete isolation from the server; the clean <phrase>integration</phrase> of <phrase>mobile</phrase> <phrase>computers</phrase> into the system is an important <phrase>side-effect</phrase> of the new technique. The <phrase>design</phrase> and implementation of disconnected <phrase>file service</phrase> in a working system, the <phrase>Coda</phrase> <phrase>file system</phrase>, is described in detail.
The Problem of <phrase>Incomplete Information</phrase> in <phrase>Relational Databases</phrase>
<phrase>Metaclasses</phrase> and Their Applications, <phrase>Data Model</phrase> <phrase>Tailoring</phrase> and <phrase>Database</phrase> <phrase>Integration</phrase>
<phrase>Distributed Programming</phrase> Paradigms with <phrase>Cryptography</phrase> Applications
<phrase>Concrete</phrase> and <phrase>Abstract Voronoi Diagrams</phrase>
Theory of <phrase>Program Structures</phrase>: Schemes, <phrase>Semantics</phrase>, Verification
A Study in <phrase>String Processing</phrase> Languages
The <phrase>Science</phrase> of <phrase>Programming</phrase>.
<phrase>Treewidth</phrase>, Computations and Approximations
A <phrase>Logical</phrase> Approach to <phrase>Discrete Math</phrase>.
<phrase>Semantics</phrase> of <phrase>Digital</phrase> Circuits
Lectures on the Complexity of <phrase>Bilinear</phrase> Problems
<phrase>Optimal</phrase> <phrase>Interprocedural Program</phrase> Optimization, A New Framework and Its Application
A <phrase>Perspective</phrase> of <phrase>Constraint-Based</phrase> Reasoning - An <phrase>Introductory Tutorial</phrase>
<phrase>Axioms</phrase> and <phrase>Hulls</phrase>
<phrase>Algebraic</phrase> <phrase>Semantics</phrase>
MMIXware, A <phrase>RISC</phrase> Computer for the Third <phrase>Millennium</phrase>
<phrase>Efficient</phrase> Structures for <phrase>Geometric</phrase> <phrase>Data Management</phrase>
<phrase>Benutzermodellierung</phrase> in Dialogsystemen
<phrase>List Decoding</phrase> of <phrase>Error-Correcting Codes</phrase> (<phrase>Winning</phrase> <phrase>Thesis</phrase> of the 2002 <phrase>ACM</phrase> <phrase>Doctoral Dissertation</phrase> <phrase>Competition</phrase>)
<phrase>Relationale</phrase> <phrase>Anfragen</phrase> - Zerlegung <phrase>und Optimierung</phrase>
Übersetzerbau - <phrase>Techniken</phrase>, <phrase>Werkzeuge</phrase>, <phrase>Anwendungen</phrase>
<phrase>A Unified</phrase> Approach to <phrase>Interior Point Algorithms</phrase> for <phrase>Linear Complementarity Problems</phrase>
<phrase>Prinzipien der</phrase> Referentialität: <phrase>Untersuchungen zur</phrase> propositionalen <phrase>Repräsentation von</phrase> <phrase>Wissen</phrase>
<phrase>Prosody</phrase> in <phrase>Speech Understanding</phrase> Systems
<phrase>Hyperedge Replacement</phrase>: <phrase>Grammars</phrase> and Languages
<phrase>Model</phrase> Generation for <phrase>Natural Language</phrase> Interpretation and Analysis
<phrase>Communication</phrase> and <phrase>Cooperation</phrase> in <phrase>Agent Systems</phrase>, A <phrase>Pragmatic</phrase> Theory
Triggermechanismen in <phrase>Datenbanksystemen</phrase>
Representing Plans <phrase>Under Uncertainty</phrase>: A <phrase>Logic</phrase> of Time, Change, and <phrase>Action</phrase>
Verkehrsanalyse in endlichen Zeiträumen: <phrase>Grundlagen</phrase> und Erweiterungen der operationalen Analyse
Lexikalisch <phrase>verteiltes</phrase> <phrase>Text-Parsing</phrase>: <phrase>Eine objektorientierte</phrase> <phrase>Spezifikation</phrase> eines Wortexpertensystems <phrase>auf der Grundlage</phrase> <phrase>des</phrase> Aktorenmodells
Specifying <phrase>Message Passing</phrase> and <phrase>Time-Critical</phrase> Systems with <phrase>Temporal Logic</phrase>
Veritying <phrase>Concurrent</phrase> Processes Using <phrase>Temporal Logic</phrase>
Distributed <phrase>Reason Maintenance</phrase> for <phrase>Multiagent Systems</phrase>
Time Structures - <phrase>Formal Description</phrase> and <phrase>Algorithmic</phrase> Representation
LOGPLAN '88 - <phrase>Report</phrase> on the <phrase>Programming Language</phrase>
<phrase>Management</phrase> of <phrase>Telecommunication</phrase> Systems and Services, Modelling and <phrase>Implementing</phrase> <phrase>TMN-Based</phrase> <phrase>Multi-Domain</phrase> <phrase>Management</phrase>
:This <phrase>monograph</phrase> is the <phrase>final report</phrase> of the <phrase>European</phrase> <phrase>RACE</phrase> <phrase>II</phrase> <phrase>Research Project</phrase> PREPARE, devoted to <phrase>designing</phrase> and <phrase>implementing</phrase> <phrase>prototype</phrase> <phrase>telecommunication</phrase> <phrase>management</phrase> systems over <phrase>real testbeds</phrase>. The <phrase>excellent results</phrase> presented are a <phrase>major</phrase> contribution to <phrase>advancing</phrase> the <phrase>state</phrase> of the <phrase>art</phrase> in the field and have been <phrase>widely acknowledged</phrase> by <phrase>standards bodies</phrase>, manufacturers, operators, <phrase>service providers</phrase>, and academics. <phrase>Prospective</phrase> readers of the <phrase>book</phrase> include those concerned with the <phrase>design</phrase>, development, delivery, and maintenance of <phrase>telecommunication</phrase> services in the <phrase>global</phrase> <phrase>service market</phrase> as well as those with a <phrase>general</phrase> theoretical or practical interest in <phrase>multi-domain</phrase> <phrase>management</phrase> issues.
<phrase>Numerical Integration</phrase> on <phrase>Advanced</phrase> <phrase>Computer Systems</phrase>
<phrase>Autonomous</phrase> <phrase>Dynamic</phrase> Reconfiguration in <phrase>Multi-Agent Systems</phrase>, <phrase>Improving</phrase> the Quality and Efficiency of <phrase>Collaborative Problem Solving</phrase>
Situationsmodellierung in der Bildfolgeauswertung
<phrase>Datenbanksysteme</phrase>: <phrase>Konzepte und</phrase> <phrase>Techniken</phrase> der <phrase>Implementierung</phrase>, 2. Auflage
Funktionelle <phrase>Analyse von</phrase> Kommunikationsprotokollen
<phrase>Datenbanksysteme</phrase>: <phrase>Konzepte und</phrase> <phrase>Techniken</phrase> der <phrase>Implementierung</phrase>
<phrase>CAD</phrase> und Arbeitssituation: <phrase>Untersuchungen zu</phrase> den <phrase>Auswirkungen von</phrase> <phrase>CAD</phrase> sowie zur menschengerechten <phrase>Gestaltung von</phrase> <phrase>CAD</phrase>-<phrase>Systemen</phrase>
<phrase>First-Order Dynamic Logic</phrase>
<phrase>Semirings</phrase>, <phrase>Automata</phrase>, Languages
<phrase>Adaptive</phrase> Modelling, Estimation and <phrase>Fusion</phrase> from <phrase>Data</phrase>: A <phrase>Neurofuzzy</phrase> Approach
This <phrase>book</phrase> <phrase>brings together</phrase> for the first time the complete theory of <phrase>data</phrase>-based <phrase>neurofuzzy</phrase> modelling and the <phrase>linguistic</phrase> attributes of <phrase>fuzzy logic</phrase> in a <phrase>single</phrase> cohesive <phrase>mathematical</phrase> framework. After <phrase>introducing</phrase> the <phrase>basic</phrase> theory of <phrase>data</phrase> <phrase>based modelling</phrase>, new concepts including extended <phrase>additive and multiplicative</phrase> submodels are developed and their extensions to <phrase>state</phrase> estimation and <phrase>data fusion</phrase> are derived. All of these <phrase>algorithms</phrase> are illustrated with benchmark and <phrase>real-life</phrase> examples to demonstrate their efficiency. The <phrase>book</phrase> aims at researchers and <phrase>advanced</phrase> professionals in <phrase>time series</phrase> modelling, <phrase>empirical data</phrase> modelling, <phrase>knowledge</phrase> discovery, <phrase>data mining</phrase> and <phrase>data fusion</phrase>.
<phrase>Constraint Databases</phrase>
A <phrase>Concurrent Pascal</phrase> <phrase>Compiler</phrase> for Minicomputers
Fehlererkennung und Fehlerbehandlung in Speicherungsstrukturen <phrase>von Datenbanksystemen</phrase>
Optimization of <phrase>SQL</phrase> Queries for <phrase>Parallel</phrase> Machines
<phrase>Parallel</phrase> execution offers a method for <phrase>reducing</phrase> the <phrase>response time</phrase> of queries against <phrase>large databases</phrase>. We address the problem of <phrase>parallel query optimization</phrase>: Given a <phrase>declarative</phrase> <phrase>SQL</phrase> query, find a <phrase>procedural</phrase> <phrase>parallel</phrase> plan that delivers the <phrase>query result</phrase> in <phrase>minimal</phrase> time. We develop <phrase>optimization algorithms</phrase> using models that incorporate both sources and obstacles to speedup. We address <phrase>independent</phrase>, <phrase>pipelined</phrase> and <phrase>partitioned</phrase> parallelism. We incorporate inherent constraints on available parallelism and the <phrase>extra cost</phrase> of <phrase>parallel</phrase> execution. Our models are motivated by experiments with <phrase>NonStop SQL</phrase>, a commercial <phrase>parallel</phrase> <phrase>DBMS</phrase>. We adopt a <phrase>two-phase</phrase> approach to <phrase>parallel query optimization</phrase>: JOQR (<phrase>join ordering</phrase> and <phrase>query rewrite</phrase>), followed by <phrase>parallelization</phrase>. JOQR minimizes total work. Then, <phrase>parallelization</phrase> spreads work among processors to minimize <phrase>response time</phrase>. For JOQR, we <phrase>model</phrase> <phrase>communication</phrase> costs and <phrase>abstract</phrase> <phrase>physical characteristics</phrase> of <phrase>data</phrase> as colors. We devise <phrase>tree</phrase> <phrase>coloring</phrase> and reordering <phrase>algorithms</phrase> that are <phrase>efficient</phrase> and <phrase>optimal</phrase>. We <phrase>model</phrase> <phrase>parallelization</phrase> as scheduling a <phrase>tree</phrase> whose <phrase>nodes represent</phrase> operators and <phrase>edges represent</phrase> <phrase>parallel</phrase>/<phrase>precedence constraints</phrase>. Computation/<phrase>communication</phrase> costs are represented as node/<phrase>edge weights</phrase>. We prove <phrase>worst-case</phrase> bounds on the <phrase>performance ratios</phrase> of our <phrase>algorithms</phrase> and measure <phrase>average</phrase> cases using <phrase>simulation</phrase>. Our <phrase>results</phrase> enable the <phrase>construction</phrase> of <phrase>SQL</phrase> compilers that <phrase>effectively exploit</phrase> <phrase>parallel</phrase> machines.
<phrase>Non-Standard</phrase> Inferences in <phrase>Description Logics</phrase>
Portable Methodenmonitoren: Dialogsysteme <phrase>zur Steuerung von</phrase> Methodenbanken, softwaretechnischer <phrase>Aufbau und</phrase> Effizienzanalyse
<phrase>Bibliography</phrase> on <phrase>Abstract Data Types</phrase>, Sponsored by the "Österr. Fonds <phrase>zur Förderung der</phrase> Wissenschaftlichen <phrase>Forschung</phrase>"
NEWCAT: <phrase>Parsing</phrase> <phrase>Natural Language</phrase> Using Left-<phrase>Associative</phrase> <phrase>Grammar</phrase>
SEMPER - <phrase>Secure</phrase> <phrase>Electronic Marketplace</phrase> for <phrase>Europe</phrase>
Überlast in <phrase>Rechensystemen</phrase>: <phrase>Modellierung</phrase> und Verhinderung
<phrase>Part-Whole</phrase> Reasoning in an <phrase>Object-Centered</phrase> Framework
On the <phrase>Computational Geometry</phrase> of <phrase>Pocket Machining</phrase>
<phrase>Semantische</phrase> <phrase>Repräsentation</phrase> komplexer Objektstrukturen: <phrase>Modelle</phrase> für nichtkonventionelle Datenbankanwendungen
Symbolische und konnektionistische <phrase>Modelle der</phrase> menschlichen <phrase>Informationsverarbeitung</phrase> - <phrase>Eine kritische</phrase> Gegenüberstellung
Modelling <phrase>Spatial</phrase> <phrase>Knowledge</phrase> on a <phrase>Linguistic</phrase> Basis: Theory - <phrase>Prototype</phrase> - <phrase>Integration</phrase>
The Use of <phrase>Projective Geometry</phrase> in <phrase>Computer Graphics</phrase>
Datenbankeinsatz.
<phrase>Interactive Markov Chains</phrase>: The <phrase>Quest</phrase> for Quantified Quality
Out of Their <phrase>Minds</phrase>: The Lives and Discoveries of 15 Great <phrase>Computer Scientists</phrase>.
<phrase>Qualitative</phrase> Representation of <phrase>Spatial</phrase> <phrase>Knowledge</phrase>
Directions in <phrase>Human Factors</phrase> for <phrase>Interactive Systems</phrase>
Mehrbenutzerkontrolle in Nicht-Standard-<phrase>Datenbanksystemen</phrase>
Grup Theoretical Methods in <phrase>Image Processing</phrase>
Uncertain <phrase>Projective Geometry</phrase>: <phrase>Statistical Reasoning</phrase> for <phrase>Polyhedral</phrase> <phrase>Object Reconstruction</phrase>
<phrase>Petri-Netz</phrase>-<phrase>Methoden und -Werkzeuge</phrase>: <phrase>Hilfsmittel zur</phrase> Entwurfsspezifikation und -validation <phrase>von Rechensystemen</phrase>
<phrase>A Comparative Study</phrase> of <phrase>Very Large Data Bases</phrase>
The <phrase>Nested</phrase> <phrase>Universal</phrase> Relation <phrase>Database</phrase> <phrase>Model</phrase>
<phrase>Anaphora</phrase> in <phrase>Natural Language Understanding</phrase>: <phrase>A Survey</phrase>
A problem that all <phrase>computer-based</phrase> <phrase>natural language understanding</phrase> (NLU) systems encounter is that of <phrase>linguistic</phrase> reference, and in particular <phrase>anaphora</phrase> (abbreviated reference). For example, in a text as simple as: \begin{quote} Nadia showed <phrase>Sue</phrase> her new <phrase>car</phrase>. The seats were Day-Glo <phrase>orange</phrase>. \end{quote} <phrase>knowing</phrase> that <phrase>``</phrase>her'''' probably means Nadia and not <phrase>Sue</phrase> and that <phrase>``</phrase>the seats'''' means the seats of Nadia''<phrase>s</phrase> new <phrase>car</phrase> is not a simple task. .<phrase>br</phrase> This <phrase>thesis</phrase> is an extensive review of the reference and anaphor problem, and the approaches to it that NLU systems have taken, from early systems such as <phrase>STUDENT</phrase> through to current <phrase>discourse</phrase>-oriented ones such as <phrase>PAL</phrase>. .<phrase>br</phrase> The problem is first examined in detail, and examples are given of many different types of anaphor, some of which have been ignored by <phrase>previous authors</phrase>. The approaches taken in traditional systems are then described and abstracted and it is shown why they were inadequate, and why <phrase>discourse</phrase> <phrase>theme</phrase> and <phrase>anaphoric</phrase> focus need to be taken into account. The <phrase>strengths and weaknesses</phrase> of current <phrase>anaphora</phrase> theories and approaches are evaluated. The <phrase>thesis</phrase> closes with a list of some remaining <phrase>research</phrase> problems. .<phrase>br</phrase> The <phrase>thesis</phrase> has been written so as to be as comprehensible as possible to both <phrase>AI</phrase> workers who know no <phrase>linguistics</phrase>, and <phrase>linguists</phrase> who have not studied <phrase>artificial intelligence</phrase>.
<phrase>Planen</phrase> <phrase>für autonome</phrase> Montageroboter
Utilizing <phrase>Problem Structure</phrase> in <phrase>Planning</phrase>, A <phrase>Local</phrase> Search Approach
Call-By-<phrase>Push</phrase>-Value: A <phrase>Functional</phrase>/Imperative <phrase>Synthesis</phrase>
<phrase>Group</phrase>-Theoretic <phrase>Algorithms</phrase> and <phrase>Graph Isomorphism</phrase>
<phrase>Interaktives</phrase> Entwerfen großer Programmsysteme: <phrase>Konzepte und</phrase> <phrase>Werkzeuge</phrase>
A <phrase>Generative</phrase> Theory of Shape, <phrase>Questioning</phrase> Klein's <phrase>Erlanger</phrase> Program
Elements of <phrase>Finite Model Theory</phrase>
<phrase>Die</phrase> <phrase>Konfigurierung</phrase> <phrase>modular</phrase> aufgebauter <phrase>Datenbanksysteme</phrase>
<phrase>Iterative</phrase> <phrase>Software Engineering</phrase> for <phrase>Multiagent Systems</phrase>: The <phrase>MASSIVE</phrase> Method
:"The <phrase>book</phrase> will serve as a valuable source of reference for <phrase>R&D</phrase> professionals <phrase>active</phrase> in <phrase>agent-based</phrase> <phrase>computing</phrase> as well as a <phrase>gentle</phrase> and <phrase>systematic</phrase> <phrase>introduction</phrase> to <phrase>agent-based systems</phrase> development and analysis for <phrase>software</phrase> engineers and <phrase>advanced</phrase> students."--<phrase>BOOK</phrase> <phrase>JACKET</phrase>.
Composition of <phrase>Secure</phrase> <phrase>Multi-Party</phrase> Protocols, A <phrase>Comprehensive</phrase> Study
<phrase>Dynamische</phrase> Integrität <phrase>von Datenbanken</phrase>: <phrase>Grundlagen</phrase> der <phrase>Spezifikation und</phrase> <phrase>Überwachung</phrase>
CLU <phrase>Reference Manual</phrase>
<phrase>Synthesising</phrase> <phrase>Synchronous</phrase> Systems by <phrase>Static Scheduling</phrase> in <phrase>Space-Time</phrase>
Foundations of <phrase>Logic Programming</phrase>, <phrase>1st Edition</phrase>
Foundations of <phrase>Logic Programming</phrase>, <phrase>2nd Edition</phrase>
Datenbankhandbuch.
<phrase>Web</phrase>-<phrase>Datenbanken</phrase>: <phrase>Einsatz</phrase> <phrase>objekt</phrase>-relationaler <phrase>Datenbanken</phrase> für <phrase>Web</phrase>-<phrase>Informationssysteme</phrase>
The Dynamics of Concepts - A <phrase>Connectionist</phrase> <phrase>Model</phrase>
<phrase>Parallele</phrase> <phrase>Implementierung</phrase> funktionaler <phrase>Programmiersprachen</phrase>
Towards a <phrase>CSCW</phrase> Framework for <phrase>Scientific Cooperation</phrase> in <phrase>Europe</phrase>
<phrase>ANNA</phrase> - A <phrase>Language</phrase> for <phrase>Annotating</phrase> <phrase>Ada</phrase> Programs, <phrase>Reference Manual</phrase>
Attributierte Grammatiken und Attributierungsalgorithmen
Exceptionbehandlung und <phrase>Synchronisation</phrase> - <phrase>Entwurf</phrase> und <phrase>Methode</phrase>
<phrase>Ein</phrase> inhaltsadressierbares Speichersystem <phrase>zur Unterstützung</phrase> zeitkritischer <phrase>Prozesse</phrase> der Informationswiedergewinnung in <phrase>Datenbanksystemen</phrase>
Fehlertolerante dezentrale Prozeßautomatisierung
<phrase>Entwurf und Realisierung</phrase> eines Multiprozessors
<phrase>Fehlerdiagnose</phrase> für Schaltnetze aus Modulen <phrase>mit</phrase> partiell injektiven Pfadfunktionen
Coroutines: A <phrase>Programming</phrase> Methodology, a <phrase>Language</phrase> <phrase>Design</phrase> and an Implementation
<phrase>Coordinating</phrase> Plans of <phrase>Autonomous Agents</phrase>
<phrase>PISA</phrase>: A <phrase>Programming</phrase> System for Interactive <phrase>Production</phrase> of <phrase>Application Software</phrase>
<phrase>Verteilte</phrase> Basisalgorithmen
An Approach to <phrase>Knowledge Base</phrase> <phrase>Management</phrase>
Relevanzanalyse: <phrase>Eine</phrase> <phrase>Kombination von</phrase> Striktheits- und Datenflußanalyse <phrase>zur effizienten</phrase> <phrase>Auswertung</phrase> funktionaler <phrase>Programme</phrase>
<phrase>Automated Deduction</phrase> in <phrase>Equational Logic</phrase> and <phrase>Cubic</phrase> Curves
Advances in <phrase>Cryptology</phrase> 1981-1997, <phrase>Electronic</phrase> <phrase>Proceedings</phrase> and <phrase>Index</phrase> of the <phrase>CRYPTO</phrase> and <phrase>EUROCRYPT</phrase> <phrase>Conferences</phrase> 1981-1997
<phrase>Data Structures</phrase> and <phrase>Algorithms</phrase> 1: <phrase>Sorting</phrase> and Searching
<phrase>Data Structures</phrase> and <phrase>Algorithms</phrase> 2: <phrase>Graph</phrase> <phrase>Algorithms</phrase> and <phrase>NP-Completeness</phrase>
<phrase>Data Structures</phrase> and <phrase>Algorithms</phrase> 3
<phrase>Erweiterung</phrase> relationaler <phrase>Datenbanksysteme</phrase> für <phrase>technische</phrase> <phrase>Anwendungen</phrase>
<phrase>Modified</phrase> <phrase>Branching</phrase> Programs and Their <phrase>Computational Power</phrase>
<phrase>WWW</phrase> - <phrase>Kommunikation</phrase>, <phrase>Internetworking</phrase>, <phrase>Web</phrase>-<phrase>Technologien</phrase>
<phrase>Algorithms</phrase> and <phrase>Data</phrase> Structures in <phrase>VLSI</phrase> <phrase>Design</phrase>: <phrase>OBDD</phrase> - Foundations and Applications
<phrase>Algorithmen und Datenstrukturen</phrase> <phrase>im</phrase> <phrase>VLSI</phrase>-<phrase>Design</phrase>: <phrase>OBDD</phrase> - <phrase>Grundlagen und Anwendungen</phrase>
<phrase>Randomness</phrase> and <phrase>Completeness</phrase> in <phrase>Computational Complexity</phrase>
<phrase>Computational complexity</phrase> studies the inherent difficulty of <phrase>computational problems</phrase> and the power of the tools we may use to solve them. We focus on <phrase>randomness</phrase> and look at several properties of <phrase>complete problems</phrase> to investigate its role as well as issues about <phrase>nondeterminism</phrase>, <phrase>alternation</phrase>, and space versus time. We investigate the use of <phrase>randomness</phrase> in the <phrase>area</phrase> of <phrase>proof checking</phrase>. By <phrase>derandomizing Arthur-Merlin games</phrase>, we show that every <phrase>language</phrase> with a <phrase>bounded</phrase> <phrase>round interactive proof</phrase> system has <phrase>subexponential</phrase> size proofs unless <phrase>the polynomial-time hierarchy collapses</phrase>. This provides the first <phrase>strong evidence</phrase> that <phrase>graph</phrase> nonisomorphism has <phrase>subexponential</phrase> size proofs of membership. Under a stronger <phrase>hypothesis</phrase> we can scale the proof size down to <phrase>polynomial</phrase>. We also show how our approach applies to several <phrase>randomized</phrase> processes other than <phrase>Arthur-Merlin games</phrase>. We develop techniques for <phrase>separating complexity classes</phrase> by <phrase>isolating</phrase> a <phrase>structural</phrase> difference between their <phrase>complete languages</phrase>. We look at several properties from this <phrase>perspective</phrase>: The <phrase>density</phrase> of <phrase>complete languages</phrase>, the redundancy in <phrase>complete languages</phrase>, and the <phrase>frequency</phrase> of occurrence of <phrase>completeness</phrase>. We show that there is no <phrase>sparse</phrase> hard <phrase>language</phrase> for <phrase>polynomial</phrase> time under <phrase>logarithmic space</phrase> reductions with a <phrase>bounded</phrase> number of queries unless <phrase>polynomial</phrase> time collapses to <phrase>logarithmic</phrase> space. The same approach works for various other <phrase>complexity classes</phrase>, in the <phrase>deterministic</phrase> as well as in the <phrase>randomized</phrase> setting. Autoreducibility defines the most <phrase>general</phrase> type of <phrase>efficient</phrase> reduction of a problem to itself. We show that <phrase>settling</phrase> the question whether all <phrase>complete languages</phrase> for <phrase>doubly exponential</phrase> time are autoreducible would yield <phrase>major</phrase> <phrase>separations</phrase>: If <phrase>yes</phrase>, we have a proof that <phrase>polynomial</phrase> time differs from <phrase>polynomial</phrase> space, and <phrase>nondeterministic</phrase> <phrase>logarithmic</phrase> space from <phrase>nondeterministic</phrase> <phrase>polynomial</phrase> time; if no, we can separate the <phrase>polynomial</phrase>-time hierarchy from <phrase>exponential time</phrase>. <phrase>Resource-bounded</phrase> measure formalizes the notions of scarceness and abundance within <phrase>complexity classes</phrase>. From the <phrase>separation</phrase> <phrase>point of view</phrase>, the theory seems particularly suited for <phrase>separating</phrase> <phrase>randomized</phrase> <phrase>polynomial</phrase> time from <phrase>exponential time</phrase>. We develop several strategies using <phrase>resource-bounded</phrase> measure aimed at <phrase>realizing</phrase> that goal: Showing a difference in measure between the hard languages of these classes, a <phrase>probabilistic method</phrase> approach, and the concept of <phrase>betting</phrase> <phrase>games</phrase>.
<phrase>Generic Model Management</phrase>: Concepts and <phrase>Algorithms</phrase>
A <phrase>Calculus of Communicating Systems</phrase>
<phrase>Ein</phrase> Molekül-<phrase>Atom</phrase>-Datenmodell für <phrase>Non-Standard</phrase>-<phrase>Anwendungen</phrase>: Anwendungsanalyse, Datenmodellentwurf und Implementierungskonzepte
Inkonsistenzen in <phrase>deduktiven Datenbanken</phrase>: <phrase>Diagnose und</phrase> Reparatur
Prinzipien piktorieller Repräsentationssysteme, <phrase>Untersuchungen zur</phrase> bildhaften <phrase>Repräsentation von</phrase> <phrase>Wissen</phrase> in informationsverarbeitenden <phrase>Systemen</phrase>
<phrase>An Introduction</phrase> to <phrase>Formal Language Theory</phrase>
<phrase>CASL</phrase> <phrase>Reference Manual</phrase>, The Complete Documentation of the <phrase>Common Algebraic Specification Language</phrase>
<phrase>Live</phrase> <phrase>Data Structures</phrase> in <phrase>Logic</phrase> Programs: <phrase>Derivation</phrase> by Means of <phrase>Abstract Interpretation</phrase>
<phrase>Modular</phrase> Specification and Verification of <phrase>Object-Oriented</phrase> Programs
This <phrase>book</phrase> presents new techniques for the <phrase>formal specification</phrase> and verification of <phrase>object-oriented</phrase> <phrase>software</phrase>. Since modularity is of critical importance for reuse and <phrase>component-based</phrase> <phrase>programming</phrase>, <phrase>special emphasis</phrase> is given to the <phrase>completeness</phrase> of the presented <phrase>specification techniques</phrase> to allow module <phrase>verification based</phrase> on the specification of the imported modules. A <phrase>formal framework</phrase> developed for a <phrase>Java</phrase> <phrase>subset</phrase> illustrates these new techniques.
Realistische <phrase>Computergraphik</phrase>: <phrase>Algorithmen</phrase>, <phrase>Datenstrukturen</phrase> und Maschinen
The <phrase>Design</phrase> of <phrase>Intelligent Agents</phrase> - A <phrase>Layered</phrase> Approach
<phrase>Modular</phrase> <phrase>Compiler</phrase> Verification - A <phrase>Refinement</phrase>-<phrase>Algebraic</phrase> Approach Advocating <phrase>Stepwise</phrase> Abstraction
The Complexity of Simple <phrase>Computer Architectures</phrase>
<phrase>Handbook</phrase> of <phrase>Networked</phrase> and <phrase>Embedded Control Systems</phrase>
<phrase>Transactional</phrase> Agents: Towards a <phrase>Robust Multi</phrase>-Agent System
<phrase>Negation</phrase> and Control in <phrase>Prolog</phrase>
<phrase>Constraint-Based</phrase> Agents
<phrase>Quality-Driven</phrase> <phrase>Query Answering</phrase> for <phrase>Integrated Information Systems</phrase>
The <phrase>Internet</phrase> and <phrase>the World Wide Web</phrase> are <phrase>becoming increasingly important</phrase> in our <phrase>highly interconnected</phrase> world. This <phrase>book</phrase> addresses the topic of <phrase>querying</phrase> the <phrase>data</phrase> available, with regard to its quality, in a <phrase>systematic</phrase> and <phrase>comprehensive</phrase> way, from a <phrase>database</phrase> <phrase>point of view</phrase>. First, <phrase>information</phrase> quality and <phrase>information quality</phrase> measures are systematically introduced before <phrase>ranking algorithms</phrase> are developed for <phrase>selecting</phrase> <phrase>Web</phrase> sources for access. The second part is devoted to <phrase>quality-driven</phrase> <phrase>query answering</phrase>, particularly to <phrase>query planning</phrase> methods and <phrase>algorithms</phrase>.
<phrase>Automated</phrase> Modeling of <phrase>Physical Systems</phrase>
The <phrase>Newton</phrase>-<phrase>Cauchy</phrase> Framework: <phrase>A Unified</phrase> Approach to <phrase>Unconstrained Nonlinear</phrase> Minimization
Reasoning and <phrase>Revision</phrase> in <phrase>Hybrid</phrase> Representation Systems
Computation for <phrase>Metaphors</phrase>, <phrase>Analogy</phrase>, and Agents.
As <phrase>an introduction</phrase> to papers in this <phrase>book</phrase> we review the notion of <phrase>metaphor</phrase> in <phrase>language</phrase>, and of <phrase>metaphor</phrase> as conceptual, and as primary to <phrase>understanding</phrase>. Yet the view of <phrase>metaphor</phrase> here is more <phrase>general</phrase>. We propose a <phrase>constructive</phrase> view of <phrase>metaphor</phrase> as mapping or <phrase>synthesis</phrase> of meaning between domains, which need not be conceptual ones. These considerations have implications for <phrase>artificial intelligence</phrase> (<phrase>AI</phrase>), <phrase>human</phrase>-computer interaction (<phrase>HCI</phrase>), <phrase>algebraic structure</phrase>-<phrase>preservation</phrase>, <phrase>constructive</phrase> <phrase>biology</phrase>, and <phrase>agent design</phrase>. In this larger setting for <phrase>metaphor</phrase>, contributions of the <phrase>selected papers</phrase> are overviewed and <phrase>key aspects</phrase> of computation for <phrase>metaphors</phrase>, <phrase>analogy</phrase> and agents highlighted.
<phrase>Probability</phrase>, Stocastic Processes, and <phrase>Queuing Theory</phrase> - The <phrase>Mathematics</phrase> of Computer <phrase>Performance Modeling</phrase>.
<phrase>Probabilistic</phrase> and <phrase>Statistical Methods</phrase> in <phrase>Cryptology</phrase>, <phrase>An Introduction</phrase> by <phrase>Selected Topics</phrase>
Foundations of <phrase>Inductive Logic Programming</phrase>
<phrase>Context-Free Grammars</phrase>: Covers, <phrase>Normal Forms</phrase>, and <phrase>Parsing</phrase>
Principles of <phrase>Artificial Intelligence</phrase>
<phrase>Isabelle/HOL</phrase> - A <phrase>Proof Assistant</phrase> for <phrase>Higher-Order Logic</phrase>
Filtering, Segmentation and Depth
Temporally Distributed Symptoms in Technical <phrase>Diagnosis</phrase>
Textgenerierung aus visuellen <phrase>Daten</phrase>: Beschreibungen von Straßenszenen
<phrase>Computing</phrase> in Systems Described by Equations
Sprachkonzepte für benutzergerechte <phrase>Systeme</phrase>
<phrase>Chance Discovery</phrase>
<phrase>Coordination</phrase> of <phrase>Internet</phrase> Agents: Models, Technologies, and Applications
A <phrase>Formal Model</phrase> of Visualization in <phrase>Computer Graphics</phrase> Systems
<phrase>Reliability Evaluation</phrase> of Some <phrase>Fault-Tolerant</phrase> <phrase>Computer Architectures</phrase>
<phrase>Co-ordination</phrase> in <phrase>Artificial Agent Societies</phrase>, <phrase>Social Structure</phrase> and Its Implications for <phrase>Autonomous</phrase> <phrase>Problem-Solving</phrase> Agents.
:This <phrase>monograph</phrase> provides a <phrase>comprehensive</phrase> survey of the different approaches to <phrase>coordination</phrase> in <phrase>societies</phrase> of <phrase>artificial</phrase> and <phrase>human</phrase> agents. Setting out from a critical assessment of the <phrase>state</phrase> of the <phrase>art</phrase>, the <phrase>author</phrase> develops a method of <phrase>structuring</phrase> <phrase>multi-agent</phrase> applications with a mechanism called <phrase>structural</phrase> <phrase>cooperation</phrase>. Agents are equipped with expertise about their environment in <phrase>order</phrase> to detect and overcome specific types of problem, they make use of their <phrase>social knowledge</phrase> to mutually adjust their activities, and they are coerced <phrase>toward</phrase> <phrase>coherent</phrase> <phrase>collective behavior</phrase> through <phrase>normative</phrase> rules.
<phrase>Direct</phrase> Methods for <phrase>Sparse</phrase> Matrices
The <phrase>Design</phrase> of <phrase>Dynamic</phrase> <phrase>Data Structures</phrase>
<phrase>Constrained Global Optimization</phrase>: <phrase>Algorithms</phrase> and Applications
The Structure of the <phrase>Relational Database</phrase> <phrase>Model</phrase>
<phrase>Software</phrase> Frameworks and <phrase>Embedded Control Systems</phrase>
<phrase>Active</phrase> Rules in <phrase>Database Systems</phrase>
<phrase>Learning</phrase>-Based <phrase>Robot</phrase> Vision, Principles and Applications
The Deisgn of <phrase>an Extendible</phrase> <phrase>Graph</phrase> <phrase>Editor</phrase>
<phrase>Isabelle</phrase> - A <phrase>Generic Theorem Prover</phrase> (with a contribution by <phrase>T</phrase>. Nipkow)
<phrase>Synchronisation</phrase> in zentralisierten <phrase>Datenbanksystemen</phrase>: <phrase>Algorithmen</phrase>, Realisierungsmöglichkeiten und <phrase>quantitative</phrase> Analyse
<phrase>Data Mining</phrase> on <phrase>Multimedia</phrase> <phrase>Data</phrase>
<phrase>Computer Programs</phrase> for <phrase>Spelling Correction</phrase>: An Experiment in <phrase>Program Design</phrase>
<phrase>Compiling</phrase> <phrase>Natural Semantics</phrase>.
<phrase>Erzeugung</phrase> interaktiver Bildverarbeitungssysteme <phrase>im</phrase> <phrase>Dialog</phrase>: <phrase>Konzepte</phrase>, <phrase>Entwurf und Implementierung eines</phrase> Dialogsystems <phrase>für die</phrase> <phrase>Bildverarbeitung</phrase> in <phrase>der Medizin</phrase>
Diensteintegrierende Kommunikationsnetze <phrase>mit</phrase> teilnehmerüberprüfbarem <phrase>Datenschutz</phrase>
<phrase>Digital Signature</phrase> Schemes, <phrase>General</phrase> Framework and <phrase>Fail-Stop Signatures</phrase>
:This <phrase>book</phrase> is based on the <phrase>author's</phrase> <phrase>Ph.D</phrase>. <phrase>thesis</phrase> which was selected during the 1995 <phrase>GI</phrase> <phrase>Doctoral Dissertation</phrase> <phrase>Competition</phrase> as the <phrase>winning</phrase> <phrase>thesis</phrase> in the foundations-of-<phrase>informatics</phrase> <phrase>track</phrase>. Birgit Pfitzmann did her <phrase>Ph.D</phrase>. work at the <phrase>University</phrase> of <phrase>Hildesheim</phrase> with <phrase>Professor</phrase> Joachim Biskup as <phrase>advisor</phrase>. <phrase>Securing</phrase> integrity for <phrase>digital</phrase> communications in the <phrase>age</phrase> of <phrase>global</phrase> <phrase>electronic</phrase> <phrase>information</phrase> exchange and <phrase>electronic commerce</phrase> is of vital interest for <phrase>democratic</phrase> <phrase>societies</phrase> and a central <phrase>technical challenge</phrase> for cryptologists. As core contribution to <phrase>advancing</phrase> the <phrase>state</phrase> of the <phrase>art</phrase>, the <phrase>author</phrase> rigorously develops the new class of <phrase>digital</phrase> <phrase>fail-stop signatures</phrase>: in contrary to all <phrase>previously introduced</phrase> <phrase>digital signature</phrase> schemes, these new <phrase>signatures</phrase> enable the supposed signer to actually prove <phrase>forging</phrase> of the scheme in the case of a successful attack. This <phrase>monograph</phrase> is <phrase>self-contained</phrase> with respect to the <phrase>historical</phrase> background and <phrase>cryptographic</phrase> primitives used. For the first time, a <phrase>general</phrase> and sophisticated framework is introduced in which <phrase>previously proposed</phrase> and the innovative failstop <phrase>signatures</phrase> are systematically presented and evaluated, from <phrase>theoretical foundations</phrase> up to <phrase>engineering</phrase> aspects. Thus the <phrase>book</phrase> is compulsory <phrase>reading</phrase> for anybody interested in <phrase>secure digital</phrase> <phrase>communication</phrase> at the <phrase>professional</phrase> level.
<phrase>On-line</phrase> <phrase>Error Detection</phrase> and <phrase>Fast</phrase> Recover Techniques for <phrase>Dependable Embedded</phrase> Processors
This <phrase>book</phrase> presents a new approach to <phrase>on-line</phrase> observation and <phrase>concurrent</phrase> checking of processors by <phrase>refining</phrase> and <phrase>improving</phrase> known techniques and <phrase>introducing</phrase> new ideas.The proposed <phrase>on-line</phrase> <phrase>error detection</phrase> and <phrase>fast</phrase> recover techniques support and <phrase>complement</phrase> other established methods. In combination with other <phrase>on-line</phrase> observation priniciples and with a combined <phrase>hardware-software</phrase> <phrase>test</phrase>, these techniques are used to fulfill a complete self-check scheme for an <phrase>embedded processor</phrase>.
<phrase>Design</phrase> of <phrase>Hashing</phrase> <phrase>Algorithms</phrase>
CONLAN <phrase>Report</phrase>
<phrase>Termination</phrase> Proofs for <phrase>Logic</phrase> Programs
<phrase>Spatial</phrase> Representation and <phrase>Motion Planning</phrase>
<phrase>Compiler</phrase> Specification and Verification
<phrase>Computational Geometry</phrase> - <phrase>An Introduction</phrase>.
Diagnostisches Problemlösen <phrase>mit</phrase> <phrase>Expertensystemen</phrase>
<phrase>Model-Checking</phrase> Based <phrase>Data</phrase> Retrieval, An Application to <phrase>Semistructured</phrase> and <phrase>Temporal Data</phrase>
Multisensordatenverarbeitung in <phrase>der Robotik</phrase>
<phrase>Synchronisation</phrase> in Mehrrechner-<phrase>Datenbanksystemen</phrase> - <phrase>Konzepte</phrase>, Realisierungsformen und <phrase>quantitative</phrase> Bewertung
<phrase>Automatic Differentiation</phrase>: Techniques and Applications
<phrase>Bounded</phrase> <phrase>Incremental</phrase> Computation
Audio System for Technical Readings.
The advent of <phrase>electronic</phrase> documents makes <phrase>information</phrase> available in more than its <phrase>visual</phrase> form <phrase>electronic</phrase> <phrase>information</phrase> can now be display-<phrase>independent</phrase>. We describe a <phrase>computing</phrase> system, <phrase>ASTER</phrase>, that audio formats <phrase>electronic</phrase> documents to produce <phrase>audio documents</phrase>. <phrase>ASTER</phrase> can speak both <phrase>literary</phrase> texts and highly <phrase>technical documents</phrase> (<phrase>presently</phrase> in <phrase>LaTeX</phrase>) that contain complex <phrase>mathematics</phrase>. <phrase>Visual communication</phrase> is characterized by the <phrase>eye</phrase>''<phrase>s</phrase> ability to actively access parts of a <phrase>two-dimensional</phrase> display. The <phrase>reader</phrase> is <phrase>active</phrase>, while the display is <phrase>passive</phrase>. This <phrase>active-passive</phrase> role is reversed by the temporal <phrase>nature</phrase> of <phrase>oral communication</phrase>: <phrase>information</phrase> flows actively past a <phrase>passive</phrase> <phrase>listener</phrase>. This prohibits <phrase>multiple views</phrase> it is impossible to first obtain a <phrase>high</phrase>-level view and then <phrase>``</phrase>look'''' at details. These shortcomings become severe when presenting complex <phrase>mathematics</phrase> orally. Audio formatting, which renders <phrase>information</phrase> structure in a manner attuned to an <phrase>auditory</phrase> display, overcomes these problems. <phrase>ASTER</phrase> is interactive, and the ability to browse <phrase>information</phrase> structure and obtain <phrase>multiple views</phrase> enables <phrase>active listening</phrase>.
<phrase>Aspect-Oriented</phrase> <phrase>Database Systems</phrase>
<phrase>Design</phrase> and Control of <phrase>Workflow</phrase> Processes: <phrase>Business Process Management</phrase> for the <phrase>Service Industry</phrase>
<phrase>FRM</phrase>: <phrase>Ein</phrase> Frame-Repräsentationsmodell <phrase>und seine</phrase> <phrase>formale</phrase> <phrase>Semantik</phrase>: <phrase>Zur Integration von</phrase> <phrase>Datenbank</phrase>- und Wissensrepräsentationsansätzen
Focusing Solutions for <phrase>Data Mining</phrase>: <phrase>Analytical Studies</phrase> and <phrase>Experimental</phrase> <phrase>Results</phrase> in <phrase>Real-World</phrase> Domains
Spielbaum-Suchverfahren
By themselves, <phrase>speech recognition</phrase> and <phrase>natural language processing</phrase> have limited applications, the reason is that each only accomplishes a part of what humans are capable of when they use <phrase>language</phrase>. <phrase>Spoken language</phrase> systems represent the <phrase>merger</phrase> of these two technologies and provide <phrase>an integrated</phrase> functionality that more <phrase>closely approximates</phrase> humans capabilities in <phrase>speech communication</phrase>.
The <phrase>Traveling Salesman</phrase>, Computational Solutions for <phrase>TSP</phrase> Applications
Petrinetze, <phrase>Eine Einführung</phrase>
Systementwurf <phrase>mit</phrase> <phrase>Netzen</phrase>
<phrase>Petri Nets</phrase>: <phrase>An Introduction</phrase>
Petrinetze, <phrase>Eine Einführung</phrase>, 2. Auflage
Elements of <phrase>distributed algorithms</phrase>: modeling and analysis with <phrase>Petri nets</phrase>
<phrase>Recognizing</phrase> <phrase>Planar</phrase> Objects Using <phrase>Invariant Image</phrase> Features
<phrase>Qualitative Spatial Reasoning</phrase> with <phrase>Topological</phrase> <phrase>Information</phrase>
<phrase>Die</phrase> Interpretation <phrase>des Verhaltens</phrase> mehrerer Akteure in Szenenfolgen
<phrase>Introduction</phrase> to <phrase>Constraint Databases</phrase>
<phrase>Introduction</phrase> to <phrase>Constraint Databases</phrase> comprehensively covers both <phrase>constraint-database</phrase> theory and several sample systems. The <phrase>book</phrase> reveals how <phrase>constraint databases</phrase> bring together techniques from a <phrase>variety</phrase> of fields, such as <phrase>logic</phrase> and <phrase>model</phrase> thoery, <phrase>algebraic</phrase> and <phrase>computational geometry</phrase>, and <phrase>symbolic computation</phrase>, to the <phrase>design</phrase> and analysis of <phrase>data</phrase> models and <phrase>query languages</phrase>. <phrase>Constraint databases</phrase> are shown to be powerful and simple tools for <phrase>data</phrase> modeling and <phrase>querying</phrase> in <phrase>application areas</phrase>---such as <phrase>environmental</phrase> modeling, <phrase>bioinformatics</phrase>, and <phrase>computer vision</phrase>---that are not suitable for <phrase>relational databases</phrase>. <phrase>Specific applications</phrase> are examined in <phrase>geographic information systems</phrase>, <phrase>spatiotemporal</phrase> <phrase>data management</phrase>, <phrase>linear programming</phrase>, <phrase>genome</phrase> <phrase>databases</phrase>, <phrase>model checking</phrase> of <phrase>automata</phrase>, and other areas.
<phrase>Coevolutionary</phrase> <phrase>Fuzzy Modeling</phrase>
The <phrase>Cray X-MP</phrase>/<phrase>Model</phrase> 24, <phrase>A Case Study</phrase> in <phrase>Pipelined</phrase> <phrase>Architecture</phrase> and <phrase>Vector</phrase> Processing
Intelligent <phrase>Perceptual</phrase> Systems: <phrase>New Directions</phrase> in Computational <phrase>Perception</phrase>
<phrase>Broadband</phrase> Network <phrase>Teletraffic</phrase> - <phrase>Performance Evaluation</phrase> and <phrase>Design</phrase> of <phrase>Broadband</phrase> <phrase>Multiservice Networks</phrase>: <phrase>Final Report</phrase> of <phrase>Action</phrase> COST 242
<phrase>Neural Nets</phrase> - A Theory for <phrase>Brains</phrase> and Machines
<phrase>Parallele</phrase> <phrase>Systeme</phrase>
<phrase>Feedback Shift Registers</phrase>
Entscheidungsorientiertes Konfigurationsmagament
CyberLaw: The <phrase>Law</phrase> of the <phrase>Internet</phrase>
Kommunikationskonzepte <phrase>für verteilte</phrase> transaktionsorientierte <phrase>Systeme</phrase>
A Connotational Theory of <phrase>Program Structure</phrase>
<phrase>Efficient</phrase> <phrase>Visual</phrase> Recognition Using the <phrase>Hausdorff</phrase> Distance
<phrase>Operational Semantics</phrase> for <phrase>Timed</phrase> Systems: A <phrase>Non-standard</phrase> Approach to <phrase>Uniform</phrase> Modeling of <phrase>Timed</phrase> and <phrase>Hybrid</phrase> Systems
Interacting <phrase>Code Motion</phrase> Transformations: Their Impact and Their Complexity.
Kryptographische <phrase>Verfahren</phrase> in <phrase>der Datenverarbeitung</phrase>
Computational <phrase>Cardiology</phrase>: Modeling of <phrase>Anatomy</phrase>, <phrase>Electrophysiology</phrase>, and <phrase>Mechanics</phrase>
<phrase>Darstellung und</phrase> <phrase>Nutzung von</phrase> Expertenwissen <phrase>für ein</phrase> Bildanalysesystem
<phrase>Data Compression</phrase>: The Complete Reference, <phrase>3rd Edition</phrase>
A <phrase>Relational</phrase> Theory of <phrase>Computing</phrase>
Using Sophisticated Models in <phrase>Resolution Theorem Proving</phrase>
<phrase>Workflow</phrase> <phrase>Management</phrase> Systems for Process Organisations
<phrase>View Synthesis</phrase> Using <phrase>Stereo</phrase> Vision
This <phrase>thesis</phrase> investigates the use of <phrase>stereo</phrase> vision for the application of <phrase>view synthesis</phrase>. <phrase>View synthesis</phrase> --the problem of <phrase>creating</phrase> images of a scene as it would appear from novel viewpoints --has traditionally been approached using methods from <phrase>computer graphics</phrase>. These methods, however, suffer from low <phrase>rendering speed</phrase>, limited achievable realism, and, most severely, their dependence on a <phrase>global</phrase> scene <phrase>model</phrase>, which typically needs to be constructed manually. In this <phrase>thesis</phrase>, we present a new approach to <phrase>view synthesis</phrase> that avoids the above problems by <phrase>synthesizing</phrase> new views from existing images of a scene. Using an <phrase>image-based</phrase> representation of <phrase>scene geometry</phrase> computed by <phrase>stereo</phrase> vision methods, a <phrase>global</phrase> <phrase>model</phrase> can be avoided, and realistic new views can be synthesized quickly using <phrase>image warping</phrase>. The new application of <phrase>stereo</phrase> for <phrase>view synthesis</phrase> makes it necessary to <phrase>re</phrase>-evaluate the requirements on <phrase>stereo</phrase> <phrase>algorithms</phrase>. We compare <phrase>view synthesis</phrase> to several traditional applications of <phrase>stereo</phrase>, and conclude that <phrase>stereo</phrase> vision is better suited for <phrase>view synthesis</phrase> than for <phrase>applications requiring</phrase> explicit 3D <phrase>reconstruction</phrase>. We also discuss ways of dealing with <phrase>partially occluded</phrase> regions of unknown depth and with completely <phrase>occluded regions</phrase> of unknown texture, and present <phrase>experiments demonstrating</phrase> that it is possible to efficiently <phrase>synthesize realistic</phrase> new views even from inaccurate and incomplete <phrase>depth information</phrase>. This <phrase>thesis</phrase> also contributes several novel <phrase>stereo</phrase> <phrase>algorithms</phrase> that are motivated by the <phrase>specific requirements</phrase> imposed by <phrase>view synthesis</phrase>. We introduce a new evidence measure based on <phrase>intensity gradients</phrase> for establishing correspondences between images. This measure combines the notions of similarity and confidence, and allows <phrase>stable</phrase> matching and easy assigning of <phrase>canonical</phrase> depth interpretations in <phrase>image regions</phrase> of insufficient <phrase>information</phrase>. We also present new <phrase>diffusion</phrase>-based <phrase>stereo</phrase> <phrase>algorithms</phrase> that are motivated by the need to correctly recover <phrase>object boundaries</phrase>. In particular, we develop a novel <phrase>Bayesian estimation</phrase> technique that <phrase>significantly outperforms</phrase> <phrase>area</phrase>-<phrase>based algorithms</phrase> using <phrase>fixed-sized</phrase> <phrase>windows</phrase>. We provide <phrase>experimental</phrase> <phrase>results</phrase> for all <phrase>algorithms</phrase> on both <phrase>synthetic and real images</phrase>.
The <phrase>Automation</phrase> of Reasoning with <phrase>Incomplete Information</phrase>, From <phrase>Semantic</phrase> Foundations to <phrase>Efficient</phrase> Computation.
<phrase>Universal</phrase> <phrase>Routing Strategies</phrase> for <phrase>Interconnection Networks</phrase>
<phrase>Bildanalyse</phrase> allgemeiner Dokumente
Migrationssteuerung und Konfigurationsverwaltung <phrase>für verteilte</phrase> <phrase>objektorientierte</phrase> <phrase>Anwendungen</phrase>
<phrase>Nonmonotonic Logics</phrase>, <phrase>Basic</phrase> Concepts, <phrase>Results</phrase>, and Techniques
<phrase>Inductive Synthesis</phrase> of <phrase>Functional</phrase> Programs, <phrase>Universal</phrase> <phrase>Planning</phrase>, <phrase>Folding</phrase> of Finite Programs, and Schema Abstraction by <phrase>Analogical Reasoning</phrase>
<phrase>Computational Aspects</phrase> of an <phrase>Order-Sorted Logic</phrase> with Term Declarations
<phrase>GPSS-FORTRAN</phrase>, Version <phrase>II</phrase>: <phrase>Einführung in die</phrase> <phrase>Simulation</phrase> diskreter <phrase>Systeme</phrase> <phrase>mit</phrase> Hilfe eines <phrase>FORTRAN</phrase>-Programmpaketes
<phrase>Meta-Level</phrase> Control for <phrase>Deductive</phrase> <phrase>Database Systems</phrase>
Relationen und <phrase>Graphen</phrase>
Relations and <phrase>Graphs</phrase> - <phrase>Discrete Mathematics</phrase> for <phrase>Computer Scientists</phrase>
<phrase>Theorie der</phrase> <phrase>logischen Programmierung</phrase>
<phrase>Spatial Data</phrase> Types for <phrase>Database Systems</phrase>, <phrase>Finite Resolution</phrase> <phrase>Geometry</phrase> for <phrase>Geographic Information Systems</phrase>
<phrase>Peer-to-Peer</phrase>: Ökonomische, <phrase>technische</phrase> und juristische <phrase>Perspektiven</phrase>, <phrase>Das aktuelle</phrase> <phrase>P2P</phrase>-Buch.
Complexity and Structure
<phrase>Generierung von</phrase> Worthypothesen in kontinuierlicher <phrase>Sprache</phrase>
<phrase>Programming</phrase> Constraint Services: <phrase>High-Level</phrase> <phrase>Programming</phrase> of Standard and New Constraint Services
Testmustergenerierung und Fehlersimulation in digitalen <phrase>Schaltungen</phrase> <phrase>mit</phrase> hoher <phrase>Komplexität</phrase>
Objective <phrase>Coordination</phrase> in <phrase>Multi-Agent System</phrase> <phrase>Engineering</phrase> - <phrase>Design</phrase> and Implementation
<phrase>Security</phrase> <phrase>Engineering</phrase> with Patterns - <phrase>Origins</phrase>, <phrase>Theoretical Models</phrase>, and New Applications
<phrase>Higher-Level</phrase> <phrase>Hardware Synthesis</phrase>
<phrase>Paragon</phrase>: A <phrase>Language</phrase> Using <phrase>Type Hierarchies</phrase> for the Specification, Implementation and Selection of <phrase>Abstract Data Types</phrase>
<phrase>Multiagent Systems</phrase> - A <phrase>Theoretical Framework</phrase> for Intentions, Know-How, and Communications
<phrase>Evolution</phrase> of <phrase>Parallel</phrase> Cellular Machines, The <phrase>Cellular Programming</phrase> Approach
Matrix Eigensystem Routines - EISPACK Guide, <phrase>Second Edition</phrase>
From <phrase>Logic</phrase> <phrase>Design</phrase> to <phrase>Logic Programming</phrase>: <phrase>Theorem Proving</phrase> Techniques and <phrase>P</phrase>-Functions
<phrase>Grading</phrase> <phrase>Knowledge</phrase>, <phrase>Extracting</phrase> <phrase>Degree</phrase> <phrase>Information</phrase> from Texts.
"Text <phrase>Knowledge</phrase> Extraction" <phrase>maps</phrase> <phrase>natural language</phrase> texts onto a <phrase>formal representation</phrase> of the facts contained in the texts. Common text <phrase>knowledge extraction</phrase> methods show a severe lack of methods for <phrase>understanding</phrase> <phrase>natural language</phrase> "<phrase>degree</phrase> expressions", like "expensive <phrase>hard disk drive</phrase>" and "good monitor", which describe gradable properties like price and quality, respectively. However, without an adequate <phrase>understanding</phrase> of such <phrase>degree</phrase> expressions it is often impossible to <phrase>grasp</phrase> the central meaning of a text. This <phrase>book</phrase> shows concise and <phrase>comprehensive</phrase> concepts for <phrase>extracting</phrase> <phrase>degree</phrase> <phrase>information</phrase> from <phrase>natural language</phrase> texts. It researches this task with regard to the three levels of (<phrase>i</phrase>) <phrase>analysing</phrase> <phrase>natural language</phrase> <phrase>degree</phrase> expressions, (<phrase>ii</phrase>) representing them in a terminologic framework, and (<phrase>iii</phrase>) inferencing on them byconstrain <phrase>t</phrase> propagation. On each of these three levels, the <phrase>author</phrase> shows that former approaches to the <phrase>degree</phrase> <phrase>understanding</phrase> problem were <phrase>too simplistic</phrase>, since theyignored byand large the role of the <phrase>background knowledge</phrase> involved. Thus, he gives a <phrase>constructive</phrase> verification of his <phrase>central hypothesis</phrase>, viz. that the proper extraction of <phrase>grading</phrase> <phrase>knowledge</phrase> relies heavilyon background <phrase>grading</phrase> <phrase>knowledge</phrase>. This <phrase>construction</phrase> proceeds as follows. First, the <phrase>author</phrase> gives <phrase>an overview</phrase> of the ParseTalk <phrase>information extraction</phrase> system. Then, from the review of relevant <phrase>linguistic</phrase> <phrase>literature</phrase>, the <phrase>author</phrase> derives two distinct categories of <phrase>natural language</phrase> <phrase>degree</phrase> expressions and proposes <phrase>knowledge</phrase>-intensive <phrase>algorithms</phrase> to handle their analyses in the ParseTalk system. These methods are applied to two text domains, viz. a <phrase>medical diagnosis</phrase> domain and a repositoryof texts from <phrase>information</phrase> technologymagazines. Moreover, for inferencing the <phrase>author</phrase> generalizes from well-known <phrase>constraint propagation</phrase> mechanisms. This <phrase>generalization</phrase> is especiallyapt for representing and reasoning with <phrase>natural language</phrase> <phrase>degree</phrase> expressions, but it is also interesting from the <phrase>point of view</phrase> where it originated, viz. the field of <phrase>temporal reasoning</phrase>. The <phrase>conclusion</phrase> of the <phrase>book</phrase> gives an <phrase>integration</phrase> of all three levels of <phrase>understanding</phrase> showing that their <phrase>coupling</phrase> leads to an even more <phrase>advanced</phrase> -- and more <phrase>efficient</phrase> -- performance of the proposed mechanisms.
<phrase>Handbook</phrase> on <phrase>Ontologies</phrase>
Ausführbare <phrase>Spezifikation von</phrase> <phrase>Directory</phrase>-<phrase>Systemen</phrase> in einer logischen <phrase>Sprache</phrase>
<phrase>Java</phrase> and the <phrase>Java Virtual Machine</phrase>: Definition, Verification, Validation
<phrase>Datenschutz</phrase> bei riskanten <phrase>Systemen</phrase>: <phrase>Eine</phrase> <phrase>Konzeption</phrase> entwickelt <phrase>am</phrase> <phrase>Beispiel eines</phrase> medizinischen Informationssystems
<phrase>Stateless</phrase> Core: <phrase>A Scalable</phrase> Approach for <phrase>Quality of Service</phrase> in the <phrase>Internet</phrase>, <phrase>Winning</phrase> <phrase>Thesis</phrase> of the 2001 <phrase>ACM</phrase> <phrase>Doctoral Dissertation</phrase> <phrase>Competition</phrase>
<phrase>Test</phrase> von <phrase>OSI</phrase>-Protokollen
<phrase>Fehlertoleranz</phrase> in verteilten Realzeitsystemen: Anwendungsorientierte <phrase>Techniken</phrase>
Maschinen-unabhängige Code-<phrase>Erzeugung</phrase> als semantikerhaltende beweisbare Programmtransformation
<phrase>Konzepte für</phrase> <phrase>eine verteilte</phrase> <phrase>wissensbasierte</phrase> Softwareproduktionsumgebung
A <phrase>Hierarchical</phrase> <phrase>Associative</phrase> Processing System
<phrase>Multimedia</phrase> <phrase>Database</phrase> System: Issues and <phrase>Research</phrase> Direction
<phrase>Efficient</phrase> Checking of <phrase>Polynomials</phrase> and Proofs anf the Hardness of <phrase>Approximation Problems</phrase>
<phrase>Turing Machines</phrase> with <phrase>Sublogarithmic Space</phrase>
<phrase>Ada</phrase> 95 <phrase>Reference Manual</phrase>, <phrase>Language</phrase> and <phrase>Standard Libraries</phrase>, <phrase>International Standard ISO/IEC</phrase> 8652: 1995(<phrase>E</phrase>)
Consolidated <phrase>Ada</phrase> <phrase>Reference Manual</phrase>. <phrase>Language</phrase> and <phrase>Standard Libraries</phrase>, <phrase>International Standard ISO/IEC</phrase> 8652/1995(<phrase>E</phrase>) with Technical <phrase>Corrigendum</phrase> 1
Artificail <phrase>Perception</phrase> and <phrase>Music</phrase> Recognition
Finite Representations of <phrase>CCS</phrase> and TCSP Programs by <phrase>Automata</phrase> and <phrase>Petri Nets</phrase>
Flagorientierte Assoziativspeicher und -prozessoren
Towards <phrase>Dynamic</phrase> <phrase>Randomized</phrase> <phrase>Algorithms</phrase> in <phrase>Computational Geometry</phrase>
<phrase>Boolean</phrase> Caclulus of Differences
<phrase>P</phrase>-Functions and <phrase>Boolean Matrix</phrase> Factorization: <phrase>A Unified</phrase> Approach for <phrase>Wired</phrase>, Programmed and <phrase>Microprogrammed</phrase> Implementations of <phrase>Discrete Algorithms</phrase>
<phrase>Algorithms</phrase> for <phrase>Parallel</phrase> <phrase>Polygon</phrase> Rendering
Challenges for <phrase>Action</phrase> Theories
The <phrase>Computational Complexity</phrase> of <phrase>Equivalence</phrase> and <phrase>Isomorphism</phrase> Problems
Visualization of Scientific <phrase>Parallel</phrase> Programs
<phrase>Global Optimization</phrase>
<phrase>Current Trends</phrase> in <phrase>Concurrency</phrase>, Overviews and <phrase>Tutorials</phrase>
Extraction and <phrase>Exploitation</phrase> of <phrase>Intensional Knowledge</phrase> from <phrase>Heterogeneous Information Sources</phrase>: <phrase>Semi-Automatic</phrase> Approaches and Tools
<phrase>Algorithms</phrase> on <phrase>Trees</phrase> and <phrase>Graphs</phrase>
<phrase>Uncertainty Handling</phrase> and <phrase>Quality Assessment</phrase> in <phrase>Data Mining</phrase>
:"<phrase>Uncertainty Handling</phrase> and <phrase>Quality Assessment</phrase> in <phrase>Data Mining</phrase> provides <phrase>an introduction</phrase> to the application of these concepts in <phrase>Knowledge</phrase> Discovery and <phrase>Data Mining</phrase>. It reviews the <phrase>state</phrase>-of-the-<phrase>art</phrase> in <phrase>uncertainty handling</phrase> and discusses a framework for unveiling and <phrase>handling uncertainty</phrase>. Coverage of <phrase>quality assessment</phrase> begins with <phrase>an introduction</phrase> to <phrase>cluster analysis</phrase> and a comparison of the methods and approaches that may be used. The techniques and <phrase>algorithms</phrase> involved in other essential <phrase>data mining</phrase> tasks, such as classification and extraction of <phrase>association rules</phrase>, are also discussed together with a review of the <phrase>quality criteria</phrase> and techniques for <phrase>evaluating</phrase> the <phrase>data mining</phrase> <phrase>results</phrase>." "This <phrase>book</phrase> presents a <phrase>general</phrase> framework for <phrase>assessing</phrase> quality and <phrase>handling uncertainty</phrase>, which is based on tested concepts and theories. This framework forms the basis of an implementation tool, 'UMiner' which is introduced to the <phrase>reader</phrase> for the first time." Aimed at IT professionals involved with <phrase>data mining</phrase> and <phrase>knowledge</phrase> discovery, the work is supported with <phrase>case studies</phrase> from <phrase>epidemiology</phrase> that illustrate how the tool works in '<phrase>real-world</phrase>' <phrase>data mining</phrase> projects. The <phrase>book</phrase> would also be of interest to <phrase>final year</phrase> undergraduates or <phrase>post-graduate</phrase> students looking at <phrase>databases</phrase>, <phrase>algorithms</phrase>, <phrase>artificial intelligence</phrase> and <phrase>information</phrase> systems particularly with regard to uncertainty and <phrase>quality assessment</phrase>.
<phrase>Interactive Multimedia</phrase> Documents: Modeling, <phrase>Authoring</phrase>, and <phrase>Implementation Experiences</phrase>
<phrase>Matchmaking</phrase> in <phrase>Electronic</phrase> Markets - <phrase>An Agent-Based</phrase> Approach towards <phrase>Matchmaking</phrase> in <phrase>Electronic</phrase> Negotiations
<phrase>Planning</phrase> and <phrase>Learning</phrase> by <phrase>Analogical Reasoning</phrase>
Closed <phrase>Object Boundaries</phrase> from <phrase>Scattered Points</phrase>
<phrase>Intelligent Information Integration</phrase> for the <phrase>Semantic Web</phrase>
Signaturanalyse: <phrase>Theoretische Grundlagen</phrase> <phrase>und Probleme</phrase>; Ausblick auf <phrase>Anwendungen</phrase>
<phrase>Software</phrase>-Diversität <phrase>und ihre</phrase> <phrase>Modellierung</phrase>: <phrase>Software</phrase>-<phrase>Fehlertoleranz</phrase> <phrase>und ihre</phrase> Bewertung durch Fehler- und Kostenmodelle
<phrase>Modular</phrase> <phrase>Construction</phrase> and <phrase>Partial Order Semantics</phrase> of <phrase>Petri Nets</phrase>
<phrase>Relational</phrase> Matching
<phrase>Vivid</phrase> <phrase>Logic</phrase>: <phrase>Knowledge-Based</phrase> Reasoning with Two Kinds of <phrase>Negation</phrase>
Natürlichsprachliche <phrase>Argumentation</phrase> in Dialogsystemen: <phrase>KI</phrase>-<phrase>Verfahren zur</phrase> <phrase>Rekonstruktion</phrase> und Erklärung approximativer Inferenzprozesse
<phrase>Alternating Sequential</phrase>/<phrase>Parallel Processing</phrase>
<phrase>Integer</phrase> Optimization by <phrase>Local</phrase> Search
Datenbankgestützte <phrase>Repräsentation</phrase> und <phrase>Extraktion von</phrase> Episodenbeschreibungen aus Bildfolgen
<phrase>Data Mining</phrase> in <phrase>Bioinformatics</phrase>
The <phrase>Logic</phrase> of <phrase>Information</phrase> Structures
The <phrase>Generic</phrase> Development <phrase>Language</phrase> Deva: Presentation and <phrase>Case Studies</phrase>
Komplexitätstheorie: <phrase>Grenzen der</phrase> <phrase>Effizienz</phrase> <phrase>von Algorithmen</phrase>
A Methodology for Uncertainty in <phrase>Knowledge-Based Systems</phrase>
Revisions- und Konsistenzkontrolle in <phrase>einer integrierten</phrase> Softwareentwicklungsumgebung
Models and Tools for <phrase>Managing</phrase> <phrase>Development Processes</phrase>
Übersetzerbau - <phrase>Theorie</phrase>, <phrase>Konstruktion</phrase>, <phrase>Generierung</phrase>
Übersetzerbau - <phrase>Theorie</phrase>, <phrase>Konstruktion</phrase>, <phrase>Generierung</phrase>, 2. Auflage
<phrase>Instantiation</phrase> Theory - On the Foundations of <phrase>Automated Deduction</phrase>
Systematische <phrase>Software-Qualitätssicherung</phrase> <phrase>anhand von</phrase> Qualitäts- und Produktmodellen
<phrase>Programming</phrase> in <phrase>Modula</phrase> 2
<phrase>Programmieren</phrase> in <phrase>Modula</phrase>-2
<phrase>Grammars</phrase> and <phrase>L</phrase> Forms: <phrase>An Introduction</phrase>
<phrase>Artificial Intelligence</phrase> Today: <phrase>Recent Trends</phrase> and Developments
Probabilistische <phrase>Verfahren für</phrase> den <phrase>Test</phrase> hochintegrierter <phrase>Schaltungen</phrase>
<phrase>Multicast</phrase>-<phrase>Kommunikation in verteilten Systemen</phrase>
<phrase>Attribute Grammar</phrase> <phrase>Inversion</phrase> and <phrase>Source-to-source Translation</phrase>
<phrase>High-Dimensional Indexing</phrase>: <phrase>Transformational</phrase> Approaches to <phrase>High</phrase>-Dimensional <phrase>Range</phrase> and <phrase>Similarity Searches</phrase>
<phrase>Association Rule Mining</phrase>, Models and <phrase>Algorithms</phrase>
Due to the popularity of <phrase>knowledge</phrase> discovery and <phrase>data mining</phrase>, in practice as well as among <phrase>academic</phrase> and <phrase>corporate</phrase> <phrase>R&D</phrase> professionals, <phrase>association rule mining</phrase> is <phrase>receiving increasing attention</phrase>. The authors present the <phrase>recent progress</phrase> achieved in <phrase>mining quantitative association rules</phrase>, <phrase>causal</phrase> rules, exceptional rules, <phrase>negative association rules</phrase>, <phrase>association rules</phrase> in multi-<phrase>databases</phrase>, and <phrase>association rules</phrase> in small <phrase>databases</phrase>. This <phrase>book</phrase> is written for researchers, professionals, and students working in the fields of <phrase>data mining</phrase>, <phrase>data</phrase> analysis, <phrase>machine learning</phrase>, and <phrase>knowledge</phrase> discovery in <phrase>databases</phrase>, and for anyone who is interested in <phrase>association rule mining</phrase>.
<phrase>Agent-Based</phrase> <phrase>Hybrid</phrase> <phrase>Intelligent Systems</phrase>: <phrase>An Agent-Based</phrase> Framework for <phrase>Complex Problem Solving</phrase>
<phrase>Kopplung von</phrase> <phrase>Rechnernetzen</phrase>: <phrase>Techniken</phrase> zu <phrase>Planung</phrase>, <phrase>Entwurf</phrase>, <phrase>Vermessung</phrase> und Leistungsoptimierung
<phrase>Automatische</phrase> Komplexitätsanalyse funktionaler <phrase>Programme</phrase>
Y12M - <phrase>Solution</phrase> of Large and <phrase>Sparse</phrase> Systems of <phrase>Linear Algebraic Equations</phrase>
<phrase>John</phrase> Zukowski's <phrase>Definitive Guide</phrase> to <phrase>Swing</phrase> for <phrase>Java</phrase> 2
<phrase>Compositionality</phrase>, <phrase>Concurrency</phrase> and <phrase>Partial</phrase> <phrase>Correctness - Proof</phrase> Theories for Networks of Processes, and Their Relationship
<phrase>Multi-Agent</phrase> <phrase>Programming</phrase>: Languages, Platforms and Applications
<phrase>Web</phrase> Dynamics - <phrase>Adapting</phrase> to Change in Content, Size, <phrase>Topology</phrase> and Use
<phrase>Understanding</phrase> <phrase>Planning</phrase> Tasks: Domain Complexity and <phrase>Heuristic</phrase> Decomposition.
Metrics for <phrase>Process Models</phrase>: Empirical Foundations of Verification, <phrase>Error Prediction</phrase>, and Guidelines for Correctness.
OMDoc - An <phrase>Open</phrase> <phrase>Markup</phrase> Format for <phrase>Mathematical</phrase> Documents [version 1.2].
<phrase>Software</phrase> Visualization - <phrase>Visualizing</phrase> the Structure, Behaviour, and <phrase>Evolution</phrase> of <phrase>Software</phrase>.
Do-All <phrase>Computing</phrase> in <phrase>Distributed Systems</phrase>: <phrase>Cooperation</phrase> in the Presence of Adversity.
<phrase>Resource Allocation</phrase> in <phrase>Wireless Networks</phrase>: Theory and <phrase>Algorithms</phrase>.
<phrase>Case-Based</phrase> <phrase>Approximate</phrase> Reasoning
<phrase>Concurrent Zero-Knowledge</phrase> - With Additional Background by <phrase>Oded Goldreich</phrase>
Dissemination of <phrase>Information</phrase> in <phrase>Communication</phrase> Networks - <phrase>Broadcasting</phrase>, <phrase>Gossiping</phrase>, <phrase>Leader Election</phrase>, and <phrase>Fault-Tolerance</phrase>
<phrase>Algorithms</phrase> and <phrase>Data</phrase> Structures: The <phrase>Basic</phrase> <phrase>Toolbox</phrase>.
<phrase>Formal Models</phrase> of <phrase>Communicating Systems</phrase> - Languages, <phrase>Automata</phrase>, and <phrase>Monadic Second-Order Logic</phrase>
<phrase>Web</phrase> <phrase>Data Mining</phrase>: <phrase>Exploring</phrase> <phrase>Hyperlinks</phrase>, Contents, and <phrase>Usage Data</phrase>
<phrase>Web mining</phrase> aims to discover useful <phrase>information</phrase> and <phrase>knowledge</phrase> from the <phrase>Web</phrase> <phrase>hyperlink</phrase> structure, <phrase>page contents</phrase>, and <phrase>usage data</phrase>. Although <phrase>Web mining</phrase> uses many conventional <phrase>data mining</phrase> techniques, it is not purely an application of traditional <phrase>data mining</phrase> due to the <phrase>semistructured</phrase> and unstructured <phrase>nature</phrase> of the <phrase>Web data</phrase> and its heterogeneity. It has also developed many of its own <phrase>algorithms</phrase> and techniques. <phrase>Liu</phrase> has written a <phrase>comprehensive</phrase> text on <phrase>Web</phrase> <phrase>data mining</phrase>. <phrase>Key topics</phrase> of <phrase>structure mining</phrase>, <phrase>content mining</phrase>, and <phrase>usage mining</phrase> are <phrase>covered</phrase> both in breadth and in depth. His <phrase>book</phrase> <phrase>brings together</phrase> all the <phrase>essential concepts</phrase> and <phrase>algorithms</phrase> from <phrase>related areas</phrase> such as <phrase>data mining</phrase>, <phrase>machine learning</phrase>, and <phrase>text processing</phrase> to form an authoritative and <phrase>coherent</phrase> text. The <phrase>book</phrase> offers a rich blend of theory and practice, addressing seminal <phrase>research</phrase> ideas, as well as <phrase>examining</phrase> the <phrase>technology</phrase> from a practical <phrase>point of view</phrase>. It is suitable for students, <phrase>researchers and practitioners</phrase> interested in <phrase>Web mining</phrase> both as a <phrase>learning</phrase> text and a reference <phrase>book</phrase>. <phrase>Lecturers</phrase> can readily use it for classes on <phrase>data mining</phrase>, <phrase>Web mining</phrase>, and <phrase>Web search</phrase>. Additional <phrase>teaching</phrase> materials such as <phrase>lecture</phrase> slides, datasets, and implemented <phrase>algorithms</phrase> are available <phrase>online</phrase>. <phrase>The ACM Portal</phrase> is published by the <phrase>Association for Computing Machinery</phrase>. <phrase>Copyright © 2010 ACM</phrase>, Inc. <phrase>Terms of Usage Privacy Policy Code</phrase> of <phrase>Ethics</phrase> <phrase>Contact</phrase> Us Useful downloads: <phrase>Adobe Acrobat</phrase> <phrase>QuickTime</phrase> <phrase>Windows Media Player</phrase> Real Player
<phrase>Data Quality</phrase>: Concepts, Methodologies and Techniques
<phrase>Web Services</phrase> - Concepts, Architectures and Applications
<phrase>Ada</phrase> 2005 Rationale: The <phrase>Language</phrase>, The <phrase>Standard Libraries</phrase>
<phrase>Ada</phrase> 2005 <phrase>Reference Manual</phrase>. <phrase>Language</phrase> and <phrase>Standard Libraries</phrase> - <phrase>International Standard ISO/IEC</phrase> 8652/1995 (<phrase>E</phrase>) with Technical <phrase>Corrigendum</phrase> 1 and Amendment 1
<phrase>Cooperative</phrase> <phrase>Bug Isolation</phrase> (<phrase>Winning</phrase> <phrase>Thesis</phrase> of the 2005 <phrase>ACM</phrase> <phrase>Doctoral Dissertation</phrase> <phrase>Competition</phrase>).
<phrase>Secure</phrase> Transaction <phrase>Protocol Analysis</phrase>: Models and Applications
<phrase>Neural Networks</phrase> - A <phrase>Systematic</phrase> <phrase>Introduction</phrase>
<phrase>Grid Computing</phrase>, <phrase>Experiment Management</phrase>, <phrase>Tool Integration</phrase>, and <phrase>Scientific Workflows</phrase>
<phrase>Business Process Management</phrase>: Concepts, Languages, Architectures
<phrase>Pedagogically</phrase> Founded <phrase>Courseware</phrase> Generation for <phrase>Web-Based Learning</phrase>, An <phrase>HTN-Planning</phrase>-<phrase>Based Approach</phrase> Implemented in PAIGOS
Kleeme-Algebren Formaler Ausdrücke
Skriptum <phrase>Informatik</phrase>: <phrase>eine</phrase> konventionelle <phrase>Einführung</phrase>, 5. Aufl.
Skriptum <phrase>Informatik</phrase>: <phrase>eine</phrase> konventionelle <phrase>Einführung</phrase>
Skriptum <phrase>Informatik</phrase>: <phrase>eine</phrase> konventionelle <phrase>Einführung</phrase>, 2., durchges. Aufl.
Skriptum <phrase>Informatik</phrase>: <phrase>eine</phrase> konventionelle <phrase>Einführung</phrase>, 3., durchges. und erw. Aufl.
Skriptum <phrase>Informatik</phrase>: <phrase>eine</phrase> konventionelle <phrase>Einführung</phrase>, 4., durchges. Aufl.
Starthilfe <phrase>Informatik</phrase>, 2., durchges. Aufl.
Starthilfe <phrase>Informatik</phrase>
Algorithmischen <phrase>Konzepte</phrase> <phrase>der Informatik</phrase> - Berechenbarkeit, Komplexitätstheorie, Algorithmik, <phrase>Kryptographie</phrase>
<phrase>Grundlagen</phrase> der <phrase>Programmiersprachen</phrase>
<phrase>Effiziente Algorithmen</phrase>
<phrase>Mathematische Grundlagen</phrase> <phrase>der Informatik</phrase> - Mathematisches Denken und Beweisen, <phrase>Eine Einführung</phrase>
<phrase>Mathematische Grundlagen</phrase> <phrase>der Informatik</phrase> - Mathematisches Denken und Beweisen, <phrase>Eine Einführung</phrase>, 2. Auflage
Transaktionssysteme
<phrase>Einführung in die</phrase> Komplexitätstheorie
Archivierung in <phrase>Datenbanksystemen</phrase> - <phrase>Konzept und</phrase> <phrase>Sprache</phrase>
<phrase>Datenbanksysteme</phrase>: <phrase>Konzepte und</phrase> <phrase>Modelle</phrase>
Arithmetik in Rechananlagen
<phrase>Aufgaben</phrase> zum Skriptum <phrase>Informatik</phrase>
<phrase>Aufgaben</phrase> zum Skriptum <phrase>Informatik</phrase>, 2., durchges. Aufl.
<phrase>Backup und</phrase> Recovery in <phrase>Datenbanksystemen</phrase>
<phrase>Semantik</phrase> und Programmverifikation
The complexity of <phrase>Boolean</phrase> functions
Kompendium <phrase>Theoretische Informatik - eine</phrase> Ideensammlung
<phrase>Effiziente Algorithmen</phrase> für grundlegende <phrase>Funktionen</phrase> (2. Auflage)
<phrase>Theoretische Informatik - eine</phrase> algorithmenorientierte <phrase>Einführung</phrase> (2. Auflage)
Compilerbau - <phrase>Eine Einführung</phrase>
<phrase>Didaktik der Informatik</phrase>, <phrase>mit</phrase> praxiserprobtem Unterrichtsmaterial.
<phrase>Didaktik der Informatik</phrase>, <phrase>mit</phrase> praxiserprobtem Unterrichtsmaterial, 2. Auflage.
Expertensysteme <phrase>für die Planung</phrase> <phrase>der Produktion</phrase>
<phrase>Grundlagen</phrase> <phrase>von Informationssystemen</phrase>
Deduktive <phrase>Datenbanken</phrase>: <phrase>Eine Einführung</phrase> <phrase>aus der Sicht der</phrase> <phrase>logischen Programmierung</phrase>
Anfrageverarbeitung in <phrase>Datenbanksystemen</phrase> - <phrase>Entwurfs- und</phrase> Implementierungskonzepte
<phrase>Datenbank</phrase>-<phrase>Engineering</phrase>: Analyse, <phrase>Entwurf und Implementierung</phrase> objektrelationaler <phrase>Datenbanken</phrase> <phrase>mit</phrase> <phrase>UML</phrase>, <phrase>DB2</phrase>-<phrase>SQL</phrase> und <phrase>Java</phrase>
Hochleistungs-Transaktionssysteme. <phrase>Konzepte und</phrase> <phrase>Entwicklungen</phrase> moderner Datenbankarchitekturen.
Bilddatenkompression: <phrase>Grundlagen</phrase>, Codierung, <phrase>MPEG</phrase>, <phrase>JPEG</phrase>
<phrase>Automatisierung</phrase> von Terminierungsbeweisen.
<phrase>Classification and Regression Trees</phrase>.
The <phrase>Probabilistic Method</phrase>
<phrase>Environmental</phrase> Systems <phrase>Research Institute</phrase>: <phrase>Understanding</phrase> <phrase>GIS</phrase> - The <phrase>ARC</phrase>/<phrase>INFO</phrase> Method, <phrase>3rd Ed</phrase>.
Modeling the <phrase>Internet</phrase> and the <phrase>Web</phrase>: <phrase>Probabilistic Method</phrase> and <phrase>Algorithms</phrase>
<phrase>Sampling</phrase> Techniques
<phrase>Sampling</phrase> Techniques
<phrase>Sampling</phrase> Techniques, <phrase>3rd Edition</phrase>.
<phrase>Exploratory Data Mining</phrase> and <phrase>Data Cleaning</phrase>
<phrase>Compiler</phrase> <phrase>Construction</phrase> for <phrase>Digital</phrase> <phrase>Computers</phrase>
<phrase>Modern Compiler</phrase> <phrase>Design</phrase>
<phrase>Rdb</phrase>/<phrase>VMS</phrase>: <phrase>Developing</phrase> the <phrase>Data Warehouse</phrase>
<phrase>Classification Algorithms</phrase>
<phrase>Garbage Collection</phrase>: <phrase>Algorithms</phrase> for <phrase>Automatic</phrase> <phrase>Dynamic</phrase> <phrase>Memory Management</phrase>.
<phrase>Finding</phrase> Groups in <phrase>Data</phrase>: <phrase>An Introduction</phrase> to <phrase>Cluster Analysis</phrase>.
The <phrase>Data Warehouse</phrase> <phrase>Toolkit</phrase>: Practical Techniques for <phrase>Building</phrase> <phrase>Dimensional Data</phrase> <phrase>Warehouses</phrase>.
Foundations of <phrase>Programming Languages</phrase>
The Essential <phrase>Distributed Objects</phrase> <phrase>Survival Guide</phrase>.
<phrase>CORBA</phrase> <phrase>Fundamentals</phrase> and <phrase>Programming</phrase>.
Applied <phrase>Operating System</phrase> Concepts, First <phrase>Edition</phrase>
<phrase>Operating System</phrase> Concepts, <phrase>Sixth</phrase> <phrase>Edition</phrase>
Statistical Decision Funtions.
Theory of Modeling and <phrase>Simulation</phrase>
<phrase>High</phrase> Performance <phrase>Parallel</phrase> <phrase>Database</phrase> Processing and <phrase>Grid</phrase> <phrase>Databases</phrase>
This <phrase>book</phrase> targets the theoretical/conceptual details needed to form a base of <phrase>understanding</phrase> and then delivers <phrase>information</phrase> on development, implementations, and <phrase>analytical modeling</phrase> of <phrase>parallel</phrase> <phrase>databases</phrase>. It includes key <phrase>information</phrase> on <phrase>new developments</phrase> with <phrase>grid</phrase> <phrase>databases</phrase>. Also uses a theoretical and practical balance to support in-depth study of <phrase>parallel query processing</phrase> offered by modern <phrase>DBMS</phrase> as well as <phrase>hands on experience</phrase> of <phrase>parallel</phrase> query <phrase>algorithms</phrase> development, implementation, and analysis.
<phrase>Creating</phrase> <phrase>Metabolic Network</phrase> Models using <phrase>Text Mining</phrase> and <phrase>Expert Knowledge</phrase>.
<phrase>Graph</phrase> Theoretic <phrase>Sequence</phrase> <phrase>Clustering Algorithms</phrase> and Their Applications to <phrase>Genome</phrase> Comparison.
<phrase>Introduction</phrase> to <phrase>Self-Assembling</phrase> <phrase>DNA</phrase> <phrase>Nanostructures</phrase> for Computation and Nanofabrication.
Phyloinformatics and <phrase>Tree</phrase> Networks.
<phrase>High-Grade</phrase> <phrase>Ore</phrase> for <phrase>Data Mining</phrase> in 3D Structures.
<phrase>Exploring</phrase> <phrase>RNA</phrase> Intermediate Conformations with the <phrase>Massively Parallel</phrase> <phrase>Genetic Algorithm</phrase>.
Mapping <phrase>Sequence</phrase> to <phrase>Rice</phrase> FPC.
Interrelated <phrase>Clustering</phrase>: An Approach for <phrase>Gene Expression</phrase> <phrase>Data Analysis</phrase>.
<phrase>Protein</phrase> Classification: A <phrase>Geometric</phrase> <phrase>Hashing</phrase> Approach.
The <phrase>Protein</phrase> <phrase>Information</phrase> Resource for <phrase>Functional Genomics</phrase> and <phrase>Proteomics</phrase>.
<phrase>Conservative</phrase> Extension in <phrase>Structural</phrase> <phrase>Operational Semantics</phrase>.
Some Pointed Questions Concerning <phrase>Asymptotic</phrase> <phrase>Lower</phrase> Bounds, and <phrase>News</phrase> from the <phrase>Isomorphism</phrase> Front.
Theoretical and <phrase>Experimental</phrase> <phrase>DNA</phrase> Computation.
Theory of <phrase>Genetic Algorithms</phrase>.
<phrase>Propositional Proof Complexity</phrase>: Past, Present, and Future.
The Underlying <phrase>Logic</phrase> of <phrase>Hoare Logic</phrase>.
<phrase>Security</phrase> Analysis Using Flow Logics.
<phrase>Quantum Computing</phrase> and <phrase>Communication</phrase> Complexity.
More <phrase>Infinite</phrase> <phrase>Results</phrase>.
A <phrase>Machine Model</phrase> for the Complexity of <phrase>NP</phrase>-<phrase>Approximation Problems</phrase>.
Functions Versus <phrase>Algorithms</phrase>.
Characterizations of <phrase>Regular Languages</phrase> in <phrase>Low Level</phrase> <phrase>Complexity Classes</phrase>.
GETGRATS and APPLIGRAPH: Theory and Applications of <phrase>Graph</phrase> Transformation.
Networks of <phrase>Language</phrase> Processors.
Networks of <phrase>Language</phrase> Processors: <phrase>Parallel Communicating</phrase> Systems.
<phrase>Herbrand's Theorem</phrase> and <phrase>Equational</phrase> Reasoning: Problems and Solutions.
On the Role of <phrase>Formal Specification</phrase> Techniques: From TAPSOFT 1985 to <phrase>ETAPS</phrase> 2000.
On <phrase>Formal Semantics</phrase> and <phrase>Integration</phrase> of <phrase>Object-Oriented Modeling</phrase> Languages.
Theory and Practice of <phrase>Software Development</phrase>: A Review of <phrase>Driving Forces</phrase> and Expectations of TAPSOFT from 1985 to 1997.
<phrase>Algebraic</phrase> Techniques in <phrase>Software Development</phrase>: A Review of Progress up to <phrase>the Mid Nineties</phrase>.
<phrase>Dynamic</phrase> <phrase>Abstract Data Types</phrase>: An Informal Proposal in 1994.
<phrase>Integration</phrase> <phrase>Paradigm</phrase> for <phrase>Data Type</phrase> and <phrase>Process Specification</phrase> Techniques.
From <phrase>Basic</phrase> Views and Aspects to <phrase>Integration</phrase> of <phrase>Specification Formalisms</phrase>.
Why <phrase>Evolutionary Algorithms</phrase>?
<phrase>Diagonalization</phrase>.
What is <phrase>Branching</phrase> Time <phrase>Semantics</phrase> and Why to Use it?
Why are <phrase>Modal Logics</phrase> so Robustly <phrase>Decidable</phrase>?
On a <phrase>Reference Model</phrase> for the <phrase>Formalization</phrase> and <phrase>Integration</phrase> of <phrase>Software Specification</phrase> Languages.
<phrase>Homotopy</phrase> and <phrase>Concurrency</phrase>.
AMAST'91 Banquet <phrase>Talk</phrase>.
The Value, if Any, of <phrase>Decidability</phrase>.
<phrase>Platonism</phrase>, <phrase>Constructivism</phrase>, and Computer Proofs vs. Proofs by Hand.
From Invariants to <phrase>Canonization</phrase>.
The <phrase>Sequential</phrase> <phrase>ASM</phrase> <phrase>Thesis</phrase>.
<phrase>An Introduction</phrase> to <phrase>Quantum Computing</phrase>.
On <phrase>Slender</phrase> Languages.
The <phrase>D0L</phrase> <phrase>Problem Revisited</phrase>.
Progress in <phrase>Descriptive</phrase> Complexity.
<phrase>DNA</phrase> <phrase>Computers</phrase>: <phrase>Tomorrow's</phrase> <phrase>Reality</phrase>.
The <phrase>Genomics</phrase> <phrase>Revolution</phrase> and its Challenges for <phrase>Algorithmic</phrase> <phrase>Research</phrase>.
Natural <phrase>Data Mining</phrase> Techniques.
Simple Words in <phrase>Equality</phrase> Sets.
It is well known that <phrase>equality</phrase> sets between two <phrase>morphisms</phrase> possess a remarkable <phrase>generative</phrase> capacity: an arbitrary <phrase>recursively enumerable set</phrase> is obtained from an <phrase>equality</phrase> set by certain simple operations. Interconnections between simplicity of computations and <phrase>structural</phrase> <phrase>primitivity</phrase> of words in <phrase>equality</phrase> sets have also been observed. The <phrase>paper</phrase> discusses recent work in this <phrase>area</phrase>, pointing out certain <phrase>open</phrase> problems and emphasizing <phrase>new directions</phrase> for <phrase>research</phrase>.
Twelve Problems in <phrase>Resource-Bounded</phrase> Measure.
<phrase>Neural Computation</phrase>: A <phrase>Research</phrase> Topic for <phrase>Theoretical Computer Science</phrase>? Some Thoughts and Pointers.
Words on Trajectories.
<phrase>Many-Valued</phrase> <phrase>Truth</phrase> Functions, Cernys' <phrase>Conjecture</phrase>, and <phrase>Road</phrase> <phrase>Coloring</phrase>.
<phrase>Lindenmayer</phrase> and <phrase>DNA</phrase>: <phrase>Watson-Crick D0L Systems</phrase>.
CoFI: The Common Framework <phrase>Initiative</phrase> for <phrase>Algebraic</phrase> Specification and Development.
Classification of <phrase>Petri Nets</phrase> Using <phrase>Adjoint Functors</phrase>.
Does <phrase>Concurrency</phrase> Theory Have Anything to Say About <phrase>Parallel Programming</phrase>?
<phrase>Splicing</phrase>: A <phrase>Challenge</phrase> for <phrase>Formal Language</phrase> Theorists.
<phrase>Computing</phrase> with <phrase>Membranes</phrase> (<phrase>P</phrase> Systems): <phrase>An Introduction</phrase>.
<phrase>Logic</phrase> on Words.
Towards <phrase>Global</phrase> Computations <phrase>Guided</phrase> by <phrase>Concurrency</phrase> Theory.
The Complexity of <phrase>Propositional</phrase> Proofs.
<phrase>Current Trends</phrase> in <phrase>Theoretical Computer Science</phrase>, Entering the 21th <phrase>Century</phrase>
<phrase>String Searching Algorithms</phrase>
<phrase>Computational Biology</phrase> and <phrase>Genome</phrase> <phrase>Informatics</phrase>
Analysis of <phrase>Biological Data</phrase>: A <phrase>Soft Computing</phrase> Approach
<phrase>In Silico</phrase> <phrase>Design</phrase> of <phrase>Ligands</phrase> Using Properties of <phrase>Target</phrase> <phrase>Active</phrase> Sites.
Sophisticated Methods for <phrase>Cancer</phrase> Classification Using <phrase>Microarray</phrase> <phrase>Data</phrase>.
A <phrase>Reliable</phrase> Classification of <phrase>Gene</phrase> Clusters for <phrase>Cancer</phrase> Samples Using <phrase>a Hybrid</phrase> <phrase>Multi-Objective Evolutionary</phrase> Procedure.
<phrase>Reconstructing</phrase> <phrase>Phylogenies</phrase> with <phrase>Memetic Algorithms</phrase> and <phrase>Branch-and-Bound</phrase>.
<phrase>An Introduction</phrase> to <phrase>Soft Computing</phrase>.
Beyond String <phrase>Algorithms</phrase>: <phrase>Protein</phrase> <phrase>Sequence Analysis</phrase> Using <phrase>Wavelet</phrase> Transforms.
<phrase>Multiobjective</phrase> <phrase>Evolutionary</phrase> Approach to <phrase>Fuzzy Clustering</phrase> of <phrase>Microarray</phrase> <phrase>Data</phrase>.
<phrase>Inferring</phrase> Regulations in a <phrase>Genomic</phrase> Network from <phrase>Gene Expression</phrase> Profiles.
Distill: <phrase>A Machine Learning Approach</phrase> to <phrase>Ab Initio</phrase> <phrase>Protein Structure Prediction</phrase>.
Filtering <phrase>Protein</phrase> Surface Motifs Using <phrase>Negative Instances</phrase> of <phrase>Active</phrase> Sites Candidates.
<phrase>Bioinformatics</phrase>: <phrase>Mining</phrase> the <phrase>Massive Data</phrase> from <phrase>High</phrase> Throughput <phrase>Genomics</phrase> Experiments.
Classification of <phrase>RNA</phrase> Sequences with <phrase>Support Vector Machines</phrase>.
<phrase>Feature Selection</phrase> for <phrase>Cancer</phrase> Classification <phrase>Using Ant Colony Optimization</phrase> and <phrase>Support Vector Machines</phrase>.
Six Degrees: The <phrase>Science</phrase> of a Connected <phrase>Age</phrase>.
<phrase>Information Retrieval</phrase> Interaction.
Standard <phrase>Codecs</phrase>: <phrase>Image Compression</phrase> to <phrase>Advanced</phrase> <phrase>Video</phrase> Coding.
<phrase>Neuronale Netze</phrase> - <phrase>Eine Einführung in die</phrase> <phrase>Grundlagen</phrase>, <phrase>Anwendungen</phrase> und Datenauswertung
The <phrase>Datacenter</phrase> as a Computer: <phrase>An Introduction</phrase> to the <phrase>Design</phrase> of <phrase>Warehouse</phrase>-Scale Machines
<phrase>Real-time</phrase> <phrase>Active</phrase> <phrase>Range Finder</phrase> Using <phrase>Light Intensity</phrase> <phrase>Modulation</phrase>.
Strategies for Registering <phrase>Range</phrase> Images from Unknown <phrase>Camera</phrase> Positions.
<phrase>High</phrase>-resolution <phrase>Ultrafast</phrase> 3D <phrase>Imaging</phrase>.
<phrase>Optoelectronic</phrase> dimensional <phrase>Integral</phrase> Inspection of <phrase>Hollow</phrase> <phrase>Cylinder</phrase>-type Articles for <phrase>conveyor</phrase> Line.
Development of a 3D Digitizer for <phrase>Breast</phrase> <phrase>Surgery</phrase> Procedures.
<phrase>Automatic</phrase> <phrase>Reconstruction</phrase> of Large 3D Models of <phrase>Real Environments</phrase> from <phrase>Unregistered</phrase> <phrase>Data</phrase>-sets.
Three-line <phrase>High</phrase>-power <phrase>Three-dimensional</phrase> <phrase>Sensor</phrase>.
<phrase>Multispectral</phrase> <phrase>Pattern Projection</phrase> <phrase>Range Finder</phrase>.
<phrase>High</phrase>-speed <phrase>Three-dimensional</phrase> <phrase>Laser</phrase> <phrase>Sensor</phrase>.
3D <phrase>Range</phrase> <phrase>Optical Sensor</phrase>: analysis of the <phrase>Measurement Errors</phrase> and Development of Procedures for Their Compensation.
3D Profilometry Using a <phrase>Dynamically Configurable</phrase> <phrase>Confocal</phrase> <phrase>Microscope</phrase>.
<phrase>Examining</phrase> <phrase>Laser</phrase> <phrase>Triangulation</phrase> System Performance Using a <phrase>Software</phrase> <phrase>Simulation</phrase>.
Effect of Sway on <phrase>Image Fidelity</phrase> in <phrase>Whole-body</phrase> <phrase>Digitizing</phrase>.
Moly: A <phrase>Prototype</phrase> Handheld 3D Digitizer with <phrase>Diffraction</phrase> <phrase>Optics</phrase>.
<phrase>Reconstruction</phrase> of the Surface of the <phrase>Human</phrase> Body from 3D <phrase>Scanner Data</phrase> Using 13-splines.
<phrase>Reverse Engineering</phrase> Using Optical 3D Sensors.
<phrase>Wrapping</phrase> 3D Scanning <phrase>Data</phrase>.
<phrase>Spherical Harmonic</phrase> <phrase>Surface Representation</phrase> with <phrase>Feedback</phrase> Control.
<phrase>Efficient</phrase> <phrase>Free-form Surface</phrase> Representation with Application in <phrase>Orthodontics</phrase>.
<phrase>Real-time</phrase> 3D <phrase>Shape Measurement</phrase> with <phrase>Digital</phrase> <phrase>Stripe</phrase> <phrase>Projection</phrase> by <phrase>Texas Instruments</phrase> <phrase>Micro</phrase> <phrase>Mirror</phrase> Devices DMD.
<phrase>Multiscale</phrase> Analysis of 3D Surface Image: Application to <phrase>Clam</phrase> <phrase>Shell</phrase> Characterization.
Multiple <phrase>Structured Light</phrase> System for the 3D Measurement of Feet.
Pose and <phrase>Motion Estimation</phrase> Using <phrase>Dual</phrase> <phrase>quaternion</phrase>-based <phrase>Extended Kalman Filtering</phrase>.
<phrase>Direct</phrase> Estimation of 3D <phrase>Motion Parameters</phrase> and <phrase>Relative Depth</phrase> Using the <phrase>Minimum Description Length</phrase> Principle.
<phrase>Depth-based</phrase> <phrase>Selective</phrase> <phrase>Image Reconstruction</phrase> Using <phrase>Spatiotemporal</phrase> <phrase>Image Analysis</phrase>.
<phrase>Toward</phrase> a Handheld <phrase>Laser Range Scanner</phrase>: <phrase>Integrating</phrase> <phrase>Observation-based</phrase> <phrase>Motion Compensation</phrase>.
<phrase>Slicing</phrase>, <phrase>Fitting</phrase>, and <phrase>Linking</phrase> (<phrase>SFL</phrase>): A <phrase>Modular</phrase> <phrase>Triangulation</phrase> Approach.
3D <phrase>Object Reconstruction</phrase> from a <phrase>Sequence</phrase> of Images Using <phrase>Voxel</phrase> <phrase>Coloring</phrase>.
3D <phrase>Profiling</phrase> by Optical <phrase>Demodulation</phrase> with an <phrase>Image Intensifier</phrase>.
<phrase>Restoration</phrase> of Broken <phrase>Earthenware</phrase> Using <phrase>Close Range</phrase> <phrase>Photogrammetry</phrase> and a <phrase>CAD</phrase> System.
<phrase>Real-time</phrase> 3D <phrase>Reconstruction</phrase> System using <phrase>CAM</phrase>-based <phrase>Highly Parallel</phrase> Processing Board.
Novel <phrase>Fully Integrated</phrase> Computer System for Custom <phrase>Footwear</phrase>: from 3D <phrase>Digitization</phrase> to <phrase>Manufacturing</phrase>.
<phrase>Reconstruction</phrase> of Complete 3D <phrase>Object Model</phrase> from <phrase>Multiview</phrase> <phrase>Range</phrase> Images.
<phrase>Color</phrase> <phrase>Digitizing</phrase> and Modeling of <phrase>Free</phrase>-form 3D Objects.
<phrase>Object Modeling</phrase> in <phrase>Multiple-object</phrase> 3D Scene Using Deformable <phrase>Simplex</phrase> Meshes.
<phrase>Robust</phrase> 3D <phrase>Reconstruction</phrase> System for <phrase>Human Jaw</phrase> Modeling.
Acquisition of 3D <phrase>Image Representation</phrase> in <phrase>Multimedia</phrase> Ambiance <phrase>Communication</phrase> using 3D <phrase>Laser Scanner</phrase> and <phrase>Digital Camera</phrase>.
New Approach for the Modeling and <phrase>Smoothing</phrase> of Scattered 3D <phrase>Data</phrase>.
<phrase>Fast</phrase> <phrase>Shape from Focus</phrase> Using <phrase>Dynamic Programming</phrase>.
Axi-vision <phrase>Camera</phrase>: A <phrase>Three-dimensional</phrase> <phrase>Camera</phrase>.
<phrase>Real-time</phrase> <phrase>Structured Light</phrase> <phrase>Depth Extraction</phrase>.
Impact of Intensity <phrase>Edge map</phrase> on Segmentation of Noisy <phrase>Range</phrase> Images.
<phrase>Interpolation</phrase> of <phrase>Ray-space</phrase> <phrase>Data</phrase> by <phrase>Adaptive</phrase> Filtering.
Three Steps to Make <phrase>Shape from Shading</phrase> Work Consistently on <phrase>Real Scenes</phrase>.
<phrase>Robust</phrase> <phrase>Cooperation</phrase> Concept for <phrase>Low-level Vision</phrase> Modules.
<phrase>Error Sensitivity</phrase> of <phrase>Rotation Angles</phrase> in the <phrase>ICP</phrase> <phrase>Algorithm</phrase>.
3D Surface <phrase>Real-time</phrase> Measurement Using <phrase>Phase-shifted</phrase> Interference <phrase>Fringe</phrase> Technique for <phrase>Craniofacial</phrase> Identification.
<phrase>Automated</phrase> Fudicial Labeling on <phrase>Human</phrase> Body <phrase>Data</phrase>.
<phrase>Segmenting</phrase> 3D Surface <phrase>Scan</phrase> <phrase>Data</phrase> of the <phrase>Human</phrase> Body by 2D <phrase>Projection</phrase>.
<phrase>Extracting</phrase> <phrase>Surface Area</phrase> Coverage by <phrase>Superimposing</phrase> 3D <phrase>Scan</phrase> <phrase>Data</phrase>.
<phrase>Entropy</phrase> of Profile Sections to Estimate the <phrase>Next</phrase> <phrase>Sensor</phrase> Position.
<phrase>Optimizing</phrase> <phrase>Triangular Mesh</phrase> Generation from <phrase>Range</phrase> Images.
CyberModeler: A <phrase>Compact</phrase> 3D <phrase>Scanner</phrase> Based on Monoscopic <phrase>Camera</phrase>.
<phrase>Adaptive</phrase> <phrase>Area-based Stereo Matching</phrase>.
<phrase>Gel</phrase> <phrase>Tomography</phrase> for 3D Acquisition of <phrase>Plant</phrase> <phrase>Root</phrase> Systems.
<phrase>Real-time</phrase> Monitoring of <phrase>Icebreaker</phrase> <phrase>Propeller</phrase> <phrase>Blades</phrase>' <phrase>Ice</phrase> Load Using <phrase>Underwater</phrase> <phrase>Laser</phrase> ranging System.
Scanning <phrase>Projection</phrase> <phrase>Grating</phrase> <phrase>Moire</phrase> <phrase>Topography</phrase>.
ShapeGrabber FootScanner: A <phrase>Low Cost</phrase> <phrase>High</phrase> Accuracy 3D System for the Acquisition of <phrase>Human</phrase> Feet.
3D <phrase>Reconstruction</phrase>, Visualization, and Measurement of <phrase>MRI</phrase> Images.
<phrase>Generating</phrase> <phrase>Animated</phrase> Sequences from 3D <phrase>Whole-body</phrase> Scans.
<phrase>Tilted</phrase> Planes in 3D <phrase>Image Analysis</phrase>.
Monitoring and Measurement of Movement of Objects by <phrase>Fringe Projection</phrase> Method.
Parameters Matching of Objects in <phrase>Video</phrase> Sequences.
<phrase>Optimizing</phrase> <phrase>Random</phrase> Patterns for Invariants-based Identification.
<phrase>Three-dimensional</phrase> <phrase>Scene Reconstruction</phrase> from Images.
3D Shape Initialization of Objects in <phrase>Multiview Image Sequences</phrase>.
3D <phrase>Textured Models</phrase> of <phrase>Indoor</phrase> Scenes from <phrase>Composite</phrase> <phrase>Range</phrase> and <phrase>Video</phrase> Images.
<phrase>Three-dimensional Shape</phrase> <phrase>Reconstruction</phrase> from <phrase>Two-dimensional</phrase> Images Using <phrase>Symmetric</phrase> <phrase>Camera</phrase> Location.
New <phrase>Class Library</phrase> for <phrase>Animation</phrase> of <phrase>Voxel</phrase> Humans.
<phrase>Opto</phrase>-<phrase>numerical Methods</phrase> of <phrase>Data Acquisition</phrase> for <phrase>Computer Graphics</phrase> and <phrase>Animation</phrase> Systems.
VIRO 3D: Tast <phrase>Three-dimensional</phrase> <phrase>Full-body</phrase> Scanning for Humans and Other <phrase>Living</phrase> Objects.
<phrase>High</phrase>-resolution <phrase>Triangulation</phrase> of <phrase>Arbitrary Shaped</phrase> Surfaces based on Coordinate Curves.
Differential Motions for <phrase>Recovering</phrase> 3D Structure and Motions from an <phrase>Unstructured Environment</phrase>.
Recreation of <phrase>Three-dimensional</phrase> Objects in a <phrase>Real-time</phrase> <phrase>Simulated Environment</phrase> by Means of a <phrase>Panoramic</phrase> <phrase>Single</phrase> <phrase>Lens</phrase> <phrase>Stereoscopic Image</phrase>-Capturing Device.
<phrase>Volumetric</phrase> <phrase>Apparel</phrase> for Visible Female.
<phrase>Gaussian Scale-Space</phrase> <phrase>Dense Disparity Estimation</phrase> with <phrase>Anisotropic</phrase> <phrase>Disparity-Field</phrase> <phrase>Diffusion</phrase>.
We present a new <phrase>reliable</phrase> <phrase>dense disparity estimation</phrase> <phrase>algorithm</phrase> which employs <phrase>Gaussian scale-space</phrase> with <phrase>anisotropic</phrase> <phrase>disparity-field</phrase> <phrase>diffusion</phrase>. This <phrase>algorithm</phrase> estimates <phrase>edge-preserving</phrase> <phrase>dense disparity</phrase> vectors using a <phrase>diffusive</phrase> method on iteratively <phrase>Gaussian</phrase>-<phrase>filtered images</phrase> with a scale, i.e. the <phrase>Gaussian</phrase> scalespace. While a <phrase>Gaussian</phrase> filter <phrase>kernel</phrase> generates a <phrase>coarser resolution</phrase> from <phrase>stereo image pairs</phrase>, only strong and meaningful boundaries are <phrase>adaptively selected</phrase> on the resolution of the <phrase>filtered images</phrase>. Then, coarse <phrase>global</phrase> <phrase>disparity vectors</phrase> are initialized using the boundary constraint. The <phrase>per-pixel</phrase> <phrase>disparity vectors</phrase> are iteratively obtained by the <phrase>local</phrase> adjustment of the <phrase>global</phrase> <phrase>disparity vectors</phrase> using an <phrase>energy</phrase>-minimization framework. The proposed <phrase>algorithm</phrase> preserves the boundaries while inner regions are <phrase>smoothed</phrase> using <phrase>anisotropic</phrase> <phrase>disparity-field</phrase> <phrase>diffusion</phrase>. In this work, the <phrase>Gaussian scale-space</phrase> efficiently avoids illegal matching on a large baseline by the restriction of the <phrase>range</phrase>. Moreover, it prevents the computation from iterating into <phrase>local</phrase> minima of <phrase>ill-posed</phrase> <phrase>diffusion</phrase> on large <phrase>gradient</phrase> areas e.g. <phrase>shadow</phrase> and texture <phrase>region</phrase>, etc. The <phrase>experimental</phrase> <phrase>results</phrase> prove the excellent localization performance preserving the disparity discontinuity of each object.
<phrase>Projection-Based</phrase> Registration Using a <phrase>Multi-View</phrase> <phrase>Camera</phrase> for <phrase>Indoor Scene</phrase> <phrase>Reconstruction</phrase>.
A <phrase>registration method</phrase> is proposed for 3D <phrase>reconstruction</phrase> of an <phrase>indoor</phrase> environment using a <phrase>multi-view</phrase> <phrase>camera</phrase>. In <phrase>general</phrase>, <phrase>previous methods</phrase> have a <phrase>high</phrase> <phrase>computational complexity</phrase> and are not <phrase>robust</phrase> for 3D <phrase>point cloud</phrase> with <phrase>low precision</phrase>. Thus, a <phrase>projection-based</phrase> registration is presented. First, depth are refined based on temporal <phrase>property</phrase> by excluding 3D points with a large variation, and <phrase>spatial</phrase> <phrase>property</phrase> by <phrase>filling holes</phrase> referring neighboring 3D points. Second, 3D <phrase>point clouds</phrase> acquired at two views are <phrase>projected onto</phrase> the same <phrase>image plane</phrase>, and <phrase>two-step</phrase> <phrase>integer</phrase> mapping enables the <phrase>modified</phrase> <phrase>KLT</phrase> to find correspondences. Then, <phrase>fine registration</phrase> is carried out by <phrase>minimizing</phrase> distance errors. <phrase>Finally</phrase>, a final <phrase>color</phrase> is evaluated using colors of corresponding points and an <phrase>indoor</phrase> environment is reconstructed by <phrase>applying</phrase> the above procedure to consecutive scenes. The <phrase>proposed method</phrase> reduces <phrase>computational complexity</phrase> by searching for correspondences within an <phrase>image plane</phrase>. It not only enables an effective registration even for 3D <phrase>point cloud</phrase> with <phrase>low precision</phrase>, but also need only a few views. The generated <phrase>model</phrase> can be adopted for interaction with as well as <phrase>navigation</phrase> in a <phrase>virtual environment</phrase>.
Registration of Multiple <phrase>Range</phrase> Scans as a <phrase>Location Recognition</phrase> Problem: <phrase>Hypothesis</phrase> Generation, <phrase>Refinement</phrase> and Verification.
This <phrase>paper</phrase> addresses the following version of the multiple <phrase>range</phrase> <phrase>scan registration</phrase> problem. A <phrase>scanner</phrase> with an associated intensity <phrase>camera</phrase> is placed at a series of locations throughout a large environment; scans are acquired at each location. The problem is to decide automatically which scans overlap and to estimate the parameters of the transformations <phrase>aligning</phrase> these scans. Our technique is based on (1) <phrase>detecting</phrase> and matching keypoints ¿ distinctive locations in <phrase>range</phrase> and <phrase>intensity images</phrase>, (2) <phrase>generating</phrase> andrefining a transformation estimate from each <phrase>keypoint</phrase> match, and (3) <phrase>deciding</phrase> if a given refined estimate is correct. While these steps are familiar, we present novel approaches to each. A new <phrase>range</phrase> <phrase>keypoint</phrase> technique is presented that uses <phrase>spin</phrase> images to describe holes in <phrase>smooth surfaces</phrase>. Intensity keypoints are detected using <phrase>multiscale</phrase> filters, described using <phrase>intensity gradient</phrase> histograms, and backprojected to form 3D keypoints. A hypothesized transformation is generated by matching a <phrase>single</phrase> <phrase>keypoint</phrase> from one <phrase>scan</phrase> to a <phrase>single</phrase> <phrase>keypoint</phrase> from another, and is refined using a <phrase>robust</phrase> form of the <phrase>ICP</phrase> <phrase>algorithm</phrase> in combination with controlled <phrase>region</phrase> growing. <phrase>Deciding</phrase> whether a refined transformation is correct is based on three criteria: <phrase>alignment accuracy</phrase>, <phrase>visibility</phrase>, and a novel <phrase>randomness</phrase> measure. Together these three steps produce good <phrase>results</phrase> in <phrase>test</phrase> scans of the Rensselaer <phrase>campus</phrase>.
In Process 3D-Sensing for <phrase>Laser</phrase> <phrase>Material Processing</phrase>.
From <phrase>Coarse to Fine</phrase> <phrase>Correspondence</phrase> of 3-<phrase>D</phrase> <phrase>Facial Images</phrase> and its Application to <phrase>Facial Caricaturing</phrase>.
<phrase>Automatic</phrase> <phrase>Class Selection</phrase> and <phrase>Prototyping</phrase> for 3-<phrase>D</phrase> <phrase>Object Classification</phrase>.
Most <phrase>research</phrase> on 3-<phrase>D</phrase> <phrase>object classification</phrase> and recognition focuses on recognition of objects in 3-<phrase>D</phrase> scenes from a small <phrase>database</phrase> of known 3-<phrase>D</phrase> models. Such an approach does not scale well to <phrase>large databases</phrase> of objects and does not generalize well to unknown (but similar) <phrase>object classification</phrase>. This <phrase>paper</phrase> presents two ideas to address these problems (<phrase>i</phrase>) <phrase>class selection</phrase>, i.e., <phrase>grouping</phrase> <phrase>similar objects</phrase> into classes (<phrase>ii</phrase>) class <phrase>prototyping</phrase>, i.e., <phrase>exploiting</phrase> common structure within classes to represent the classes. At <phrase>run time</phrase> matching a query against the <phrase>prototypes</phrase> is sufficient for classification. This approach will not only reduce the retrieval time but also will help increase the <phrase>generalizing</phrase> power of theclassification <phrase>algorithm</phrase>. Objects are segmented into classes automatically using an <phrase>agglomerative clustering algorithm</phrase>. <phrase>Prototypes</phrase> from these classes are extracted using one of three class <phrase>prototyping</phrase> <phrase>algorithms</phrase>. <phrase>Experimental</phrase> <phrase>results</phrase> demonstrate the effectiveness of the two steps in <phrase>speeding up</phrase> the classification process <phrase>without sacrificing</phrase> accuracy.
<phrase>Weighted</phrase> <phrase>Cone</phrase>-<phrase>Curvature</phrase>: Applications for 3D Shapes Similarity.
Capturing 2½<phrase>D</phrase> Depth and Texture of <phrase>Time-Varying</phrase> Scenes Using Structured <phrase>Infrared Light</phrase>.
Accurate <phrase>Principal Directions</phrase> Estimation in <phrase>Discrete Surfaces</phrase>.
Accurate <phrase>local surface</phrase> <phrase>geometry</phrase> estimation in <phrase>discrete surfaces</phrase> is an important problem with <phrase>numerous applications</phrase>. <phrase>Principal curvatures</phrase> and <phrase>principal directions</phrase> can be used in applications such as <phrase>shape analysis</phrase> and recognition, <phrase>object segmentation</phrase>, <phrase>adaptive smoothing</phrase>, <phrase>anisotropic</phrase> <phrase>fairing</phrase> of <phrase>irregular</phrase> meshes, and <phrase>anisotropic</phrase> <phrase>texture mapping</phrase>. In this <phrase>paper</phrase>, a novel approach for accurate <phrase>principal direction</phrase> estimation in <phrase>discrete surfaces</phrase> is described. The proposed approach is based on <phrase>local</phrase> <phrase>directional</phrase> curve <phrase>sampling</phrase> of the surface where the <phrase>sampling</phrase> <phrase>frequency</phrase> can be controlled. This <phrase>local</phrase> <phrase>model</phrase> has a <phrase>large number</phrase> of degrees of freedoms compared with known techniques and so can better represent the <phrase>local</phrase> <phrase>geometry</phrase>. The proposed approach is <phrase>quantitatively evaluated</phrase> and compared with known techniques for <phrase>principal direction</phrase> estimation. In <phrase>order</phrase> to perform an <phrase>unbiased</phrase> evaluation in which <phrase>smoothing</phrase> effects are <phrase>factored</phrase> out, we use a set of <phrase>randomly generated</phrase> <phrase>Bezier surface</phrase> patches for which the <phrase>principal directions</phrase> can be <phrase>computed analytically</phrase>.
3D Modeling System of <phrase>Human</phrase> Face and Full 3D <phrase>Facial Caricaturing</phrase>.
This <phrase>paper</phrase> proposes a method for modeling 3D face from the 2D <phrase>facial images</phrase> captured from the surrounding 2D cameras by which the <phrase>color</phrase> texture and <phrase>surface shape</phrase> <phrase>information</phrase> of the face are synchronously measured. And 3D <phrase>facial caricaturing</phrase> method is proposed by using the 3D(the <phrase>polygon</phrase> <phrase>data</phrase>) <phrase>face model</phrase>. <phrase>Automatic</phrase> method for <phrase>extracting</phrase> regions of the <phrase>facial parts</phrase> is <phrase>technically</phrase> proposed, and the <phrase>feature points</phrase> are extracted from those regions. We propose the mesh <phrase>model</phrase> composed of 44 <phrase>feature points</phrase> and 82 meshes to <phrase>cover</phrase> a <phrase>head</phrase>. To generate the <phrase>caricature</phrase> from this <phrase>polygon</phrase> <phrase>data</phrase>, the individuality feature is defined in value by the difference of the <phrase>feature points</phrase> between the input face and the mean face, which was defined from the <phrase>average</phrase> of many input faces.
<phrase>Colour</phrase> Texture <phrase>Fusion</phrase> of <phrase>Multiple Range Images</phrase>.
On the Detection of <phrase>Feature Points</phrase> of 3D <phrase>Facial Image</phrase> and its Application to 3D <phrase>Facial Caricature</phrase>.
3D <phrase>Animation</phrase> Of <phrase>Cerebral</phrase> Activity Using Both <phrase>Spatial</phrase> And Temporal <phrase>fMRI</phrase> <phrase>Information</phrase>.
Interactive <phrase>Shape Acquisition</phrase> using Marker Attached <phrase>Laser</phrase> Projecto.
<phrase>CAD</phrase> and Vision in <phrase>Rangefinder</phrase>-based Dimensional <phrase>Metrology</phrase>.
A concept of <phrase>CAD</phrase> <phrase>model</phrase>-based <phrase>automated</phrase> 3D measurement and the evaluation of its feasibility in cases drawn from <phrase>industrial</phrase> needs. <phrase>Automated</phrase> 3D measurement can be seen as comprising two steps: measurement <phrase>planning</phrase> and measurement execution. The concept was evaluated by <phrase>implementing</phrase> a <phrase>graphical</phrase> measurement <phrase>planning</phrase> tool and two <phrase>automatic</phrase> <phrase>optical measurement</phrase> systems equipped with <phrase>vision systems</phrase> for <phrase>sensory feedback</phrase>. The operation chain from <phrase>CAD</phrase> <phrase>model</phrase>-based measurement <phrase>planning</phrase> to comparison between the measured and designed geometries was demonstrated. Successful experiments with <phrase>automatic</phrase> operation controlled by the measurement plan and vision guidance were carried out and the key <phrase>performance criteria</phrase> were met.
<phrase>Uncalibrated</phrase> <phrase>Multiple Image</phrase> <phrase>Stereo</phrase> System with Arbitrarily <phrase>Movable</phrase> <phrase>Camera</phrase> and Projector for <phrase>Wide Range</phrase> Scanning.
In this <phrase>paper</phrase>, we propose an <phrase>uncalibrated</phrase>, multi-image 3D <phrase>reconstruction</phrase>, using <phrase>coded structured light</phrase>. Normally, a conventional <phrase>coded structured light</phrase> system consists of a <phrase>camera</phrase> and a projector and needs precalibration before scanning. Since the <phrase>camera</phrase> and the projector have to be fixed after <phrase>calibration</phrase>, <phrase>reconstruction</phrase> of a <phrase>wide area</phrase> of the scene or <phrase>reducing</phrase> occlusions by multiple scanning are difficult and sometimes impossible. In the <phrase>proposed method</phrase>, multiple scanning while moving the <phrase>camera</phrase> or the projector is possible by <phrase>applying</phrase> the <phrase>uncalibrated stereo</phrase> method, thereby achieving a multi-image 3D <phrase>reconstruction</phrase>. As compared to the conventional <phrase>coded structured light</phrase> method, our system does not require <phrase>calibration</phrase> of <phrase>extrinsic camera parameters</phrase>, occlusions are reduced, and a <phrase>wide area</phrase> of the scene can be acquired. As compared to <phrase>image-based</phrase> multi-<phrase>image reconstruction</phrase>, the proposed system can obtain <phrase>dense</phrase> shape <phrase>data</phrase> with <phrase>higher precision</phrase>. As a result of these advantages, users can freely move either the cameras or projectors to <phrase>scan</phrase> a <phrase>wide range</phrase> of objects, but not if both the <phrase>camera</phrase> and the projector are moved at the same time.
<phrase>Three-Dimensional</phrase> <phrase>Reconstruction</phrase> of the <phrase>Bony Structures</phrase> involved in the <phrase>Articular</phrase> Complex of the <phrase>Human</phrase> <phrase>Shoulder</phrase> Using <phrase>Shape-Based Interpolation</phrase> and <phrase>Contour</phrase>-Based <phrase>Extrapolation</phrase>.
<phrase>Virtual Environment</phrase> Modeling by <phrase>Integrated Optical</phrase> and <phrase>Acoustic</phrase> Sensing.
<phrase>AVENUE</phrase>: <phrase>Automated</phrase> Site Modeling in <phrase>Urban</phrase> Environments.
<phrase>OSCAR</phrase>: <phrase>Object Segmentation</phrase> Using <phrase>Correspondence</phrase> and Relaxation.
<phrase>Efficient</phrase> <phrase>Discovery Service</phrase> for a <phrase>Digital Library</phrase> of 3D Models.
Many <phrase>geographically distributed</phrase> experts in different areas such as <phrase>medical imaging</phrase>, <phrase>e-commerce</phrase>, and <phrase>digital</phrase> <phrase>museums</phrase>, are in need of 3D models. Although 3D models are becoming widely available due to the recent <phrase>technological advancement</phrase> and <phrase>modeling tools</phrase>, we lack a <phrase>digital library</phrase> system where they can be searched and retrieved efficiently. In this <phrase>paper</phrase> we focus on <phrase>an efficient</phrase> <phrase>discovery service</phrase> consisting of <phrase>multi-level</phrase> <phrase>hierarchical</phrase> browsing service that <phrase>enables users</phrase> to navigate <phrase>large sets</phrase> of 3D models. For this purpose, we use <phrase>shape based</phrase> <phrase>clustering</phrase> to <phrase>abstract</phrase> a large set of 3D models to a small set of representative models (key models). Our service applies <phrase>clustering</phrase> recursively to limit the number of key models that a <phrase>user views</phrase> at a time. <phrase>Clustering</phrase> is derived from metrics that are based on a concept of compression and <phrase>similarity computation</phrase> using <phrase>surface signatures</phrase>. <phrase>Signatures</phrase> are the <phrase>two-dimensional</phrase> representations of a 3D <phrase>model</phrase> and they can be used to define similarity between 3D models. We integrated the proposed browsing capability with 3DLIB,(a <phrase>digital library</phrase> for 3-<phrase>D</phrase> models that we are <phrase>building</phrase> at <phrase>Old Dominion University</phrase>), and evaluated the proposed browsing service using the <phrase>Princeton</phrase> Shape Benchmark (PSB). Our <phrase>evaluation shows</phrase> significant better <phrase>precision and recall</phrase> as compared to other approaches.
<phrase>Industrial</phrase> <phrase>Painting</phrase> Inspection using <phrase>Specular</phrase> <phrase>Sharpness</phrase>.
<phrase>Digital</phrase> 3D plus <phrase>color imaging</phrase> is a growing field as it has many <phrase>industrial</phrase> applications. One of them is the precise <phrase>understanding</phrase> of <phrase>optical properties</phrase> of objects, which is possible to obtain from 3D plus <phrase>brightness</phrase> or <phrase>color</phrase> <phrase>data</phrase>. Those properties are usually important inspection criteria; for example, the <phrase>specular</phrase> <phrase>sharpness</phrase> of a coatted surface is usually related to the <phrase>coating</phrase> quality. This <phrase>paper</phrase> is related to a procedure for <phrase>recovering</phrase> the <phrase>specular</phrase> <phrase>sharpness</phrase> and other surface-<phrase>related properties</phrase> from objects. The current approach works on 3D plus <phrase>brightness</phrase> or <phrase>color</phrase> <phrase>data</phrase>, which are retrieved in two steps using a common <phrase>structured-light</phrase> <phrase>triangulation</phrase>-based technique and an ordinary non-structured <phrase>spot</phrase> <phrase>light</phrase>. Some <phrase>experimental</phrase> <phrase>results</phrase> obtained on <phrase>industrial</phrase> parts are also shown.
<phrase>Automatic</phrase> 3D modeling of <phrase>palatal</phrase> <phrase>plaster</phrase> casts.
Geometrically <phrase>Stable</phrase> <phrase>Sampling</phrase> for the <phrase>ICP</phrase> <phrase>Algorithm</phrase>.
<phrase>On-Line</phrase> <phrase>Hand-Eye Calibration</phrase>.
<phrase>Multiresolution</phrase> <phrase>Interactive Modeling</phrase> with <phrase>Efficient</phrase> Visualization.
3D <phrase>interactive modeling</phrase> from <phrase>range</phrase> <phrase>data</phrase> aims at simultaneously producing and <phrase>visualizing</phrase> the <phrase>surface model</phrase> of an object while <phrase>data</phrase> is collected. The <phrase>current research</phrase> <phrase>challenge</phrase> is producing the <phrase>final result</phrase> in <phrase>real-time</phrase>. Using a <phrase>recently</phrase> proposed framework, a <phrase>surface model</phrase> is built in a <phrase>volumetric</phrase> structure encoding a <phrase>vector field</phrase> in the <phrase>neighborhood</phrase> of the <phrase>object surface</phrase>. In this <phrase>paper</phrase>, it is shown that the framework allows one to locally control the <phrase>model</phrase> resolution during acquisition. Using <phrase>ray tracing</phrase>, <phrase>efficient</phrase> visualization approaches of the <phrase>multiresolution</phrase> <phrase>vector field</phrase> are described and compared. More precisely, it is shown that volume traversal can be optimized while <phrase>preventing</phrase> holes and <phrase>reducing</phrase> <phrase>aliasing</phrase> in the <phrase>rendered image</phrase>.
A <phrase>Robust</phrase> <phrase>Image-Based</phrase> Method for 3D Registration.
Today modeling from <phrase>reality</phrase> receives more and more attention. In this <phrase>paper</phrase>, we present a novel <phrase>image-based</phrase> 3D <phrase>registration method</phrase>. Compared with a previous one it does not require accurate <phrase>starting position</phrase>, <phrase>albedo</phrase> and <phrase>geometric</phrase> invariants, but has to address the more apparent <phrase>mismatch</phrase> problems. First, distinctive <phrase>corner</phrase> points, which <phrase>act</phrase> as <phrase>salient features</phrase> for subsequent <phrase>image matching</phrase>, are detected via the <phrase>minimal</phrase> <phrase>eigenvalue</phrase> of the <phrase>auto-correlation</phrase> matrix. Then, a <phrase>verification scheme</phrase> discards the potential mismatches by thresholds of the <phrase>correlation coefficients</phrase> and <phrase>point-to-point</phrase> distances. <phrase>Experimental</phrase> <phrase>results</phrase> demonstrate the superiority of our proposed <phrase>verification scheme</phrase> to the previous one using only <phrase>correlation coefficients</phrase> under the <phrase>relaxed</phrase> conditions.
A 3D <phrase>Laser</phrase> <phrase>Micro</phrase>-<phrase>sensor</phrase> <phrase>Integrating</phrase> Control and <phrase>Data Processing</phrase> in <phrase>an FPGA-Based</phrase> <phrase>Calculator</phrase>.
<phrase>Hierarchical</phrase> <phrase>Coarse to Fine</phrase> <phrase>Depth Estimation</phrase> for Realistic <phrase>View Interpolation</phrase>.
This <phrase>paper</phrase> presents a novel approach for <phrase>view synthesis</phrase> and <phrase>image interpolation</phrase>. The <phrase>algorithm</phrase> is build up in a <phrase>hierarchical</phrase> way, and this on different <phrase>structural</phrase> levels <phrase>instead</phrase> of using a classic <phrase>image pyramid</phrase>. First coarse matching is done on a ýshape basisý only. A <phrase>background-foreground segmentation</phrase> yields a <phrase>fairly accurate</phrase> <phrase>contour</phrase> for every incoming <phrase>video</phrase> <phrase>stream</phrase>. Inter-relating these contours is a 1D problem and as such very <phrase>fast</phrase>. This step is then used to compute small <phrase>position dependent</phrase> <phrase>bounding</phrase>-boxes in 3D space which enclose the underlying object. The <phrase>next</phrase> step is a more expensive <phrase>window based</phrase> matching, within the volume of these <phrase>bounding</phrase>-boxes. This is limited to a number of regions around ýpromisingý <phrase>feature points</phrase>. <phrase>Global</phrase> <phrase>regularisation</phrase> is obtained by a <phrase>graph cut</phrase>. Speed <phrase>results</phrase> here from limiting the number of <phrase>feature points</phrase>. In a third step the <phrase>interpolation</phrase> is ýpre-renderedý and simultaneously evaluated on a <phrase>per pixel</phrase> basis. This is done by <phrase>computing</phrase> a Birchfield <phrase>dissimilarity measure</phrase> on the <phrase>GPU</phrase>. <phrase>Per pixel</phrase> parallelised operations keep <phrase>computational cost</phrase> low. <phrase>Finally</phrase> the bad interpolated parts are ýpatchedý. This <phrase>per pixel</phrase> correction yields the final interpolated view at the finest level. Here we will also deal explicitly with <phrase>opacity</phrase> at the <phrase>borders</phrase> of the <phrase>foreground object</phrase>.
3D Modeling of <phrase>Outdoor</phrase> Environments by <phrase>Integrating</phrase> <phrase>Omnidirectional</phrase> <phrase>Range</phrase> and <phrase>Color</phrase> Images.
This <phrase>paper</phrase> describes a 3D <phrase>modeling method</phrase> for <phrase>wide area</phrase> <phrase>outdoor</phrase> environments which is based on <phrase>integrating</phrase> <phrase>omnidirectional</phrase> <phrase>range</phrase> and <phrase>color images</phrase>. In the <phrase>proposed method</phrase>, <phrase>outdoor</phrase> scenes can be efficiently digitized by an <phrase>omnidirectional</phrase> <phrase>laser rangefinder</phrase> which can obtain a 3D shape with <phrase>high</phrase>-accuracy and by an <phrase>omnidirectional</phrase> <phrase>multi-camera</phrase> system (<phrase>OMS</phrase>) which can capture a <phrase>high</phrase>-resolution <phrase>color</phrase> image. <phrase>Multiple range images</phrase> are registered by <phrase>minimizing</phrase> the distances between corresponding points in the different <phrase>range</phrase> images. In <phrase>order</phrase> to register <phrase>multiple range images</phrase> stably, points on plane portions detected from the <phrase>range</phrase> <phrase>data</phrase> are used in <phrase>registration process</phrase>. The <phrase>position and orientation</phrase> acquired by <phrase>RTK-GPS</phrase> and <phrase>gyroscope</phrase> are used as <phrase>initial values</phrase> of <phrase>simultaneous</phrase> registration. The 3D <phrase>model</phrase> obtained by registration of <phrase>range</phrase> <phrase>data</phrase> is mapped by textures selected from <phrase>omnidirectional</phrase> images in consideration of the resolution of texture and occlusions of the <phrase>model</phrase>. In experiments, we have carried out 3D modeling of our <phrase>campus</phrase> with the <phrase>proposed method</phrase>.
<phrase>Detecting</phrase> Cylinders in 3D <phrase>Range</phrase> <phrase>Data</phrase> Using <phrase>Model Selection</phrase> Criteria.
In this <phrase>paper</phrase>, we use a <phrase>model selection</phrase> criterion to <phrase>decide whether</phrase> two cylinders should be merged as a <phrase>single</phrase> <phrase>cylinder</phrase> or they should be left separated. We compare and evaluate an extensive number of different <phrase>model selection</phrase> criteria for this purpose and examine which factors can affect their performance. We conclude that <phrase>SSC</phrase>, GIC, MCAIC and CAIC have a better performance (for this particular application) compared to the other criteria.
<phrase>Constructing</phrase> Models of <phrase>Articulating</phrase> Objects: <phrase>Range</phrase> <phrase>Data</phrase> Partitioning.
In this <phrase>paper</phrase> we consider one <phrase>aspect</phrase> of the problem of <phrase>automatically building</phrase> <phrase>shape models</phrase> of <phrase>articulating</phrase> objects from example <phrase>range</phrase> images. Central to the <phrase>model</phrase> <phrase>construction</phrase> problem is the registration of <phrase>range</phrase> <phrase>data</phrase>, taken from different <phrase>vantage points</phrase>, into a common <phrase>coordinate frame</phrase>. This <phrase>involves determining</phrase> a transformation for each set of <phrase>range</phrase> <phrase>data</phrase> which aligns overlapping <phrase>surface points</phrase> in the common frame. Current <phrase>registration algorithms</phrase> have been developed <phrase>specifically</phrase> for <phrase>rigid objects</phrase>, but it is not obvious how these can be extended to articulated or more generally <phrase>deformable objects</phrase>. Here, we propose that <phrase>range</phrase> images of <phrase>articulated objects</phrase> are first segmented into their rigid subcomponents. Each subcomponent can then be registered in isolation using the <phrase>existing algorithms</phrase> <phrase>designed specifically</phrase> for <phrase>rigid parts</phrase> and the final <phrase>model</phrase> formed by reassembling all of the submodels. This has motivated the development of a rigid part <phrase>segmentation algorithm</phrase> which is described and demonstrated here. The <phrase>algorithm</phrase> is currently limited to non-umbilic surfaces, but in this more <phrase>restricted</phrase> domain is shown to work well.
<phrase>Human</phrase> Identification from <phrase>Body Shape</phrase>.
<phrase>Extracting</phrase> Main Modes of <phrase>Human Body Shape</phrase> Variation from 3-<phrase>D</phrase> <phrase>Anthropometric</phrase> <phrase>Data</phrase>.
<phrase>Characterizing</phrase> the variations of the <phrase>human body</phrase> shape is <phrase>fundamentally important</phrase> to many applications ranging from <phrase>animation</phrase> to <phrase>product design</phrase>. 3-<phrase>D</phrase> scanning <phrase>technology</phrase> makes it possible to digitize the complete surfaces of a <phrase>large number</phrase> of <phrase>human</phrase> bodies, providing much <phrase>richer information</phrase> about the <phrase>body shape</phrase> than the traditional <phrase>anthropometric</phrase> measurements. This <phrase>technology</phrase> <phrase>opens up</phrase> opportunities to extract new measurements for <phrase>quantifying</phrase> the <phrase>body shape</phrase>. Using the <phrase>data</phrase> from the first <phrase>large scale</phrase> 3-<phrase>D</phrase> <phrase>anthropometric</phrase> survey, the <phrase>CAESAR</phrase> <phrase>project</phrase>, we demonstrate that the <phrase>human body</phrase> shape can be represented by a small number of <phrase>principal components</phrase>. <phrase>Principal Component Analysis</phrase> extracts <phrase>orthogonal basis</phrase> vectors, called eigenpersons, from the space of <phrase>body shapes</phrase>. The shape of any individual person can then be expressed by the <phrase>linear combination</phrase> of the <phrase>basis vectors</phrase>. We demonstrate that some of these components correspond to the <phrase>commonly used</phrase> <phrase>body measurements</phrase> like height and weight and others indicate new ways of charactering <phrase>body shape</phrase> variations. We develop tools to visualize the changes of the <phrase>body shape</phrase> along the <phrase>main components</phrase>. These tools help understand the meaningful components of the <phrase>human body</phrase> shape.
A Method for the Registration of <phrase>Attributed</phrase> <phrase>Range</phrase> Images.
<phrase>Data Acquisition</phrase> and Representation of <phrase>Mechanical Parts</phrase> and Interfaces to <phrase>Manufacturing</phrase> Devices.
In this <phrase>paper</phrase> we address <phrase>data acquisition</phrase>, <phrase>data</phrase> <phrase>represen- tation</phrase> and interfaces to <phrase>manufacturing</phrase> devices as they relate to <phrase>automatic</phrase> creation of <phrase>electronic</phrase> files for representing the complete <phrase>geometry</phrase> of an <phrase>arbitrarily shaped</phrase> part.
Accuracy of 3D <phrase>Range</phrase> Scanners by Measurement of the Slanted Edge <phrase>Modulation</phrase> <phrase>Transfer Function</phrase>.
<phrase>Design</phrase> Considerations for a <phrase>Range</phrase> <phrase>Image Sensor</phrase> Containing a <phrase>PSD</phrase>-array and An <phrase>On-chip</phrase> <phrase>Multiplexer</phrase>.
In the present <phrase>paper</phrase> we introduce a <phrase>range</phrase> <phrase>image sensor</phrase>, the <phrase>PSD</phrase>-chip, designed for <phrase>sheet</phrase> of <phrase>light</phrase> <phrase>range</phrase> <phrase>imaging</phrase>. The <phrase>image sensor</phrase> consists of an array of 128 <phrase>Position Sensitive</phrase> Detector (<phrase>PSD</phrase>)-<phrase>strips</phrase> with <phrase>a 20</phrase> <phrase>mm</phrase> length and a 28 /<phrase>spl mu</phrase>/<phrase>m</phrase> pitch. <phrase>Design</phrase> considerations for the <phrase>image sensor</phrase> are discussed, as well as the <phrase>on-chip</phrase> <phrase>electronics</phrase>. The <phrase>on-chip</phrase> <phrase>electronics</phrase> consists of an <phrase>analog</phrase> part and a <phrase>digital</phrase> part. The <phrase>analog</phrase> preamplifiers deal with the <phrase>low-pass</phrase> filtering of the <phrase>sensor</phrase>-signals in <phrase>order</phrase> to reduce the noise bandwidth. The <phrase>digital</phrase> part consists of an <phrase>analog</phrase> current <phrase>multiplexer</phrase>, implemented in <phrase>ECL</phrase> <phrase>technology</phrase>. Our goal is to achieve a 2 <phrase>MHz</phrase> <phrase>range</phrase>/<phrase>frequency</phrase> at 12 <phrase>bits</phrase> resolution.
<phrase>Image-Gradient</phrase>-<phrase>Guided</phrase> <phrase>Real-Time</phrase> <phrase>Stereo</phrase> on <phrase>Graphics Hardware</phrase>.
We present a <phrase>real-time</phrase> <phrase>correlation-based</phrase> <phrase>stereo</phrase> <phrase>algorithm</phrase> with <phrase>improved accuracy</phrase>. Encouraged by the success of recent <phrase>stereo</phrase> <phrase>algorithms</phrase> that aggregate the matching <phrase>cost based</phrase> on <phrase>color</phrase> segmentation, a novel <phrase>image-gradient</phrase>-<phrase>guided</phrase> <phrase>cost aggregation</phrase> scheme is presented in this <phrase>paper</phrase>. The new scheme is designed to fit the <phrase>architecture</phrase> of recent <phrase>graphics processing units</phrase> (<phrase>GPUs</phrase>). As a result, our <phrase>stereo</phrase> <phrase>algorithm</phrase> can run completely on the <phrase>graphics board</phrase>: from <phrase>rectification</phrase>, matching cost computation, <phrase>cost aggregation</phrase>, to the final disparity selection. Compared with many <phrase>real-time</phrase> <phrase>stereo</phrase> <phrase>algorithms</phrase> that use fixed <phrase>windows</phrase>, noticeable <phrase>accuracy improvement</phrase> has been obtained <phrase>without sacrificing</phrase> <phrase>realtime</phrase> performance. In addition, existing <phrase>global optimization</phrase> <phrase>algorithms</phrase> can also benefit from the new <phrase>cost aggregation</phrase> scheme. The effectiveness of our approach is demonstrated with several widely used <phrase>stereo</phrase> datasets and <phrase>live</phrase> <phrase>data</phrase> captured from a <phrase>stereo camera</phrase>.
<phrase>Structure and Motion</phrase> from Two <phrase>Uncalibrated</phrase> Views Using Points on Planes.
<phrase>Automatic</phrase> <phrase>CAD</phrase> Modeling of <phrase>Industrial</phrase> <phrase>Pipes</phrase> from <phrase>Range</phrase> Images.
We present in this <phrase>paper</phrase> a method to obtain automatically <phrase>CAD</phrase> models of <phrase>industrial</phrase> <phrase>pipes</phrase> from <phrase>range</phrase> images. The models are based on two <phrase>geometric</phrase> primitives, cylinders and <phrase>torii</phrase>, which are enough to represent most parts of the <phrase>pipes</phrase>. The images are obtained with an accurate <phrase>long</phrase>-distance <phrase>laser</phrase> <phrase>range</phrase> <phrase>sensor</phrase> developed for <phrase>reverse engineering</phrase> in <phrase>industrial</phrase> structures. The <phrase>key issue</phrase> for <phrase>automatic</phrase> <phrase>CAD</phrase> modeling is the <phrase>automatic</phrase> segmentation of the <phrase>data</phrase> into subsets of points corresponding to the desired primitives. To do so, we use <phrase>differential geometry</phrase> to segment lines of <phrase>centers</phrase> of <phrase>curvature</phrase> into <phrase>straight and curved</phrase> parts, corresponding to the <phrase>cylinder</phrase> and <phrase>torus</phrase> parts of the <phrase>original image</phrase>. <phrase>Differential geometry</phrase> <phrase>results</phrase> being noisy and <phrase>biased</phrase>, we use an <phrase>optimal</phrase> approach for the computation of <phrase>centers</phrase> of <phrase>curvature</phrase>.
<phrase>Fast</phrase> <phrase>Global</phrase> Registration of 3D <phrase>Sampled Surfaces</phrase> using a Multi-<phrase>Z</phrase>-Buffer Technique.
We present a new method for the <phrase>global</phrase> registration of several overlapping 3D surfaces sampled on an object. The method is based on the <phrase>ICP</phrase> (<phrase>iterative closest point</phrase>) <phrase>algorithm</phrase> and on a segmentation of the <phrase>sampled points</phrase> in <phrase>an optimized</phrase> set of <phrase>z</phrase>-buffers. This multi-<phrase>z</phrase>-buffer technique provides a 3D <phrase>space partitioning</phrase> which <phrase>greatly accelerates</phrase> the search of the <phrase>nearest neighbours</phrase> in the establishment of the <phrase>point-to-point</phrase> <phrase>correspondence</phrase> between overlapping surfaces. Then a <phrase>randomized</phrase> <phrase>iterative</phrase> registration is processed on the surface set. We have tested an implementation of this technique on real <phrase>sampled surfaces</phrase>. It appears to be <phrase>rapid</phrase> accurate and <phrase>robust</phrase>, especially in the case of <phrase>highly curved</phrase> objects.
3-<phrase>D</phrase> Vision <phrase>Technology</phrase> for <phrase>Occupant</phrase> Detection and Classification.
This <phrase>paper</phrase> describes a 3-<phrase>D</phrase> vision system based on a new 3-<phrase>D</phrase> <phrase>sensor</phrase> <phrase>technology</phrase> for the detection and classification of occupants in a <phrase>car</phrase>. New generation of so-called "<phrase>smart</phrase> <phrase>airbags</phrase>" require the <phrase>information</phrase> about the <phrase>occupancy</phrase> type and position of the <phrase>occupant</phrase>. This <phrase>information</phrase> allows a distinct control of the <phrase>airbag</phrase> <phrase>inflation</phrase>. In <phrase>order</phrase> to reduce the <phrase>risk</phrase> of injuries due to <phrase>airbag</phrase> deployment, the <phrase>airbag</phrase> can be suppressed completely in case of a child <phrase>seat</phrase> oriented in <phrase>reward</phrase> direction. In this <phrase>paper</phrase> we propose a 3-<phrase>D</phrase> vision system based on a 3-<phrase>D</phrase> optical <phrase>time-of-flight</phrase> (<phrase>TOF</phrase>) <phrase>sensor</phrase>, for the detection and classification of the <phrase>occupancy</phrase> on the <phrase>passenger</phrase> <phrase>seat</phrase>. <phrase>Geometrical shape</phrase> features are extracted from the 3-<phrase>D</phrase> <phrase>image sequences</phrase>. Polynomialclassifier is considered for the <phrase>classification task</phrase>. A comparison of <phrase>classifier performance</phrase> with <phrase>principle components</phrase> (eigenimages) is presented. This <phrase>paper</phrase> also discuss the robustness of the features with variation of the <phrase>data</phrase>. The full scale <phrase>tests</phrase> have been conducted on a <phrase>wide range</phrase> of realistic situations (adults/children/child seats etc.) which may occur in a <phrase>vehicle</phrase>.
<phrase>Digital</phrase> 3D <phrase>Imaging</phrase> System for <phrase>Rapid</phrase> Response on <phrase>Remote</phrase> Sites.
Is <phrase>Appearance-Based</phrase> <phrase>Structure from Motion</phrase> Viable?
Using <phrase>k-d Trees</phrase> for <phrase>Robust</phrase> 3D <phrase>Point Pattern Matching</phrase>.
Optimized <phrase>Position Sensors</phrase> for <phrase>Flying</phrase>-<phrase>Spot</phrase> <phrase>Active</phrase> <phrase>Triangulation</phrase> Systems.
Registration and <phrase>Fusion</phrase> of Intensity and <phrase>Range</phrase> <phrase>Data</phrase> for 3D Modelling of <phrase>Real World</phrase> Scenes.
<phrase>Automatic</phrase> <phrase>Editing</phrase> and <phrase>Curve-fitting</phrase> of 3-<phrase>D</phrase> Surface <phrase>Scan</phrase> <phrase>Data</phrase> of the <phrase>Human</phrase> Body.
This <phrase>paper</phrase> presents an <phrase>automatic</phrase> method to <phrase>trim</phrase> <phrase>arms</phrase> from the surface <phrase>scan data</phrase> of the <phrase>human</phrase> body. Curve and <phrase>surface approximation</phrase> are employed to refill the <phrase>data</phrase> <phrase>gap</phrase> after the <phrase>trimming</phrase> process. This delivers a more realistic <phrase>torso model</phrase> for further applications.
<phrase>Object Model</phrase> Creation from <phrase>Multiple Range Images</phrase>: Acquisition, <phrase>Calibration</phrase>, <phrase>Model Building</phrase> and Verification.
This <phrase>paper</phrase> demonstrates the accuracy of a <phrase>prototype</phrase> <phrase>Laser</phrase> <phrase>Range</phrase> <phrase>Camera</phrase> (LRC) developed at the <phrase>National Research Council of Canada</phrase> for the creation of models of <phrase>real objects</phrase>. A <phrase>laser</phrase> survey performed in collaboration with the <phrase>Canadian Space Agency</phrase> and <phrase>NASA</phrase> is used as a <phrase>test case</phrase>. The object selected for this particular <phrase>test case</phrase> is the <phrase>Orbiter</phrase> <phrase>Docking</phrase> System (<phrase>ODS</phrase>) located at the <phrase>Kennedy Space Center</phrase>, <phrase>Florida</phrase>. During the <phrase>laser</phrase> survey, 128 <phrase>range</phrase> (and registered intensity) images were acquired all around the <phrase>ODS</phrase>. These images were then processed in our <phrase>laboratory</phrase>. A full <phrase>model</phrase> of the <phrase>top</phrase> portion of the <phrase>ODS</phrase> was created along with an almost complete <phrase>model</phrase> of the <phrase>ODS</phrase>. The <phrase>ODS</phrase> has a <phrase>diameter</phrase> of 1.6 <phrase>m</phrase> and a height of 3.9 <phrase>m</phrase>. Targets mounted on the <phrase>top</phrase> portion of the <phrase>ODS</phrase> were used to assess the accuracy of the <phrase>calibration</phrase> and of the <phrase>image registration</phrase> process. These targets were measured with a network of theodolites a day prior to the <phrase>laser</phrase> survey and used as a reference. With the current <phrase>calibration</phrase> and <phrase>range</phrase> <phrase>image registration</phrase> techniques, an accuracy better than 0.25 <phrase>mm</phrase> in <phrase>X</phrase> and <phrase>Y</phrase>, and, 0.80 <phrase>mm</phrase> in <phrase>Z</phrase> was achieved. These <phrase>results</phrase> compare favorably with the <phrase>single</phrase> point accuracy obtained after <phrase>calibration</phrase>, i.e., about 0.25 <phrase>mm</phrase> in <phrase>X</phrase> and <phrase>Y</phrase>, and, 0.50 <phrase>mm</phrase> in <phrase>Z</phrase>. These figures and others should testify on the usefulness of a LRC for accurate <phrase>model building</phrase>.
A <phrase>Scene Analysis</phrase> System for the Generation of 3-<phrase>D</phrase> Models.
A <phrase>scene analysis</phrase> system for the 3-<phrase>D</phrase> modeling of objects is presented. It combines <phrase>surface reconstruction</phrase> techniques with <phrase>object recognition</phrase> for the generation of 3-<phrase>D</phrase> models for <phrase>computer graphic</phrase> applications. The system permits the insertion of highlevel constraints, like a specific angle between two <phrase>house</phrase> walls, in an <phrase>explicit knowledge</phrase> base implemented as a <phrase>semantic</phrase> <phrase>net</phrase>. The applicability of those constraints is proved by asserting and <phrase>testing hypotheses</phrase> in an interpretation phase. In the case of rejection a more <phrase>general</phrase> constraint or <phrase>model</phrase> is selected. The capabilities of the system were shown for the modeling of buildings using depth from <phrase>stereo</phrase> and <phrase>contour information</phrase>. The system reconstructs the surface of the <phrase>scene objects</phrase> using the constraints selected in the prior interpretation.
<phrase>Real-Time</phrase> <phrase>Geometrical</phrase> Tracking and <phrase>Pose Estimation</phrase> Using <phrase>Laser</phrase> <phrase>Triangulation</phrase> and <phrase>Photogrammetry</phrase>.
<phrase>Efficient</phrase> and <phrase>Reliable</phrase> Template Set Matching for 3D <phrase>Object Recognition</phrase>.
<phrase>Recursive</phrase> <phrase>Model</phrase> Optimization Using <phrase>ICP</phrase> and <phrase>Free</phrase> Moving 3D <phrase>Data Acquisition</phrase>.
A <phrase>Nearest Neighbor</phrase> Method for <phrase>Efficient</phrase> <phrase>ICP</phrase>.
A <phrase>Geometric</phrase> Approach to the Segmentation of <phrase>Range</phrase> Images.
<phrase>Approximate</phrase> <phrase>K</phrase>-<phrase>D</phrase> <phrase>Tree</phrase> Search for <phrase>Efficient</phrase> <phrase>ICP</phrase>.
Accuracy of 3D Scanning Technologies in a Face Scanning Scenario.
In this <phrase>paper</phrase>, we will review several different 3D scanning devices. We will present a method for empirical accuracy analysis, and apply it to several scanners providing <phrase>an overview</phrase> of their technologies. The scanners include both <phrase>general</phrase> purpose and face specific scanning devices. We will focus on face scanning technique, although the technique should be applicable to other domains as well. The <phrase>proposed method</phrase> involves several different <phrase>calibration</phrase> faces of known shape and comparisons of their scans to investigate both <phrase>absolute</phrase> accuracy and <phrase>repeatability</phrase>.
<phrase>Hand Posture</phrase> Estimation from 2D <phrase>Monocular</phrase> Image.
<phrase>Hierarchical</phrase> Segmentation of <phrase>Range</phrase> Images with <phrase>Contour</phrase> Constraints.
This <phrase>paper</phrase> describes a new <phrase>algorithm</phrase> to segment in <phrase>continuous</phrase> <phrase>parametric</phrase> regions <phrase>range</phrase> images. The <phrase>algorithm</phrase> starts with an <phrase>initial partition</phrase> of small <phrase>first order</phrase> regions using a <phrase>robust fitting</phrase> <phrase>algorithm</phrase> constrained by the detection of depth and <phrase>orientation discontinuities</phrase>. The <phrase>algorithm</phrase> then optimally <phrase>group</phrase> these regions into larger and larger regions using <phrase>parametric</phrase> functions until an approximation limit is reached. The <phrase>algorithm</phrase> uses <phrase>Bayesian</phrase> <phrase>decision theory</phrase> to determine the <phrase>local</phrase> <phrase>optimal</phrase> <phrase>grouping</phrase> and the complexity of the <phrase>parametric</phrase> <phrase>model</phrase> used to represent the <phrase>range</phrase> signal. After the <phrase>segmentation process</phrase> an <phrase>exact</phrase> description of the boundary of each <phrase>region</phrase> is computed from the mutual intersections of the extracted surfaces. <phrase>Experimental</phrase> <phrase>results</phrase> show <phrase>significant improvement</phrase> of <phrase>region boundary</phrase> localization. A <phrase>systematic</phrase> comparison of our <phrase>algorithm</phrase> to the most well known <phrase>algorithm</phrase> in the <phrase>literature</phrase> is presented to highlight the contributions of this <phrase>paper</phrase>.
<phrase>Reliable</phrase> 3D Surface Acquisition, Registration and Validation Using Statistical <phrase>Error Models</phrase>.
<phrase>Non-Parametric</phrase> 3D <phrase>Surface Completion</phrase>.
We consider the completion of the <phrase>hidden</phrase> or <phrase>missing portions</phrase> of 3D objects after the visible portions have been acquired with 2½<phrase>D</phrase> (or 3D) <phrase>range</phrase> capture. Our approach uses a combination of <phrase>global</phrase> <phrase>surface fitting</phrase>, to derive the underlying <phrase>geometric</phrase> <phrase>surface completion</phrase>, together with an extension, from 2D to 3D, of <phrase>non-parametric</phrase> <phrase>texture synthesis</phrase> in <phrase>order</phrase> to complete localised <phrase>surface texture</phrase> <phrase>relief</phrase> and structure. Through this combination and adaptation of existing completion techniques we are able to achieve realistic, plausible completion of 2½<phrase>D</phrase> <phrase>range</phrase> captures.
<phrase>Robust</phrase> <phrase>Surface Matching</phrase> for Registration.
<phrase>Micro</phrase>-<phrase>Stereoscopic</phrase> Vision System for the <phrase>Determination</phrase> of <phrase>Air</phrase> Bubbles and <phrase>Aqueous</phrase> Droplets Content within <phrase>Oil</phrase> Drops in Simulated Processes of <phrase>Multiphase</phrase> Fermentations.
<phrase>Industrial</phrase> <phrase>fermentation</phrase> procedures involve the <phrase>mixing</phrase> of multiple phases (solid, <phrase>liquid</phrase>, <phrase>gaseous</phrase>), where the <phrase>interfacial</phrase> <phrase>area</phrase> between the phases (<phrase>air</phrase> bubbles, <phrase>oil</phrase> drops and <phrase>aqueous</phrase> medium) determines the <phrase>nutrients</phrase> transfer and <phrase>hence</phrase> the performance of the <phrase>culture</phrase>. Interactions between phases occur, <phrase>giving rise</phrase> to the formation of <phrase>complex structures</phrase> containing <phrase>air</phrase> bubbles and small drops from the <phrase>aqueous</phrase> phase, trapped in <phrase>oil</phrase> drops (<phrase>water</phrase>-in-<phrase>oil</phrase>-in-<phrase>water</phrase>). A <phrase>two-dimensional</phrase> observation of this phenomenon may <phrase>lead</phrase> to an erroneous <phrase>determination</phrase> of the phenomena occurring since bubbles and droplets coming from different <phrase>focal</phrase> planes may appear overlapped. In the present work, an original strategy to solve this problem is described. <phrase>Micro</phrase>-<phrase>stereoscopic</phrase> <phrase>on-line</phrase> <phrase>image acquisition</phrase> techniques have been used, so as to obtain accurate images from the cultures for further <phrase>three-dimensional</phrase> analysis. Using this methodology, the <phrase>three-dimensional</phrase> <phrase>spatial</phrase> position of the trapped bubbles and droplets moving at <phrase>high</phrase> speed can be calculated in <phrase>order</phrase> to determine their <phrase>relative concentration</phrase>. To evaluate the accuracy of this technique, the <phrase>results</phrase> obtained with our system have been compared with those obtained by an <phrase>expert</phrase>. An agreement of 95% was achieved. Also, this technique was able to evaluate 14% more bubbles and droplets corresponding to overlaps that the <phrase>expert</phrase> was not able to <phrase>discern</phrase> in non-<phrase>stereoscopic</phrase> images.
3D <phrase>optical scanning</phrase> <phrase>diagnostics</phrase> for <phrase>Leonardo</phrase> <phrase>Da</phrase> Vinci's "Adorazione <phrase>dei</phrase> <phrase>Magi</phrase>" conservation.
<phrase>Unsupervised</phrase> 3D <phrase>Object Recognition</phrase> and <phrase>Reconstruction</phrase> in Unordered Datasets.
This <phrase>paper</phrase> presents a system for <phrase>fully automatic</phrase> recognition and <phrase>reconstruction</phrase> of 3D objects in <phrase>image databases</phrase>. We pose the <phrase>object recognition</phrase> problem as one of <phrase>finding</phrase> consistent matches between all images, subject to the constraint that the images were taken from a <phrase>perspective</phrase> <phrase>camera</phrase>. We assume that the objects or scenes are rigid. For each image we associate a <phrase>camera</phrase> matrix, which is <phrase>parameterised</phrase> by rotation, <phrase>translation</phrase> and <phrase>focal length</phrase>. We use <phrase>invariant local features</phrase> to find matches between all images, and the <phrase>RANSAC algorithm</phrase> to find those that are consistent with the <phrase>fundamental matrix</phrase>. Objects are recognised as subsets of matching images. We then solve for the <phrase>structure and motion</phrase> of each object, using a <phrase>sparse</phrase> <phrase>bundle adjustment algorithm</phrase>. Our <phrase>results</phrase> demonstrate that it is possible to recognise and reconstruct 3D objects from an unordered <phrase>image database</phrase> with no <phrase>user input</phrase> at all.
Accuracy Verification and Enhancement in 3D Modeling: Application to Donatello's Maddalena.
<phrase>Optimal</phrase> Postures and <phrase>Positioning</phrase> for <phrase>Human</phrase> Body Scanning.
Advancements in <phrase>technology</phrase> for <phrase>digitizing</phrase> the surface of the <phrase>human</phrase> body are providing new opportunities for <phrase>research</phrase> in <phrase>engineering</phrase> <phrase>anthropometry</phrase>, the study of <phrase>human</phrase> body measurement for <phrase>design</phrase> and evaluation purposes. The <phrase>availability</phrase> of the <phrase>technology</phrase> is just the first step in <phrase>applying</phrase> <phrase>surface scanning</phrase> to <phrase>engineering</phrase> <phrase>anthropometry</phrase>; several issues remain to be resolved to make these tools useful for <phrase>engineering</phrase> applications. One <phrase>important issue</phrase> is the <phrase>standardization</phrase> of <phrase>positioning</phrase> and the <phrase>posture</phrase> of the subject for scanning. In <phrase>engineering</phrase> it is not enough to be able to measure one individual one time in one <phrase>posture</phrase>, but it is also necessary to measure the individual in different postures and compare the individual with many other people who have been comparably measured. Not <phrase>surprisingly</phrase>, people can be more difficult to measure precisely than fixed <phrase>stationary objects</phrase>. In the process of <phrase>developing</phrase> standardized procedures for <phrase>surveying</phrase> the <phrase>civilian</phrase> populations of <phrase>North America</phrase> and <phrase>Europe</phrase>, an experiment was conducted to determine <phrase>optimal</phrase> scanning positions. While this experiment used just one type of scanning <phrase>technology</phrase>, many of the methods are <phrase>transferable</phrase> to other methods as well. This <phrase>paper</phrase> discusses the <phrase>results</phrase> from that investigation.
3D <phrase>Digitization</phrase> of a Large <phrase>Model</phrase> of <phrase>Imperial Rome</phrase>.
This <phrase>paper</phrase> describes 3D acquisition and modeling of the "Plastico <phrase>di</phrase> <phrase>Roma</phrase> antica", a large <phrase>plaster</phrase>-of-<phrase>Paris</phrase> <phrase>model</phrase> of <phrase>imperial Rome</phrase> (16x17 meters) created in the <phrase>last</phrase> <phrase>century</phrase>. Its overall size demands an acquisition approach typical of large structures, but it is also characterized by extremely <phrase>tiny</phrase> details, typical of <phrase>small objects</phrase>: houses are a few centimeters <phrase>high</phrase>; their <phrase>doors</phrase>, <phrase>windows</phrase>, etc. are smaller than 1 <phrase>cm</phrase>. The approach followed to resolve this "<phrase>contradiction</phrase>" is described. The result is a huge but precise 3D <phrase>model</phrase> created by using a special <phrase>metrology</phrase> <phrase>Laser</phrase> <phrase>Radar</phrase>. We give an account of the procedures of reorienting the large <phrase>point clouds</phrase> obtained after each acquisition step (50-60 <phrase>million points</phrase>) into a <phrase>single</phrase> reference system by means of <phrase>measuring</phrase> fixed redundant <phrase>reference points</phrase>. <phrase>Finally</phrase> we show how the <phrase>data</phrase> set can be properly <phrase>divided into</phrase> 2x2 meters sub-areas for allowing <phrase>data</phrase> <phrase>merging</phrase> and <phrase>mesh editing</phrase>..
3D Registration by Textured <phrase>Spin</phrase>-Images.
This work is motivated by the desire of <phrase>exploiting</phrase> for 3D registration purposes the <phrase>photometric</phrase> <phrase>information</phrase> current <phrase>range</phrase> cameras typically associate to <phrase>range</phrase> <phrase>data</phrase>. <phrase>Automatic</phrase> pairwise 3D registration procedures are two steps procedures with the first step performing an <phrase>automatic</phrase> crude estimate of the <phrase>rigid motion</phrase> parameters and the second step <phrase>refining</phrase> them by the <phrase>ICP</phrase> <phrase>algorithm</phrase> or some of its variations. Methods for <phrase>efficiently implementing</phrase> the first crude <phrase>automatic</phrase> estimate are still an <phrase>open</phrase> <phrase>research</phrase> <phrase>area</phrase>. <phrase>Spin</phrase>-images are a 3D matching tecnique very effective in this task. Since <phrase>spin</phrase>-images solely exploit <phrase>geometry</phrase> <phrase>information</phrase> it appears natural to extend their original definition to include <phrase>texture information</phrase>. Such an operation can clearly be made in many ways. This work introduces one particular extension of <phrase>spin</phrase>-images, called textured <phrase>spin</phrase>-images, and demostrates its performance for 3D registration. It will be seen that textured <phrase>spin</phrase>-images enjoy <phrase>remarkable properties</phrase> since they can give <phrase>rigid motion</phrase> estimates more <phrase>robust</phrase>, more precise, more resilient to noise than standard <phrase>spin</phrase>-images at a <phrase>lower computational cost</phrase>.
<phrase>Calibration</phrase> of a <phrase>Zooming Camera</phrase> using the <phrase>Normalized</phrase> Image of the <phrase>Absolute</phrase> <phrase>Conic</phrase>.
3-<phrase>D</phrase> <phrase>Landmark</phrase> Detection and Identification in the <phrase>CAESAR</phrase> <phrase>Project</phrase>.
<phrase>Euclidean</phrase> <phrase>Reconstruction</phrase> from <phrase>Translational</phrase> Motion Using <phrase>Multiple Cameras</phrase>.
We investigate the possibility of <phrase>Euclidean</phrase> <phrase>reconstruction</phrase> from <phrase>translational</phrase> motion, using multiple <phrase>uncalibrated cameras</phrase>. We show that in the case of <phrase>multiple cameras</phrase> viewing a <phrase>translating</phrase> scene, no <phrase>additional constraints</phrase> are given by the <phrase>translational</phrase> motion compared to the more <phrase>general</phrase> case with one <phrase>camera</phrase> viewing a scene undergoing a <phrase>general</phrase> motion. However, the <phrase>knowledge</phrase> of <phrase>translational</phrase> motion allows an intermediate <phrase>affine</phrase> <phrase>reconstruction</phrase> from each <phrase>camera</phrase>, and <phrase>aids</phrase> in the <phrase>reconstruction</phrase> process by <phrase>simplifying</phrase> several steps, resulting in a more <phrase>reliable</phrase> <phrase>algorithm</phrase> for 3D <phrase>reconstruction</phrase>. We also identify the critical directions of <phrase>translation</phrase>, for which no <phrase>affine</phrase> <phrase>reconstruction</phrase> is possible. Experiments on real and <phrase>simulated data</phrase> are performed to illustrate that the <phrase>method works</phrase> in practice.
<phrase>Automated</phrase> <phrase>Pavement Distress</phrase> Collection and Analysis: A 3-<phrase>D</phrase> Approach.
<phrase>Compact</phrase> and Portable 3D <phrase>Camera</phrase> for <phrase>Space Applications</phrase>.
Comparison of <phrase>HK</phrase> and <phrase>SC</phrase> <phrase>Curvature</phrase> Description Methods.
<phrase>Generalized</phrase> Cylinders Extraction in a <phrase>Range</phrase> Image.
We deal with 3D <phrase>object modeling</phrase> using <phrase>generalized</phrase> cylinders from a <phrase>single</phrase> <phrase>range</phrase> image. We focus on right <phrase>generalized</phrase> cylinders, a class of <phrase>generalized</phrase> cylinders for which the <phrase>cross-section</phrase> is at <phrase>right angle</phrase> with the <phrase>axis</phrase>. No homogeneity or <phrase>straightness</phrase> constraints are imposed. The crucial part of this work is the extraction of <phrase>axis</phrase> points and the representation of the <phrase>axis</phrase> curve in 3D space. <phrase>Interesting results</phrase> are obtained with a broad <phrase>variety</phrase> of <phrase>range</phrase> images.
<phrase>Realistic Human</phrase> <phrase>Head</phrase> Modeling with <phrase>Multi-View</phrase> Hairstyle <phrase>Reconstruction</phrase>.
We present a method for <phrase>constructing</phrase> <phrase>photorealistic</phrase> 3D <phrase>head</phrase> models from <phrase>color images</phrase> and a <phrase>geometric</phrase> <phrase>head model</phrase> of a specific person. With a simple <phrase>experimental</phrase> setup, we employ a <phrase>user-assisted</phrase> technique to register the <phrase>uncalibrated images</phrase> with the <phrase>geometric</phrase> <phrase>model</phrase>. A <phrase>weighted averaging</phrase> method is then used to extract a <phrase>panoramic</phrase> <phrase>texture map</phrase> from the <phrase>input images</phrase>. To recover the hairstyle of the specified person, a <phrase>virtual</phrase> <phrase>photo</phrase> plane is defined, according to a corresponding true <phrase>photo</phrase> plane, on which one <phrase>input image</phrase> is recorded. It provides hints to compute the 3D positions of the <phrase>visual</phrase> <phrase>contour</phrase> points of the <phrase>hair</phrase> from the images taken at different viewpoints. <phrase>Finally</phrase>, more hairs are grown to <phrase>cover</phrase> the whole <phrase>region</phrase> of the <phrase>scalp</phrase> using an <phrase>interpolation</phrase> method on the 3D <phrase>scalp</phrase> <phrase>mesh surfaces</phrase>.
<phrase>Large Data Sets</phrase> and Confusing Scenes in 3-<phrase>D</phrase> <phrase>Surface Matching</phrase> and Recognition.
How Much 3D-<phrase>Information</phrase> Can We Acquire? Optical <phrase>Range</phrase> Sensors at the Physical Limit, and Where to Apply Them.
<phrase>Automatic</phrase> Body Measurement for <phrase>Mass Customization</phrase> of Garments.
<phrase>Automatic</phrase> Registration of <phrase>Range</phrase> Images Based on <phrase>Correspondence</phrase> of Complete Plane Patches.
One of the difficulties in registering two <phrase>range</phrase> images scanned by 3D <phrase>laser</phrase> scanners is how to get a correct <phrase>correspondence</phrase> over the two images automatically. In this <phrase>paper</phrase>, we propose an <phrase>automatic registration</phrase> method based on matching of extracted planes. First, we introduce a new class of features: complete plane patches (<phrase>CPP</phrase>) on the basis of analysis of properties of <phrase>real scenes</phrase>. Then we generate a <phrase>compact</phrase> interpretation <phrase>tree</phrase> for these features. <phrase>Finally</phrase>, the <phrase>image registration</phrase> is accomplished automatically by searching the interpretation <phrase>tree</phrase>.
<phrase>Semi-Automatic</phrase> <phrase>Range</phrase> to <phrase>Range</phrase> Registration: A <phrase>Feature-Based</phrase> Method.
A Self-Referenced <phrase>Hand-Held</phrase> <phrase>Range</phrase> <phrase>Sensor</phrase>.
Segmentation of <phrase>Range</phrase> Images into <phrase>Planar</phrase> Regions.
This <phrase>paper</phrase> presents <phrase>a hybrid</phrase> approach to the segmentation of <phrase>range</phrase> images into <phrase>planar</phrase> regions. The term <phrase>hybrid</phrase> refers to a combination of edge- and <phrase>region</phrase>-based considerations. A <phrase>reliable</phrase> <phrase>computational procedure</phrase> which takes the <phrase>range</phrase> image discontinuities into account is presented for <phrase>computing</phrase> the pixel's normal. The <phrase>segmentation algorithm</phrase> consists of two parts. In the first one, the <phrase>pixels</phrase> are aggregated according to <phrase>local</phrase> properties derived from the <phrase>input data</phrase> and are represented by a <phrase>region adjacency graph</phrase> (<phrase>RAG</phrase>). At this stage, the image is still over-segmented. In the second part, the segmentation is refined thanks to the <phrase>construction</phrase> of an <phrase>irregular</phrase> <phrase>pyramid</phrase>. The base of the <phrase>pyramid</phrase> is the <phrase>RAG</phrase> <phrase>previously extracted</phrase>. The over-<phrase>segmented regions</phrase> are merged using a <phrase>surface-based</phrase> description. This <phrase>algorithm</phrase> has been evaluated on 80 <phrase>real images</phrase> acquired by two different <phrase>range</phrase> sensors using the methodology proposed in (<phrase>Hoover</phrase> <phrase>et al</phrase>., 1996). <phrase>Experimental</phrase> <phrase>results</phrase> are presented and compared to others obtained by four <phrase>research</phrase> groups.
<phrase>Locking</phrase> onto 3D-Structure by a Combined <phrase>Vergence</phrase> and <phrase>Fusion</phrase> System.
A 3D Scanning System Based on Low-Occlusion Approach.
<phrase>Multi-Resolution</phrase> <phrase>Geometric</phrase> <phrase>Fusion</phrase>.
<phrase>Geometric</phrase> <phrase>fusion</phrase> of multiple sets of overlapping surface measurements is an important problem for complete 3D object or environment modelling. <phrase>Fusion</phrase> based on a discrete <phrase>implicit surface</phrase> representation enables <phrase>fast</phrase> <phrase>reconstruction</phrase> for <phrase>complex object</phrase> modelling. However, surfaces are represented at a <phrase>single</phrase> resolution resulting in impractical <phrase>storage costs</phrase> for accurate <phrase>reconstruction</phrase> of <phrase>large objects</phrase>. This <phrase>paper</phrase> addresses accurate <phrase>reconstruction</phrase> of <phrase>surface models</phrase> <phrase>independent</phrase> of <phrase>object size</phrase>. <phrase>An incremental</phrase> <phrase>algorithm</phrase> is presented for <phrase>implicit surface</phrase> representation of an arbitrary <phrase>triangulated mesh</phrase> in a <phrase>volumetric</phrase> <phrase>envelope</phrase> around the surface. A <phrase>hierarchical</phrase> <phrase>volumetric</phrase> structure is introduced for <phrase>efficient</phrase> representation by <phrase>local</phrase> approximation of the surface within a fixed <phrase>error bound</phrase> using the maximum <phrase>voxel</phrase> size. <phrase>Multi-resolution</phrase> <phrase>geometric</phrase> <phrase>fusion</phrase> is achieved by incrementally <phrase>constructing</phrase> a <phrase>hierarchical</phrase> <phrase>surface representation</phrase> with <phrase>bounded</phrase> error. <phrase>Results</phrase> are presented for validation of the <phrase>multi-resolution</phrase> representation accuracy and <phrase>reconstruction</phrase> of <phrase>real objects</phrase>. <phrase>Multi-resolution</phrase> <phrase>geometric</phrase> <phrase>fusion</phrase> achieves a significant reduction in representation cost for the same level of <phrase>geometric</phrase> accuracy.
A <phrase>Light</phrase> <phrase>Modulation</phrase>/<phrase>Demodulation</phrase> Method for <phrase>Real-Time</phrase> 3D <phrase>Imaging</phrase>.
This <phrase>paper</phrase> describes a novel method for <phrase>digitizing</phrase> the 3D shape of an object in <phrase>real-time</phrase>, which can be used for capturing <phrase>live</phrase> <phrase>sequence</phrase> of the 3D shape of moving or <phrase>deformable objects</phrase> such as faces. Two DMD (= <phrase>Digital</phrase> <phrase>Micro</phrase> <phrase>Mirror</phrase>) devices are used as <phrase>high</phrase> speed switches for modulating and demodulating <phrase>light</phrase> <phrase>rays</phrase>. One DMD is used to generate <phrase>rays</phrase> of <phrase>light</phrase> pulses, which are <phrase>projected onto</phrase> the object to be measured. Another DMD is used to demodulate the <phrase>light</phrase> reflected from the object <phrase>illuminated</phrase> by the <phrase>light</phrase> pulses into <phrase>intensity image</phrase> that describes the disparity. A <phrase>prototype</phrase> <phrase>range finder</phrase> <phrase>implementing</phrase> the <phrase>proposed method</phrase> has been built. The <phrase>experimental</phrase> <phrase>results</phrase> showed that the <phrase>proposed method</phrase> works and <phrase>video</phrase> sequences of <phrase>disparity images</phrase> can be captured in <phrase>real time</phrase>.
<phrase>Toward</phrase> <phrase>Optimal</phrase> <phrase>Structured Light</phrase> Patterns.
A methodology for the <phrase>optimal design</phrase> of <phrase>projection</phrase> patterns for stereometric <phrase>structured light</phrase> systems is presented. The similarity as well as the difference between the <phrase>design</phrase> of <phrase>projection</phrase> patterns and the <phrase>design</phrase> of <phrase>optimal</phrase> signals for <phrase>digital</phrase> <phrase>communication</phrase> are discussed. The <phrase>design</phrase> of <phrase>K</phrase> <phrase>projection</phrase> patterns for a <phrase>structured light</phrase> system with <phrase>L</phrase> distinct planes of <phrase>light</phrase> is shown to be equivalent to the placement of <phrase>L</phrase> points in a <phrase>K</phrase> <phrase>dimensional space</phrase> subject to certain constraints. <phrase>optimal design</phrase> in the <phrase>MSE</phrase> sense is defined, but shown to <phrase>lead</phrase> to an intractable <phrase>multi-parameter</phrase> <phrase>global optimization</phrase> problem. <phrase>Intuitively</phrase> appealing <phrase>suboptimal solutions</phrase> derived from the <phrase>family</phrase> of <phrase>K</phrase> <phrase>dimensional space</phrase>-filling <phrase>Hilbert</phrase> curves are obtained. <phrase>Preliminary experimental results</phrase> are presented.
<phrase>Edge-Based</phrase> Approach to <phrase>Mesh Simplification</phrase>.
A Complete <phrase>U-V-Disparity</phrase> Study for <phrase>Stereovision</phrase> Based 3D <phrase>Driving Environment</phrase> Analysis.
<phrase>Reliable</phrase> <phrase>understanding</phrase> of the 3D <phrase>driving environment</phrase> is vital for <phrase>obstacle detection</phrase> and <phrase>Adaptive</phrase> <phrase>Cruise Control</phrase> (<phrase>ACC</phrase>) applications. <phrase>Laser</phrase> or <phrase>millimeter wave</phrase> <phrase>radars</phrase> have shown good performance in <phrase>measuring</phrase> <phrase>relative speed</phrase> and distance in a <phrase>highway</phrase> <phrase>driving environment</phrase>. However the accuracy of these systems decreases in an <phrase>urban</phrase> traffic environment as more confusion occurs due to factors such as <phrase>parked vehicles</phrase>, guardrails, <phrase>poles</phrase> and <phrase>motorcycles</phrase>. A <phrase>stereovision</phrase> based sensing system provides an effective supplement to <phrase>radar</phrase>-based <phrase>road scene</phrase> analysis with its much wider <phrase>field of view</phrase> and more accurate <phrase>lateral</phrase> <phrase>information</phrase>. This <phrase>paper</phrase> presents <phrase>an efficient</phrase> <phrase>solution</phrase> using a <phrase>stereovision</phrase> based <phrase>road scene</phrase> analysis <phrase>algorithm</phrase> which employs the "<phrase>U-V-disparity</phrase>" concept. This concept is used to classify a 3D <phrase>road</phrase> scene into relative surface planes and characterize the features of <phrase>road</phrase> <phrase>pavement</phrase> surfaces, roadside structures and obstacles. <phrase>Real-time</phrase> implementation of the <phrase>disparity map</phrase> calculation and the "<phrase>U-V-disparity</phrase>" classification is also presented.
<phrase>Calibration</phrase>-<phrase>Free</phrase> Approach to 3D <phrase>Reconstruction</phrase> Using <phrase>Light Stripe</phrase> Projections on a <phrase>Cube</phrase> Frame.
<phrase>Moving Objects</phrase> Detection from Time-Varied Background: An Application of <phrase>Camera</phrase> 3D <phrase>Motion Analysis</phrase>.
<phrase>PALM</phrase>: Portable <phrase>Sensor</phrase>-<phrase>Augmented</phrase> Vision System for Large-<phrase>Scene Modeling</phrase>.
<phrase>Automatic</phrase> <phrase>Burr</phrase> Detection on Surfaces of <phrase>Revolution</phrase> Based on <phrase>Adaptive</phrase> 3D Scanning.
This <phrase>paper</phrase> describes how to <phrase>automatically extract</phrase> the presence and location of <phrase>geometrical</phrase> irregularities on a surface of <phrase>revolution</phrase>. To this end a <phrase>partial</phrase> 3D <phrase>scan</phrase> of the <phrase>workpiece</phrase> under consideration is acquired by <phrase>structured light</phrase> ranging. The application we focus on is the detection and removal of burrs on <phrase>industrial</phrase> workpieces. <phrase>Cylindrical</phrase> <phrase>metallic</phrase> objects will cause a strong <phrase>specular reflection</phrase> in every direction. These highlights are compensated for in the projected patterns, <phrase>hence</phrase> ýadaptive 3D scanningý. The <phrase>triangular mesh</phrase> <phrase>produced</phrase> is then used to identify the <phrase>axis</phrase> and generatrix of the corresponding surface of <phrase>revolution</phrase>. The <phrase>search space</phrase> for <phrase>finding</phrase> this <phrase>axis</phrase> is <phrase>four dimensional</phrase>: a valid choice of parameters is two <phrase>orientation angles</phrase> (as in <phrase>spherical coordinates</phrase>) and the 2D <phrase>intersection</phrase> point with the plane spanned by two out of three <phrase>axis</phrase> of the <phrase>local</phrase> coordinate system. For <phrase>finding</phrase> the <phrase>axis</phrase> we <phrase>test</phrase> the <phrase>circularity</phrase> of the <phrase>planar</phrase> intersections of the mesh in different directions, using <phrase>statistical estimation</phrase> methods to deal with noise. <phrase>Finally</phrase> the ýidealý generatrix derived from the <phrase>scan data</phrase> is compared to the real <phrase>surface topology</phrase>. The difference will identify the <phrase>burr</phrase>. The <phrase>algorithm</phrase> is demonstrated on a <phrase>metal</phrase> <phrase>wheel</phrase> that has burrs on both sides. <phrase>Visual</phrase> servoing of a <phrase>robotic arm</phrase> based on this detection is <phrase>work in progress</phrase>.
<phrase>Automatic</phrase> 3D Modeling Using <phrase>Range</phrase> Images Obtained from Unknown Viewpoints.
<phrase>Partial</phrase> <phrase>Surface Integration</phrase> Based on <phrase>Variational Implicit</phrase> Functions and Surfaces for 3D <phrase>Model Building</phrase>.
Most <phrase>three-dimensional</phrase> <phrase>acquisition systems</phrase> generate several <phrase>partial</phrase> reconstructions that have to be registered and integrated for <phrase>building</phrase> a complete 3D <phrase>model</phrase>. In this <phrase>paper</phrase>, we propose a <phrase>volumetric</phrase> shape <phrase>integration</phrase> method, consisting of <phrase>weighted</phrase> <phrase>signed distance functions</phrase> represented as <phrase>variational implicit</phrase> functions (VIF) or surfaces (<phrase>VIS</phrase>). Texture <phrase>integration</phrase> is solved <phrase>similarly</phrase> by using three <phrase>weighted</phrase> <phrase>color</phrase> functions also based on VIFs. Using these <phrase>continuous</phrase> (not <phrase>grid</phrase>-based) representations solves <phrase>current limitations</phrase> of <phrase>volumetric</phrase> methods: no <phrase>memory</phrase> inefficient and resolution limiting <phrase>grid</phrase> representation is required. The built-in <phrase>smoothing</phrase> properties of the <phrase>VIS</phrase> representations also improve the robustness of the final <phrase>integration</phrase> against noise in the <phrase>input data</phrase>. <phrase>Experimental</phrase> <phrase>results</phrase> are performed on real-<phrase>live</phrase>, <phrase>noiseless</phrase> and noisy <phrase>synthetic data</phrase> of <phrase>human</phrase> faces in <phrase>order</phrase> to show the robustness and accuracy of the <phrase>integration</phrase> <phrase>algorithm</phrase>.
<phrase>Geometric</phrase> Matching of 3-<phrase>D</phrase> Objects: <phrase>Assessing</phrase> the <phrase>Range</phrase> of Successful <phrase>Initial Configurations</phrase>.
<phrase>Robust</phrase> and Accurate <phrase>Partial</phrase> <phrase>Surface Registration</phrase> Based on <phrase>Variational Implicit</phrase> Surfaces for <phrase>Automatic</phrase> 3D <phrase>Model Building</phrase>.
<phrase>Three-dimensional</phrase> models are often assembled from several <phrase>partial</phrase> reconstructions from unknown viewpoints. In <phrase>order</phrase> to provide a <phrase>fully automatic</phrase>, <phrase>robust</phrase> and accurate method for <phrase>aligning</phrase> and <phrase>integrating</phrase> <phrase>partial</phrase> reconstructions without any <phrase>prior knowledge</phrase> of the relative viewpoints of the <phrase>sensor</phrase> or the <phrase>geometry</phrase> of the <phrase>imaging</phrase> process, we propose <phrase>a 4</phrase>-step registration and <phrase>integration</phrase> <phrase>algorithm</phrase> based on a common <phrase>Variational Implicit</phrase> Surface (<phrase>VIS</phrase>) representation of the <phrase>partial</phrase> <phrase>surface reconstructions</phrase>. First, a <phrase>global</phrase> crude registration without <phrase>a priori</phrase> <phrase>knowledge</phrase> is performed followed by a <phrase>pose refinement</phrase> of <phrase>partial</phrase> <phrase>reconstruction</phrase> pairs. <phrase>Pair-wise</phrase> registrations are <phrase>converted into</phrase> a <phrase>multi-view</phrase> registration, before a final <phrase>integration</phrase> of the reconstructions into one entity or <phrase>model</phrase> occurs. Furthermore, making use of the <phrase>smoothing</phrase> properties of the <phrase>VIS</phrase> representations, the <phrase>algorithm</phrase> proves to be <phrase>robust</phrase> against noise in the <phrase>reconstruction</phrase> <phrase>data</phrase>. <phrase>Experimental</phrase> <phrase>results</phrase> on real-<phrase>live</phrase>, as well as <phrase>noiseless</phrase> and noisy <phrase>simulated data</phrase> are presented to show the feasibility, the accuracy and robustness of our <phrase>registration scheme</phrase>.
<phrase>Stereo</phrase> by <phrase>Multiperspective</phrase> <phrase>Imaging</phrase> under <phrase>6 DOF</phrase> <phrase>Camera</phrase> Motion.
<phrase>Multiperspective</phrase> <phrase>imaging</phrase> has been used to recover the structure of a scene. Although several <phrase>algorithms</phrase> for <phrase>structure recovery</phrase> have been developed as typified by <phrase>stereo</phrase> panoramas, there exists no common framework which subsumes various <phrase>camera</phrase> motions to capture <phrase>stereo</phrase> images. This <phrase>paper</phrase> presents a framework for <phrase>stereo</phrase> by <phrase>multiperspective</phrase> <phrase>imaging</phrase>, which is <phrase>general</phrase> in that it can handle 6 <phrase>degree</phrase>-of-freedom (<phrase>DOF</phrase>) <phrase>camera</phrase> motion. We derive <phrase>geometric</phrase> constraints, equation for <phrase>structure recovery</phrase> and that for an epipolar curve by modeling the acquisition of <phrase>stereo</phrase> images using <phrase>push</phrase>-broom cameras (line sensors). We consider a class of <phrase>camera</phrase> motion called a <phrase>vertical</phrase> view plane class and demonstrate that several <phrase>previous results</phrase> are really <phrase>special cases</phrase> of our <phrase>results</phrase>. <phrase>Numerical examples</phrase> are given to show the correctness of the derived equations.
<phrase>Planar</phrase> Patch Extraction with Noisy <phrase>Depth Data</phrase>.
A <phrase>Hierarchical</phrase> Method for <phrase>Aligning</phrase> <phrase>Warped</phrase> Meshes.
Joined Segmentation of <phrase>Cortical</phrase> Surface and <phrase>Brain</phrase> Volume in <phrase>MRI</phrase> Using a <phrase>Homotopic</phrase> Deformable Cellular <phrase>Model</phrase>.
Modeling from <phrase>Reality</phrase>.
<phrase>Spatio-Temporal</phrase> <phrase>Fusion</phrase> of <phrase>Multiple View</phrase> <phrase>Video</phrase> Rate 3D Surfaces.
We consider the problem of <phrase>geometric</phrase> <phrase>integration</phrase> and representation of <phrase>multiple views</phrase> of non-rigidly deforming 3D <phrase>surface geometry</phrase> captured at <phrase>video</phrase> rate. <phrase>Instead</phrase> of treating each frame as a separate mesh we present a representation which <phrase>takes into consideration</phrase> temporal and <phrase>spatial coherence</phrase> in the <phrase>data</phrase> where possible. We first segment <phrase>gross</phrase> base transformations using <phrase>correspondence</phrase> based on a <phrase>closest point</phrase> metric and represent these motions as <phrase>piecewise</phrase> <phrase>rigid transformations</phrase>. The remaining <phrase>residual</phrase> is encoded as <phrase>displacement maps</phrase> at each frame giving a displacement <phrase>video</phrase>. At both these stages occlusions and <phrase>missing data</phrase> are interpolated to give a representation which is <phrase>continuous</phrase> in space and time. We demonstrate the <phrase>integration</phrase> of <phrase>multiple views</phrase> for four different non-rigidly deforming scenes: hand, face, cloth and a <phrase>composite</phrase> scene. The <phrase>approach achieves</phrase> the <phrase>integration</phrase> of <phrase>multiple-view</phrase> <phrase>data</phrase> at different times into one representation which can processed and edited.
<phrase>Fast</phrase> Alignment of 3D <phrase>Geometrical</phrase> Models and 2D <phrase>Color Images</phrase> Using 2D <phrase>Distance Maps</phrase>.
This <phrase>paper</phrase> presents <phrase>a fast</phrase> <phrase>pose estimation</phrase> <phrase>algorithm</phrase> of a 3D <phrase>free</phrase> form object in 2D images using 2D <phrase>distance maps</phrase>. One of the popular techniques of the <phrase>pose estimation</phrase> of 3D object in 2D image is the <phrase>point-based</phrase> method such as the <phrase>ICP</phrase> <phrase>algorithm</phrase>. However, the calculation cost for <phrase>determining</phrase> <phrase>point correspondences</phrase> is expensive. To overcome this problem, the <phrase>proposed method</phrase> utilizes a <phrase>distance map</phrase> on the 2D <phrase>image plane</phrase>, which is constructed quite rapidly by the <phrase>Fast</phrase> <phrase>Marching</phrase> Method. For <phrase>pose estimation</phrase> of the object, <phrase>contour</phrase> lines of the 2D image and the <phrase>projection</phrase> of the 3D object are aligned using the <phrase>distance map</phrase> iteratively by the <phrase>robust</phrase> <phrase>M</phrase>-<phrase>estimator</phrase>. Some <phrase>experimental</phrase> <phrase>results</phrase> with simulated models and actual images of the <phrase>endoscopic</phrase> operation are successfully carried out.
Acquisition of <phrase>View-Based</phrase> 3-<phrase>D</phrase> <phrase>Object Models</phrase> Using <phrase>Supervised</phrase>, <phrase>Unstructured Data</phrase>.
<phrase>Existing techniques</phrase> for <phrase>view-based</phrase> 3-<phrase>D</phrase> <phrase>object recognition</phrase> using <phrase>computer vision</phrase> rely on training the system on a particular object before it is introduced into an environment. This training often consists of taking over 100 images at predetermined points around the <phrase>viewing sphere</phrase> in an attempt to account for most angles for viewing the object. However, in many circumstances, the environment is well known and we only expect to see a small <phrase>subset</phrase> of all possible appearances. In this <phrase>paper</phrase>, we will <phrase>test</phrase> the idea that under these conditions, it is possible to <phrase>train</phrase> an <phrase>object recognition</phrase> system on-the-<phrase>fly</phrase> using images of an object as it appears in its environment, with <phrase>supervision</phrase> from the user. Furthermore, because some views of an object are much more likely than others, the number of <phrase>training images</phrase> required can be <phrase>greatly reduced</phrase>.
<phrase>Fusing</phrase> and Guiding <phrase>Range</phrase> Measurements with <phrase>Colour</phrase> <phrase>Video</phrase> Images.
<phrase>Combining</phrase> <phrase>data</phrase> from different sensors provides richer <phrase>data</phrase> for <phrase>visualisation</phrase> and helps in <phrase>automatic</phrase> detection and recognition of objects. This <phrase>paper</phrase> presents two methods relating <phrase>two dimensional</phrase> images from <phrase>colour</phrase> <phrase>CCD</phrase> cameras with <phrase>three dimensional</phrase> <phrase>data</phrase> from <phrase>range</phrase> scanners. The first method is applicable in a static case and provides the <phrase>geometrically correct</phrase> <phrase>solution</phrase>. The second one offers an <phrase>approximate</phrase> <phrase>solution</phrase> but can be used in a <phrase>dynamic</phrase> environment for guiding <phrase>selective</phrase> <phrase>range</phrase> measurements and simplifies the <phrase>calibration</phrase> process. The error introduced by this approximation has been derived as a <phrase>function</phrase> of the distance to the object and <phrase>geometry</phrase> of the set-up. <phrase>Results</phrase> of <phrase>combining</phrase> <phrase>range</phrase> <phrase>information</phrase> from a <phrase>laser</phrase> <phrase>camera</phrase> and <phrase>colour</phrase> <phrase>camera</phrase> are presented.
Using <phrase>PCA</phrase> to <phrase>Model</phrase> Shape for <phrase>Process Control</phrase>.
Before <phrase>surface mount</phrase> components can be placed on a <phrase>circuit board</phrase>, it is necessary to <phrase>print</phrase> <phrase>solder paste</phrase> onto <phrase>pads</phrase>. The <phrase>paste</phrase> is then melted to make an electrical connection (reflow). A <phrase>screen printing</phrase> process is used to <phrase>print</phrase> the <phrase>solder paste</phrase> onto the board. This is a complicated process with a <phrase>large number</phrase> of <phrase>input parameters</phrase>. Some of these parameters can be controlled and it is the purpose of this work to investigate control of the <phrase>process based</phrase> on measurement of the output shape of the printed <phrase>paste</phrase>. The shape is measured using a <phrase>laser range scanner</phrase> <phrase>Principal Component Analysis</phrase> (<phrase>PCA</phrase>) is proposed as a tool for describing <phrase>solder paste</phrase> shape with a small number of parameters. This <phrase>paper</phrase> discusses the use of <phrase>PCA</phrase> for <phrase>shape analysis</phrase> in <phrase>range</phrase> images as well as <phrase>explaining</phrase> how such a description can be incorporated into a <phrase>process control</phrase> loop.
<phrase>Fitting</phrase> of 3D <phrase>Circles and Ellipses</phrase> Using a Parameter <phrase>Decomposition Approach</phrase>.
Many optimization processes encounter a problem inefficiently reaching a <phrase>global minimum</phrase> or a near <phrase>global minimum</phrase>. <phrase>Traditional methods</phrase> such as <phrase>Levenberg-Marquardt algorithm</phrase> and <phrase>trust</phrase>-<phrase>region</phrase> method face the problems of dropping into <phrase>local</phrase> minima as well. On the other hand, some <phrase>algorithms</phrase> such as <phrase>simulated annealing</phrase> and <phrase>genetic algorithm</phrase> try to find a <phrase>global minimum</phrase> but they are mostly <phrase>time-consuming</phrase>. Without a good initialization, many <phrase>optimization methods</phrase> are unable to guarantee a <phrase>global minimum</phrase> result. We address a novel method in 3D <phrase>circle</phrase> and <phrase>ellipse fitting</phrase>, which alleviates the <phrase>optimization problem</phrase>. It can not only increase the <phrase>probability</phrase> of getting in <phrase>global</phrase> minima but also reduce the computation time. Based on our previous work, we decompose the parameters into two parts: one part of parameters can be solved by an <phrase>analytic</phrase> or a <phrase>direct</phrase> method and another part has to be solved by an <phrase>iterative</phrase> procedure. Via this scheme, the <phrase>topography</phrase> of optimization space is <phrase>simplified</phrase> and therefore we reduce the number of <phrase>local</phrase> minima and the computation time. We <phrase>experimentally compare</phrase> our method with the traditional ones and show <phrase>superior</phrase> performance.
<phrase>Reducing</phrase> <phrase>Movement Artifacts</phrase> in <phrase>Whole Body</phrase> Scanning.
<phrase>Movement artifacts</phrase> during <phrase>whole body</phrase> scanning are a <phrase>major</phrase> concern when <phrase>reproducible results</phrase> are required. To determine the <phrase>magnitude</phrase> of the artifacts, 11 subjects were scanned with and without a <phrase>positioning</phrase> device on the <phrase>head</phrase>. The sway of the body was determined by a force plate. It was shown that the pointer on the <phrase>head</phrase> reduced the <phrase>magnitude</phrase> of the <phrase>forward/backward</phrase> sway by over 50%. The resulting <phrase>standard deviation</phrase> is less than the resolution of the <phrase>scanner</phrase>. <phrase>Movement artifacts</phrase> within the body, like <phrase>head</phrase> rotation, are hard to control. Again, the pointer on the <phrase>head</phrase> assists in <phrase>reducing</phrase> the artifacts. The <phrase>ventilation</phrase> depth during the <phrase>scan</phrase> determines the shape of the <phrase>chest</phrase> and should be standardized to get <phrase>reproducible results</phrase>.
Extraction and Tracking of Surfaces in <phrase>Range</phrase> <phrase>Image Sequences</phrase>.
<phrase>Range</phrase> <phrase>Image Registration</phrase>: A <phrase>Software</phrase> Platform and <phrase>Empirical Evaluation</phrase>.
<phrase>Surface Registration</phrase> by Matching <phrase>Oriented Points</phrase>.
For registration of 3-<phrase>D</phrase> <phrase>free</phrase>-form surfaces we have developed a representation which requires no <phrase>knowledge</phrase> of the transformation between views. The representation comprises <phrase>descriptive</phrase> images associated with <phrase>oriented points</phrase> on the surface of an object. Constructed using <phrase>single</phrase> point bases, these images are <phrase>data</phrase> level <phrase>shape descriptions</phrase> that are used for <phrase>efficient</phrase> matching of <phrase>oriented points</phrase>. Correlation of images is used to establish <phrase>point correspondences</phrase> between two views; from these correspondences a <phrase>rigid transformation</phrase> that aligns the views is calculated. The transformation is then refined and verified using a <phrase>modified</phrase> <phrase>iterative closest point algorithm</phrase>. To demonstrate the generality of our approach, we present <phrase>results</phrase> from multiple sensing domains.
A <phrase>Laser Range Scanner</phrase> Designed for <phrase>Minimum</phrase> <phrase>Calibration</phrase> Complexity.
A System for <phrase>Semi-Automatic</phrase> Modeling of <phrase>Complex Environments</phrase>.
We present a <phrase>perception</phrase> system, called <phrase>Artisan</phrase>, that <phrase>semi-automatically</phrase> builds 3-<phrase>D</phrase> models of a <phrase>robot's</phrase> workspace. <phrase>Range</phrase> images are acquired with a <phrase>scanning laser</phrase> <phrase>rangefinder</phrase> and then processed, based an a <phrase>systematic</phrase> <phrase>sensor</phrase> characterization, to <phrase>remove noise</phrase> and artifacts. Complex 3-<phrase>D</phrase> objects represented as <phrase>surface meshes</phrase> are <phrase>subsequently</phrase> recognized in the <phrase>range</phrase> images and inserted into a <phrase>virtual</phrase> workspace. This <phrase>graphical</phrase> <phrase>virtual</phrase> workspace is then used to by <phrase>human</phrase> operators to plan and execute <phrase>remote</phrase> <phrase>robotic</phrase> operations.
<phrase>Image-Based</phrase> Techniques for <phrase>Digitizing</phrase> Environments and Artifacts.
Registration and <phrase>Integration</phrase> of Textured 3-<phrase>D</phrase> <phrase>Data</phrase>.
In <phrase>general</phrase>, <phrase>multiple views</phrase> are required to create a complete 3-<phrase>D</phrase> <phrase>model</phrase> of an object or of a multi-roomed <phrase>indoor</phrase> scene. In this work, we address the problem of <phrase>merging</phrase> multiple textured 3-<phrase>D</phrase> <phrase>data</phrase> sets, each of which corresponds to a different view of a scene or object. There are two steps to the <phrase>merging</phrase> process: registration and <phrase>integration</phrase>. To register, or align, <phrase>data</phrase> sets we use a <phrase>modified</phrase> version of the <phrase>Iterative Closest Point algorithm</phrase>; our version, which we call <phrase>color</phrase> <phrase>ICP</phrase>, considers not only 3-<phrase>D</phrase> <phrase>information</phrase>, but <phrase>color</phrase> as well. We show that the use of <phrase>color</phrase> decreases <phrase>registration error</phrase> by an <phrase>order</phrase> of <phrase>magnitude</phrase>. Once the 3-<phrase>D</phrase> <phrase>data</phrase> sets have been registered we integrate them to produce a <phrase>seamless</phrase>, <phrase>composite</phrase> 3-<phrase>D</phrase> textured <phrase>model</phrase>. Our approach to <phrase>integration</phrase> uses a 3-<phrase>D</phrase> <phrase>occupancy grid</phrase> to represent likelihood of <phrase>spatial</phrase> <phrase>occupancy</phrase> through <phrase>voting</phrase>. In addition to <phrase>occupancy</phrase> <phrase>information</phrase>, we store <phrase>surface normal</phrase> in each <phrase>voxel</phrase> of the <phrase>occupancy grid</phrase>. <phrase>Surface normal</phrase> is used to <phrase>robustly extract</phrase> a surface from the <phrase>occupancy grid</phrase>; on that surface we blend textures from <phrase>multiple views</phrase>.
<phrase>Building</phrase> <phrase>Symbolic</phrase> <phrase>Information</phrase> for 3D <phrase>Human</phrase> Body Modeling from <phrase>Range</phrase> <phrase>Data</phrase>.
<phrase>Automatic</phrase> 3 -- <phrase>D</phrase> <phrase>Digitization</phrase> using a <phrase>Laser Rangefinder</phrase> with a Small <phrase>Field of View</phrase>.
We address the problem of the <phrase>automation</phrase> of surface <phrase>digitization</phrase> using a precision 3-<phrase>D</phrase> <phrase>laser rangefinder</phrase>. Because of their small <phrase>field of view</phrase>, such sensors navigate closely to the digitized object and are subject to collisions. <phrase>Unlike previous</phrase> techniques that addressed only the exhaustiveness of <phrase>digitization</phrase>, this work focuses on <phrase>collision avoidance</phrase>. To safely identify empty space, <phrase>shadow</phrase> and occlusion phenomena are <phrase>carefully analyzed</phrase>, and so is the effect of <phrase>sampling</phrase>. Then, the <phrase>planning</phrase> problem is solved using a <phrase>hierarchical</phrase> approach. At <phrase>low level</phrase>, we digitize a <phrase>single</phrase> view and address <phrase>collision avoidance</phrase> using <phrase>path planning</phrase> techniques. At <phrase>high</phrase> level, the problem becomes the choice of the <phrase>next</phrase> best view. Some <phrase>implementation details</phrase> and <phrase>experimental</phrase> <phrase>results</phrase> are presented.
<phrase>Three-Dimensional</phrase> Modelling and Rendering of the <phrase>Human</phrase> <phrase>Skeletal</phrase> <phrase>Trunk</phrase> from 2D <phrase>Radiographic Images</phrase>.
<phrase>Compact</phrase> 3D Profilometer with <phrase>Grazing</phrase> <phrase>Incidence</phrase> <phrase>Diffraction</phrase> <phrase>Optics</phrase>.
<phrase>Fast</phrase> Multiple-<phrase>Baseline Stereo</phrase> with Occlusion.
This <phrase>paper</phrase> presents a new and <phrase>fast</phrase> <phrase>algorithm</phrase> for <phrase>multi-baseline stereo</phrase> designed to handle the occlusion problem. The <phrase>algorithm</phrase> is <phrase>a hybrid</phrase> between <phrase>fast</phrase> <phrase>heuristic</phrase> occlusion <phrase>overcoming</phrase> <phrase>algorithms</phrase> that precompute an <phrase>approximate visibility</phrase> and slower methods that use correct <phrase>visibility</phrase> handling. Our approach is based on <phrase>iterative</phrase> <phrase>dynamic programming</phrase> and computes simultaneously disparity and <phrase>camera</phrase> <phrase>visibility</phrase>. <phrase>Interestingly</phrase>, <phrase>dynamic programming</phrase> makes it possible to compute exactly part of the <phrase>visibility information</phrase>. The remainder is obtained through heuristics. The validity of our scheme is established using real imagery with <phrase>ground truth</phrase> and <phrase>compares favorably</phrase> with otherstate-of-the-<phrase>art</phrase> <phrase>multi-baseline stereo</phrase> <phrase>algorithms</phrase>.
<phrase>Building</phrase> 3-<phrase>D</phrase> <phrase>City</phrase> Models from Multiple <phrase>Unregistered</phrase> Profile <phrase>Maps</phrase>.
The <phrase>paper</phrase> presents an approach for <phrase>building</phrase> 3-<phrase>D</phrase> <phrase>city</phrase> models for <phrase>virtual</phrase> environments from multiple 3-<phrase>D</phrase> <phrase>data</phrase> sets acquired from different viewpoints by <phrase>light</phrase> <phrase>striping</phrase>. The <phrase>raw data</phrase> sets are represented as <phrase>single</phrase> valued <phrase>parametric</phrase> surfaces called the 3-<phrase>D</phrase> profile <phrase>maps</phrase>. The profile <phrase>maps</phrase> are registered to the same coordinate system by an <phrase>iterative</phrase> <phrase>surface matching</phrase> <phrase>algorithm</phrase> developed previously. The registration proceeds hierarchically from low to <phrase>high</phrase> resolution and all the <phrase>data</phrase> sets are matched simultaneously but an initial registration is assumed to be known. After having segmented each <phrase>map</phrase> by a <phrase>region</phrase> growing <phrase>algorithm</phrase>, the <phrase>maps</phrase> are integrated into a <phrase>piecewise</phrase> <phrase>planar surface</phrase> <phrase>model</phrase> by <phrase>merging</phrase> compatible segments in the overlapping areas. The <phrase>borders</phrase> of the segments are also traced an the <phrase>parametric</phrase> domains of the <phrase>maps</phrase> as a step for <phrase>building</phrase> a <phrase>wireframe model</phrase>. <phrase>Test</phrase> <phrase>results</phrase> are shown in the case of a <phrase>scale model</phrase> of an <phrase>urban area</phrase> digitized in <phrase>laboratory</phrase> conditions.
<phrase>An Improved</phrase> <phrase>Calibration</phrase> Technique for <phrase>Coupled</phrase> <phrase>Single-Row</phrase> Telemeter and <phrase>CCD Camera</phrase>.
<phrase>Toward</phrase> a successful 3D and textural <phrase>reconstruction</phrase> of <phrase>urban</phrase> scenes, the use of both <phrase>single-row</phrase> based <phrase>telemetric</phrase> and <phrase>photographic</phrase> <phrase>data</phrase> in a same framework has proved to be a powerful technique. A necessary condition to obtain good <phrase>results</phrase> is to accurately calibrate the <phrase>telemetric</phrase> and <phrase>photographic</phrase> sensors together. We present a study of this <phrase>calibration</phrase> process and propose <phrase>an improved</phrase> <phrase>extrinsic calibration</phrase> technique. It is based on an existing technique which consists in scanning a <phrase>planar</phrase> pattern in several poses, giving a set of <phrase>relative position</phrase> and orientation constraints. The <phrase>innovation</phrase> is the use of a more appropriate <phrase>laser beam</phrase> distance between <phrase>telemetric</phrase> points and the <phrase>planar</phrase> <phrase>target</phrase>. Moreover, we use <phrase>robust</phrase> methods to manage <phrase>outliers</phrase> at several steps of the <phrase>algorithm</phrase>. Improved <phrase>results</phrase> on both theoretical and <phrase>experimental</phrase> <phrase>data</phrase> are given.
<phrase>Self-Calibration</phrase> of a <phrase>Light</phrase> <phrase>Striping</phrase> System by Matching Multiple 3-<phrase>D</phrase> Profile <phrase>Maps</phrase>.
<phrase>Transform-Based</phrase> Methods for <phrase>Indexing</phrase> and Retrieval of 3D Objects.
We compare two <phrase>transform-based</phrase> <phrase>indexing</phrase> methods for retrieval of 3D objects. We apply 3D <phrase>Discrete Fourier Transform</phrase> (<phrase>DFT</phrase>) and 3D <phrase>Radial</phrase> <phrase>Cosine</phrase> Transform (RCT) to the voxelized <phrase>data</phrase> of 3D objects. <phrase>Rotation invariant</phrase> features are derived from the coefficients of these transforms. Furthermore we compare two different <phrase>voxel</phrase> representations, namely, <phrase>binary</phrase> denoting object and background space, and <phrase>continuous</phrase> after <phrase>distance transformation</phrase>. In the <phrase>binary</phrase> <phrase>voxel</phrase> representation the <phrase>voxel</phrase> values are simply set to 1 on the surface of the object and 0 elsewhere. In the <phrase>continuous</phrase>-valued representation the space is filled with a <phrase>function</phrase> of <phrase>distance transform</phrase>. The <phrase>rotation invariance</phrase> properties of the <phrase>DFT</phrase> and RCT schemes are analyzed. We have conducted <phrase>retrieval experiments</phrase> on the <phrase>Princeton</phrase> Shape Benchmark and investigated the <phrase>retrieval performance</phrase> of the methods using several <phrase>quality measures</phrase>.
A <phrase>Multi-Resolution</phrase> <phrase>ICP</phrase> with <phrase>Heuristic</phrase> <phrase>Closest Point</phrase> Search for <phrase>Fast</phrase> and <phrase>Robust</phrase> 3D Registration of <phrase>Range</phrase> Images.
Effective 3D Modeling Of <phrase>Heritage</phrase> Sites.
<phrase>Identifying</phrase> the Interface between Two <phrase>Sand</phrase> Materials.
To study the behavior of <phrase>water</phrase> flow at interfaces between different <phrase>soil</phrase> materials we made <phrase>computed tomography</phrase> scans of <phrase>sand</phrase> samples using <phrase>synchrotron light</phrase>. The samples were prepared with an interface between two <phrase>sand</phrase> materials. The <phrase>contact</phrase> points between grains at the interface between the <phrase>sands</phrase> were identified using a combination of <phrase>watershed</phrase> segmentation and a classifier that used the <phrase>grain-size</phrase> and -location. The process from a <phrase>bilevel image</phrase> to a classified image is described. In the classified image five classes are represented; two for the grains and three for the <phrase>contact</phrase> points to represent <phrase>intra- and inter</phrase>-class <phrase>contact</phrase> points.
<phrase>Silhouette</phrase> and <phrase>Stereo</phrase> <phrase>Fusion</phrase> for 3D <phrase>Object Modeling</phrase>.
In this <phrase>paper</phrase>, we present a new approach to <phrase>high</phrase> quality 3D <phrase>object reconstruction</phrase>. Starting from a calibrated <phrase>sequence</phrase> of <phrase>color images</phrase>, the <phrase>algorithm</phrase> is able to reconstruct both the 3D <phrase>geometry</phrase> and the texture. The core of the method is based on a <phrase>deformable model</phrase>, which defines the framework where texture and <phrase>silhouette</phrase> <phrase>information</phrase> can be fused. This is achieved by defining two <phrase>external forces</phrase> based on the images: a texture driven force and a <phrase>silhouette</phrase> driven force. The texture force is computed in two steps: a multi-<phrase>stereo</phrase> correlation <phrase>voting</phrase> approach and a <phrase>gradient</phrase> <phrase>vector</phrase> flow <phrase>diffusion</phrase>. Due to the <phrase>high</phrase> resolution of the <phrase>voting</phrase> approach, a <phrase>multi-grid</phrase> version of the <phrase>gradient</phrase> <phrase>vector</phrase> flow has been developed. Concerning the <phrase>silhouette</phrase> force, a new formulation of the <phrase>silhouette</phrase> constraint is derived. It provides a <phrase>robust</phrase> way to integrate the silhouettes in the <phrase>evolution</phrase> <phrase>algorithm</phrase>. As a consequence, we are able to recover the <phrase>contour</phrase> generators of the <phrase>model</phrase> at the end of the iteration process. <phrase>Finally</phrase>, a <phrase>texture map</phrase> is computed from the <phrase>original images</phrase> for the reconstructed 3D <phrase>model</phrase>.
<phrase>Extracting</phrase> <phrase>Surface Patches</phrase> from Complete <phrase>Range</phrase> Descriptions.
<phrase>Constructing</phrase> a full <phrase>CAD</phrase> <phrase>model</phrase> of a part requires <phrase>feature descriptions</phrase> from all sides; in this case we consider <phrase>surface patches</phrase> as the <phrase>geometric</phrase> primitives. Most <phrase>previous research</phrase> in <phrase>surface patch</phrase> extraction has concentrated on <phrase>extracting</phrase> patches from a <phrase>single</phrase> view. This leads to several problems with <phrase>aligning</phrase> and <phrase>combining</phrase> <phrase>partial</phrase> patch fragments in <phrase>order</phrase> to produce complete part models. We have avoided these problems by <phrase>adapting</phrase> our <phrase>single</phrase> view, <phrase>range</phrase> <phrase>data</phrase> segmentation program to extract patches, and thus models, directly from fully merged <phrase>range</phrase> datasets.
<phrase>Foreword</phrase>.
Scanning and Processing 3D Objects for <phrase>Web</phrase> Display.
<phrase>Coordination</phrase> of Appearance and <phrase>Motion Data</phrase> for <phrase>Virtual View Generation</phrase> of Traditional Dances.
A novel method is proposed for <phrase>virtual view generation</phrase> of traditional dances. In the proposed framework, a traditional <phrase>dance</phrase> is captured separately for appearance registration and motion registration. By <phrase>coordinating</phrase> the appearance and <phrase>motion data</phrase>, we can easily control <phrase>virtual</phrase> <phrase>camera</phrase> motion within a <phrase>dancer</phrase>-centered coordinate system. For this purpose, a <phrase>coordination</phrase> problem should be solved between the appearance and <phrase>motion data</phrase>, since they are captured separately and the <phrase>dancer</phrase> moves freely in the <phrase>room</phrase>. The present <phrase>paper</phrase> shows a practical <phrase>algorithm</phrase> to solve it. A set of <phrase>algorithms</phrase> are also provided for appearance and motion registration, and <phrase>virtual view generation</phrase> from <phrase>archived data</phrase>. In the appearance registration, a 3D <phrase>human</phrase> shape is recovered in each time from a set of <phrase>input images</phrase> after <phrase>suppressing</phrase> their backgrounds. By <phrase>combining</phrase> the recovered 3D shape and a set of images for each time, we can <phrase>compose</phrase> archived <phrase>dance</phrase> <phrase>data</phrase>. In the motion registration, <phrase>stereoscopic</phrase> tracking is accomplished for <phrase>color</phrase> markers placed on the <phrase>dancer</phrase>. A <phrase>virtual view generation</phrase> is formalized as a <phrase>color blending</phrase> among <phrase>multiple views</phrase>, and a novel and <phrase>efficient</phrase> <phrase>algorithm</phrase> is proposed for the composition of a natural <phrase>virtual</phrase> view from a set of images. In the <phrase>proposed method</phrase>, weightings of the <phrase>linear combination</phrase> are calculated from both an assumed <phrase>viewpoint</phrase> and a <phrase>surface normal</phrase>.
<phrase>Exploiting</phrase> Mirrors for <phrase>Laser Stripe</phrase> 3D Scanning.
<phrase>Virtual</phrase> <phrase>Reconstruction</phrase> of broken and unbroken <phrase>Pottery</phrase>.
<phrase>Multisensor Fusion</phrase> for <phrase>Volumetric Reconstruction</phrase> of <phrase>Large Outdoor</phrase> Areas.
This <phrase>paper</phrase> presents techniques for the <phrase>merging</phrase> of 3D <phrase>Data</phrase> coming from different sensors, such as <phrase>ground</phrase> and <phrase>aerial</phrase> <phrase>laser</phrase> <phrase>range</phrase> scans. The 3D Models created are reconstructed to give a <phrase>photo</phrase>-realistic scene enabling <phrase>interactive virtual</phrase> <phrase>walkthroughs</phrase>, measurements and <phrase>scene change</phrase> analysis. The reconstructed <phrase>model</phrase> is based on a <phrase>weighted</phrase> <phrase>integration</phrase> of all available <phrase>data</phrase> based on <phrase>sensor</phrase>-<phrase>specific parameters</phrase> such as <phrase>noise level</phrase>, accuracy, <phrase>inclination</phrase> and <phrase>reflectivity</phrase> of the <phrase>target</phrase>, <phrase>spatial</phrase> distribution of points. The <phrase>geometry</phrase> is robustly reconstructed with a <phrase>volumetric</phrase> approach. Once registered and weighed, all <phrase>data</phrase> is <phrase>re</phrase>-sampled in a <phrase>multi-resolution</phrase> <phrase>distance field</phrase> usingout-of-core techniques. The final mesh is extracted by <phrase>contouring</phrase> the <phrase>iso</phrase>-surface with a <phrase>feature preserving</phrase> <phrase>dual contouring</phrase> <phrase>algorithm</phrase>. The <phrase>paper</phrase> shows <phrase>results</phrase> of the above technique applied to <phrase>Verona</phrase> (<phrase>Italy</phrase>) <phrase>city centre</phrase>.
Further <phrase>Improving</phrase> <phrase>Geometric Fitting</phrase>.
We give a <phrase>formal definition</phrase> of <phrase>geometric fitting</phrase> in a way that suits <phrase>computer vision</phrase> applications. We point out that the performance of <phrase>geometric fitting</phrase> should be evaluated in the limit of small noise rather than in the limit of a <phrase>large number</phrase> of <phrase>data</phrase> as recommended in the statistical <phrase>literature</phrase>. Taking the KCR <phrase>lower</phrase> bound as an optimality requirement and focusing on the <phrase>linearized</phrase> constraint case, we compare the accuracy of Kanataniýs <phrase>renormalization</phrase> with <phrase>maximum likelihood</phrase> (<phrase>ML</phrase>) approaches including the FNS of Chojnacki <phrase>et al</phrase>. and the HEIV of Leedan and Meer. Our <phrase>analysis reveals</phrase> the <phrase>existence</phrase> of a method <phrase>superior</phrase> to all these.
Solving <phrase>architectural</phrase> modelling problems using <phrase>knowledge</phrase>.
Processing <phrase>Range</phrase> <phrase>Data</phrase> for <phrase>Reverse Engineering</phrase> and <phrase>Virtual Reality</phrase>.
A <phrase>Low-Cost</phrase> <phrase>Range Finder</phrase> Using a Visually Located, <phrase>Structured Light</phrase> Source.
<phrase>Refining</phrase> <phrase>Triangle</phrase> Meshes by <phrase>Non-linear</phrase> Subdivision.
<phrase>Real-time</phrase> <phrase>Range</phrase> Scanning of <phrase>Deformable Surfaces</phrase> by Adaptively <phrase>Coded Structured Light</phrase>.
<phrase>Deformable Model</phrase> with <phrase>Adaptive</phrase> Mesh and <phrase>Automated</phrase> <phrase>Topology</phrase> Changes.
<phrase>Scale Selection</phrase> for Classification of <phrase>Point-Sampled</phrase> 3-<phrase>D</phrase> Surfaces.
<phrase>Three-dimensional</phrase> <phrase>ladar data</phrase> are <phrase>commonly used</phrase> to perform <phrase>scene understanding</phrase> for <phrase>outdoor mobile robots</phrase>, <phrase>specifically</phrase> in <phrase>natural terrain</phrase>. One effective method is to classify points using features based on <phrase>local</phrase> <phrase>point cloud</phrase> distribution into surfaces, <phrase>linear structures</phrase> or <phrase>clutter</phrase> <phrase>volumes</phrase>. But the <phrase>local</phrase> features are computed using 3-<phrase>D</phrase> points within a support-volume. <phrase>Local</phrase> and <phrase>global</phrase> point <phrase>density</phrase> variations and the presence of <phrase>multiple manifolds</phrase> make the problem of <phrase>selecting</phrase> the size of this support volume, or scale, challenging. In this <phrase>paper</phrase> we adopt an approach inspired by <phrase>recent developments</phrase> in <phrase>computational geometry</phrase> [5] and investigate the problem of <phrase>automatic</phrase> <phrase>data</phrase>-driven <phrase>scale selection</phrase> to improve <phrase>point cloud</phrase> classification. The approach is validated with <phrase>results</phrase> using <phrase>data</phrase> from different sensors in various environments classified into different <phrase>terrain</phrase> types (<phrase>vegetation</phrase>, <phrase>solid surface</phrase> and <phrase>linear structure</phrase>)¹.
An <phrase>Automation</phrase> System for <phrase>Industrial</phrase> 3-<phrase>D</phrase> <phrase>Laser</phrase> <phrase>Digitizing</phrase>.
Estimation of <phrase>Elastic</phrase> Constants from 3D <phrase>Range</phrase>-Flow.
<phrase>Bayesian</phrase> Estimation of Distance and <phrase>Surface Normal</phrase> with a <phrase>Time-of-Flight</phrase> <phrase>Laser Rangefinder</phrase>.
Advances in the <phrase>Cooperation</phrase> of <phrase>Shape from Shading</phrase> and <phrase>Stereo</phrase> Vision.
The <phrase>Parallel</phrase> <phrase>Iterative Closest Point Algorithm</phrase>.
<phrase>Building</phrase> 3D <phrase>Facial Models</phrase> and <phrase>Detecting</phrase> <phrase>Face Pose</phrase> in 3D Space.
The Mapping of Texture on <phrase>VR</phrase> <phrase>Polygonal Models</phrase>.
<phrase>Road Surface</phrase> Inspection using <phrase>Laser</phrase> Scanners Adapted for the <phrase>High</phrase> Precision Measurements of Large <phrase>Flat</phrase> Surfaces.
<phrase>Toward</phrase> a <phrase>Near Optimal</phrase> <phrase>Quad/Triangle Subdivision</phrase> <phrase>Surface Fitting</phrase>.
In this <phrase>paper</phrase> we present a new framework for <phrase>subdivision surface fitting</phrase> of <phrase>arbitrary surfaces</phrase> (not closed objects) represented by <phrase>polygonal meshes</phrase>. Our approach is particularly suited for output surfaces from a mechanical or <phrase>CAD</phrase> <phrase>object segmentation</phrase> for a <phrase>piecewise</phrase> <phrase>subdivision surface</phrase> approximation. Our <phrase>algorithm</phrase> produces a <phrase>mixed</phrase> quadrangle-<phrase>triangle</phrase> <phrase>control mesh</phrase>, <phrase>near optimal</phrase> in terms of face and vertex numbers while remaining <phrase>independent</phrase> of the connectivity of the input mesh. The first step approximates the boundaries with <phrase>subdivision curves</phrase> and creates an initial <phrase>subdivision surface</phrase> by optimally <phrase>linking</phrase> the <phrase>boundary control</phrase> points with respect to the lines of <phrase>curvature</phrase> of the <phrase>target</phrase> surface. Then, a second step optimizes the initial control <phrase>polyhedron</phrase> by iteratively moving <phrase>control points</phrase> and <phrase>enriching</phrase> regions according to the <phrase>error distribution</phrase>. <phrase>Experiments conducted</phrase> on several surfaces and on a whole segmented mechanical object, have <phrase>proven</phrase> the <phrase>coherency</phrase> and theefficiency of our <phrase>algorithm</phrase>, compared with <phrase>existing methods</phrase>.
<phrase>An Efficient</phrase> <phrase>Scattered Data</phrase> Approximation Using <phrase>Multilevel</phrase> <phrase>B</phrase>-Splines Based on <phrase>Quasi</phrase>-Interpolants.
In this <phrase>paper</phrase>, we propose <phrase>an efficient</phrase> <phrase>approximation algorithm</phrase> using <phrase>multilevel</phrase> <phrase>B</phrase>-splines based on <phrase>quasi</phrase>-interpolants. <phrase>Multilevel</phrase> technique uses a <phrase>coarse to fine</phrase> hierarchy to generate a <phrase>sequence</phrase> of <phrase>bicubic B-spline</phrase> functions whose <phrase>sum</phrase> approaches the desired <phrase>interpolation</phrase> <phrase>function</phrase>. To compute a set of <phrase>control points</phrase>, <phrase>quasi</phrase>-interpolants gives a procedure for <phrase>deriving</phrase> <phrase>local</phrase> <phrase>spline approximation</phrase> methods where a <phrase>B-spline</phrase> coefficient only depends on <phrase>data</phrase> points taken from the <phrase>neighborhood</phrase> of the support corresponding the <phrase>B-spline</phrase>. <phrase>Experimental</phrase> <phrase>results</phrase> show that the <phrase>smooth surface reconstruction</phrase> with <phrase>high</phrase> accuracy can be obtained from a selected set of scattered or <phrase>dense</phrase> <phrase>irregular</phrase> samples.
The <phrase>Digital</phrase> <phrase>Michelangelo</phrase> <phrase>Project</phrase>.
<phrase>Evaluating</phrase> <phrase>Collinearity</phrase> Constraint for <phrase>Automatic</phrase> <phrase>Range</phrase> <phrase>Image Registration</phrase>.
While most of the existing <phrase>range</phrase> <phrase>image registration</phrase> <phrase>algorithms</phrase> either have to extract and match <phrase>structural</phrase> (<phrase>geometric</phrase> or optical) features or have to estimate the <phrase>motion parameters</phrase> of interest from <phrase>outliers</phrase> corrupted <phrase>point correspondence</phrase> <phrase>data</phrase> for the <phrase>elimination</phrase> of <phrase>false matches</phrase> in the process of <phrase>image registration</phrase>, the <phrase>registration error</phrase> and the <phrase>collinearity</phrase> error derived directly from the traditional <phrase>closest point</phrase> criterion are also capable of doing the same job. However, the latter has an advantage of <phrase>easy implementation</phrase>. The purpose of this <phrase>paper</phrase> is to investigate which definition of <phrase>collinearity</phrase> is more accurate and <phrase>stable</phrase> in <phrase>eliminating false</phrase> matches inevitably introduced by the <phrase>closest point</phrase> criterion. The experiments based on <phrase>real images</phrase> show the <phrase>advantages and disadvantages</phrase> of different definitions of <phrase>collinearity</phrase>.
<phrase>Multi-Resolution</phrase> Modeling and <phrase>Locally Refined</phrase> <phrase>Collision Detection</phrase> for <phrase>Haptic</phrase> Interaction.
The <phrase>computational cost</phrase> of a <phrase>collision detection</phrase> (<phrase>CD</phrase>) <phrase>algorithm</phrase> on <phrase>polygonal</phrase> surfaces depends highly on the complexity of the models. A novel "<phrase>locally refined</phrase>" approach is introduced in this <phrase>paper</phrase> for <phrase>fast</phrase> <phrase>CD</phrase> in <phrase>haptic</phrase> rendering applications, e.g. <phrase>haptic</phrase> <phrase>surgery</phrase> and <phrase>haptic</phrase> <phrase>sculpture</phrase> simulations. <phrase>Exact</phrase> interference detections are performed on proposed <phrase>locally refined</phrase> meshes, which are in <phrase>multi-resolution</phrase> representation. The meshes are generated using <phrase>mesh simplification</phrase> and <phrase>space partition</phrase>. A new <phrase>BVH</phrase> <phrase>algorithm</phrase> called "<phrase>Active</phrase> <phrase>Bounding</phrase> <phrase>Tree</phrase>", or <phrase>AB</phrase>-<phrase>Tree</phrase>, handling collision queries is introduced. At runtime the meshes are dynamically refined to <phrase>higher resolution</phrase> in areas that are most likely to <phrase>collide</phrase> with other objects. The <phrase>algorithms</phrase> are <phrase>successfully demonstrated</phrase> in <phrase>an interactive</phrase> <phrase>haptic</phrase> environment. Compared to existing <phrase>CD</phrase> <phrase>algorithms</phrase> on <phrase>single</phrase> resolution models, noticeable <phrase>performance improvement</phrase> has been observed in terms of the precision of collision queries, <phrase>frame rate</phrase>, and <phrase>memory</phrase> usage.
<phrase>Evaluating</phrase> <phrase>Structural</phrase> Constraints for Accurate <phrase>Range</phrase> <phrase>Image Registration</phrase>.
<phrase>An Adaptive</phrase> <phrase>Dandelion Model</phrase> for <phrase>Reconstructing</phrase> <phrase>Spherical</phrase> <phrase>Terrain</phrase>-Like <phrase>Visual</phrase> <phrase>Hull</phrase> Surfaces.
In this <phrase>paper</phrase> we present <phrase>an adaptive</phrase> <phrase>Dandelion Model</phrase> for <phrase>reconstructing</phrase> <phrase>spherical</phrase> <phrase>terrain</phrase>-like <phrase>Visual</phrase> <phrase>Hull</phrase> (<phrase>VH</phrase>) surfaces. The <phrase>Dandelion Model</phrase> represents a solid by a <phrase>pencil</phrase> of organized <phrase>line segments</phrase> emitted from a common point. The directions and the <phrase>topology</phrase> of the <phrase>line segments</phrase> are derived from the <phrase>triangle</phrase> <phrase>facets</phrase> of a <phrase>geodesic</phrase> <phrase>sphere</phrase>, which are recursively subdivided until the desired precision is achieved. The initial lines are <phrase>cut</phrase> by silhouettes in 2D and then lifted back to 3D to determine the <phrase>ending points</phrase> of the <phrase>line segments</phrase> defining <phrase>sampling</phrase> points on the <phrase>spherical</phrase> <phrase>terrain</phrase>-like <phrase>VH</phrase> surface. A mesh <phrase>model</phrase> can be <phrase>easily constructed</phrase> from the <phrase>Dandelion Model</phrase>. Our <phrase>algorithm</phrase> has the advantages of <phrase>controllable</phrase> precision, <phrase>adaptive</phrase> resolution, simplicity and speediness. We validate our <phrase>algorithm</phrase> by theories and experiments.
<phrase>A Fast</phrase> and Accurate 3-<phrase>D</phrase> <phrase>Rangefinder</phrase> using the Biris <phrase>Technology</phrase>: The TRID <phrase>Sensor</phrase>.
In many <phrase>industrial</phrase> applications such as <phrase>autonomous vehicle</phrase> guidance and <phrase>robotic</phrase> manipulations, <phrase>reliable</phrase> 3-<phrase>D</phrase> <phrase>informations</phrase> must be extracted from the scene in <phrase>order</phrase> to provide a <phrase>robust</phrase> description of the environment in which the system evolves. This <phrase>paper</phrase> presents the TRID <phrase>sensor</phrase>, a simple, <phrase>fast</phrase>, <phrase>robust</phrase> and accurate 3-<phrase>D</phrase> <phrase>sensing device</phrase> based on the Biris <phrase>technology</phrase>. TRID is limited to a <phrase>lateral</phrase> resolution of one point. <phrase>Experimental</phrase> <phrase>results</phrase> show that an accuracy better than 0.15% can be obtained for the depth component (<phrase>Z</phrase>) of 3-<phrase>D</phrase> points at a distance of 1.3 <phrase>meter</phrase> from a <phrase>wooden</phrase> <phrase>black</phrase> painted <phrase>beam</phrase> surface with an acquisition rate of 8.5 points/<phrase>s</phrase>.
3D <phrase>Statistical Shape Models</phrase> for <phrase>Medical</phrase> <phrase>Image Segmentation</phrase>.
<phrase>Reliable</phrase> and <phrase>Rapidly-Converging</phrase> <phrase>ICP</phrase> <phrase>Algorithm</phrase> Using <phrase>Multiresolution</phrase> <phrase>Smoothing</phrase>.
<phrase>Frequency Domain</phrase> Estimation of 3-<phrase>D</phrase> <phrase>Rigid Motion</phrase> Based on <phrase>Range</phrase> and Intensity <phrase>Data</phrase>.
<phrase>Video</phrase>-rate <phrase>registered range</phrase> and intensity <phrase>data</phrase> are at reach of <phrase>current sensor</phrase> <phrase>technology</phrase>. This wealth of <phrase>data</phrase> can be <phrase>profitably exploited</phrase> in <phrase>order</phrase> to estimate <phrase>rigid motion</phrase> parameters as the approaches to 3-<phrase>D</phrase> <phrase>motion estimation</phrase>, based on the <phrase>optical flow</phrase> of both types of <phrase>data</phrase>, indicate. This work introduces an <phrase>alternative</phrase> for 3-<phrase>D</phrase> <phrase>motion estimation</phrase> based on the <phrase>Fourier transform</phrase> of the 3-<phrase>D</phrase> <phrase>intensity function</phrase> implicitly described by the registered time-sequences of <phrase>range</phrase> and intensity <phrase>data</phrase>. The proposed procedure can <phrase>lead</phrase> to an <phrase>unsupervised</phrase> method for 3-<phrase>D</phrase> <phrase>rigid motion</phrase> estimation. This method has several advantages related to the fact that it uses the total available <phrase>information</phrase> and not sets of features. With respect to <phrase>memory</phrase> <phrase>occupancy</phrase> the use of a time-<phrase>sequence</phrase> of a 3-<phrase>D</phrase> <phrase>intensity function</phrase> represents a considerable <phrase>data</phrase> reduction with respect to a pair of time-sequences of 2-<phrase>D</phrase> functions. The proposed technique, which extends to the 3-<phrase>D</phrase> case previous <phrase>frequency domain</phrase> <phrase>estimation algorithms</phrase> developed for the <phrase>planar</phrase> case, retain their robustness.
<phrase>Automatic</phrase> Modeling of Animatable <phrase>Virtual</phrase> Humans - <phrase>A Survey</phrase>.
<phrase>Rangefinder</phrase> using Time Correlated <phrase>Single</phrase> <phrase>Photon</phrase> <phrase>Counting</phrase>.
This <phrase>paper</phrase> describes a method for <phrase>acquiring</phrase> <phrase>range</phrase> <phrase>data</phrase> based on time-correlated <phrase>single</phrase> <phrase>photon</phrase> <phrase>counting</phrase> (TCSPC) and details the <phrase>data analysis</phrase> techniques used to compute the <phrase>range</phrase> measurements. The <phrase>prototype</phrase> <phrase>sensor</phrase> being built in our <phrase>laboratory</phrase> is capable of <phrase>measuring</phrase> up to 100 points per second with an accuracy of about 15 /<phrase>spl mu</phrase>/<phrase>m</phrase>.
Generation of <phrase>Geometric</phrase> <phrase>Model</phrase> by Registration and <phrase>Integration</phrase> of <phrase>Multiple Range Images</phrase>.
<phrase>Surface Curvature</phrase> Estimation from the <phrase>Signed Distance</phrase> Field.
<phrase>Simultaneous</phrase> <phrase>Determination</phrase> of Registration and <phrase>Deformation Parameters</phrase> among 3D <phrase>Range</phrase> Images.
Conventional <phrase>registration algorithms</phrase> are mostly concerned with <phrase>rigid-body transformation</phrase> parameters between a pair of 3D <phrase>range</phrase> images. Our proposed framework aims to determine, in <phrase>a unified</phrase> manner, not only such <phrase>rigid transformation</phrase> parameters but also various <phrase>deformation parameters</phrase>, assuming that the deformation we handle here is <phrase>strictly defined</phrase> by some <phrase>parameterized</phrase> formulation derived from the deformation mechanism. While conventional <phrase>registration algorithms</phrase> usually calcurate six parameters (three <phrase>translation</phrase> and three <phrase>rotation parameters</phrase>), our proposed <phrase>algorithm</phrase> estimates <phrase>deformation parameters</phrase> as well. In this <phrase>paper</phrase>, we describe how we formulated such an <phrase>algorithm</phrase>, implemented it, and evaluated its performance.
A Method of Style <phrase>Discrimination</phrase> of <phrase>Oil Painting</phrase> Based on 3D <phrase>Range</phrase> <phrase>Data</phrase>.
A Portable <phrase>Three-Dimensional</phrase> Digitizer.
A portable <phrase>three-dimensional</phrase> digitizer using a <phrase>monocular</phrase> <phrase>camera</phrase> is presented in this <phrase>paper</phrase>. The digitizer <phrase>automatically acquires</phrase> the shape of a <phrase>target</phrase> object as well as its texture. The digitizer has the following advantages: 1) <phrase>compact</phrase> and inexpensive, 2) <phrase>skill</phrase>-<phrase>free</phrase> 3D <phrase>image acquisition</phrase>, and 3) handles a <phrase>wide range</phrase> of objects of various materials. The <phrase>digitizing</phrase> <phrase>algorithm</phrase> is based on the "<phrase>Shape-from-Silhouette</phrase>" framework, where several novel techniques are embedded as follows. In the <phrase>silhouette</phrase> extraction, not only <phrase>pixel</phrase>-level <phrase>subtraction</phrase> between images but also <phrase>region</phrase>-level <phrase>subtraction</phrase> are embedded so as to achieve precise extraction. The <phrase>texture acquisition</phrase> is treated as a <phrase>labeling problem</phrase> in an <phrase>energy</phrase> minimization framework, which enables us to get realistic textures with a simple operation. Our <phrase>experiments showed</phrase> that the <phrase>digitizing</phrase> speed of the digitizer was practical.
<phrase>Calibration</phrase> of a <phrase>Laser Stripe</phrase> <phrase>Profiler</phrase>.
3-<phrase>D</phrase> Motion and Shape from <phrase>Multiple Image</phrase> Sequences.
<phrase>Streaming Transmission</phrase> of <phrase>Point-Sampled Geometry</phrase> Based on <phrase>View-Dependent</phrase> <phrase>Level-of-Detail</phrase>.
<phrase>Active</phrase> <phrase>Balloon</phrase> <phrase>Model</phrase> Based On 3D <phrase>Skeleton</phrase> Extraction By <phrase>Competitive Learning</phrase>.
Computations on a <phrase>Spherical</phrase> View Space for <phrase>Efficient</phrase> <phrase>Planning</phrase> of Viewpoints in 3-<phrase>D</phrase> <phrase>Object Modeling</phrase>.
<phrase>Reconstruction</phrase> of <phrase>Complex Environments</phrase> by <phrase>Robust</phrase> Pre-aligned <phrase>ICP</phrase>.
Stroboscopic <phrase>Stereo</phrase> <phrase>Rangefinder</phrase>.
<phrase>Fast</phrase> and <phrase>Robust</phrase> Registration of 3D Surfaces Using Low <phrase>Curvature</phrase> Patche.
<phrase>Automatic</phrase> <phrase>Reconstruction</phrase> of 3D Objects using a <phrase>Mobile</phrase> Monoscopic <phrase>Camera</phrase>.
A method for the <phrase>automatic</phrase> <phrase>reconstruction</phrase> of 3D objects from <phrase>multiple camera views</phrase> for 3D <phrase>multimedia</phrase> applications is presented. Conventional 3D <phrase>reconstruction</phrase> techniques use equipment that restrict the flexibility of the user. In <phrase>order</phrase> to increase this flexibility, the presented method is characterized by a simple measurement environment, that consists of a new <phrase>calibration</phrase> pattern placed below the object allowing object and <phrase>pattern acquisition</phrase> simultaneously. This ensures, that each view can be calibrated individually. From these obtained <phrase>calibrated camera</phrase> views, a textured 3D <phrase>wireframe model</phrase> is estimated using a <phrase>shape-from-silhouette</phrase> approach and <phrase>texture mapping</phrase> of the original <phrase>camera</phrase> views. Experiments with this system have confirmed a significant gain of flexibility for the user and a drastic reduction of costs for <phrase>technical equipment</phrase> while ensuring comparable <phrase>model</phrase> quality as conventional <phrase>reconstruction</phrase> techniques at the same time.
3D <phrase>Reconstruction</phrase> from Two <phrase>Orthogonal</phrase> Views Using <phrase>Simulated Annealing</phrase> Approach.
<phrase>Automatic</phrase> <phrase>Model</phrase> <phrase>Refinement</phrase> for 3D <phrase>Reconstruction</phrase> with <phrase>Mobile</phrase> <phrase>Robots</phrase>.
<phrase>Locating</phrase> Landmarks on <phrase>Human</phrase> Body <phrase>Scan</phrase> <phrase>Data</phrase>.
<phrase>Software</phrase> for <phrase>locating</phrase> <phrase>anthropometric</phrase> landmarks from a <phrase>cloud</phrase> of more than 100000 <phrase>three dimensional</phrase> <phrase>data</phrase> points, captured from a <phrase>human</phrase> subject, is presented. The <phrase>software</phrase> is part of <phrase>an incremental</phrase> approach that <phrase>progressively refines</phrase> the identification of <phrase>data</phrase> points. The first phase of identification is to <phrase>orient</phrase> and segment the <phrase>human</phrase> body <phrase>data</phrase> points. <phrase>Algorithms</phrase> for these tasks are presented, with a description of their use. One of the <phrase>algorithms</phrase>, a <phrase>discrete point</phrase> <phrase>cusp</phrase> detector is believed to be unique. The <phrase>software</phrase> has been tested on twenty different body <phrase>scan data</phrase> sets and shown to be <phrase>robust</phrase>.
<phrase>Fast</phrase> <phrase>Simultaneous</phrase> Alignment of <phrase>Multiple Range Images</phrase> Using <phrase>Index</phrase> Images.
This <phrase>paper</phrase> describes <phrase>a fast</phrase> and easy-to-use <phrase>simultaneous alignment</phrase> method of <phrase>multiple range images</phrase>. The most <phrase>time consuming</phrase> part of alignment process is searching corresponding points. Although "<phrase>Inverse</phrase> <phrase>calibration</phrase>" method quickly searches corresponding points in complexity <phrase>O</phrase>(n), where n is the number of vertices, the method requires some <phrase>look-up</phrase> tables or precise sensorýs parameters. Then, we propose an easy-to-use method that uses "<phrase>Index</phrase> Image": "<phrase>Index</phrase> image" can be rapidly created using <phrase>graphics hardware</phrase> without precise sensorýs parameters. For <phrase>fast</phrase> computation of <phrase>rigid transformation</phrase> matrices of a <phrase>large number</phrase> of <phrase>range</phrase> images, we utilized <phrase>linearized</phrase> <phrase>error function</phrase> and applied <phrase>incomplete Cholesky</phrase> <phrase>conjugate gradient</phrase> (ICCG) method for <phrase>solving linear equations</phrase>. Some <phrase>experimental</phrase> <phrase>results</phrase> that aligned a <phrase>large number</phrase> of <phrase>range</phrase> images measured with <phrase>laser</phrase> <phrase>range</phrase> sensors show the effectiveness of our method.
<phrase>Parallel</phrase> Alignment of a <phrase>Large Number</phrase> of <phrase>Range</phrase> Images.
<phrase>Contour Point</phrase> Tracking by <phrase>Enforcement</phrase> of <phrase>Rigidity</phrase> Constraints.
The <phrase>aperture</phrase> problem is one of the omnipresent issues in <phrase>computer vision</phrase>. Its <phrase>local</phrase> character constrains <phrase>point matching</phrase> to <phrase>high</phrase> <phrase>textured areas</phrase>, so that points ingradient- oriented regions (such as <phrase>straight lines</phrase>) can not be reliably matched. We propose a new method to overcome this problem by devising a <phrase>global matching</phrase> strategy under the factorization framework. We solve the n-frame <phrase>correspondence</phrase> problem under this context by assuming the <phrase>rigidity</phrase> of the scene. To this end, a <phrase>geometric</phrase> contraint is used that selects the matching <phrase>solution</phrase> resulting in a <phrase>rank</phrase>-4 <phrase>observation matrix</phrase>. The <phrase>rank</phrase> of the <phrase>observation matrix</phrase> is a <phrase>function</phrase> of the matching solutions associated to each image and as such a simulteaneous <phrase>solution</phrase> for all frames has to be found. An <phrase>optimization procedure</phrase> is used in this text in <phrase>order</phrase> to find the <phrase>solution</phrase>.
<phrase>Dense Disparity Estimation</phrase> Using <phrase>Gabor Filters</phrase> and <phrase>Image Derivatives</phrase>.
<phrase>Incremental</phrase> <phrase>Catmull-Clark Subdivision</phrase>.
In this <phrase>paper</phrase>, a new <phrase>adaptive</phrase> method for <phrase>Catmull-Clark subdivision</phrase> is introduced. <phrase>Adaptive</phrase> subdivision refines <phrase>specific areas</phrase> of a <phrase>model</phrase> according to user or application needs. Naive <phrase>adaptive subdivision</phrase> <phrase>algorithm</phrase> change the connectivity of the mesh, causing <phrase>geometrical</phrase> inconsistencies that alter the <phrase>limit surface</phrase>. Our method expands the specified <phrase>region</phrase> of the mesh such that when it is adaptively subdivided, it produces a <phrase>smooth surface</phrase> whose selected <phrase>area</phrase> is identical to when the entire mesh is refined. This technique also produces a surface with an increasing <phrase>level of detail</phrase> from <phrase>coarse to fine</phrase> areas of the surface. We compare our <phrase>adaptive</phrase> subdivision with other schemes and present some example applications.
A <phrase>Contour-Based</phrase> Approach to 3D Text Labeling on <phrase>Triangulated Surfaces</phrase>.
This <phrase>paper</phrase> presents a simple and <phrase>efficient</phrase> method of forming a 3D text <phrase>label</phrase> on a 3D <phrase>triangulated surface</phrase>. The <phrase>label</phrase> is formed by projecting the 2D contours that define the text <phrase>silhouette</phrase> onto the <phrase>triangulated surface</phrase>, forming 3D <phrase>contour</phrase> paths. Surface <phrase>polygons</phrase> upon which the 3D <phrase>contour</phrase> paths <phrase>lie</phrase> are retriangulated using a novel approach that forms a <phrase>polyline</phrase> defining the <phrase>region</phrase> outside the <phrase>contour</phrase>. This <phrase>algorithm</phrase> produces labeled 3D surfaces that conform to the specifications of the <phrase>STL</phrase> format, making them suitable for fabrication by a <phrase>rapid prototyping</phrase> machine. We demonstrate the effectiveness of the <phrase>algorithm</phrase> in forming <phrase>flat</phrase> and extruded <phrase>labels</phrase> on <phrase>non-trivial</phrase> surfaces.
<phrase>Nefertiti</phrase>: A Query by Content <phrase>Software</phrase> for <phrase>Three-Dimensional</phrase> Models <phrase>Databases</phrase> <phrase>Management</phrase>.
This <phrase>paper</phrase> presents a new approach for the classification and retrieval of <phrase>three-dimensional</phrase> images and models from <phrase>databases</phrase>. A set of <phrase>retrieval algorithms</phrase> is introduced. These <phrase>algorithms</phrase> are <phrase>content-based</phrase>, meaning that the input is not made out of <phrase>keywords</phrase> but of <phrase>three-dimensional</phrase> models. <phrase>Tensor</phrase> of <phrase>inertia</phrase>, distribution of normals, distribution of <phrase>cords</phrase> and <phrase>multiresolution</phrase> analysis are used to describe each <phrase>model</phrase>. The <phrase>database</phrase> can be searched by scale, shape or <phrase>color</phrase> or any combination of these parameters. A <phrase>user friendly</phrase> interface makes the retrieval operation simple and intuitive and allows to edit <phrase>reference models</phrase> according to the specifications of the user. <phrase>Experimental</phrase> <phrase>results</phrase> using a <phrase>database</phrase> of more than 400 <phrase>range</phrase> images and 1000 <phrase>VRML</phrase> models are presented.
<phrase>Automatic</phrase> <phrase>Feature Correspondence</phrase> for <phrase>Scene Reconstruction</phrase> from <phrase>Multiple Views</phrase>.
<phrase>Dual</phrase>-<phrase>Beam</phrase> <phrase>Structured-Light</phrase> Scanning for 3-<phrase>D</phrase> <phrase>Object Modeling</phrase>.
<phrase>Estimating</phrase> Pose Through <phrase>Local</phrase> <phrase>Geometry</phrase>.
<phrase>Constructing</phrase> <phrase>NURBS Surface</phrase> <phrase>Model</phrase> from Scattered and Unorganized <phrase>Range</phrase> <phrase>Data</phrase>.
A <phrase>Point-and-Shoot</phrase> <phrase>Color</phrase> 3D <phrase>Camera</phrase>.
A <phrase>Range</phrase> Image <phrase>Refinement</phrase> Technique for <phrase>Multi-view</phrase> 3D <phrase>Model</phrase> <phrase>Reconstruction</phrase>.
<phrase>Reconstruction</phrase> of Surfaces behind Occlusions in <phrase>Range</phrase> Images.
<phrase>A Fast</phrase> Point-to-<phrase>Tangent</phrase> Plane Technique for <phrase>Multi-view</phrase> Registration.
<phrase>Bayesian</phrase> Modelling of <phrase>Camera Calibration</phrase> and <phrase>Reconstruction</phrase>.
<phrase>Camera calibration</phrase> methods, whether <phrase>implicit</phrase> or explicit, are a critical part of most 3D <phrase>vision systems</phrase>. These methods involve estimation of a <phrase>model</phrase> for the <phrase>camera</phrase> that <phrase>produced</phrase> the <phrase>visual</phrase> input, and <phrase>subsequently</phrase> to infer the 3D structure that gave <phrase>rise</phrase> to the input. However, in these systems the error in <phrase>calibration</phrase> is typically unknown, or if known, the effect of <phrase>calibration</phrase> error on <phrase>subsequent processing</phrase> (e.g. 3d <phrase>reconstruction</phrase>) is not accounted for. In this <phrase>paper</phrase>, we propose a <phrase>Bayesian</phrase> <phrase>camera calibration</phrase> method that explicitly computes <phrase>calibration</phrase> error, and we show how <phrase>knowledge</phrase> of this error can be used to improve the accuracy of <phrase>subsequent processing</phrase>. What distinguishes the work is the explicit computation of a <phrase>posterior distribution</phrase> on unknown <phrase>camera</phrase> parameters, rather than just a best estimate. <phrase>Marginalizing</phrase> (<phrase>averaging</phrase>) subsequent estimates by this posterior is shown to reduce <phrase>reconstruction</phrase> error over <phrase>calibration</phrase> approaches that rely on a <phrase>single</phrase> best estimate. The method is made practical using <phrase>sampling</phrase> techniques, that require only the evaluation of the <phrase>calibration</phrase> <phrase>error function</phrase> and the specification of <phrase>priors</phrase>. Samples with their corresponding <phrase>probability</phrase> weights can be used to produce better estimates of the <phrase>camera</phrase> parameters. Moreover, these samples can be directly used to improve estimates that rely on <phrase>calibration</phrase> <phrase>information</phrase>, like 3D <phrase>reconstruction</phrase>. We evaluate our method using <phrase>simulated data</phrase> for a <phrase>structure from motion</phrase> problem, in which the same <phrase>point matches</phrase> are used to calibrate the <phrase>camera</phrase>, estimate the motion, and reconstruct the 3D <phrase>geometry</phrase>. Our <phrase>results</phrase> show improved <phrase>reconstruction</phrase> over <phrase>non-linear</phrase> <phrase>Camera calibration</phrase> methods like the <phrase>Maximum Likelihood</phrase> estimate. Additionally, this approach scales much better in the face of increasingly noisy <phrase>point matches</phrase>.
<phrase>Affine</phrase> Transformations of 3D Objects Represented with <phrase>Neural Networks</phrase>.
Acquisition of <phrase>Three-Dimensional</phrase> <phrase>Information</phrase> in a <phrase>Real Environment</phrase> by Using the <phrase>Stereo</phrase> <phrase>Omni-directional</phrase> System (<phrase>SOS</phrase>).
A Registration Aid.
Although the <phrase>iterative closest point algorithm</phrase> is very effective in registering <phrase>range</phrase> <phrase>data</phrase>, the quality of registration depends on the <phrase>geometry</phrase> of the <phrase>sampled surfaces</phrase>. This work presents a registration aid which can <phrase>greatly reduce</phrase> the possibility of catastrophic registration failure, increase the quality of registration and register <phrase>range</phrase> <phrase>data</phrase> which does not overlap. By placing the aid into the scene along with the object(<phrase>s</phrase>) of interest, <phrase>range</phrase> images taken from any <phrase>vantage point</phrase> within the <phrase>range</phrase> scanner's workspace can be registered onto a <phrase>model</phrase> of the aid and thus into a common <phrase>reference frame</phrase>. By considering the causes of registration failure, the surface of the aid is designed so that any <phrase>range</phrase> image taken of it from any point in the scanner's workspace will properly register with a <phrase>model</phrase> of the aid. The reliability of the aid is demonstrated with a <phrase>Monte Carlo</phrase> experiment and its utility is demonstrated with examples from an <phrase>automated</phrase> surface acquisition system.
<phrase>Free</phrase>-Form <phrase>Surface Reconstruction</phrase> from <phrase>Multiple Images</phrase> .
<phrase>Hand-Held</phrase> Acquisition of 3D Models with a <phrase>Video Camera</phrase>.
A <phrase>MRF</phrase> Formulation for <phrase>Coded Structured Light</phrase>.
<phrase>Multimedia</phrase> projectors and cameras make possible the use of <phrase>structured light</phrase> to <phrase>solve problems</phrase> such as 3D <phrase>reconstruction</phrase>, <phrase>disparity map</phrase> computation and <phrase>camera</phrase> or <phrase>projector calibration</phrase>. Each <phrase>projector displays</phrase> patterns over a scene viewed by a <phrase>camera</phrase>, thereby allowing <phrase>automatic</phrase> computation of <phrase>camera</phrase>-projector <phrase>pixel</phrase> correspondences. This <phrase>paper</phrase> introduces a new <phrase>algorithm</phrase> to establish this <phrase>correspondence</phrase> in <phrase>difficult cases</phrase> of <phrase>image acquisition</phrase>. A <phrase>probabilistic model</phrase> formulated as a <phrase>Markov Random Field</phrase> uses the <phrase>stripe</phrase> images to find the most likely correspondences in the presence of noise. Our <phrase>model</phrase> is <phrase>specially tailored</phrase> to handle the unfavorable <phrase>projector-camera</phrase> <phrase>pixel</phrase> ratios that occur in multiple-projector <phrase>single</phrase>-<phrase>camera</phrase> setups. For the case where more than one <phrase>camera</phrase> is used, we propose a <phrase>robust</phrase> approach to establish correspondences between the cameras and compute an accurate <phrase>disparity map</phrase>. To <phrase>conduct experiments</phrase>, a <phrase>ground truth</phrase> was first reconstructed from a <phrase>high</phrase> quality acquisition. Various degradations were applied to the pattern images which were then solved using our method. The <phrase>results</phrase> were compared to the <phrase>ground truth</phrase> for <phrase>error analysis</phrase> and showed very good performances, even near <phrase>depth discontinuities</phrase>.
The ModelCamera: a <phrase>Hand-Held</phrase> Device for <phrase>Interactive Modeling</phrase>.
Multi-projectors for <phrase>arbitrary surfaces</phrase> without explicit <phrase>calibration</phrase> nor reconstructio.
<phrase>Virtual</phrase> Environments for Critical Intervention Support: Modeling, <phrase>Design</phrase> and <phrase>Implementation Issues</phrase>.
<phrase>Cramer-Rao Bounds</phrase> for <phrase>Nonparametric</phrase> <phrase>Surface Reconstruction</phrase> from <phrase>Range</phrase> <phrase>Data</phrase>.
Tolerance Control with <phrase>High</phrase> Resolution 3D Measurement.
<phrase>Anisotropic</phrase> <phrase>diffusion</phrase> of <phrase>surface normals</phrase> for <phrase>feature preserving</phrase> <phrase>surface reconstruction</phrase>.
<phrase>CAD</phrase>-Based <phrase>Range</phrase> <phrase>Sensor</phrase> Placement for <phrase>Optimum</phrase> 3D <phrase>Data</phrase> Acquisitio.
A Flexible 3D Modeling System Based on <phrase>Combining</phrase> <phrase>Shape-from-Silhouette</phrase> with <phrase>Light-Sectioning</phrase> <phrase>Algorithm</phrase>.
In this <phrase>paper</phrase> we present a flexible modeling system for obtaining the <phrase>texture-mapped</phrase> 3D <phrase>geometric</phrase> <phrase>model</phrase>. The modeling system uses an <phrase>algorithm</phrase> <phrase>combining</phrase> <phrase>shape-from-silhouette</phrase> with <phrase>light-sectioning</phrase>. In the <phrase>algorithm</phrase>, at first, a <phrase>rough</phrase> <phrase>shape model</phrase> is obtained by <phrase>shape-from-silhouette</phrase> method almost automatically. <phrase>Next</phrase>, concavities and complex parts on the <phrase>object surface</phrase> are obtained by <phrase>light-sectioning</phrase> method with manual scanning. For <phrase>applying</phrase> <phrase>light-sectioning</phrase> method to <phrase>volume data</phrase>, we propose <phrase>volumetric</phrase> <phrase>light-sectioning</phrase> <phrase>algorithm</phrase>. Then our modeling system can realize easy and accurate generation of 3D <phrase>geometric</phrase> <phrase>model</phrase>.
<phrase>Multiview</phrase> Registration for <phrase>Large Data Sets</phrase>.
<phrase>Physics-Based</phrase> Models for <phrase>Image Analysis</phrase>/<phrase>Synthesis</phrase> and <phrase>Geometric</phrase> <phrase>Design</phrase>.
This <phrase>paper</phrase> reviews <phrase>recently</phrase> developed <phrase>physics</phrase>-based <phrase>surface modeling</phrase> techniques for <phrase>geometric</phrase> <phrase>design</phrase>, <phrase>medical</phrase> <phrase>image analysis</phrase>, and <phrase>human facial</phrase> modeling. It briefly motivates the problems of interest in each <phrase>application area</phrase>, describes the models that the authors have developed to address them, presents sample <phrase>results</phrase>, and provides references to <phrase>technical papers</phrase> containing the full details.
<phrase>Robust</phrase> Meshes from Multiple <phrase>Range</phrase> <phrase>Maps</phrase>.
This <phrase>paper</phrase> presents a method for modeling the surface of an object from a <phrase>sequence</phrase> of <phrase>range</phrase> <phrase>maps</phrase>. Our method is based on a <phrase>volumetric</phrase> approach that produces a <phrase>compact</phrase> surface without boundary. It provides robustness through the use of <phrase>interval analysis</phrase> techniques and <phrase>computational efficiency</phrase> through <phrase>hierarchical</phrase> processing using octrees.
<phrase>Determining</phrase> <phrase>Characteristic Views</phrase> of a 3D Object by <phrase>Visual Hulls</phrase> and <phrase>Hausdorff</phrase> Distance.
<phrase>Nowadays</phrase>, with the exponential growing of 3D <phrase>object representations</phrase> in <phrase>private</phrase> <phrase>databases</phrase> or on the <phrase>web</phrase>, it is all the more required to match these objects from some views. To improve the <phrase>results</phrase> of their matching, we work on the <phrase>characteristic views</phrase> of an object. The aim of this study is to find how many <phrase>characteristic views</phrase> are required and what <phrase>relative positions</phrase> are <phrase>optimal</phrase>. This is the reason why the <phrase>visual hulls</phrase> are used. From some 2D masks, the nearest possible 3D mesh from the original object is computed. <phrase>OpenGL</phrase> views are used to build the <phrase>visual hulls</phrase> of 3D models from a given collection and then the distance between the <phrase>visual hulls</phrase> and the models are measured thanks to the <phrase>Hausdorff</phrase> distance. Then the best view parameters are deduced to reduce the distance. These shots show that three <phrase>orthogonal</phrase> views give <phrase>results</phrase> very close to the ones given by twelve views on a isocahedron. Some other <phrase>results</phrase> on the view resolution and the <phrase>field of view</phrase> are discussed.
<phrase>Projective</phrase> <phrase>Surface Matching</phrase> of <phrase>Colored</phrase> 3D Scans.
We present a new method for registering multiple 3D scans of a <phrase>colored</phrase> object. Each <phrase>scan</phrase> is regarded as a <phrase>color</phrase> and <phrase>range</phrase> image of the object recorded by a <phrase>pinhole camera</phrase>. Consider a pair of cameras that see <phrase>overlapping parts</phrase> of the objects. For correct <phrase>camera</phrase> poses, the actual image of the <phrase>overlap area</phrase> in one <phrase>camera</phrase> matches the rendition of the <phrase>overlap area</phrase> as seen by the other <phrase>camera</phrase>. We define a <phrase>mismatch</phrase> score <phrase>summarizing</phrase> discrepancies in <phrase>color</phrase>, <phrase>range</phrase>, and <phrase>silhouette</phrase> between pairs of images, and we present an <phrase>algorithm</phrase> to efficiently minimize this <phrase>mismatch</phrase> score over <phrase>camera</phrase> poses.
3D Modeling of <phrase>Archaeological</phrase> Vessels Using <phrase>Shape from Silhouette</phrase>.
<phrase>Adaptive</phrase> Enhancement of 3D Scenes using <phrase>Hierarchical</phrase> Registration of <phrase>Texture-Mapped</phrase> 3D models.
Relighting Acquired Models of <phrase>Outdoor</phrase> Scenes.
In this <phrase>paper</phrase> we introduce a relighting <phrase>algorithm</phrase> for diffuse <phrase>outdoor</phrase> scenes that enables us to create <phrase>geometrically correct</phrase> and illumination consistent models from a series of <phrase>range</phrase> scans and a set of overlapping photographs that have been taken under different <phrase>illumination conditions</phrase>. To perform the relighting we compute a set of mappings from the <phrase>overlap region</phrase> of two images. We call these mappings <phrase>Irradiance</phrase> Ratio <phrase>Maps</phrase> (IRMs). Our <phrase>algorithm</phrase> handles <phrase>cast</phrase> shadows, being able to relight <phrase>shadowed</phrase> regions into non-<phrase>shadowed</phrase> regions <phrase>and vice-versa</phrase>. We solve these cases by <phrase>computing</phrase> four different IRMs, to handle all four combinations of <phrase>shadowed</phrase> vs. non-<phrase>shadowed</phrase> surfaces. To relight the <phrase>non-overlapping</phrase> <phrase>region</phrase> of an image, we look into the appropriate <phrase>IRM</phrase> which we <phrase>index</phrase> on <phrase>surface normal</phrase>, and apply its value to the corresponding <phrase>pixels</phrase>. The result is an illumination consistent set of images.
Approaches to a <phrase>Color</phrase> Scannerless <phrase>Range</phrase> <phrase>Imaging</phrase> System.
<phrase>Efficient</phrase> <phrase>Surface Reconstruction</phrase> from <phrase>Range</phrase> Curves.
3-<phrase>D</phrase> Modeling from <phrase>Range</phrase> Imagery: <phrase>An Incremental</phrase> Method with a <phrase>Planning</phrase> Component.
In this <phrase>paper</phrase> we present a method for <phrase>automatically constructing</phrase> a <phrase>CAD</phrase> <phrase>model</phrase> of an unknown object from <phrase>range</phrase> images. The method is <phrase>an incremental</phrase> one that interleaves a sensing operation that acquires and merges <phrase>information</phrase> into the <phrase>model</phrase> with a <phrase>planning</phrase> phase to determine the <phrase>next</phrase> <phrase>sensor</phrase> position or "view". This is accomplished by <phrase>integrating</phrase> a system for 3-<phrase>D</phrase> <phrase>model</phrase> acquisition with a <phrase>sensor</phrase> <phrase>planner</phrase>. The <phrase>model</phrase> acquisition system provides facilities for <phrase>range image</phrase> acquisition, <phrase>solid model</phrase> <phrase>construction</phrase> and <phrase>model</phrase> <phrase>merging</phrase>: both <phrase>mesh surface</phrase> and solid representations are used to build a <phrase>model</phrase> of the <phrase>range</phrase> <phrase>data</phrase> from each view, which is then merged with the <phrase>model</phrase> built from previous sensing operations. The <phrase>planning</phrase> system utilizes the resulting incomplete <phrase>model</phrase> to plan the <phrase>next</phrase> sensing operation by <phrase>finding</phrase> a <phrase>sensor</phrase> <phrase>viewpoint</phrase> that will improve the fidelity of the <phrase>model</phrase>. <phrase>Experimental</phrase> <phrase>results</phrase> are presented for a complex part that includes <phrase>polygonal</phrase> faces, <phrase>curved</phrase> surfaces, and large <phrase>self-occlusions</phrase>.
<phrase>Virtual</phrase> <phrase>Clay</phrase> Modeling System Using <phrase>Multi-Viewpoint</phrase> Images.
This <phrase>paper</phrase> proposes a "non-<phrase>contact</phrase> <phrase>virtual</phrase> <phrase>clay</phrase> modeling system." We developed a <phrase>prototype</phrase> of <phrase>three-dimensional</phrase> modeling system that allows users to shape "<phrase>virtual</phrase> <phrase>clay</phrase>" with their <phrase>hand movements</phrase>. In our <phrase>proposed method</phrase>, the usersý <phrase>hand movements</phrase> are observed with <phrase>multiple cameras</phrase> to estimate their positions. The <phrase>human</phrase> hand surface and <phrase>virtual</phrase> <phrase>clay</phrase> are modeled by using <phrase>subdivision surface</phrase>. Using these estimated <phrase>hand positions</phrase>, <phrase>virtual</phrase> <phrase>clay</phrase> is shaped based on a <phrase>direct</phrase> <phrase>free-form deformation</phrase> technique. To improve <phrase>processing speed</phrase>, we implemented the proposed system on a <phrase>PC</phrase> cluster. This system proves the feasibility of an intuitive <phrase>virtual</phrase> <phrase>clay</phrase> modeling system.
<phrase>Human Figure</phrase> <phrase>Reconstruction</phrase> and Modeling from <phrase>Single</phrase> Image or <phrase>Monocular</phrase> <phrase>Video</phrase> <phrase>Sequence</phrase>.
<phrase>Generating</phrase> <phrase>Smooth Surfaces</phrase> with <phrase>Bicubic</phrase> Splines over <phrase>Triangular Meshes</phrase>: <phrase>Toward</phrase> <phrase>Automatic</phrase> <phrase>Model Building</phrase> from Unorganized 3D Points.
3D Models from Extended <phrase>Uncalibrated Video Sequences</phrase>: Addressing <phrase>Key-Frame</phrase> Selection and <phrase>Projective</phrase> Drift.
In this <phrase>paper</phrase>; we present an approach that is able to reconstruct 3D models from extended <phrase>video</phrase> sequences captured with an <phrase>uncalibrated</phrase> <phrase>hand-held camera</phrase>. We focus on two <phrase>specific issues</phrase>: (1) <phrase>key-frame</phrase> selection, and ( 2 ) <phrase>projective</phrase> drift. Given a <phrase>long</phrase> <phrase>video</phrase> <phrase>sequence</phrase> it is often not practical to work with all videoframes. In addition, to allow for effective <phrase>outlier</phrase> rejection and <phrase>motion estimation</phrase> it is necessary to have a sufficient baseline between frames. For this purpose, we propose a <phrase>key-frame selection</phrase> procedure based on a <phrase>robust</phrase> <phrase>model selection</phrase> criterion. Our approach guarantees that the <phrase>camera</phrase> motion can be estimated reliably by <phrase>analyzing</phrase> the <phrase>feature correspondences</phrase> between three consecutive views. Another problem for <phrase>long</phrase> <phrase>uncalibrated video sequences</phrase> is <phrase>projective</phrase> drift. <phrase>Error accumulation</phrase> leads to a non-<phrase>projective</phrase> <phrase>distortion</phrase> of the <phrase>model</phrase>. This causes the <phrase>projective</phrase> basis at the beginning and the end of the <phrase>sequence</phrase> to become inconsistent and leads to the failure of <phrase>self-calibration</phrase>. We propose a <phrase>self-calibration</phrase> approach that is insensitive to this <phrase>global</phrase> <phrase>projective</phrase> drift. Afterself-<phrase>calibration</phrase> <phrase>triplets</phrase> of <phrase>key-frames</phrase> are aligned using <phrase>absolute</phrase> orientation and hierarchically merged into a complete <phrase>metric reconstruction</phrase>. <phrase>Next</phrase>, we compute a detailed 3D <phrase>surface model</phrase> using <phrase>stereo</phrase> matching. The 3D <phrase>model</phrase> is textured using some of the frames.
Correction of <phrase>Color Information</phrase> of a 3D <phrase>Model</phrase> Using a <phrase>Range</phrase> <phrase>Intensity Image</phrase>.
A <phrase>range</phrase> <phrase>intensity image</phrase>, which is also called a <phrase>reflectance</phrase> image, refers to the <phrase>intensity image</phrase> that is acquired simultaneously with the <phrase>range</phrase> image captured using an <phrase>active</phrase> <phrase>range</phrase> <phrase>sensor</phrase>. This <phrase>paper</phrase> proposes a method that uses this image to correct the <phrase>color information</phrase> of a textured 3D <phrase>model</phrase>. The <phrase>color information</phrase> is usually obtained by <phrase>texture mapping</phrase> of <phrase>color images</phrase> acquired by a <phrase>digital camera</phrase>. The <phrase>lighting condition</phrase> for the <phrase>color images</phrase> are usually not controlled, thus the <phrase>color information</phrase> is not precise. On the other hand, the <phrase>lighting condition</phrase> for the <phrase>range</phrase> <phrase>intensity image</phrase> is controlled since it is obtained from a controlled and known lighting as required for the purpose of <phrase>range</phrase> measurement. The <phrase>paper</phrase> describes the method for <phrase>combining</phrase> the two sources of <phrase>information</phrase>; experiments show the effectiveness of the <phrase>correction method</phrase>.
Modeling <phrase>Structured Environments</phrase> by a <phrase>Single</phrase> <phrase>Moving Camera</phrase>.
<phrase>Combining</phrase> Off- and <phrase>On-Line</phrase> <phrase>Calibration</phrase> of a <phrase>Digital Camera</phrase>.
<phrase>Shape Recovery</phrase> and Analysis of Large <phrase>Screw</phrase> Threads.
<phrase>Stable</phrase> <phrase>Real-Time</phrase> Interaction Between <phrase>Virtual</phrase> Humans And <phrase>Real Scenes</phrase> .
The <phrase>Caesar</phrase> <phrase>Project</phrase>: A 3-<phrase>D</phrase> Surface <phrase>Anthropometry</phrase> Survey.
Surflet-Pair-Relation Histograms: A Statistical 3D-<phrase>Shape Representation</phrase> for <phrase>Rapid</phrase> Classification.
3D <phrase>Shape Recovery</phrase> and <phrase>Registration based</phrase> on the <phrase>Projection</phrase> of <phrase>Non Coherent</phrase> <phrase>Structured Light</phrase>.
<phrase>Efficient</phrase> <phrase>Reconstruction</phrase> of <phrase>Indoor</phrase> Scenes with <phrase>Color</phrase>.
<phrase>Computing</phrase> <phrase>Camera</phrase> Positions from a <phrase>Multi-camera</phrase> <phrase>Head</phrase>.
<phrase>Shape Reconstruction</phrase> of <phrase>Human</phrase> Foot from <phrase>Multi-Camera</phrase> Images Based on <phrase>PCA</phrase> of <phrase>Human</phrase> Shape <phrase>Database</phrase>.
<phrase>Recently</phrase>, researches and developments for <phrase>measuring</phrase> and modeling of <phrase>human</phrase> body are taking much attention. Our aim is to capture accurate shape of <phrase>human</phrase> foot, using 2D <phrase>images acquired</phrase> by <phrase>multiple cameras</phrase>, which can capture <phrase>dynamic</phrase> behavior of the object. In this <phrase>paper</phrase>, 3D <phrase>active shape models</phrase> is used for accurate <phrase>reconstruction</phrase> of <phrase>surface shape</phrase> of <phrase>human</phrase> foot. We apply <phrase>Principal Component Analysis</phrase> (<phrase>PCA</phrase>) of <phrase>human</phrase> shape <phrase>database</phrase>, so that we can represent humanýs <phrase>foot shape</phrase> by approximately 12 <phrase>principal component</phrase> shapes. Because of the reduction of dimensions for representing the <phrase>object shape</phrase>, we can efficiently recover the <phrase>object shape</phrase> from <phrase>multi-camera</phrase> images, even <phrase>though</phrase> the <phrase>object shape</phrase> is <phrase>partially occluded</phrase> in some of input views. To demonstrate the <phrase>proposed method</phrase>, two kinds of experiments are presented: <phrase>high</phrase> accuracy <phrase>reconstruction</phrase> of <phrase>human</phrase> foot in a <phrase>virtual reality</phrase> environment with <phrase>CG</phrase> <phrase>multi-camera</phrase> images and in <phrase>real world</phrase> with eight <phrase>CCD</phrase> cameras. In those experiments, the recovered shape error with our method is around 2mm, while the error is around 4mm with <phrase>volume intersection</phrase> method.
Registering Two <phrase>Overlapping Range Images</phrase>.
Registration of 3-<phrase>D</phrase> <phrase>Partial</phrase> <phrase>Surface Models</phrase> using <phrase>Luminance</phrase> and <phrase>Depth Information</phrase>.
<phrase>Textured surface</phrase> models of <phrase>three-dimensional</phrase> objects are <phrase>gaining importance</phrase> in <phrase>computer graphics</phrase> applications. These models often have to be merged from several overlapping <phrase>partial</phrase> models which have to be registered (i.e. the relative transformation between the <phrase>partial</phrase> models has to be determined) prior to the <phrase>merging</phrase> process. In this <phrase>paper</phrase> a method is presented that makes use of both <phrase>camera</phrase>-based <phrase>depth information</phrase> (e.g. from <phrase>stereo</phrase>) and the <phrase>luminance</phrase> image. The <phrase>luminance</phrase> <phrase>information</phrase> is exploited to determine corresponding <phrase>point sets</phrase> on the <phrase>partial</phrase> surfaces using an <phrase>optical flow</phrase> approach. <phrase>Quaternions</phrase> are then employed to determine the transformation between the <phrase>partial</phrase> models which minimizes the <phrase>sum</phrase> of the 3-<phrase>D</phrase> <phrase>Euclidian</phrase> distances between the corresponding <phrase>point sets</phrase>. In <phrase>order</phrase> to find corresponding points on the <phrase>partial</phrase> surfaces <phrase>luminance</phrase> <phrase>information</phrase> is <phrase>linearized</phrase>. The procedure is <phrase>iterated</phrase> until convergence is reached. In contrast to only using <phrase>depth information</phrase>, employing <phrase>luminance</phrase> <phrase>speeds up</phrase> convergence and reduces remaining <phrase>degrees of freedom</phrase> (e.g. when registering <phrase>sphere</phrase>-like shapes).
Curve and <phrase>Surface Models</phrase> to Drive 3D <phrase>Reconstruction</phrase> Using <phrase>Stereo</phrase> and Shading.
<phrase>Faithful</phrase> <phrase>Recovering</phrase> of <phrase>Quadric</phrase> Surfaces from 3D <phrase>Range</phrase> <phrase>Data</phrase>.
Segmentation and Modeling of Approximately <phrase>Rotationally Symmetric</phrase> Objects in 3D <phrase>Ultrasound</phrase>.
<phrase>Indoor Scene</phrase> <phrase>Reconstruction</phrase> from Sets of Noisy <phrase>Range</phrase> Images.
3D Capture for <phrase>Computer Graphics</phrase>.
<phrase>Real-Time</phrase> <phrase>Image Based</phrase> Rendering from <phrase>Uncalibrated Images</phrase>.
We present a novel <phrase>real-time</phrase> <phrase>image-based</phrase> rendering system for <phrase>generating</phrase> realistic novel views of <phrase>complex scenes</phrase> from a set of <phrase>uncalibrated images</phrase>. A combination ofstructure-and-motion and <phrase>stereo</phrase> techniques is used to obtain <phrase>calibrated cameras</phrase> and <phrase>dense depth maps</phrase> for all recorded images. These <phrase>depth maps</phrase> are <phrase>converted into</phrase> restrictive <phrase>quadtrees</phrase>, which allow for <phrase>adaptive</phrase>, <phrase>view-dependent</phrase> <phrase>tessellations</phrase> while storing per-vertex quality. When rendering a novel view, a <phrase>subset</phrase> of suitable cameras is selected based upon a <phrase>ranking</phrase> criterion. In the <phrase>spirit</phrase> of the unstructured lumigraph rendering approach a <phrase>blending</phrase> field is evaluated, although the implementation is adapted on several points. We alleviate the need for the creation of a <phrase>geometric</phrase> <phrase>proxy</phrase> for each novel view while the <phrase>camera</phrase> <phrase>blending</phrase> field is sampled in a more <phrase>optimal</phrase>, <phrase>non-uniform</phrase> way and combined with the per-vertex quality to reduce texture artifacts. In <phrase>order</phrase> to make <phrase>real-time</phrase> visualization possible, all critical steps of the <phrase>visualization pipeline</phrase> are programmed in a <phrase>highly optimized</phrase> way on <phrase>commodity graphics hardware</phrase> using the <phrase>OpenGL Shading Language</phrase>. The proposed system can handle <phrase>complex scenes</phrase> such as <phrase>large outdoor</phrase> scenes as well as <phrase>small objects</phrase> with a <phrase>large number</phrase> of acquired images.
<phrase>Computing</phrase> Consistent Normals and Colors from <phrase>Photometric</phrase> <phrase>Data</phrase>.
<phrase>Model</phrase>-Based Scanning <phrase>Path Generation</phrase> for Inspection.
<phrase>Image-Based</phrase> Object <phrase>Editing</phrase>.
<phrase>Enhanced</phrase>, <phrase>Robust</phrase> <phrase>Genetic Algorithms</phrase> for <phrase>Multiview</phrase> <phrase>Range</phrase> <phrase>Image Registration</phrase>.
<phrase>Efficient</phrase> Variants of the <phrase>ICP</phrase> <phrase>Algorithm</phrase>.
<phrase>Combining</phrase> texture and shape for <phrase>automatic</phrase> crude patch registration.
On <phrase>Estimating</phrase> the Position of Fragments on <phrase>Rotational</phrase> <phrase>Symmetric</phrase> <phrase>Pottery</phrase>.
A Discrete <phrase>Reeb Graph</phrase> Approach for the Segmentation of <phrase>Human Body</phrase> Scans .
<phrase>Next</phrase> <phrase>View Planning</phrase> for a Combination of <phrase>Passive</phrase> and <phrase>Active</phrase> Acquisition Techniques.
<phrase>Additional Reviewers</phrase>.
<phrase>Curvature</phrase> Estimation for Segmentation of <phrase>Triangulated Surfaces</phrase>.
3-<phrase>D</phrase> Modeling of <phrase>Human</phrase> Hand with <phrase>Motion Constraints</phrase>.
Taking <phrase>Consensus</phrase> of <phrase>Signed Distance</phrase> Field for <phrase>Complementing</phrase> Unobservable Surface.
<phrase>Progressive</phrase> <phrase>Multilevel</phrase> Meshes from <phrase>Octree</phrase> Particles.
Effective <phrase>Nearest Neighbor Search</phrase> for <phrase>Aligning</phrase> and <phrase>Merging</phrase> <phrase>Range</phrase> Images.
<phrase>Digitizing</phrase> <phrase>Archaeological</phrase> Excavations from <phrase>Multiple Views</phrase>.
We present a novel approach on <phrase>digitizing</phrase> <phrase>large scale unstructured</phrase> environments like <phrase>archaeological</phrase> excavations using off-the-<phrase>shelf</phrase> <phrase>digital</phrase> still cameras. The cameras are calibrated with respect to few markers captured by a <phrase>theodolite</phrase> system. Having all cameras registered in the same coordinate system enables a <phrase>volumetric</phrase> approach. Our new <phrase>algorithm</phrase> has as input multiple <phrase>calibrated images</phrase> and outputs an <phrase>occupancy</phrase> <phrase>voxel</phrase> space where occupied <phrase>pixels</phrase> have a <phrase>local</phrase> orientation and a confidence value. Both, orientation and confidence facilitate <phrase>an efficient</phrase> rendering and <phrase>texture mapping</phrase> of the resulting <phrase>point cloud</phrase>. Our <phrase>algorithm</phrase> combines the following new features: Images are <phrase>back-projected</phrase> to hypothesized <phrase>local</phrase> patches in the world and correlated on these patches yielding the best orientation. Adjacent cameras build tuples which yield a product of <phrase>pairwise correlations</phrase>, called strength. <phrase>Multiple camera</phrase> tuples compete each other for the best strength for each <phrase>voxel</phrase>. A <phrase>voxel</phrase> is regarded as occupied if strength is maximum along the normal. <phrase>Unlike</phrase> other <phrase>multi-camera</phrase> <phrase>algorithms</phrase> using silhouettes, photoconsistency, or <phrase>global</phrase> <phrase>correspondence</phrase>, our <phrase>algorithm</phrase> makes no assumption on <phrase>camera</phrase> locations being outside the <phrase>convex hull</phrase> of the scene. We present compelling <phrase>results</phrase> of outdoors <phrase>excavation</phrase> areas.
<phrase>Appearance-Based</phrase> <phrase>Virtual View Generation</phrase> of <phrase>Temporally-Varying</phrase> Events from <phrase>Multi-Camera</phrase> Images in the 3D <phrase>Room</phrase>.
A Mechanism for <phrase>Range</phrase> Image <phrase>Integration</phrase> without <phrase>Image Registration</phrase>.
A mechanism is introduced that automatically integrates <phrase>multi-view</phrase> <phrase>range</phrase> images without registering the images. The mechanism is based on a reference <phrase>double</phrase>-frame that acts as the coordinate system of the scene. A <phrase>single</phrase>-view <phrase>range</phrase> image of a scene is obtained by <phrase>sweeping</phrase> a <phrase>laser</phrase> line over the scene by hand and <phrase>analyzing</phrase> the acquired <phrase>light</phrase> stripes. <phrase>Range images</phrase> captured from different views of the scene will be in the coordinate system of the <phrase>double</phrase>-frame, and thus, will automatically integrate without further processing.
<phrase>Three-Dimensional Shape</phrase> Modeling with Extended Hyperquadrics.
<phrase>Dynamic</phrase> <phrase>Gaze</phrase>-Controlled Levels of Detail of <phrase>Polygonal</phrase> Objects in 3-<phrase>D</phrase> Environment Modeling.
Recovery of Shape and <phrase>Surface Reflectance</phrase> of <phrase>Specular</phrase> Object from Rotation of <phrase>Light</phrase> Source.
<phrase>Active</phrase> Modeling of 3-<phrase>D</phrase> Objects: <phrase>Planning</phrase> on the <phrase>Next</phrase> Best Pose (NBP) for <phrase>Acquiring</phrase> <phrase>Range</phrase> Images.
We propose a new method of <phrase>creating</phrase> a complete <phrase>model</phrase> of a <phrase>curved</phrase> object from <phrase>multiple range images</phrase> acquired by showing it at different poses. The pose of the object is changed by a <phrase>manipulator</phrase> in <phrase>order</phrase> to view the object from some specified viewpoints. The pose is planned after each new image is merged into <phrase>a unified</phrase> representation. A rating <phrase>function</phrase> for the <phrase>planning</phrase> is defined to take into consideration the factors such as possibility of <phrase>merging</phrase> new <phrase>data</phrase>, <phrase>registration accuracy</phrase> and <phrase>control point</phrase> selection.
<phrase>Shape Measurement</phrase> of <phrase>Discontinuous</phrase> Objects using Projected <phrase>Fringes</phrase> and Temporal <phrase>Phase Unwrapping</phrase>.
Temporal <phrase>phase unwrapping</phrase> is a method of <phrase>analyzing</phrase> <phrase>fringe</phrase> patterns in which the <phrase>fringe</phrase> phase, /<phrase>spl Phi</phrase>/, at each <phrase>pixel</phrase> is measured and <phrase>unwrapped</phrase> as a <phrase>function</phrase> of time, <phrase>t</phrase>. We propose a method for <phrase>improving</phrase> the <phrase>signal-to-noise ratio</phrase> of the total <phrase>phase change</phrase> by <phrase>incorporating</phrase> <phrase>data</phrase> from the intermediate phase values. The performance of the method is compared theoretical and experimentally, using <phrase>data</phrase> from a <phrase>fringe</phrase> <phrase>projector based</phrase> on a <phrase>spatial</phrase> tight modulator. The best way to use the method is with /<phrase>spl Phi</phrase>/ decreasing exponentially with time from its maximum value to zero; this provides <phrase>significant improvements</phrase> in reliability, accuracy and computation time compared with the original temporal <phrase>unwrapping</phrase> <phrase>algorithm</phrase>.
<phrase>Bootstrapped</phrase> <phrase>Real-Time</phrase> <phrase>Ego Motion Estimation</phrase> and <phrase>Scene Modeling</phrase>.
<phrase>Estimating</phrase> the motion of a <phrase>moving camera</phrase> in an <phrase>unknown environment</phrase> is essential for a number of applications ranging from as-built <phrase>reconstruction</phrase> to <phrase>augmented reality</phrase>. It is a <phrase>challenging problem</phrase> especially when <phrase>real-time</phrase> performance is required. Our approach is to estimate the <phrase>camera</phrase> motion while <phrase>reconstructing</phrase> the shape and appearance of the most salient <phrase>visual</phrase> features in the scene. In our 3D <phrase>reconstruction</phrase> process, correspondences are obtained by tracking the <phrase>visual</phrase> features from <phrase>frame to frame</phrase> with <phrase>optical flow</phrase> tracking. <phrase>Optical-flow</phrase>-based <phrase>tracking methods</phrase> have limitations in tracking the <phrase>salient features</phrase>. Often larger <phrase>translational</phrase> motions and even moderate <phrase>rotational</phrase> motions can result in drifts. We propose to augment <phrase>flow-based</phrase> tracking by <phrase>building</phrase> a <phrase>landmark</phrase> representation around reliably reconstructed features. A <phrase>planar</phrase> patch around the reconstructed <phrase>feature point</phrase> provides matching <phrase>information</phrase> that prevents drifts in <phrase>flow-based</phrase> <phrase>feature tracking</phrase> and allows establishment of correspondences across the frames with large baselines. <phrase>Selective</phrase> and <phrase>periodic</phrase> such <phrase>correspondence</phrase> mappings <phrase>drastically improve</phrase> scene and <phrase>motion reconstruction</phrase> while adhering to the <phrase>real-time</phrase> requirements. The method is <phrase>experimentally tested</phrase> to be both accurate and computational <phrase>efficient</phrase>.
3-<phrase>D</phrase> <phrase>Imager</phrase> for Dimensional <phrase>Gauging</phrase> of <phrase>Industrial</phrase> Workpieces: <phrase>State</phrase>-of-the-<phrase>Art</phrase> of the Development of a <phrase>Robust</phrase> and <phrase>Versatile</phrase> System.
<phrase>Experimental</phrase> Analysis of <phrase>Harmonic</phrase> Shape Images.
<phrase>Fast</phrase> <phrase>Range</phrase> <phrase>Image Segmentation</phrase> by an <phrase>Edge Detection</phrase> Strategy.
A <phrase>Physically-Based</phrase> <phrase>Model</phrase> for <phrase>Real-Time</phrase> <phrase>Facial Expression</phrase> <phrase>Animation</phrase>.
<phrase>Globally Convergent</phrase> <phrase>Range</phrase> <phrase>Image Registration</phrase> by <phrase>Graph</phrase> <phrase>Kernel</phrase> <phrase>Algorithm</phrase>.
<phrase>Automatic</phrase> <phrase>range</phrase> <phrase>image registration</phrase> without any <phrase>knowledge</phrase> of the <phrase>viewpoint</phrase> requires identification of common regions across different <phrase>range</phrase> images and then establishing <phrase>point correspondences</phrase> in these regions. We formulate this as a <phrase>graph-based</phrase> <phrase>optimization problem</phrase>. More <phrase>specifically</phrase>, we define a <phrase>graph</phrase> in which each vertex represents a putative match of two points, each edge represents <phrase>binary</phrase> consistency decision between two matches, and each <phrase>edge orientation</phrase> represents match quality from worse to better putative match. Then <phrase>strict</phrase> sub-<phrase>kernel</phrase> defined in the <phrase>graph</phrase> is maximized. The maximum <phrase>strict</phrase> sub-<phrase>kernel</phrase> <phrase>algorithm</phrase> enables us to <phrase>uniquely determine</phrase> the largest consistent matching of points. To evaluate the quality of a <phrase>single</phrase> match, we employ the <phrase>histogram</phrase> of <phrase>triple</phrase> <phrase>products</phrase> that are generated by all <phrase>surface normals</phrase> in a point <phrase>neighborhood</phrase>. Our <phrase>experimental</phrase> <phrase>results</phrase> show the effectiveness of our method for <phrase>rough</phrase> <phrase>range</phrase> <phrase>image registration</phrase>.
<phrase>Robust</phrase> Recognition and <phrase>Pose Determination</phrase> of 3-<phrase>D</phrase> Objects Using <phrase>Range</phrase> Images in <phrase>Eigenspace</phrase>.
The <phrase>Planar</phrase>: A <phrase>Mobile</phrase> <phrase>VR</phrase> Tool with <phrase>Pragmatic</phrase> <phrase>Pose Estimation</phrase> for Generation and Manipulation of 3D <phrase>Data</phrase> in <phrase>Industrial</phrase> Environments.
We present the <phrase>prototype</phrase> of the <phrase>Planar</phrase>, a novel <phrase>input/output</phrase> device designed for applications in task areas focusing on the generation and manipulation of 3D <phrase>data</phrase>, e.g. <phrase>CAD</phrase> or styling. <phrase>Technically</phrase>, the <phrase>Planar</phrase> offers a <phrase>spatially aware</phrase> <phrase>pen</phrase>-sensitive display, mounted on an <phrase>adjustable</phrase>, scooter-like <phrase>autonomous</phrase> platform. The <phrase>movable</phrase> screen, with 6 <phrase>degrees of freedom</phrase>, can <phrase>act</phrase> like a window into 3D <phrase>virtual</phrase> environments and allows for <phrase>efficient</phrase> 2D and 3D interaction at the same time. We <phrase>report</phrase> on the <phrase>pose estimation</phrase> system of the Planar's display where we focus on two <phrase>enhanced</phrase> optical <phrase>mice</phrase> combined to <phrase>track</phrase> <phrase>horizontal</phrase> 2D <phrase>position/orientation</phrase>. <phrase>Results</phrase> of this <phrase>pragmatic</phrase> approach are presented and discussed. In <phrase>order</phrase> to demonstrate the potential of the <phrase>Planar</phrase> we show a small review/<phrase>sketching</phrase>/<phrase>annotation</phrase> application. The overall goal of this work is to contribute to the development of real <phrase>VR</phrase> applications.
From <phrase>Range</phrase> <phrase>Data</phrase> to <phrase>Animated</phrase> <phrase>Anatomy</phrase>-Based Faces: A <phrase>Model Adaptation</phrase> Method.
This <phrase>paper</phrase> presents a new method for <phrase>reconstructing</phrase> <phrase>animated</phrase>, <phrase>anatomy</phrase>-based <phrase>facial models</phrase> of individuals from <phrase>range</phrase> <phrase>data</phrase> with <phrase>minimal</phrase> <phrase>manual intervention</phrase>. A <phrase>prototype</phrase> <phrase>model</phrase> with a <phrase>multi-layer</phrase> <phrase>skin</phrase>-<phrase>muscle</phrase>-<phrase>skull</phrase> structure serves as the <phrase>starting point</phrase> for our method. After the <phrase>global</phrase> adaptation, the <phrase>skin</phrase> mesh of the <phrase>prototype</phrase> <phrase>model</phrase> is represented as a <phrase>dynamic</phrase> <phrase>deformable model</phrase> which is deformed to fit <phrase>scanned data</phrase> according to <phrase>internal force</phrase> <phrase>stemming</phrase> from the <phrase>elastic</phrase> properties of the surface and <phrase>external forces</phrase> <phrase>produced</phrase> from the <phrase>scanned data</phrase> points and features. The underlying <phrase>muscle</phrase> layer that consists of three types of <phrase>facial muscles</phrase> is automatically adapted. According to the adapted <phrase>skin</phrase> and <phrase>muscle</phrase> structures, a set of <phrase>automatically generated</phrase> <phrase>skull</phrase> <phrase>feature points</phrase> is transformed to drive a <phrase>volume morphing</phrase> of the template <phrase>skull</phrase> <phrase>model</phrase> for <phrase>skull</phrase> <phrase>fitting</phrase>. The reconstructed <phrase>model</phrase> realistically reproduces the shape and features of a specific person and can be <phrase>animated</phrase> instantly.
<phrase>View Planning</phrase> with a Registration Constraint.
<phrase>Reconstructing</phrase> <phrase>Urban</phrase> 3D <phrase>Model</phrase> Using <phrase>Vehicle</phrase>-Borne <phrase>Laser</phrase> <phrase>Range</phrase> Scanners.
Discrete <phrase>Pose Space</phrase> Estimation to Improve <phrase>ICP</phrase>-Based Tracking.
<phrase>Iterative Closest Point</phrase> (<phrase>ICP</phrase>) -based tracking works well when the <phrase>interframe</phrase> motion is within the <phrase>ICP</phrase> <phrase>minimum</phrase> well space. For large <phrase>interframe</phrase> motions resulting from a limited <phrase>sensor</phrase> acquisition rate relative to the speed of the <phrase>object motion</phrase>, it suffers from <phrase>slow convergence</phrase> and a tendency to be stalled by <phrase>local</phrase> minima. A novel method is proposed to improve the performance of <phrase>ICP</phrase>-based tracking. The method is based upon the <phrase>Bounded</phrase> <phrase>Hough Transform</phrase> (BHT) which estimates the <phrase>object pose</phrase> in a coarse discrete <phrase>pose space</phrase>. Given an initial <phrase>pose estimate</phrase>, and assuming that the <phrase>interframe</phrase> motion is <phrase>bounded</phrase> in all 6 pose dimensions, the BHT estimates the current frameýs pose. On its own, the BHT is able to <phrase>track</phrase> an objectýs pose in <phrase>sparse range data</phrase> both efficiently and reliably, albeit with a <phrase>limited precision</phrase>. Experiments on both simulated and <phrase>real data</phrase> show the BHT to be more <phrase>efficient</phrase> than a number of variants of the <phrase>ICP</phrase> for a similar <phrase>degree</phrase> of reliability. <phrase>A hybrid</phrase> method has also been implemented wherein at each frame the BHT is followed by a few <phrase>ICP</phrase> iterations. This <phrase>hybrid</phrase> method is more <phrase>efficient</phrase> than the <phrase>ICP</phrase>, and is more <phrase>reliable</phrase> than either the BHT or <phrase>ICP</phrase> separately.
3D <phrase>Head Pose Estimation</phrase> with <phrase>Optical Flow</phrase> and Depth Constraints.
<phrase>Efficient</phrase> <phrase>Photometric</phrase> <phrase>Stereo</phrase> Technique for <phrase>Three-Dimensional</phrase> Surfaces with Unknown <phrase>BRDF</phrase>.
The present <phrase>paper</phrase> focuses on <phrase>efficient</phrase> <phrase>inverse</phrase> rendering using a <phrase>Photometric</phrase> <phrase>Stereo</phrase> technique for realistic surfaces. The technique primarily assumes the <phrase>Lambertian</phrase> <phrase>reflection</phrase> <phrase>model</phrase> only. For <phrase>non-Lambertian</phrase> surfaces, application of the technique to real surfaces in <phrase>order</phrase> to estimate 3-<phrase>D</phrase> shape and <phrase>spatially varying reflectance</phrase> from <phrase>sparse</phrase> images <phrase>remains difficult</phrase>. In the present <phrase>paper</phrase>, we propose a new <phrase>Photometric</phrase> <phrase>Stereo</phrase> technique by which to efficiently recover a full <phrase>surface model</phrase>, starting from a small set of photographs. The proposed technique allows diffuse <phrase>albedo</phrase> to <phrase>vary arbitrarily</phrase> over surfaces while non-diffuse characteristics <phrase>remain constant</phrase> for a material. <phrase>Specifically</phrase>, the <phrase>basic</phrase> approach is to first recover the <phrase>specular</phrase> <phrase>reflectance</phrase> parameters of the surfaces by a novel <phrase>optimization procedure</phrase>. These parameters are then used to estimate the <phrase>diffuse reflectance</phrase> and <phrase>surface normal</phrase> for each point. As a result, a lighting-<phrase>independent</phrase> <phrase>model</phrase> of the <phrase>geometry</phrase> and <phrase>reflectance</phrase> properties of the surface is established using the <phrase>proposed method</phrase>, which can be used to <phrase>re</phrase>-render the images under novel lighting via traditional rendering methods.
Extract and Display <phrase>Moving Object</phrase> in All Direction by Using <phrase>Stereo</phrase> <phrase>Omnidirectional</phrase> System(<phrase>SOS</phrase>).
Estimation of 3-<phrase>D</phrase> Pose and Shape from a <phrase>Monocular</phrase> <phrase>Image Sequence</phrase> and <phrase>Realtime</phrase> <phrase>Human</phrase> Tracking.
<phrase>Digital Preservation</phrase> of <phrase>Ancient</phrase> <phrase>Cuneiform</phrase> Tablets Using 3D-Scanning.
<phrase>Program Committee</phrase>.
Optimized Compression of <phrase>Triangle Mesh</phrase> <phrase>Geometry</phrase> Using Prediction <phrase>Trees</phrase>.
<phrase>Efficient</phrase> <phrase>Interactive Rendering</phrase> of Detailed Models with <phrase>Hierarchical</phrase> Levels of Detail.
Recent <phrase>acquisition systems</phrase>, such as the one developed at the <phrase>University</phrase> of <phrase>California</phrase> at <phrase>Berkeley</phrase>, are capable of collecting large, detailed, <phrase>highly textured</phrase> models that standard levels of detail (<phrase>LOD</phrase>) <phrase>rendering techniques</phrase> [<phrase>Adaptive</phrase> display <phrase>algorithm</phrase> for <phrase>interactive frame rates</phrase> during visualization of <phrase>complex virtual environments</phrase>] cannot handle efficiently. We propose an out-of-core <phrase>rendering engine</phrase> which applies the cost and benefit approach of the <phrase>Adaptive</phrase> Display <phrase>algorithm</phrase> by Funkhouser and Séquin [<phrase>Adaptive</phrase> display <phrase>algorithm</phrase> for <phrase>interactive frame rates</phrase> during visualization of <phrase>complex virtual environments</phrase>] to <phrase>Hierarchical</phrase> Levels of Detail (HLODs) [HLODs for faster display of large <phrase>static and dynamic</phrase> environments]. <phrase>Unlike</phrase> the <phrase>Adaptive</phrase> Display <phrase>algorithm</phrase>, we do not <phrase>skip</phrase> objects to maintain <phrase>interactivity</phrase> when many objects are visible. Funkhouser and Séquin apply <phrase>hysteresis</phrase> by adding a penalty in the benefit heuristics to discourage disturbing <phrase>visual effects</phrase> due to <phrase>fast</phrase> switching of detail in the <phrase>model</phrase>. However, this penalty may not be sufficient if the user is moving around rapidly in the scene. <phrase>Instead</phrase>, we have developed a more <phrase>robust</phrase> temporal <phrase>hysteresis</phrase> by retaining how much detail is rendered over a time <phrase>period</phrase>. We have implemented our <phrase>rendering engine</phrase> to run on a common <phrase>personal computer</phrase> with a standard <phrase>graphics card</phrase>. The <phrase>engine</phrase> is capable of <phrase>visualizing</phrase>, in both <phrase>walk</phrase>-through and <phrase>fly</phrase>-through mode, a detailed <phrase>model</phrase> of 25 <phrase>city</phrase> blocks comprised of 7 <phrase>million triangles</phrase> and 720 million <phrase>color</phrase> <phrase>pixels</phrase>. Our <phrase>engine</phrase> maintains a <phrase>constant frame rate</phrase> and limits excessive flickering simultaneously.
<phrase>Network Protocol</phrase> for <phrase>I</phrase> teraction and <phrase>Scalable Distributed</phrase> Visualization.
Disordered Patterns <phrase>Projection</phrase> For 3D Motion <phrase>Recovering</phrase>.
In this <phrase>paper</phrase> we present a new <phrase>color</phrase> <phrase>structured light</phrase> technique based on a disordered codeword strategy. The aim of this method is to recover 3D <phrase>information</phrase> in <phrase>moving scenes</phrase> in such a way that the <phrase>correspondence</phrase> problem is easily and robustly solved. With this goal in <phrase>mind</phrase> a six-connectivity <phrase>topology</phrase> has been introduced in our pattern and <phrase>color</phrase> features have been inserted on it. <phrase>Repetition</phrase> and <phrase>disorder</phrase> are allowed in the codeword which implies that the <phrase>Hamming distance</phrase> between contiguous codewords increases. As a consequence of that, code loss circumstances can be <phrase>efficiently handled</phrase>. Additionally, <phrase>computational cost</phrase> in the code <phrase>recovering</phrase> phase is highly reduced since codewords are defined as sets. A <phrase>structured light</phrase> <phrase>projection</phrase> system has been built in our <phrase>lab</phrase> and a wide <phrase>test</phrase> under real moving conditions has been carried out. This <phrase>experimentation</phrase> has been performed on <phrase>medium resolution</phrase> and for slow movements specifications giving <phrase>promising results</phrase>.
<phrase>Object Classification</phrase> by <phrase>Functional</phrase> Parts.
<phrase>Reconstruction</phrase> of <phrase>Spherical</phrase> Representation Models From Multiple <phrase>Partial</phrase> Models.
<phrase>Automated</phrase> <phrase>Texture Mapping</phrase> of 3D <phrase>City</phrase> Models With <phrase>Oblique</phrase> <phrase>Aerial</phrase> Imagery.
This <phrase>paper</phrase> describes an approach to <phrase>texture mapping</phrase> a 3D <phrase>city</phrase> <phrase>model</phrase> obtained from aerialand <phrase>ground</phrase>-based <phrase>laser</phrase> scans with <phrase>oblique</phrase> <phrase>aerial</phrase> imagery. First, the images are automatically registered by matching 2D image lines with projections of 3D lines from the <phrase>city</phrase> <phrase>model</phrase>. Then, for each <phrase>triangle</phrase> in the <phrase>model</phrase>, the <phrase>optimal</phrase> image is selected by <phrase>taking into account</phrase> occlusion, <phrase>image resolution</phrase>, <phrase>surface normal</phrase> orientation, and <phrase>coherence</phrase> with neighboring <phrase>triangles</phrase>. <phrase>Finally</phrase>, the utilized <phrase>texture patches</phrase> from all images are combined into one <phrase>texture atlas</phrase> for <phrase>compact</phrase> representation and <phrase>efficient</phrase> rendering. We evaluate our approach on a <phrase>data</phrase> set of <phrase>downtown</phrase> <phrase>Berkeley</phrase>.
<phrase>Human</phrase> Motion: Modeling and Recognition of Actions and Interactions.
Processing of <phrase>image sequences</phrase> has progressed from simple <phrase>structure from motion</phrase> <phrase>paradigm</phrase> to the recognition of actions / interactions as events. <phrase>Understanding</phrase> <phrase>human</phrase> activities in <phrase>video</phrase> has many <phrase>potential applications</phrase> including <phrase>automated</phrase> <phrase>surveillance</phrase>, <phrase>video</phrase> <phrase>archival</phrase>/retrieval, <phrase>medical diagnosis</phrase>, <phrase>sports</phrase> analysis, and <phrase>human</phrase>-computer interaction. <phrase>Understanding</phrase> <phrase>human</phrase> activities involves various steps of <phrase>low-level vision</phrase> processing such as segmentation, tracking, <phrase>pose recovery</phrase>, and <phrase>trajectory estimation</phrase> as well as <phrase>high</phrase>-level <phrase>processing tasks</phrase> such as body modeling and representation of <phrase>action</phrase>. While <phrase>low-level</phrase> processing has been <phrase>actively studied</phrase>, <phrase>high</phrase>-level processing is just beginning to receive attention. This is partly because <phrase>high</phrase>-level processing depends on the <phrase>results</phrase> of <phrase>low-level</phrase> processing. However, <phrase>high</phrase>-level processing also requires some <phrase>independent</phrase> and additional approaches and methodologies. In this <phrase>paper</phrase>, we focus on the following aspects of <phrase>high</phrase>-level processing: (1) <phrase>human</phrase> body modeling, (2) <phrase>level of detail</phrase> needed to understand <phrase>human</phrase> actions, (3) approaches to <phrase>human</phrase> <phrase>action</phrase> recognition, and (4) <phrase>high</phrase>-level recognition schemes with <phrase>domain knowledge</phrase>. The review is illustrated by examples of each of the areas discussed, including <phrase>recent developments</phrase> in our work on <phrase>understanding</phrase> <phrase>human</phrase> activities.
<phrase>Data Processing</phrase> <phrase>Algorithms</phrase> for <phrase>Generating</phrase> Textured 3D <phrase>Building</phrase> <phrase>Façade</phrase> Meshes From <phrase>Laser</phrase> Scans and <phrase>Camera</phrase> Images.
<phrase>Linear Shift-Invariant</phrase> Operators for Processing <phrase>Surface Meshes</phrase>.
<phrase>Shift-invariant</phrase> operators for <phrase>surface meshes</phrase> are defined using <phrase>geometric</phrase> realizations of the mesh. Then, <phrase>shift-invariance</phrase> essentially means <phrase>isotropy</phrase> w.r.t. a <phrase>distance metric</phrase>. The particular case of the so-defined <phrase>LSI</phrase> operators with small support is analyzed in detail, showing a connection to <phrase>mean value coordinates</phrase>. The <phrase>topological</phrase> <phrase>Laplacian</phrase> operator turns out to be the <phrase>LSI</phrase> operator of the <phrase>topological</phrase> realization of the mesh. More generally, assuming different <phrase>geometric</phrase> realizations or metrics allows <phrase>interpreting</phrase> various <phrase>mesh processing</phrase> techniques as <phrase>LSI</phrase> operators.
<phrase>Combining</phrase> <phrase>fringe projection</phrase> method of 3D object monitoring with <phrase>virtual reality</phrase> environment: concept and <phrase>initial results</phrase>.
<phrase>Seeing</phrase> into the Past: <phrase>Creating</phrase> a 3D Modeling Pipeline for <phrase>Archaeological</phrase> Visualization.
<phrase>Archaeology</phrase> is a destructive process in which accurate and detailed <phrase>recording</phrase> of a site is imperative. As a site is exposed, documentation is required in <phrase>order</phrase> to recreate and understand the site in context. We have developed a 3D modeling pipeline that can assist <phrase>archaeologists</phrase> in the documentation effort by <phrase>building</phrase> rich, geometrically and photometrically accurate 3D models of the site. The <phrase>modeling effort</phrase> begins with <phrase>data</phrase> acquisition (images, <phrase>range</phrase> scans, <phrase>GIS</phrase> <phrase>data</phrase>, and <phrase>video</phrase>) and ends with the use of a sophisticated <phrase>visualization tool</phrase> that can be used by researchers to explore and understand the site. The pipeline includes new methods for <phrase>shadow</phrase>-<phrase>based registration</phrase> of 2D images and temporal <phrase>change detection</phrase>. Our <phrase>multimodal</phrase> <phrase>augmented reality</phrase> system allows users wearing <phrase>head</phrase>-tracked, see-through, <phrase>head</phrase>-worn displays to visualize the site <phrase>model</phrase> and associated <phrase>archaeological</phrase> artifacts, and to interact with them using <phrase>speech and gesture</phrase>.
<phrase>Real Time</phrase> Visualization of 3D <phrase>variable</phrase> in time <phrase>Object based</phrase> on <phrase>Cloud</phrase> of Points <phrase>Data</phrase> Gathered by <phrase>Coloured</phrase> Structure <phrase>Light</phrase> <phrase>Projection</phrase> System.
The problem of <phrase>virtual view</phrase> creation has <phrase>received increasing attention</phrase> in <phrase>recent years</phrase>. <phrase>Major</phrase> <phrase>current approaches</phrase> are based on <phrase>modified</phrase> <phrase>stereo vision</phrase> systems. <phrase>Recently</phrase> the structure <phrase>light</phrase> measurement system based on <phrase>digital</phrase> <phrase>light</phrase> <phrase>projection</phrase> supported by special <phrase>data</phrase> coding and processing allow to <phrase>rapid</phrase> 3D <phrase>shape acquisition</phrase>. Application of this <phrase>technology</phrase> to record 3D <phrase>data</phrase> has <phrase>increased significantly</phrase> the accuracy of reconstructed shape and <phrase>simplified</phrase> <phrase>data</phrase> manipulation process. In the <phrase>paper</phrase> the <phrase>general</phrase> concept of <phrase>virtual reality</phrase> system supported by <phrase>data</phrase> gathered by means of structure <phrase>light</phrase> <phrase>projection</phrase> is presented. The methodology of conversion of <phrase>cloud</phrase> of <phrase>measurement points</phrase> (<phrase>x</phrase>,<phrase>y</phrase>,<phrase>z</phrase>,<phrase>R</phrase>,<phrase>G</phrase>,<phrase>B</phrase>) into <phrase>virtual reality</phrase> environment is described. It is supported by implementation of a <phrase>virtual</phrase> <phrase>camera</phrase> concept, as the mean for <phrase>interactive object</phrase> visualization. The methodology of <phrase>real time</phrase> 3D object visualization based on its coding by means of specially formed contours and their <phrase>B-spline</phrase> approximation is presented. The applicability of the methodology has been shown on numerically generated <phrase>data</phrase> which simulate performance of the measurement system. The total processing path was <phrase>successfully tested</phrase>.
<phrase>Frequency Domain</phrase> Registration of <phrase>Computer Tomography</phrase> <phrase>Data</phrase>.
This <phrase>paper</phrase> presents a new method for registering <phrase>computer tomography</phrase> (<phrase>CT</phrase>) <phrase>volumetric data</phrase> of <phrase>human</phrase> <phrase>bone</phrase> structures relative to observations made at different times. The system we advance was tested with different kinds of <phrase>CT data</phrase> sets. In this <phrase>paper</phrase> we <phrase>report</phrase> on some representative <phrase>experimental</phrase> <phrase>results</phrase> obtained with the <phrase>CT data</phrase> of the <phrase>hip</phrase> <phrase>bones</phrase> of a patient prior to and after prosthetic <phrase>surgery</phrase> aimed at the <phrase>reconstruction</phrase> of the <phrase>hip</phrase> articulation. The <phrase>method works</phrase> with rigid <phrase>data</phrase> having arbitrary <phrase>relative position</phrase> and orientation and proves to be <phrase>robust</phrase> with respect to <phrase>CT</phrase> acquisition noise and with respect to the <phrase>segmentation technique</phrase> adopted to select the <phrase>region</phrase> of interest for registration. The method is capable of registering correctly <phrase>data</phrase> sets taken from the same articulation and whose components have undergone small relative displacements. The method is also amenable to registration of heteregeneous kinds of <phrase>volumetric data</phrase>, e.g., <phrase>CT scans</phrase> and <phrase>Magnetic Resonance</phrase> Imagery (<phrase>MRI</phrase>) scans, which show different characteristics in <phrase>correspondence</phrase> to the same <phrase>organic</phrase> structure.
Recognition of <phrase>Object Contours</phrase> from <phrase>Stereo</phrase> Images: An Edge Combination Approach.
In this <phrase>paper</phrase>, we present an <phrase>algorithm</phrase> to combine <phrase>edge information</phrase> from <phrase>stereo</phrase>-derived <phrase>depth maps</phrase> with edges from the original intensity/<phrase>color</phrase> image to improve the <phrase>contour</phrase> detection in <phrase>images of natural scenes</phrase>. After <phrase>computing</phrase> the <phrase>disparity map</phrase>, we generate a so-called "edge combination image", which relies on those edges of the <phrase>original image</phrase> that are also present in the <phrase>stereo</phrase> <phrase>map</phrase>. We describe an <phrase>algorithm</phrase> to identify corresponding intensity and <phrase>depth edges</phrase>, which are usually slightly displaced due to non-<phrase>perfect</phrase> <phrase>stereo</phrase> <phrase>reconstruction</phrase>. Our <phrase>experiments demonstrate</phrase> how the proposed edge combination approach can be used in conjunction with an <phrase>active</phrase> contours <phrase>algorithm</phrase> to achieve better <phrase>segmentation results</phrase>.
<phrase>Enhanced</phrase> <phrase>Real-time</phrase> <phrase>Stereo</phrase> Using <phrase>Bilateral</phrase> Filtering.
In <phrase>recent years</phrase>, there have been significant strides in increasing quality of <phrase>range</phrase> from <phrase>stereo</phrase> using <phrase>global</phrase> techniques such as <phrase>energy</phrase> minimization. These methods cannot yet achieve <phrase>real-time</phrase> performance. However, the need to improve <phrase>range</phrase> quality for <phrase>real-time</phrase> applications persists. All <phrase>real-time</phrase> <phrase>stereo</phrase> implementations rely on a simple correlation step which employs some <phrase>local similarity</phrase> metric between the left and right image. Typically, the correlation <phrase>takes place</phrase> on an <phrase>image pair</phrase> <phrase>modified</phrase> in some way to compensate for <phrase>photometric</phrase> variations between the left and right cameras. Improvements and modifications to such <phrase>algorithms</phrase> tend to fall into one of two <phrase>broad categories</phrase>: those which address the correlation step itself (e.g., shiftable <phrase>windows</phrase>, <phrase>adaptive</phrase> <phrase>windows</phrase>) and those which address the <phrase>pre-processing</phrase> of input imagery (e.g. <phrase>band</phrase>-<phrase>pass</phrase> filtering, <phrase>Rank</phrase>, <phrase>Census</phrase>). Our efforts <phrase>lie</phrase> in the latter <phrase>area</phrase>. We present in this <phrase>paper</phrase> a modification of the standard <phrase>band-pass filtering</phrase> technique used by many <phrase>SSD</phrase>- and <phrase>SAD</phrase>-based correlation <phrase>algorithms</phrase>. By using the <phrase>bilateral</phrase> filter of <phrase>Tomasi</phrase> and Manduchi [<phrase>Bilateral</phrase> filtering for <phrase>gray</phrase> and <phrase>color images</phrase>], we minimize blurring at the filtering stage. We show that in conjunction with <phrase>SAD</phrase> correlation, our new method improves <phrase>stereo</phrase> quality at <phrase>range</phrase> discontinuities while maintaining <phrase>real-time</phrase> performance.
<phrase>Fast</phrase> Interpolated Cameras by <phrase>Combining</phrase> a <phrase>GPU</phrase> based <phrase>Plane Sweep</phrase> with a <phrase>Max</phrase>-Flow <phrase>Regularisation</phrase> <phrase>Algorithm</phrase>.
The <phrase>paper</phrase> presents a method for the <phrase>high</phrase> speed calculation of crude <phrase>depth maps</phrase>. Performance and applicability are illustrated for <phrase>view interpolation</phrase> based on two input <phrase>video</phrase> streams, but the <phrase>algorithm</phrase> is perfectly amenable to <phrase>multi-camera</phrase> environments. First <phrase>a fast</phrase> <phrase>plane sweep algorithm</phrase> generates the crude <phrase>depth map</phrase>. Speed <phrase>results</phrase> from <phrase>hardware accelerated</phrase> transformations and <phrase>parallel processing</phrase> available on the <phrase>GPU</phrase>. All computations on the <phrase>graphical</phrase> board are performed <phrase>pixel-wise</phrase> and a <phrase>single</phrase> <phrase>pass</phrase> of the <phrase>sweep</phrase> only processes one input resolution. A second step uses a <phrase>min-cut/max-flow</phrase> <phrase>algorithm</phrase> to ameliorate the previous result. The <phrase>depth map</phrase>, a noisy <phrase>interpolated image</phrase> and <phrase>correlation measures</phrase> are available on the <phrase>GPU</phrase>. They are reused and combined with <phrase>spatial</phrase> <phrase>connectivity information</phrase> and <phrase>temporal continuity</phrase> considerations in a <phrase>graph</phrase> formulation. <phrase>Position dependent</phrase> <phrase>sampling</phrase> densities allow the system to use <phrase>multiple image</phrase> resolutions. The <phrase>min-cut</phrase> <phrase>separation</phrase> of this <phrase>graph</phrase> yields the <phrase>global minimum</phrase> of the associated <phrase>energy</phrase> <phrase>function</phrase>. Limiting the <phrase>search range</phrase> according to the initialisation provided by the <phrase>plane sweep</phrase> further <phrase>speeds up</phrase> the process. The required hardware are only two cameras and a regular <phrase>PC</phrase>.
A <phrase>Bayesian</phrase> Framework for 3D Models Retrieval Based on <phrase>Characteristic Views</phrase>.
The <phrase>management</phrase> of <phrase>big</phrase> <phrase>databases</phrase> of <phrase>three-dimensional</phrase> models (used in <phrase>CAD</phrase> applications, visualization, <phrase>games</phrase>, etc.) is a very important domain. The ability to characterize and <phrase>easily retrieve</phrase> models is a <phrase>key issue</phrase> for the designers and the final users. In this frame, two main approaches exist: search by example of a <phrase>three-dimensional</phrase> <phrase>model</phrase>, and search by a 2D view. In this <phrase>paper</phrase>, we present a novel framework for the characterization of a 3D <phrase>model</phrase> by a set of views (called <phrase>characteristic views</phrase>), and an <phrase>indexing</phrase> process of these models with a <phrase>Bayesian</phrase> <phrase>probabilistic</phrase> approach using the <phrase>characteristic views</phrase>. The framework is <phrase>independent</phrase> from the descriptor used for the <phrase>indexing</phrase>. We illustrate our <phrase>results</phrase> using different descriptors on a collection of threedimensional models supplied by <phrase>Renault</phrase> <phrase>Group</phrase>.
3D <phrase>Model</phrase> <phrase>Watermarking</phrase> for <phrase>Indexing</phrase> using the <phrase>Generalized</phrase> <phrase>Radon Transform</phrase>.
The present <phrase>paper</phrase> proposes a novel method for 3D-<phrase>model</phrase> <phrase>watermarking</phrase> for <phrase>indexing</phrase>. The proposed approach is based on the use of a <phrase>Generalized</phrase> <phrase>Radon</phrase> Transformation. More <phrase>specifically</phrase>, the <phrase>Cylindrical</phrase> <phrase>Integration</phrase> Transform (CIT) is initially applied to the 3D models in <phrase>order</phrase> to produce <phrase>descriptor vectors</phrase>. At the same time a <phrase>watermarking</phrase> technique, based on CIT is used in <phrase>order</phrase> to embed a specific <phrase>model</phrase> <phrase>identifier</phrase> in the nodes of the 3D <phrase>model</phrase>. This <phrase>identifier</phrase> links the <phrase>model</phrase> to its descriptor <phrase>vector</phrase>, which is extracted only once and stored in a <phrase>database</phrase>. Every time this <phrase>model</phrase> is employed as a <phrase>query model</phrase>, <phrase>watermark</phrase> detection is used so as to retrieve the corresponding <phrase>identifier</phrase> and further the descriptor <phrase>vector</phrase>, which can be further used in a <phrase>matching algorithm</phrase>. The proposed techniques are <phrase>evaluated experimentally</phrase> in terms of both <phrase>watermarking</phrase> efficiency and <phrase>content-based retrieval</phrase> performance.
A <phrase>Structure-from-Motion</phrase> Method: Use of Motion in <phrase>Three-Dimensional</phrase> <phrase>Reconstruction</phrase> of <phrase>Moving Objects</phrase> from <phrase>Multiple-View</phrase> <phrase>Image Sequences</phrase>.
Solving the <phrase>correspondence</phrase> problem is the most essential task for <phrase>multiview reconstruction</phrase> techniques, yet <phrase>finding</phrase> unique correspondences between <phrase>multiple views</phrase> is impossible at some points, due to such problems as occlusions and ambiguities. We have developed a <phrase>closed-form</phrase> <phrase>solution</phrase> through <phrase>constructive</phrase> <phrase>geometry</phrase> for a <phrase>special case</phrase> of the <phrase>structure-from-motion</phrase> (<phrase>SfM</phrase>) problem with four <phrase>rigidly moving</phrase> points. This <phrase>solution</phrase> allows the 3-<phrase>D</phrase> position of a point on a <phrase>moving object</phrase> to be computed without having to find the <phrase>correspondence</phrase> between its projections on the <phrase>image planes</phrase> of <phrase>multiple views</phrase>, given its projected 2-<phrase>D</phrase> <phrase>motion vector</phrase> on an <phrase>image plane</phrase> and 3-<phrase>D</phrase> <phrase>information</phrase> of three other points. With this method we do not have to depend entirely on <phrase>stereo</phrase>/<phrase>multiview</phrase> <phrase>feature correspondences</phrase> in <phrase>reconstructing</phrase> 3-<phrase>D</phrase> objects, <phrase>hence</phrase> <phrase>easing</phrase> those problems caused by occlusions and ambiguities.
3D <phrase>Data Acquisition</phrase> and <phrase>Elaboration</phrase> for Classification and Recognition of Objects and People.
Distributed <phrase>quantitative</phrase> evaluation of 3D <phrase>patient specific</phrase> <phrase>arterial</phrase> models.
New <phrase>Imaging</phrase> <phrase>Frontiers</phrase>: 3D and <phrase>Mixed Reality</phrase>.
<phrase>Projection</phrase> <phrase>Model</phrase>, 3D <phrase>Reconstruction</phrase> and <phrase>Rigid Motion</phrase> Estimation from Non-<phrase>Central Catadioptric</phrase> Images.
This <phrase>paper</phrase> addresses the problem of <phrase>rigid motion</phrase> estimation and 3D <phrase>reconstruction</phrase> in <phrase>vision systems</phrase> where it is possible to recover the <phrase>incident light</phrase> ray direction from the <phrase>image points</phrase>. Such systems include <phrase>pinhole</phrase> cameras and <phrase>catadioptric cameras</phrase>. Given two images of the same scene acquired from two different positions, the transformation is estimated by means of an <phrase>iterative</phrase> process. The <phrase>estimation process</phrase> aims at having corresponding incident <phrase>rays</phrase> intersecting at the same 3D point. <phrase>Geometrical</phrase> relationships are derived to support the <phrase>estimation method</phrase>. Furthermore, this <phrase>paper</phrase> also addresses the problem of the mapping from 3D points to <phrase>image points</phrase>, for non-<phrase>central catadioptric cameras</phrase> with <phrase>mirror</phrase> surfaces given by <phrase>quadrics</phrase>. The <phrase>projection</phrase> <phrase>model</phrase> presented can be expressed in a <phrase>non-linear</phrase> equation of only one <phrase>variable</phrase>, being more <phrase>stable</phrase> and easier to solve than the <phrase>classical</phrase> <phrase>Snell's law</phrase>. Experiments with <phrase>real images</phrase> are presented, by using <phrase>simulated annealing</phrase> as <phrase>estimation method</phrase>.
Scalable and <phrase>Efficient</phrase> Coding of 3D <phrase>Model</phrase> Extracted from a <phrase>Video</phrase>.
This <phrase>paper</phrase> presents <phrase>an efficient</phrase> and <phrase>scalable coding</phrase> scheme for transmitting a <phrase>stream</phrase> of 3D models extracted from a video.As in <phrase>classical</phrase> <phrase>model-based</phrase> <phrase>video</phrase> coding, the <phrase>geometry</phrase>, connectivity, and texture of the 3D models have to be transmitted, as well as the <phrase>camera</phrase> position for each frame in the original <phrase>video</phrase>. The <phrase>proposed method</phrase> is based on <phrase>exploiting</phrase> the interrelations existing between each type of <phrase>information</phrase>, <phrase>instead</phrase> of coding them independently, allowing a better prediction of the <phrase>next</phrase> 3D <phrase>model</phrase> in the <phrase>stream</phrase>. <phrase>Scalability</phrase> is achieved through the use of <phrase>wavelet</phrase>-based representations for both texture and <phrase>geometry</phrase> of the models. A consistent connectivity is built for all 3D models extracted from the <phrase>video</phrase> <phrase>sequence</phrase>, which allows a more <phrase>compact</phrase> representation and straightforward <phrase>geometric</phrase> <phrase>morphing</phrase> between successive models. Furthermore this leads to a consistent <phrase>wavelet</phrase> decomposition for 3D models in the <phrase>stream</phrase>. <phrase>Quantitative and qualitative</phrase> <phrase>results</phrase> for the <phrase>proposed scheme</phrase> are compared with the <phrase>state</phrase> of the <phrase>art</phrase> <phrase>video</phrase> coder H264, 3D <phrase>model</phrase>-based Galpin coder and <phrase>independent</phrase> <phrase>MPEG4</phrase>-based coding of the <phrase>information</phrase>. Targeted applications include distant visualization of the original <phrase>video</phrase> at <phrase>very low bitrate</phrase> and <phrase>interactive navigation</phrase> in the extracted 3D scene on heterogeneous terminals.
Modeling shapes and textures from images: <phrase>new frontiers</phrase>.
<phrase>Fusing</phrase> Multiple <phrase>Color Images</phrase> for <phrase>Texturing</phrase> Models.
A <phrase>commonly encountered</phrase> problem when <phrase>creating</phrase> 3D models of large <phrase>real scenes</phrase> is unnatural <phrase>color</phrase> texture <phrase>fusion</phrase>. Due to variations in lighting and <phrase>camera</phrase> settings (both manual and <phrase>automatic</phrase>), captured <phrase>color texture</phrase> <phrase>maps</phrase> of the same structure can have very different colors. When <phrase>fusing multiple</phrase> views to create larger models, this <phrase>color</phrase> variation leads to a poor appearance with odd <phrase>color</phrase> <phrase>tilings</phrase> on homogeneous surfaces. This <phrase>paper</phrase> <phrase>extends previous</phrase> <phrase>research</phrase> on pairwise <phrase>global</phrase> <phrase>color correction</phrase> to <phrase>multiple overlapping</phrase> images. The <phrase>central idea</phrase> is to estimate a set of <phrase>blending</phrase> transformations that minimize the overall <phrase>color</phrase> discrepancy in the <phrase>overlapping regions</phrase>, thus spreading <phrase>residual</phrase> <phrase>color</phrase> errors, rather than letting them accumulate.
<phrase>Half-Edge</phrase> Multi-<phrase>Tessellation</phrase>: A <phrase>Compact</phrase> Representation for <phrase>Multi-Resolution</phrase> <phrase>Tetrahedral</phrase> Meshes.
A <phrase>Prototype</phrase> of <phrase>Video</phrase> See-through <phrase>Mixed Reality</phrase> Interactive System.
<phrase>Mixed reality</phrase> (<phrase>MR</phrase>), sometimes called <phrase>enhanced</phrase> <phrase>reality</phrase>, is a <phrase>variety</phrase> of <phrase>virtual environment</phrase> (<phrase>VE</phrase>) which explores various approaches to combine <phrase>natural environment</phrase> with <phrase>immersive display</phrase> <phrase>technology</phrase>. <phrase>VE</phrase> technologies completely immerse a user inside a <phrase>synthetic environment</phrase>. In contrast, <phrase>MR</phrase> system adds <phrase>electronic</phrase> <phrase>data</phrase> from a <phrase>cyberspace</phrase> on the <phrase>physical space</phrase> as a base, allows the users to see the <phrase>real world</phrase> with <phrase>virtual</phrase> objects superimposed upon. Moreover, <phrase>MR</phrase> can assist the <phrase>users interact</phrase> with the <phrase>virtual</phrase> object in the more realistic environment. The objective of our <phrase>research</phrase> is to investigate the potential of <phrase>MR</phrase> technique on <phrase>improving</phrase> interaction between <phrase>human</phrase> and computer through <phrase>developing</phrase> a <phrase>video</phrase>-see through <phrase>mixed reality</phrase> system. Further applications will be built upon this <phrase>generic</phrase> platform.
Novel Diffractive <phrase>Optical Elements</phrase> and <phrase>Algorithms</phrase> for <phrase>Real-Time</phrase> 3D and <phrase>Hyperspectral Imaging</phrase>.
<phrase>Geometry</phrase> Processing - <phrase>A Personal Perspective</phrase>.
Optimized <phrase>Spectral Estimation</phrase> Methods for Improved <phrase>Co</phrase> orimetry with <phrase>Laser</phrase> Scanning Systems.
Using the <phrase>Expectation-Maximization Algorithm</phrase> for <phrase>Depth Estimation</phrase> and Segmentation of <phrase>Multi-view</phrase> Images.
3D <phrase>Stereoscopic Image</phrase> Pairs by <phrase>Depth-Map</phrase> Generation.
This <phrase>paper</phrase> presents a new <phrase>unsupervised</phrase> technique aimed to generate <phrase>stereoscopic</phrase> views <phrase>estimating</phrase> <phrase>depth information</phrase> from a <phrase>single</phrase> input image.Using a <phrase>single input</phrase> image, <phrase>vanishing lines</phrase>/points are extracted using a few heuristics to generate an approximated depth map.The <phrase>depth map</phrase> is then used to generate <phrase>stereo</phrase> pairs.The overall method is <phrase>well suited</phrase> for <phrase>real time</phrase> application and works also on <phrase>CFA</phrase> (<phrase>Colour</phrase> Filtering Array) <phrase>data</phrase> acquired by <phrase>consumer</phrase> <phrase>imaging</phrase> devices. <phrase>Experimental</phrase> <phrase>results</phrase> on a <phrase>large dataset</phrase> are reported.
<phrase>Visualizing</phrase> <phrase>Legacy</phrase> Stratigraphic <phrase>Data</phrase> From <phrase>Archaeological</phrase> Handbooks.
<phrase>Architecture</phrase> of a 3D - <phrase>Simulation</phrase> Environment for <phrase>Active Vision Systems</phrase> and <phrase>Mobile</phrase> <phrase>Robots</phrase>.
Multi-<phrase>Stereo</phrase> 3D <phrase>Object Reconstruction</phrase>.
The <phrase>ORIGAMI</phrase> <phrase>Project</phrase>: <phrase>advanced</phrase> tools and techniques for <phrase>high</phrase>-end <phrase>mixing</phrase> and interaction between real and <phrase>virtual</phrase> content.
<phrase>Stereo Image</phrase> Coder Based on <phrase>MRF</phrase> Analysis for <phrase>Disparity Estimation</phrase> and <phrase>Morphological</phrase> Encoding.
This <phrase>paper</phrase> presents a <phrase>stereoscopic image</phrase> coder based on the <phrase>MRF model</phrase> and <phrase>MAP</phrase> estimation of the <phrase>disparity field</phrase>. The <phrase>MRF model</phrase> minimizes the noise of the <phrase>disparity compensation</phrase> because it <phrase>takes into account</phrase> the <phrase>residual energy</phrase>, <phrase>smoothness</phrase> constraints and the occlusion field. The <phrase>disparity compensation</phrase> is formulated as a <phrase>MAP-MRF</phrase> problem in the <phrase>spatial</phrase> domain and the <phrase>MRF</phrase> field consists of the <phrase>disparity vector</phrase> and occlusion field, which is <phrase>partitioned</phrase> into three regions by an initial <phrase>double-threshold</phrase> setting. The <phrase>MAP</phrase> search is conducted in a <phrase>block-based</phrase> sense on one or two of the three regions, providing <phrase>faster execution</phrase>. The reference and the <phrase>residual</phrase> images are decomposed by a <phrase>discrete wavelet transform</phrase> and the <phrase>transform coefficients</phrase> are encoded by employing the <phrase>morphological</phrase> representation of <phrase>wavelet</phrase> coefficients <phrase>algorithm</phrase>. As a result of the <phrase>morphological</phrase> encoding, the reference and <phrase>residual</phrase> images together with the <phrase>disparity vector</phrase> field are transmitted in <phrase>partitions</phrase> <phrase>lowering</phrase> the total <phrase>entropy</phrase>. The <phrase>experimental</phrase> evaluation on <phrase>synthetic and real images</phrase> shows beneficial performance of the proposed <phrase>algorithm</phrase>.
<phrase>Remote</phrase> Machinery Maintenance System with the use of <phrase>Virtual Reality</phrase>.
<phrase>Point Samples</phrase> for <phrase>Efficient</phrase> 3D Processing and <phrase>Content Creation</phrase>.
Improvement of Metric Accuracy of <phrase>Digital</phrase> 3D Models through <phrase>Digital</phrase> <phrase>Photogrammetry</phrase>. <phrase>A Case Study</phrase>: Donatello's Maddalena.
How can we exploit typical <phrase>architectural</phrase> structures to improve <phrase>model</phrase> recovery?
An Analysis of Errors in <phrase>Feature-Preserving</phrase> <phrase>Mesh Simplification</phrase> Based on <phrase>Edge Contraction</phrase>.
The <phrase>Quadric Error Metric</phrase> (QEM) [1] criterion has been <phrase>widely applied</phrase> in <phrase>mesh simplification</phrase> procedures. Related criteria--such as the <phrase>Quasi</phrase>-<phrase>Covariance</phrase> <phrase>Error Metric</phrase> (QCEM) [2], which may produce <phrase>superior</phrase> <phrase>results</phrase> to the QEM--have also been reported in <phrase>recent years</phrase>. In this <phrase>paper</phrase>, the underlying reasons that criteria such as QEM and QCEM are so successful in <phrase>mesh simplification</phrase> processes are considered through analysis of error in the <phrase>simplification</phrase> process. Focus is on the use of the QEM and QCEM criteria in <phrase>edge contraction</phrase>-based <phrase>mesh simplification</phrase>.
<phrase>IBR</phrase>-<phrase>based compression</phrase> for <phrase>remote</phrase> visualization.
Analysis of <phrase>Secondary</phrase> Structure Elements of <phrase>Proteins</phrase> Using <phrase>Indexing</phrase> Techniques.
<phrase>Real-Time</phrase>, Accurate Depth of Field using <phrase>Anisotropic</phrase> <phrase>Diffusion</phrase> and <phrase>Programmable</phrase> <phrase>Graphics Cards</phrase>.
<phrase>Computer graphics</phrase> cameras lack the <phrase>finite Depth</phrase> of Field (<phrase>DOF</phrase>) present in <phrase>real world</phrase> ones. This <phrase>results</phrase> in all objects being rendered <phrase>sharp</phrase> regardless of their depth, <phrase>reducing</phrase> the realism of the scene. On <phrase>top</phrase> of that, <phrase>real-world</phrase> <phrase>DOF</phrase> provides a <phrase>depth cue</phrase>, that helps the <phrase>human</phrase> <phrase>visual</phrase> system decode the elements of a scene. Several methods have been proposed to render images with finite <phrase>DOF</phrase>, but these have always implied an important <phrase>trade</phrase>-off between speed and accuracy. In this <phrase>paper</phrase>, we introduce a novel <phrase>anisotropic</phrase> <phrase>diffusion</phrase> <phrase>Partial Differential Equation</phrase> (<phrase>PDE</phrase>) that is applied to the 2D image of the scene rendered with a <phrase>pin-hole</phrase> <phrase>camera</phrase>. In this <phrase>PDE</phrase>, the amount of blurring on the 2D image depends on the <phrase>depth information</phrase> of the 3D scene, present in the <phrase>Z</phrase>-buffer. This equation is <phrase>well posed</phrase>, has <phrase>existence and uniqueness</phrase> <phrase>results</phrase>, and it is a good approximation of the optical phenomenon, without the <phrase>visual</phrase> artifacts and depth inconsistencies present in other approaches. Because both inputs to our <phrase>algorithm</phrase> are present at the <phrase>graphics card</phrase> at every <phrase>moment</phrase>, we can run the processing entirely in the <phrase>GPU</phrase>. This fact, <phrase>coupled</phrase> with the particular <phrase>numerical scheme</phrase> chosen for our <phrase>PDE</phrase>, allows for <phrase>real-time rendering</phrase> using a <phrase>programmable</phrase> <phrase>graphics card</phrase>.
Dynamically <phrase>Optimised</phrase> 3D (<phrase>Virtual Reality</phrase>) <phrase>Data Transmission</phrase> for <phrase>Mobile</phrase> Devices.
<phrase>Nowadays</phrase> the <phrase>processing power</phrase> of <phrase>mobile phones</phrase>, <phrase>Smartphones</phrase> and <phrase>PDA's</phrase> is increasing as well as the transmission bandwidth.Nevertheless there is still the need to reduce the content and the need of processing the data.Discussed will be proposals and solutions for <phrase>dynamic</phrase> reduction of the transmitted content.For that, <phrase>device specific</phrase> properties will be taken into account, as much as for the aim to reduce the need of <phrase>processing power</phrase> at the <phrase>client side</phrase> to be able to display the 3D (<phrase>Virtual Reality</phrase>) data.Therefore, well known technologies e.g. <phrase>data</phrase> compression are combined with new developed ideas to reach the goal of <phrase>adaptive</phrase> content transmission.To achieve a <phrase>device dependent</phrase> reduction of <phrase>processing power</phrase> the <phrase>data</phrase> have to be <phrase>pre processed</phrase> at the <phrase>server side</phrase> or the server even has to take over functionality of <phrase>weak</phrase> <phrase>mobile</phrase> devices.
<phrase>Learning</phrase> Illumination Models While Tracking.
In this <phrase>paper</phrase> we present a method for estimation of 3D motion of a <phrase>rigid object</phrase> from a <phrase>video</phrase> <phrase>sequence</phrase>, while simultaneously <phrase>learning</phrase> the parameters of an <phrase>illumination model</phrase> that describe the <phrase>lighting conditions</phrase> under which the <phrase>video</phrase> was captured. This is achieved by alternately <phrase>estimating</phrase> motion and illumination parameters in a <phrase>recently</phrase> proposed <phrase>mathematical</phrase> framework for <phrase>integrating</phrase> the effects of motion, illumination and structure. The motion is represented in terms of <phrase>translation</phrase> and rotation of the object <phrase>centroid</phrase>, and the illumination is represented using a <phrase>spherical harmonics</phrase> linear basis. The method does not assume any <phrase>model</phrase> for the variation of the <phrase>illumination conditions</phrase>-lighting can <phrase>change slowly</phrase> or drastically, <phrase>locally or globally</phrase>. Also, it can be composed of combinations of point and extended sources. For <phrase>multiple cameras</phrase> viewing an object, we derive a new <phrase>photometric</phrase> constraint that relates the illumination parameters in two or more <phrase>independent</phrase> <phrase>video</phrase> sequences. This constraint allows verification of the illumination parameters obtained from <phrase>multiple views</phrase> and <phrase>synthesis</phrase> of new views under the same <phrase>lighting conditions</phrase>. We demonstrate the effectiveness of our <phrase>algorithm</phrase> in tracking under severe changes of <phrase>lighting conditions</phrase>.
<phrase>VENUS</phrase> <phrase>Subsurface</phrase> <phrase>Ionosphere</phrase> <phrase>Radar</phrase> <phrase>Sounder</phrase>: VENSIS.
Due to <phrase>optically</phrase> opaque <phrase>atmosphere</phrase>, <phrase>radar</phrase> is the best way to observe the surface of <phrase>Venus</phrase> from <phrase>orbit</phrase>. <phrase>Magellan</phrase> has obtained <phrase>global</phrase> <phrase>SAR imaging</phrase>, as well as <phrase>altimetry</phrase> and <phrase>emissivity</phrase>. As a <phrase>subsurface</phrase> <phrase>sounder</phrase>, VENSIS would obtain fundamentally different kinds of <phrase>geologic</phrase> <phrase>information</phrase> than <phrase>Magellan</phrase>. Mapping of interfaces of <phrase>geologic</phrase> units (e.g. <phrase>tessera</phrase>, plains, <phrase>lava flows</phrase>, impact <phrase>debris</phrase>) could be extended into the third <phrase>dimension</phrase>. <phrase>Reflectivity</phrase> variations recorded at the surface by <phrase>Magellan</phrase> are likely to extend into <phrase>subsurface</phrase>, providing <phrase>dielectric</phrase> contrast at interfaces.
<phrase>Human</phrase> <phrase>Action</phrase> Recognition By <phrase>Sequence</phrase> of Movelet Codewords.
<phrase>Fast</phrase> and <phrase>Robust</phrase> Bore Detection in <phrase>Range</phrase> <phrase>Image Data</phrase> for <phrase>Industrial Automation</phrase>.
This <phrase>paper</phrase> presents <phrase>a fast</phrase> and <phrase>robust</phrase> method to precisely segment and locate bore holes of 4 to 50mm <phrase>diameter</phrase>. The task is solved by a <phrase>robot</phrase> moving a <phrase>compact</phrase> <phrase>triangulation</phrase> scanning <phrase>sensor</phrase> to all sides of the object and scanning the bore holes. <phrase>Exploiting</phrase> the <phrase>knowledge</phrase> about the expected bore <phrase>diameter</phrase> and bore pose makes it possible to develop <phrase>highly robust</phrase> <phrase>algorithms</phrase> for an <phrase>industrial</phrase> application. <phrase>Sparse data</phrase> of the bore <phrase>hole</phrase> is sufficient to segment the bore <phrase>independent</phrase> of bore <phrase>hole</phrase> <phrase>chamfer</phrase> type using a <phrase>robust</phrase> <phrase>normal vector</phrase> fit and a <phrase>classification based</phrase> on the <phrase>Gaussian</phrase> image. A <phrase>sequential</phrase> <phrase>algorithm</phrase> to fit the bore <phrase>cylinder</phrase> makes it possible to calculate the bore pose in less than 1 second. <phrase>Experiments demonstrate</phrase> that 120 degrees of the bore <phrase>hole</phrase> surface are sufficient for <phrase>robust</phrase> localization within 0.3mm and 0.5 degrees even in the presence of <phrase>ghost</phrase> points and notches in the bore holes.
<phrase>Helmholtz</phrase> <phrase>Stereopsis</phrase> on <phrase>Rough</phrase> and Strongly <phrase>Textured Surfaces</phrase>.
<phrase>Helmholtz</phrase> <phrase>Stereopsis</phrase> (<phrase>HS</phrase>) has <phrase>recently</phrase> been explored as a promising technique for capturing shape of objects with unknown <phrase>reflectance</phrase>. So far, it has been <phrase>widely applied</phrase> to objects of smooth <phrase>geometry</phrase> and <phrase>piecewise</phrase> <phrase>uniform</phrase> <phrase>Bidirectional Reflectance Distribution Function</phrase> (<phrase>BRDF</phrase>). Moreover, for <phrase>non-convex</phrase> surfaces the <phrase>inter-reflection</phrase> effects have been completely neglected. We extend the method to surfaces which <phrase>exhibit strong</phrase> texture, nontrivial <phrase>geometry</phrase> and are possibly <phrase>non-convex</phrase>. The problem associated with these <phrase>surface features</phrase> is that <phrase>Helmholtz</phrase> <phrase>reciprocity</phrase> is apparently violated when <phrase>point-based</phrase> measurements are used independently to establish the matching constraint as in the standard <phrase>HS</phrase> implementation. We argue that the problem is avoided by <phrase>computing</phrase> <phrase>radiance</phrase> measurements on <phrase>image regions</phrase> corresponding exactly to projections of the same <phrase>surface point</phrase> <phrase>neighbourhood</phrase> with appropriate scale. The <phrase>experimental</phrase> <phrase>results</phrase> demonstrate the success of the novel method proposed on <phrase>real objects</phrase>.
<phrase>Ellipsoid</phrase> decomposition of 3D-<phrase>model</phrase>.
<phrase>Construction</phrase> of <phrase>Large-Scale</phrase> <phrase>Virtual Environment</phrase> by <phrase>Fusing</phrase> <phrase>Range</phrase> <phrase>Data</phrase>, <phrase>Texture Images</phrase>, and <phrase>Airborne</phrase> <phrase>Altimetry Data</phrase>.
Accurate 3D Acquisition of <phrase>Freely Moving</phrase> Objects.
This <phrase>paper</phrase> presents a new <phrase>acquisition method</phrase> for 3D <phrase>laser</phrase> scanners that combines <phrase>imaging</phrase>, <phrase>fast</phrase> <phrase>geometrical</phrase> <phrase>object tracking</phrase>, and <phrase>automatic</phrase> <phrase>pose estimation</phrase> to register <phrase>range</phrase> profiles of <phrase>freely moving</phrase> objects. The method was developed to solve the constraint of <phrase>rigidity</phrase> between <phrase>free</phrase>-<phrase>moving objects</phrase> and a 3D <phrase>scanner</phrase> while preserving the accuracy of the <phrase>range</phrase> measurements. <phrase>Rigidity</phrase> constraint imposes that a 3D <phrase>scanner</phrase> or any external <phrase>positioning</phrase> devices must be perfectly <phrase>stable</phrase> relative to the object during scanning. This is often impossible for moving structures such as when using <phrase>scaffolding</phrase>, <phrase>industrial</phrase> conveyers, or <phrase>robotic arms</phrase>. The method starts by <phrase>creating</phrase> a <phrase>rough</phrase>, <phrase>partial</phrase>, and distorted estimate of the <phrase>model</phrase> of the object from an initial <phrase>subset</phrase> of <phrase>sparse range data</phrase>. Then, it recursively improves and refines the <phrase>model</phrase> by adding new <phrase>range</phrase> <phrase>information</phrase>. In <phrase>parallel</phrase>, <phrase>real-time</phrase> tracking of the object is performed to <phrase>center</phrase> the <phrase>scan</phrase> on the object. A <phrase>high</phrase>-resolution and accurate 3D <phrase>model</phrase> of a <phrase>free</phrase>-floating object, and <phrase>real-time</phrase> tracking of its position is obtained.
Using <phrase>Omnidirectional</phrase> <phrase>Structure from Motion</phrase> for Registration of <phrase>Range</phrase> Images of <phrase>Minimal</phrase> Overlap.
In this <phrase>paper</phrase>, we propose a novel method of <phrase>merging</phrase> a series of <phrase>range</phrase> images with a <phrase>minimal</phrase> overlap between any two consecutive <phrase>range</phrase> images. We rigidly <phrase>mount</phrase> a <phrase>parabolic</phrase> <phrase>catadioptric camera</phrase> to the <phrase>range scanner</phrase>. Using two omniviews we are able to <phrase>accurately estimate</phrase> the <phrase>relative displacement</phrase> between two <phrase>range</phrase> views. The resultant motion is used for the registration of all <phrase>range</phrase> <phrase>data</phrase> to the same coordinate system. An additional <phrase>perspective</phrase> <phrase>camera</phrase> calibrated with respect to the <phrase>scanner</phrase> is used for <phrase>texture mapping</phrase>.
A <phrase>Statistical Method</phrase> for <phrase>Robust</phrase> 3D <phrase>Surface Reconstruction</phrase> from <phrase>Sparse Data</phrase>.
<phrase>General</phrase> <phrase>information</phrase> about a class of objects, such as <phrase>human</phrase> faces or teeth, can help to solve the otherwise <phrase>ill-posed</phrase> problem of <phrase>reconstructing</phrase> a complete surface from <phrase>sparse</phrase> 3D <phrase>feature points</phrase> or 2D projections of points. We present a technique that uses a <phrase>vector space</phrase> representation of shape (3D <phrase>Morphable Model</phrase>) to infer missing <phrase>vertex coordinates</phrase>. <phrase>Regularization</phrase> derived from a <phrase>statistical approach</phrase> makes the system <phrase>stable</phrase> and <phrase>robust</phrase> with respect to noise by <phrase>computing</phrase> the <phrase>optimal</phrase> <phrase>tradeoff between</phrase> <phrase>fitting</phrase> quality and <phrase>plausibility</phrase>. We present a <phrase>direct</phrase>, non-<phrase>iterative algorithm</phrase> to calculate this <phrase>optimum</phrase> efficiently, and a method for simultaneously <phrase>compensating</phrase> unknown <phrase>rigid transformations</phrase>. The system is applied and evaluated in two different fields: (1) <phrase>reconstruction</phrase> of 3D faces at unknown orientations from 2D <phrase>feature points</phrase> at interactive rates, and (2) <phrase>restoration</phrase> of missing <phrase>surface regions</phrase> of teeth for <phrase>CAD-CAM</phrase> <phrase>production</phrase> of <phrase>dental</phrase> inlays and other <phrase>medical</phrase> applications.
<phrase>Enhanced</phrase> <phrase>Vector Quantization</phrase> for <phrase>Data</phrase> Reduction and Filtering.
Modern <phrase>automatic</phrase> digitizers can sample <phrase>huge amounts</phrase> of 3D <phrase>data</phrase> points on the <phrase>object surface</phrase> in a <phrase>short</phrase> time. <phrase>Point based</phrase> graphics is becoming a popular framework to reduce the <phrase>cardinality</phrase> of these <phrase>data</phrase> sets and to filter <phrase>measurement noise</phrase>, without having to store in <phrase>memory</phrase> and process <phrase>mesh connectivity</phrase>. <phrase>Main contribution</phrase> of this <phrase>paper</phrase> is the <phrase>introduction</phrase> of <phrase>soft clustering</phrase> techniques in the field of <phrase>point clouds</phrase> processing. In this approach <phrase>data</phrase> points are not assigned to a <phrase>single</phrase> cluster, but they contribute in the <phrase>determination</phrase> of the position of several <phrase>cluster centres</phrase>. As a result a better representation of the <phrase>data</phrase> is achieved. In <phrase>Soft clustering</phrase> techniques, a <phrase>data set</phrase> is represented with a reduced number of points called <phrase>Reference Vectors</phrase> (<phrase>RV</phrase>), which minimize an adequate <phrase>error measure</phrase>. As the position of the <phrase>RVs</phrase> is determined by "<phrase>learning</phrase>", which can be viewed as an <phrase>iterative optimization</phrase> procedure, they are inherently slow. We show here how partitioning the <phrase>data</phrase> domain into disjointed regions called hyperboxes (<phrase>HB</phrase>), the computation can be localized and the computational time reduced to linear in the number of <phrase>data</phrase> points (<phrase>O</phrase>(N)), saving more than 75% on <phrase>real applications</phrase> with respect to <phrase>classical</phrase> <phrase>soft</phrase>-<phrase>VQ</phrase> solutions, making therefore <phrase>VQ</phrase> suitable to the task. The procedure is suitable for a <phrase>parallel</phrase> <phrase>HW</phrase> implementation, which would <phrase>lead</phrase> to a complexity sub-linear in N. An <phrase>automatic</phrase> procedure for setting the <phrase>voxel</phrase> side and the other parameters can be derived from the <phrase>data</phrase>-set analysis. <phrase>Results</phrase> obtained in the <phrase>reconstruction</phrase> of faces of both humans and puppets as well as on models from <phrase>clouds</phrase> of points made available on the <phrase>WEB</phrase> are reported and discussed in comparison with other available methods.
ShapeLab: <phrase>A Unified</phrase> Framework for 2D & 3D <phrase>Shape Retrieval</phrase>.
2D or 3D shapes are the most important <phrase>visual information</phrase> that we use to recognize an object. We propose <phrase>a unified</phrase> framework "ShapeLab" to search similar 2D or 3D shapes from an existing <phrase>database</phrase>. Users can search 3D shapes with a 2D input, <phrase>and vice versa</phrase>. ShapeLab is composed of four <phrase>key components</phrase>: (1) <phrase>pose determination</phrase> for 3D models; (2) 2D <phrase>orthogonal</phrase> <phrase>view generation</phrase> based on <phrase>multiple levels</phrase> of detail; (3) <phrase>similarity measurement</phrase> between 2D shapes; and (4) <phrase>freehand sketch</phrase>-<phrase>based user interface</phrase>. Key <phrase>algorithms</phrase> <phrase>supporting</phrase> the above components are <phrase>briefly described</phrase>. Experiments show ShapeLab can provide a better performance such as <phrase>high</phrase> accuracy, flexibility and <phrase>scalability</phrase> compared to the available methods.
<phrase>Online</phrase> <phrase>Surface Reconstruction</phrase> from Unorganized 3D-Points for the <phrase>DLR</phrase> Hand-<phrase>Guided</phrase> <phrase>Scanner</phrase> System.
Hand-<phrase>guided</phrase> scanners allow for <phrase>digitization</phrase> by manually <phrase>sweeping</phrase> a <phrase>laser beam</phrase> over an <phrase>object's surface</phrase>. The result highly depends on the way the user handles the system and his ability to keep <phrase>track</phrase> of the parts of the surface that are already scanned. Processing and visualization during <phrase>data</phrase> acquisition are helpful in this context. In this <phrase>paper</phrase>, we propose an <phrase>online</phrase> <phrase>surface reconstruction algorithm</phrase> for the visualization of the <phrase>DLR</phrase> <phrase>scanner</phrase> system <phrase>data</phrase>. The <phrase>algorithm</phrase> successively generates a <phrase>triangle</phrase> mesh by incrementally inserting 3D points. Point neighborhoods are used to limit the point <phrase>density</phrase>, to estimate the <phrase>surface normal</phrase> at the inserted point, and to locally <phrase>re</phrase>-triangulate the mesh. A <phrase>dynamic</phrase> <phrase>data structure</phrase> for <phrase>fast</phrase> <phrase>neighborhood</phrase> search without restrictions to the amount of vertices or the <phrase>object size</phrase> and with <phrase>low complexity</phrase> is introduced. <phrase>Finally</phrase>, <phrase>results</phrase> with the hand-<phrase>guided</phrase> <phrase>scanner</phrase> system are presented.
<phrase>Robust</phrase> <phrase>Structure from Motion</phrase> under <phrase>Weak Perspective</phrase>.
It is widely known that, for the <phrase>affine camera model</phrase>, both shape and <phrase>motion data</phrase> can be <phrase>factorized</phrase> directly from the <phrase>measurement matrix</phrase> constructed from 2D <phrase>image points</phrase> coordinates. However, <phrase>classical</phrase> <phrase>algorithms</phrase> for <phrase>Structure from Motion</phrase> (<phrase>SfM</phrase>) are not <phrase>robust</phrase>: measurement <phrase>outliers</phrase>, that is, incorrectly detected or <phrase>matched feature points</phrase> can destroy the result. A few methods to robustify <phrase>SfM</phrase> have already been proposed. Different <phrase>outlier detection</phrase> schemes have been used. We examine <phrase>an efficient</phrase> <phrase>algorithm</phrase> by Trajkovic <phrase>et al</phrase>. [<phrase>Robust</phrase> <phrase>recursive</phrase> <phrase>structure and motion recovery</phrase> under <phrase>affine projection</phrase>] who use <phrase>affine camera model</phrase> and the Least <phrase>Median</phrase> of Squares (LMedS) method to separate inliers from <phrase>outliers</phrase>. LMedS is only applicable when the ratio of inliers exceeds 50%. We show that the <phrase>Least Trimmed Squares</phrase> (<phrase>LTS</phrase>) method is more <phrase>efficient</phrase> in <phrase>robust</phrase> <phrase>SfM</phrase> than LMedS. In particular, we demonstrate that <phrase>LTS</phrase> can handle <phrase>inlier</phrase> ratios below 50%. We also show that using the real (<phrase>Euclidean</phrase>) <phrase>motion data</phrase> <phrase>results</phrase> in a more precise <phrase>SfM</phrase> <phrase>algorithm</phrase> that using the <phrase>affine camera model</phrase>. Based on these observations, we propose a novel <phrase>robust</phrase> <phrase>SfM</phrase> <phrase>algorithm</phrase> and discuss its advantages and limits. The <phrase>proposed method</phrase> and the Trajkovicprocedure are quantitatively compared on <phrase>synthetic data</phrase> in different simulated situations. The methods are also tested on synthesized and real <phrase>video</phrase> sequences.
<phrase>GPU</phrase>-Assisted <phrase>Z</phrase>-Field <phrase>Simplification</phrase>.
<phrase>Height fields</phrase> and <phrase>depth maps</phrase> which we collectively refer to as <phrase>z</phrase>-fields, usually carry a <phrase>lot</phrase> of <phrase>redundant information</phrase> and are often used in <phrase>real-time</phrase> applications. This is the reason why <phrase>efficient</phrase> methods for their <phrase>simplification</phrase> are necessary. On the other hand, the <phrase>computation power</phrase> and programmability of <phrase>commodity graphics hardware</phrase> has significantly grown. We present an adaptation of an existing <phrase>real-time</phrase> <phrase>z</phrase>-field <phrase>simplification</phrase> method for execution in <phrase>graphics hardware</phrase>. The main parts of the <phrase>algorithm</phrase> are implemented as fragment programs which run on the <phrase>GPU</phrase>. The resulting <phrase>polygonal models</phrase> are identical to the ones obtained by the original method. The main benefit is that the <phrase>computation load</phrase> is imposed on the <phrase>GPU</phrase>, freeing-up the <phrase>CPU</phrase> for other tasks. Additionally, the new method exhibits a <phrase>performance improvement</phrase> when compared to a pure <phrase>CPU</phrase> implementation.
<phrase>Estimating</phrase> the <phrase>Principal Curvatures</phrase> and the <phrase>Darboux</phrase> Frame from Real 3D <phrase>Range</phrase> <phrase>Data</phrase>.
Tracking Densely Moving Markers.
Using <phrase>Principal Curvatures</phrase> and <phrase>Darboux</phrase> Frame to Recover 3D <phrase>Geometric</phrase> Primitives from <phrase>Range</phrase> Images.
3D <phrase>Shape Estimation</phrase> Based on <phrase>Density</phrase> Driven <phrase>Model Fitting</phrase>.
<phrase>Multiple View</phrase> <phrase>Reconstruction</phrase> of People.
This <phrase>paper</phrase> presents <phrase>a unified</phrase> framework for <phrase>model</phrase>-based and <phrase>model</phrase>-<phrase>free</phrase> <phrase>reconstruction</phrase> of people from <phrase>multiple camera views</phrase> in a <phrase>studio</phrase> environment. Shape and appearance of the reconstructed <phrase>model</phrase> are <phrase>optimised</phrase> simultaneously based on <phrase>multiple view</phrase> <phrase>silhouette</phrase>, <phrase>stereo</phrase> and <phrase>feature correspondence</phrase>. <phrase>A priori</phrase> <phrase>knowledge</phrase> of <phrase>surface structure</phrase> is introduced as <phrase>regularisation</phrase> constraints. <phrase>Model</phrase>-based <phrase>reconstruction</phrase> assumes a known <phrase>generic</phrase> <phrase>humanoid</phrase> <phrase>model</phrase> <phrase>a priori</phrase>, which is fitted to the <phrase>multi-view</phrase> observations to produce a <phrase>structured representation</phrase> for <phrase>animation</phrase>. <phrase>Model</phrase>-<phrase>free</phrase> <phrase>reconstruction</phrase> makes no <phrase>priori assumptions</phrase> on <phrase>scene geometry</phrase> allowing the <phrase>reconstruction</phrase> of complex <phrase>dynamic</phrase> scenes. <phrase>Results</phrase> are presented for <phrase>reconstruction</phrase> of sequences of people from <phrase>multiple views</phrase>. The <phrase>model-based</phrase> approach produces a consistent <phrase>structured representation</phrase>, which is <phrase>robust</phrase> in the presence of <phrase>visual</phrase> ambiguities. This overcomes limitations of existing <phrase>visual</phrase>-<phrase>hull</phrase> and <phrase>stereo</phrase> techniques. <phrase>Model</phrase>-<phrase>free</phrase> <phrase>reconstruction</phrase> allows <phrase>high</phrase>-quality <phrase>novel view-synthesis</phrase> with accurate <phrase>reproduction</phrase> of the detailed dynamics for <phrase>hair</phrase> and loose <phrase>clothing</phrase>. <phrase>Multiple view</phrase> <phrase>optimisation</phrase> achieves a <phrase>visual</phrase> quality comparable to the <phrase>captured video</phrase> without <phrase>visual</phrase> artefacts due to <phrase>misalignment</phrase> of images.
<phrase>Blind Watermarking</phrase> of 3D Shapes using Localized Constraints.
This <phrase>paper</phrase> develops a <phrase>digital watermarking</phrase> methodology for 3-<phrase>D</phrase> <phrase>graphical</phrase> objects defined by <phrase>polygonal meshes</phrase>. In <phrase>watermarking</phrase> or <phrase>fingerprinting</phrase> the aim is to embed a code in a given <phrase>media</phrase> without producing identifiable changes to it. One should be able to retrieve the embedded <phrase>information</phrase> even after the shape had suffered various modifications. Two <phrase>blind watermarking</phrase> techniques <phrase>applying</phrase> perturbations onto the <phrase>local</phrase> <phrase>geometry</phrase> for selected vertices are described in this <phrase>paper</phrase>. The proposed methods produce localized changes of <phrase>vertex locations</phrase> that do not alter the <phrase>mesh topology</phrase>. A study of the effects caused by vertex location modification is provided for a <phrase>general</phrase> class of surfaces. The robustness of the proposed <phrase>algorithms</phrase> is tested at <phrase>noise perturbation</phrase> and object cropping.
<phrase>Tele</phrase>-3D - <phrase>Developing</phrase> a Handheld <phrase>Scanner</phrase> Using <phrase>Structured Light</phrase> <phrase>Projection</phrase>.
Acquisition, Modelling and Rendering of <phrase>Very Large</phrase> <phrase>Urban</phrase> Environments.
In this <phrase>paper</phrase> we describe a <phrase>vehicle</phrase> borne <phrase>data</phrase> acquisition system for <phrase>urban</phrase> environments and associated 3D <phrase>data management</phrase> and <phrase>interactive rendering</phrase> <phrase>software</phrase>. The <phrase>data</phrase> acquisition system is capable of acquire 3D <phrase>data</phrase> from <phrase>urban areas</phrase> with <phrase>centimetre</phrase> resolution including <phrase>automatic</phrase> capturing of <phrase>colour</phrase>. The system includes a <phrase>management</phrase> and <phrase>interactive rendering</phrase> <phrase>software</phrase> which is designed to <phrase>cope</phrase> with the huge quantities of <phrase>data</phrase> generated by the acquisition system. It uses out-of-core <phrase>pre-processing</phrase> to transform <phrase>data</phrase> into octrees. <phrase>Real-time</phrase> <phrase>interactive rendering</phrase> is achieved by using novel techniques such as front-to-back <phrase>octree</phrase> traversal, <phrase>occlusion query</phrase> and <phrase>speculative</phrase> <phrase>pre-fetching</phrase>. The <phrase>paper</phrase> presents the <phrase>results</phrase> of the described techniques applied to large <phrase>public</phrase> areas including the <phrase>City</phrase> <phrase>Centre</phrase> of <phrase>Verona</phrase>, <phrase>Italy</phrase>.
From 3D <phrase>Shape Capture</phrase> to <phrase>Animated</phrase> Models.
<phrase>Neuroanatomical</phrase> <phrase>Imaging</phrase>: Constrained 3D <phrase>Reconstruction</phrase> Using <phrase>Variational Implicit</phrase> Techniques.
<phrase>Real-Time</phrase> <phrase>Speech-Driven</phrase> 3D <phrase>Face Animation</phrase>.
Some Unusual Ways of Visually Sensing 3D Shapes.
<phrase>User-Controlled</phrase> <phrase>Simplification</phrase> of <phrase>Polygonal Models</phrase>.
<phrase>Polygonal Models</phrase> are ubiquitous in <phrase>Computer Graphics</phrase> but their <phrase>real time</phrase> manipulation and rendering especially in <phrase>interactive application</phrase> environments have become a <phrase>threat</phrase> because of their huge sizes and complexity. A whole <phrase>family</phrase> of <phrase>automatic</phrase> <phrase>algorithms</phrase> emerged during the <phrase>last</phrase> decade to help out this problem, but they reduce the complexity of the models uniformly without <phrase>caring</phrase> about <phrase>semantic</phrase> importance of localized parts of a mesh. Only a few <phrase>algorithms</phrase> deal with <phrase>adaptive</phrase> <phrase>simplification</phrase> of <phrase>polygonal models</phrase>. We propose a new <phrase>model</phrase> for <phrase>user-driven</phrase> <phrase>simplification</phrase> <phrase>exploiting</phrase> the <phrase>simplification</phrase> hierarchy and hypertriangulation <phrase>model</phrase> [A resolution modeling system] that lends a user the most of the functionalities of existing <phrase>adaptive</phrase> <phrase>simplification</phrase> <phrase>algorithms</phrase> in one place and is quite simple to implement. The proposed new underlying <phrase>data structures</phrase> are <phrase>compact</phrase> and support <phrase>real time</phrase> <phrase>navigation</phrase> across <phrase>continuous</phrase> LODs of a <phrase>model</phrase>; any desirable <phrase>LOD</phrase> can be extracted efficiently and can further be <phrase>fine-tuned</phrase>. The proposed <phrase>model</phrase> for <phrase>adaptive</phrase> <phrase>simplification</phrase> supports two key operations for <phrase>selective refinement</phrase> and <phrase>selective</phrase> <phrase>simplification</phrase>; their effect has been shown on various <phrase>polygonal models</phrase>. Comparison with related work shows that the proposed <phrase>model</phrase> provides combined environment at <phrase>reduced overhead</phrase> of <phrase>memory space</phrase> usage and faster <phrase>running times</phrase>.
<phrase>Non-Rigid</phrase> <phrase>Range</phrase>-<phrase>Scan</phrase> Alignment Using <phrase>Thin-Plate Splines</phrase>.
We present a <phrase>non-rigid</phrase> <phrase>alignment algorithm</phrase> for <phrase>aligning</phrase> <phrase>high</phrase>-resolution <phrase>range</phrase> <phrase>data</phrase> in the presence of <phrase>low-frequency</phrase> deformations, such as those caused by <phrase>scanner</phrase> <phrase>calibration</phrase> error. Traditional <phrase>iterative closest points</phrase> (<phrase>ICP</phrase>) <phrase>algorithms</phrase>, which rely on <phrase>rigid-body</phrase> alignment, fail in these cases because the error appears as a <phrase>non-rigid</phrase> <phrase>warp</phrase> in the <phrase>data</phrase>. Our <phrase>algorithm</phrase> combines the robustness and efficiency of <phrase>ICP</phrase> with the expressiveness of <phrase>thin-plate splines</phrase> to align <phrase>high</phrase>-resolution <phrase>scanned data</phrase> accurately, such as scans from the <phrase>Digital</phrase> <phrase>Michelangelo</phrase> <phrase>Project</phrase> [The <phrase>Digital</phrase> <phrase>Michelangelo</phrase> <phrase>Project</phrase>: 3-<phrase>D</phrase> scanning of large statues]. This application is distinguished from previous uses of the <phrase>thin-plate spline</phrase> by the fact that the resolution and size of <phrase>warping</phrase> are several <phrase>orders of magnitude</phrase> smaller than the extent of the mesh, thus requiring especially precise <phrase>feature correspondence</phrase>.
<phrase>Shape Distortion</phrase> Analysis of the <phrase>Shape-from-Shading</phrase> <phrase>Algorithm</phrase> Using <phrase>Jacobi Iterative Method</phrase>.
<phrase>Metrological</phrase> Analysis of a Procedure for the <phrase>Automatic</phrase> 3D Modeling of <phrase>Dental</phrase> <phrase>Plaster</phrase> Casts.
As well known, in the <phrase>reconstruction</phrase> of the 3D models through <phrase>optical systems</phrase>, the errors are due to the <phrase>single</phrase>-view acquisition error and to the 3D modeling procedure. The latter can be ascribed to the various phases of the 3D modeling pipeline: <phrase>pairwise registration</phrase>, <phrase>global</phrase> registration, <phrase>surface integration</phrase>. This work examines the acquisition error as well as the errors due to an <phrase>automatic</phrase> procedure <phrase>recently</phrase> proposed for the 3D modeling of <phrase>dental</phrase> <phrase>plaster</phrase> casts. This contribution derives a simple <phrase>error propagation</phrase> <phrase>model</phrase>, rather useful for practical <phrase>simulation</phrase> purposes. From a <phrase>general</phrase> <phrase>viewpoint</phrase>, this contribution proposes a useful <phrase>simulation</phrase> of <phrase>error propagation</phrase> in 3D modeling, it shows the quality of an <phrase>automatic</phrase> 3D modeling procedure <phrase>recently</phrase> proposed and it shows the accuracy of 3D modeling <phrase>dental</phrase> <phrase>plaster</phrase> casts by <phrase>current commercial</phrase> <phrase>range</phrase> cameras and the considered <phrase>automatic</phrase> method.
<phrase>Mathematical</phrase> Aspects of <phrase>Shape Reconstruction</phrase> from an <phrase>Image Sequence</phrase>.
<phrase>Spherical</phrase> <phrase>Diffusion</phrase> for 3D <phrase>Surface Smoothing</phrase>.
A <phrase>diffusion</phrase>-<phrase>based approach</phrase> to <phrase>surface smoothing</phrase> is presented. Surfaces are represented as <phrase>scalar functions</phrase> defined on the <phrase>sphere</phrase>. The approach is equivalent to <phrase>Gaussian smoothing</phrase> on the <phrase>sphere</phrase> and is <phrase>computationally efficient</phrase> since it does not require <phrase>iterative smoothing</phrase>. Furthermore, it does not suffer from the well-known <phrase>shrinkage</phrase> problem. <phrase>Evolution</phrase> of important <phrase>shape features</phrase> (<phrase>parabolic</phrase> curves) under <phrase>diffusion</phrase> is demonstrated. A <phrase>nonlinear</phrase> modification of the <phrase>diffusion</phrase> process is introduced in <phrase>order</phrase> to improve <phrase>smoothing</phrase> behavior of elongated and poorly centered objects.
Coding with <phrase>ASCII</phrase>: <phrase>compact</phrase>, yet <phrase>text-based</phrase> 3D content.
Realistic Models of Children <phrase>Heads</phrase> from 3D-<phrase>MRI</phrase> Segmentation and <phrase>Tetrahedral Mesh</phrase> <phrase>Construction</phrase>.
In <phrase>order</phrase> to analyze the sensitivity of children to <phrase>RF</phrase> fields and <phrase>mobile phones</phrase> in particular, the <phrase>SAR</phrase> (Specific <phrase>Absorption</phrase> Ratio) defined as the power absorbed by a unit of <phrase>mass</phrase> of tissues (<phrase>W</phrase>/<phrase>kg</phrase>) should be computed based on a <phrase>numerical model</phrase> of the head.We propose to build realistic models from 3D-<phrase>MRI</phrase> of children heads.The method is composed of two steps. The first one consists in <phrase>segmenting</phrase> the main tissues in these images (<phrase>skin</phrase>, <phrase>fat</phrase>, muscles, <phrase>cortical</phrase> and <phrase>marrow</phrase> <phrase>bones</phrase>, <phrase>cerebrospinal fluid</phrase>, <phrase>grey</phrase> and <phrase>white matter</phrase>, <phrase>blood</phrase>, etc).The segmentation is based on <phrase>mathematical morphology</phrase> methods which are well adapted to this aim and provide a <phrase>robust</phrase> and <phrase>automatic</phrase> method requiring <phrase>minimum</phrase> user intervention.Using <phrase>simplified</phrase> <phrase>segmented images</phrase>, the second step concerns the <phrase>tetrahedral</phrase> mesh generation.Our method uses almost <phrase>regular meshes</phrase> and <phrase>topological</phrase> tools to preserve the <phrase>topological</phrase> <phrase>arrangement</phrase> of the <phrase>head</phrase> tissues.A method to guarantee a good <phrase>geometrical</phrase> quality is also provided.
Theoretical Accuracy Analysis of N-<phrase>Ocular</phrase> <phrase>Vision Systems</phrase> for <phrase>Scene Reconstruction</phrase>, <phrase>Motion Estimation</phrase>, and <phrase>Positioning</phrase>.
<phrase>Theoretical models</phrase> are derived to analyze the accuracy of N-<phrase>Ocular</phrase> <phrase>vision systems</phrase> for <phrase>scene reconstruction</phrase>, <phrase>motion estimation</phrase> and self <phrase>positioning</phrase>. <phrase>Covariance</phrase> matrices are given to estimate the <phrase>uncertainty bounds</phrase> for the reconstructed points in 3-<phrase>D</phrase> space, <phrase>motion parameters</phrase>, and 3-<phrase>D</phrase> position of the vision system. <phrase>Simulation</phrase> <phrase>results</phrase> of various experiments, based on synthetic and <phrase>real data</phrase> acquired with <phrase>a 12</phrase>-<phrase>camera</phrase> <phrase>stereo</phrase> <phrase>panoramic imaging</phrase> system, are given to demonstrate the application of these models, as well as to evaluate the performance of the <phrase>panoramic</phrase> system for <phrase>high</phrase>-precision 3-<phrase>D</phrase> mapping and <phrase>positioning</phrase>.
<phrase>Local</phrase> <phrase>Approximate</phrase> 3D Matching of <phrase>Proteins</phrase> in <phrase>Viral</phrase> <phrase>Cryo-EM</phrase> <phrase>Density</phrase> <phrase>Maps</phrase>.
<phrase>Experimental</phrase> <phrase>structure analysis</phrase> of <phrase>biological molecules</phrase> (e.g, <phrase>proteins</phrase>) or <phrase>macromolecular</phrase> complexes (e.g, <phrase>viruses</phrase>) can be used to generate <phrase>three-dimensional</phrase> <phrase>density</phrase> <phrase>maps</phrase> of these entities. Such a <phrase>density</phrase> <phrase>map</phrase> can be viewed as a <phrase>three-dimensional</phrase> <phrase>gray-scale</phrase> image where space is subdivided in voxels of a given size. The focus of this <phrase>paper</phrase> is the analysis of <phrase>virus</phrase> <phrase>density</phrase> <phrase>maps</phrase>. The <phrase>hull</phrase> of a <phrase>virus</phrase> consists of many copies of one or several different <phrase>proteins</phrase>. An important tool for the study of <phrase>viruses</phrase> is <phrase>cryo-electron microscopy</phrase> (<phrase>cryo-EM</phrase>), a technique with insufficient resolution to directly determine the <phrase>arrangement</phrase> of the <phrase>proteins</phrase> in the <phrase>virus</phrase>. We therefore created a tool that locates <phrase>proteins</phrase> in the <phrase>three-dimensional</phrase> <phrase>density</phrase> <phrase>map</phrase> of a <phrase>virus</phrase>. The goal is to fully determine the locations and orientations of the <phrase>protein</phrase>(<phrase>s</phrase>) in the <phrase>virus</phrase> given the <phrase>virus</phrase>' <phrase>three-dimensional</phrase> <phrase>density</phrase> <phrase>map</phrase> and a <phrase>database</phrase> of <phrase>density</phrase> <phrase>maps</phrase> of one or more <phrase>protein</phrase> candidates.
<phrase>Stochastic</phrase> <phrase>Mesh-Based</phrase> <phrase>Multiview Reconstruction</phrase>.
<phrase>An Experimental</phrase> Comparison of <phrase>Feature-Based</phrase> 3D <phrase>Retrieval Methods</phrase>.
3D objects are an important type of <phrase>multimedia</phrase> <phrase>data</phrase> with many promising application possibilities. Defining the aspects that constitute the similarity among 3D objects, and <phrase>designing</phrase> <phrase>algorithms</phrase> that implement such similarity definitions is a <phrase>difficult problem</phrase>. Over the <phrase>last</phrase> few years, a strong interest in methods for <phrase>feature-based</phrase> 3D <phrase>similarity search</phrase> has arisen, and a growing number of <phrase>competing algorithms</phrase> for <phrase>content-based</phrase> retrieval of 3D objects have been proposed. We present an <phrase>extensive experimental evaluation</phrase> of the <phrase>retrieval effectiveness</phrase> and efficiency of a large part of the <phrase>current state</phrase>-of-the-<phrase>art</phrase> <phrase>feature-based</phrase> methods for 3D <phrase>similarity search</phrase>, giving a <phrase>contrasting</phrase> assessment of the different approaches.
Neural Mesh <phrase>Ensembles</phrase>.
This <phrase>paper</phrase> proposes the use of <phrase>neural network ensembles</phrase> to <phrase>boost</phrase> the performance of <phrase>a neural network based</phrase> <phrase>surface reconstruction algorithm</phrase>. <phrase>Ensemble</phrase> is a very popular and powerful <phrase>statistical technique</phrase> based on the idea of <phrase>averaging</phrase> several outputs of a <phrase>probabilistic</phrase> <phrase>algorithm</phrase>. In the context of <phrase>surface reconstruction</phrase>, two main <phrase>problems arise</phrase>. The first is <phrase>finding</phrase> <phrase>an efficient</phrase> way to <phrase>average</phrase> meshes with different connectivity, and the second is tuning the parameters for <phrase>surface reconstruction</phrase> to maximize the performance of the <phrase>ensemble</phrase>. We solve the first problem by voxelizing all the meshes on the same <phrase>regular grid</phrase> and taking <phrase>majority vote</phrase> on each <phrase>voxel</phrase>. We tune the parameters experimentally, <phrase>borrowing</phrase> ideas from <phrase>weak</phrase> <phrase>learning</phrase> methods.
<phrase>Weaver</phrase>, an <phrase>automatic</phrase> texture <phrase>builder</phrase>.
From the <phrase>Lab</phrase> to the <phrase>Silver</phrase> Screen: <phrase>Computer Vision</phrase> and the <phrase>Art</phrase> of <phrase>Special Effects</phrase>.
RoboScan: An <phrase>Automatic</phrase> System for Accurate and Unattended 3D Scanning.
We describe an <phrase>automatic</phrase> system for <phrase>fast</phrase> unattended acquisition of accurate and complete 3D models, called RoboScan. The <phrase>design</phrase> goal is to reduce the three main bottlenecks in <phrase>human</phrase>-assisted 3D scanning: the selection of the <phrase>range</phrase> <phrase>maps</phrase> to be taken (<phrase>view planning</phrase>), the <phrase>positioning</phrase> of the <phrase>scanner</phrase> in the environment, and the <phrase>range</phrase> <phrase>maps</phrase>' alignment. The system is designed around a commercial <phrase>laser</phrase>-based 3D <phrase>scanner</phrase> moved by a <phrase>robotic arm</phrase>. The acquisition <phrase>session</phrase> is organised in two stages. First, an initial <phrase>sampling</phrase> of the surface is performed by the <phrase>automatic</phrase> selection of a set of views. Then, some added views are <phrase>automatically selected</phrase>, acquired and merged to the initial set in <phrase>order</phrase> to fill the <phrase>surface regions</phrase> left unsampled. Both the initial set of <phrase>range</phrase> <phrase>maps</phrase> and the <phrase>subsequently</phrase> added ones are <phrase>post</phrase>-processed automatically, by using the known <phrase>scanner</phrase> positions to initialise the alignment phase. <phrase>Results</phrase> of the assessment of the system on real acquisitions are presented and discussed.
<phrase>Computational Experiments</phrase> with <phrase>Area</phrase>-Based <phrase>Stereo</phrase> for <phrase>Image-Based</phrase> Rendering.
<phrase>Optimal and Near - Optimal</phrase> Solutions for 3D Structure Comparisons.
<phrase>Photo</phrase>-<phrase>Consistency Based</phrase> Registration of an <phrase>Uncalibrated</phrase> <phrase>Image Pair</phrase> to a 3D <phrase>Surface Model</phrase> Using <phrase>Genetic Algorithm</phrase>.
We consider the following <phrase>data fusion</phrase> problem. A 3D object with textured <phrase>Lambertian</phrase> surface is measured and independently photographed. A triangulated <phrase>model</phrase> of the object and two <phrase>uncalibrated images</phrase> are obtained. The goal is to precisely register the images to the <phrase>model</phrase>. Solving this problem is necessary for <phrase>building</phrase> a <phrase>geometrically accurate</phrase>, <phrase>photorealistic</phrase> <phrase>model</phrase> from <phrase>laser</phrase>-scanned 3D <phrase>data</phrase> and <phrase>high</phrase> quality images. <phrase>Recently</phrase>, we have proposed a novel method that generalises the <phrase>photo</phrase>-consistency approach by <phrase>Clarkson</phrase> <phrase>et al</phrase>. [Using <phrase>photo</phrase>-consistency to register 2D <phrase>optical images</phrase> of the <phrase>human</phrase> face to a 3D <phrase>surface model</phrase>] to the case of <phrase>uncalibrated cameras</phrase>, when both <phrase>intrinsic and extrinsic</phrase> parameters are unknown. This gives a user the freedom of taking the pictures by a conventional <phrase>digital camera</phrase>, from arbitrary positions and with varying <phrase>zoom</phrase>. The method is based on manual <phrase>pre-registration</phrase> followed by a <phrase>genetic</phrase> <phrase>optimisation algorithm</phrase>. A brief description of the <phrase>pilot</phrase> version of the method [<phrase>Precise registration</phrase> of an <phrase>uncalibrated</phrase> <phrase>image pair</phrase> to a 3D <phrase>surface model</phrase>] has been given together with the <phrase>results</phrase> of a few initial <phrase>tests</phrase>. In this <phrase>paper</phrase>, we <phrase>report</phrase> on some new significant developments in this <phrase>project</phrase>. The <phrase>critical issue</phrase> of robustness against <phrase>illumination changes</phrase> is addressed and various <phrase>colour</phrase> representations and <phrase>cost functions</phrase> are tested and compared. Natural constraints are introduced and <phrase>experimentally validated</phrase> to simplify the <phrase>camera</phrase> <phrase>model</phrase> and accelerate the <phrase>algorithm</phrase>. <phrase>Finally</phrase>, we present synthetic and <phrase>real data</phrase> with <phrase>ground truth</phrase>, apply the improved method to the <phrase>data</phrase> and measure the quality of the <phrase>results</phrase>.
<phrase>Multiresolution</phrase> Approach to <phrase>Three-Dimensional</phrase> <phrase>Stereo</phrase> Vision.
An Approach to Using <phrase>Image-Based</phrase> Techniques across Unreliable <phrase>Peer-to-Peer</phrase> Networks.
<phrase>Acquiring</phrase> <phrase>Height Maps</phrase> of Faces from a <phrase>Single</phrase> Image.
In this <phrase>paper</phrase> we explore how to improve the quality of the <phrase>height map</phrase> recovered from faces using <phrase>shape-from-shading</phrase>. One of the problems with <phrase>reliable</phrase> face <phrase>surface reconstruction</phrase> using <phrase>shape-from-shading</phrase> is that <phrase>local</phrase> errors in the <phrase>needle map</phrase> can cause implosion of <phrase>facial features</phrase>, and in particular the <phrase>nose</phrase>. To overcome this problem in this <phrase>paper</phrase> we develop a method for ensuring surface <phrase>convexity</phrase>. This is done by modifying the <phrase>gradient</phrase> orientations in accordance with <phrase>critical points</phrase> on the surface. We utilize a <phrase>local</phrase> shape indicator as a criteria to decide which <phrase>surface normals</phrase> are to be <phrase>modified</phrase>. Experiments show that altering the directions of a <phrase>surface normal</phrase> field of a face leads to a <phrase>considerable improvement</phrase> in its integrated <phrase>height map</phrase>.
Towards <phrase>Urban</phrase> 3D <phrase>Reconstruction</phrase> from <phrase>Video</phrase>.
The <phrase>paper</phrase> introduces a <phrase>data</phrase> collection system and a <phrase>processing pipeline</phrase> for <phrase>automatic</phrase> <phrase>geo</phrase>-registered 3D <phrase>reconstruction</phrase> of <phrase>urban</phrase> scenes from <phrase>video</phrase>. The system collects <phrase>multiple video streams</phrase>, as well as <phrase>GPS</phrase> and <phrase>INS</phrase> measurements in <phrase>order</phrase> to place the reconstructed models in <phrase>geo</phrase>-registered coordinates. Besides <phrase>high</phrase> quality in terms of both <phrase>geometry</phrase> and appearance, we aim at <phrase>real-time</phrase> performance. Even <phrase>though</phrase> our <phrase>processing pipeline</phrase> is currently far from being <phrase>real-time</phrase>, we select techniques and we <phrase>design</phrase> <phrase>processing modules</phrase> that can achieve <phrase>fast</phrase> performance on <phrase>multiple CPUs</phrase> and <phrase>GPUs</phrase> aiming at <phrase>real-time</phrase> performance in the <phrase>near future</phrase>. We present the main considerations in <phrase>designing</phrase> the system and the steps of the <phrase>processing pipeline</phrase>. We show <phrase>results</phrase> on real <phrase>video</phrase> sequences captured by our system.
<phrase>Improving</phrase> Environment Modelling by Edge Occlusion <phrase>Surface Completion</phrase>.
<phrase>Visual</phrase> <phrase>Data</phrase> Navigators "Collaboratories".
View Dependence of 3D Recovery from <phrase>Folded</phrase> Pictures and <phrase>Warped</phrase> 3D Faces.
In a popular <phrase>visual illusion</phrase>, the <phrase>portrait</phrase> on <phrase>paper currency</phrase> is <phrase>folded</phrase> into an <phrase>M</phrase> shape along <phrase>vertical</phrase> lines through the <phrase>nose</phrase> and the <phrase>eyes</phrase>. When this <phrase>folded</phrase> <phrase>picture</phrase> is <phrase>tilted</phrase> back and <phrase>forth</phrase> horizontally the face undergoes striking changes in expression. This <phrase>distortion</phrase> reveals two insights concerning 3D representation in the <phrase>human</phrase> <phrase>visual</phrase> system and we have explored these with experiments on simple <phrase>schematic</phrase> faces and observations on distortions of <phrase>laser</phrase> <phrase>range</phrase> images of faces. The observations show first that when <phrase>recovering</phrase> depicted depth, <phrase>pictorial</phrase> cues are interpreted independently of <phrase>binocular</phrase> <phrase>depth information</phrase> and second, that the recovery of <phrase>facial expression</phrase> is based on a scaled prototypical face structure.
<phrase>Variational</phrase> <phrase>Multiframe</phrase> <phrase>Stereo</phrase> in the Presence of <phrase>Specular Reflections</phrase>.
A <phrase>Depth Map</phrase> Representation for <phrase>Real-Time</phrase> Transmission and <phrase>View-Based</phrase> Rendering of a <phrase>Dynamic</phrase> 3D Scene.
<phrase>Probabilistic</phrase> 3D <phrase>Data Fusion</phrase> for <phrase>Adaptive</phrase> Resolution <phrase>Surface Generation</phrase>.
3D <phrase>Shape Registration</phrase> using <phrase>Regularized</phrase> Medial Scaffolds.
This <phrase>paper</phrase> proposes a novel method for <phrase>global registration</phrase> based on matching 3D medial structures of <phrase>unorganized point clouds</phrase> or <phrase>triangulated meshes</phrase>. Most practical known methods are based on the <phrase>Iterative Closest Point</phrase> (<phrase>ICP</phrase>) <phrase>algorithm</phrase>, which requires an <phrase>initial alignment</phrase> close to the <phrase>globally optimal</phrase> <phrase>solution</phrase> to ensure convergence to a valid <phrase>solution</phrase>. Furthermore, it can also fail when there are points in one dataset with no corresponding matches in the other dataset. The <phrase>proposed method</phrase> <phrase>automatically finds</phrase> an <phrase>initial alignment</phrase> close to the <phrase>global optimal</phrase> by using the medial structure of the datasets. For this purpose, we first compute the <phrase>medial scaffold</phrase> of a 3D dataset: a 3D <phrase>graph</phrase> made of special <phrase>shock</phrase> curves <phrase>linking</phrase> special <phrase>shock</phrase> nodes. This <phrase>medial scaffold</phrase> is then <phrase>regularized</phrase> <phrase>exploiting</phrase> the known transitions of the 3D <phrase>medial axis</phrase> under deformation or <phrase>perturbation</phrase> of the <phrase>input data</phrase>. The resulting <phrase>simplified</phrase> medial scaffolds are then registered using a <phrase>modified</phrase> <phrase>graduated</phrase> assignment <phrase>graph matching</phrase> <phrase>algorithm</phrase>. The <phrase>proposed method</phrase> shows robustness to noise, <phrase>shape deformations</phrase>, and varying surface <phrase>sampling</phrase> densities.
A <phrase>Multi-Resolution</phrase> Scheme <phrase>ICP</phrase> <phrase>Algorithm</phrase> for <phrase>Fast</phrase> <phrase>Shape Registration</phrase>.
<phrase>Super</phrase> <phrase>High</phrase> Resolution 3D <phrase>Imaging</phrase> and <phrase>Efficient</phrase> Visualization.
<phrase>Applying</phrase> Mesh <phrase>Conformation</phrase> on <phrase>Shape Analysis</phrase> with <phrase>Missing Data</phrase>.
A mesh <phrase>conformation</phrase> approach that makes use of deformable <phrase>generic</phrase> meshes has been applied to establishing correspondences between 3D shapes with missing data.Given a <phrase>group</phrase> of shapes with correspondences, we can build up a <phrase>statistical shape model</phrase> by <phrase>applying</phrase> <phrase>principal component analysis</phrase> (<phrase>PCA</phrase>). The <phrase>conformation</phrase> at first globally <phrase>maps</phrase> the <phrase>generic</phrase> mesh to the 3D <phrase>shape based</phrase> on manually located corresponding landmarks, and then locally deforms the <phrase>generic</phrase> mesh to clone the 3D shape.The <phrase>local</phrase> deformation is constrained by <phrase>minimizing</phrase> the <phrase>energy</phrase> of an <phrase>elastic</phrase> model.An <phrase>algorithm</phrase> was also embedded in the <phrase>conformation</phrase> process to fill missing surface <phrase>data</phrase> of the shapes.Using <phrase>synthetic data</phrase>, we demonstrate that the <phrase>conformation</phrase> preserves the configuration of the <phrase>generic</phrase> mesh and <phrase>hence</phrase> it helps to establish good correspondences for shape analysis.Case studies of the <phrase>principal component analysis</phrase> of shapes were presented to illustrate the successes and advantages of our approach.
<phrase>Adaptive</phrase> <phrase>Online</phrase> Transmission of 3D TexMesh Using <phrase>Scale-Space</phrase> Analysis.
<phrase>Wavelet</phrase> Coding of Structured <phrase>Geometry</phrase> <phrase>Data</phrase> Considering <phrase>Rate-Distortion</phrase> Properties.
Reliability and Judging <phrase>Fatigue</phrase> Reduction in 3D <phrase>Perceptual Quality</phrase> Estimation.
<phrase>Content-Based Image Retrieval</phrase> from Large <phrase>Medical</phrase> <phrase>Databases</phrase>.
<phrase>Markerless Human Motion</phrase> Transfer.
In this <phrase>paper</phrase> we develop a <phrase>computer vision</phrase>-based system to transfer <phrase>human</phrase> motion from one subject to another. Our system uses a network of eight calibrated and <phrase>synchronized cameras</phrase>. We first build detailed <phrase>kinematic</phrase> models of the subjects based on our <phrase>algorithms</phrase> for <phrase>extracting</phrase> <phrase>shape from silhouette</phrase> across time [A 3D <phrase>reconstruction</phrase> <phrase>algorithm</phrase> <phrase>combining</phrase> shape-frame-shilhouette]. These models are then used to capture the motion (<phrase>joint</phrase> angles) of the subjects in new <phrase>video</phrase> sequences. <phrase>Finally</phrase> we describe an <phrase>image-based rendering</phrase> <phrase>algorithm</phrase> to render the <phrase>captured motion</phrase> applied to the <phrase>articulated model</phrase> of another person. Our <phrase>rendering algorithm</phrase> uses an <phrase>ensemble</phrase> of <phrase>spatially and temporally</phrase> distributed images to generate <phrase>photo</phrase>-realistic <phrase>video</phrase> of the transferred motion. We demonstrate the performance of the system by rendering throwing and kungfu motions on subjects who did not perform them.
<phrase>Topology</phrase> and <phrase>Geometry</phrase> of <phrase>Unorganized Point Clouds</phrase>.
We present a new method for defining neighborhoods, and assigning <phrase>principal curvature</phrase> frames, and mean and <phrase>Gauss</phrase> curvatures to the points of an unorganized oriented <phrase>point-cloud</phrase>. The neighborhoods are estimated by <phrase>measuring</phrase> implicitly the surface distance between points. The 3D <phrase>shape recovery</phrase> is based on <phrase>conformal geometry</phrase>, works directly on the <phrase>cloud</phrase>, does not rely on the generation of <phrase>polygonal</phrase>, or smooth models. <phrase>Test</phrase> <phrase>results</phrase> on <phrase>publicly available</phrase> <phrase>synthetic data</phrase>, as <phrase>ground truth</phrase>, demonstrate that the method <phrase>compares favorably</phrase> to the established approaches for <phrase>quantitative</phrase> 3D <phrase>shape recovery</phrase>. The <phrase>proposed method</phrase> is developed to serve <phrase>applications involving</phrase> <phrase>point based</phrase> rendering and <phrase>reliable</phrase> extraction of <phrase>differential properties</phrase> from noisy <phrase>unorganized point-clouds</phrase>.
A <phrase>Content-Based Retrieval</phrase> System with a Customizeable 3D Output <phrase>Visualizer</phrase>.
<phrase>Octree</phrase>-based <phrase>Fusion</phrase> of <phrase>Shape from Silhouette</phrase> and Shape from <phrase>Structured Light</phrase>.
<phrase>Uncalibrated</phrase> 3 <phrase>metric reconstruction</phrase> and flattened <phrase>texture acquisition</phrase> from a <phrase>single</phrase> view of a surface of <phrase>revolution</phrase>.
<phrase>Inpainting</phrase> from <phrase>Multiple Views</phrase>.
<phrase>Face Recognition</phrase> from 3D <phrase>Data</phrase> using <phrase>Iterative Closest Point Algorithm</phrase> and <phrase>Gaussian Mixture Models</phrase>.
A new approach to <phrase>face verification</phrase> from 3D <phrase>data</phrase> is presented. The method uses 3D <phrase>registration techniques</phrase> designed to work with <phrase>resolution levels</phrase> typical of the <phrase>irregular</phrase> <phrase>point cloud</phrase> representations provided by <phrase>Structured Light</phrase> scanning. <phrase>Preprocessing</phrase> using <phrase>a-priori</phrase> <phrase>information</phrase> of the <phrase>human</phrase> face and the <phrase>Iterative Closest Point algorithm</phrase> are employed to establish <phrase>correspondence</phrase> between <phrase>test</phrase> and <phrase>target</phrase> and to compensate for the <phrase>non-rigid</phrase> <phrase>nature</phrase> of the surfaces. <phrase>Statistical modelling</phrase> in the form of <phrase>Gaussian Mixture Models</phrase> is used to parameterise the distribution of errors in <phrase>facial surfaces</phrase> after registration and is employed to differentiate between <phrase>intra</phrase>- and extra-personal comparison of <phrase>range</phrase> images. An <phrase>Equal Error Rate</phrase> of 2.67% was achieved on the 30 subject manual <phrase>subset</phrase> of the the 3d_rma <phrase>database</phrase>.
Entire <phrase>Model</phrase> Acquisition System using Handheld 3D Digitizer.
In this <phrase>paper</phrase>, a <phrase>real-time</phrase>, handheld 3D <phrase>model</phrase> acquisition system consisting of a <phrase>laser</phrase> projector, a <phrase>video camera</phrase> and a <phrase>turntable</phrase> is described. The user projects a <phrase>stripe</phrase> of <phrase>light</phrase> at the 3D object by hand while <phrase>rotating</phrase> the object on a <phrase>turntable</phrase>. The <phrase>projected light</phrase> and <phrase>LED</phrase> markers attached to the <phrase>laser</phrase> projector and <phrase>turntable</phrase> are captured by the <phrase>video camera</phrase>. By <phrase>estimating</phrase> the 3D orientation of the <phrase>laser</phrase> projector and the <phrase>turntable</phrase> angle from the 2D locations of the markers, the 3D location of the surface <phrase>lit</phrase> by the <phrase>laser</phrase> can be calculated. In addition, <phrase>post-processing</phrase> <phrase>algorithms</phrase> for <phrase>refining</phrase> the estimated 3D <phrase>data</phrase> have been proposed. The <phrase>algorithm</phrase> not only improves the accuracy of the 3D measurement, but also achieves to decrease the number of <phrase>LEDs</phrase> for 3D <phrase>data</phrase> estimation; therefore, it <phrase>significantly improves</phrase> the userýs convenience in scanning the object. With this system, users can measure an entire 3D object in <phrase>real-time</phrase>.
3D Effect Generation from <phrase>Monocular</phrase> View.
<phrase>Synthetic Image</phrase> of <phrase>Multiresolution</phrase> <phrase>Sketch</phrase> Leads to New Features.
A new approach to <phrase>construction</phrase> of <phrase>robust</phrase> features is proposed and applied to an instance of the <phrase>correspondence</phrase> problem. The <phrase>main idea</phrase> is to construct a <phrase>synthetic image</phrase> by a <phrase>multiresolution</phrase> <phrase>sketch</phrase> (<phrase>MS</phrase>) of an image and involve it into extraction of the invariants. The <phrase>MS</phrase> is constructed by processing the image with <phrase>a scalable</phrase> detector of the <phrase>semi-local</phrase> 1D-elements. Then, a <phrase>synthetic image</phrase> is constructed with all elements of the <phrase>MS</phrase>. <phrase>Local maxima</phrase> of the first and second derivatives of the <phrase>synthetic image</phrase> along <phrase>discrete curves</phrase> of the <phrase>MS</phrase> <phrase>lead</phrase> to some <phrase>singular</phrase> elements represented by the points of a 4D <phrase>manifold</phrase>. It turns out that a representative <phrase>subset</phrase> of the <phrase>singular</phrase> elements is <phrase>stable</phrase>. To prove that, the <phrase>pair-wise</phrase> <phrase>correspondence</phrase> between subsets of <phrase>singular</phrase> elements of two shots of a <phrase>film</phrase> was established experimentally by a consistency technique, which, <phrase>unlike</phrase> <phrase>past approaches</phrase>, does not involve <phrase>epipolar constraints</phrase>.
<phrase>Hierarchical</phrase> 3D <phrase>Surface Reconstruction</phrase> based on <phrase>Radial Basis Functions</phrase>.
<phrase>Volumetric</phrase> methods based on <phrase>implicit</phrase> surfaces are <phrase>commonly used</phrase> in <phrase>surface reconstruction</phrase> from <phrase>uniformly distributed</phrase> <phrase>sparse</phrase> 3D <phrase>data</phrase>. The case of <phrase>non-uniform</phrase> <phrase>distributed data</phrase> has <phrase>recently</phrase> deserved more attention, because it <phrase>occurs frequently</phrase> in practice. This <phrase>paper</phrase> describes a <phrase>volumetric</phrase> approach to <phrase>surface reconstruction</phrase> from <phrase>non-uniform</phrase> <phrase>data</phrase> which is suitable for the <phrase>reconstruction</phrase> of surfaces from images, in particular from <phrase>multiple views</phrase>. Differently from <phrase>volumetric</phrase> methods which use both 3D <phrase>surface points</phrase> and <phrase>surface normals</phrase>, the approach does not use the <phrase>surface normals</phrase> because they are often unreliable when estimated from <phrase>image data</phrase>. The method is based on a <phrase>hierarchical</phrase> partitioning of the <phrase>volume data</phrase> set. The working volume is <phrase>split</phrase> and classified at different scales of <phrase>spatial</phrase> resolution into surface, <phrase>internal and external</phrase> voxels and this hierarchy is described by an <phrase>octree</phrase> structure in a <phrase>multiscale</phrase> framework. The <phrase>octree</phrase> structure is used to build a <phrase>multiresolution</phrase> description of the surface by means of <phrase>compact</phrase> support <phrase>radial basis functions</phrase> (<phrase>RBF</phrase>). A hierarchy of surface approximations at different levels of details is built by representing the voxels at the same <phrase>octree</phrase> level as <phrase>RBF</phrase> of similar <phrase>spatial</phrase> support. At each scale, <phrase>information</phrase> related to the <phrase>reconstruction</phrase> error drives the <phrase>reconstruction</phrase> process at the following <phrase>finer scale</phrase>. <phrase>Preliminary results</phrase> on <phrase>synthetic data</phrase> and <phrase>future perspectives</phrase> are presented.
<phrase>Shape Matching</phrase> using the 3D <phrase>Radon Transform</phrase>.
In this <phrase>paper</phrase> a novel method for 3D <phrase>model</phrase> <phrase>content-based</phrase> search and retrieval based on the 3D <phrase>Radon Transform</phrase> and a <phrase>querying</phrase>-by-3D-<phrase>model</phrase> approach, is presented. Descriptors are extracted using the 3D <phrase>Radon Transform</phrase> and <phrase>applying</phrase> a set of functionals on the <phrase>transform coefficients</phrase>. <phrase>Similarity measures</phrase> are then created for the extracted descriptors and introduced into a 3D <phrase>model</phrase>-<phrase>matching algorithm</phrase>. This <phrase>results</phrase> to a very <phrase>fast</phrase> and accurate <phrase>matching method</phrase>. Experiments were performed using two different <phrase>databases</phrase> and <phrase>comparing</phrase> the <phrase>proposed method</phrase> with others. <phrase>Experimental</phrase> <phrase>results</phrase> show that the <phrase>proposed method</phrase> can be used for 3D <phrase>model</phrase> search and retrieval in a <phrase>highly efficient</phrase> manner.
<phrase>Archiving</phrase> <phrase>Technology</phrase> for <phrase>Plant</phrase> Inspection <phrase>Images Captured</phrase> by <phrase>Mobile</phrase> <phrase>Active</phrase> Cameras - 4D Visible <phrase>Memory</phrase>.
<phrase>Filling Holes</phrase> in <phrase>Complex Surfaces</phrase> using <phrase>Volumetric</phrase> <phrase>Diffusion</phrase>.
<phrase>Robust</phrase> <phrase>Concealment</phrase> for Erroneous Block Bursts in <phrase>Stereoscopic</phrase> Images.
With the increasing number of image <phrase>communication</phrase> applications especially in the <phrase>low complexity</phrase> domain, <phrase>error concealment</phrase> has become a very important field of <phrase>research</phrase>. Since many <phrase>compression standards</phrase> for <phrase>images and videos</phrase> are <phrase>block-based</phrase> a <phrase>lot</phrase> of methods were applied to conceal block losses in <phrase>monocular</phrase> images. The <phrase>fast</phrase> progress of capture, representation and <phrase>display technologies</phrase> for 3D <phrase>image data</phrase> advances the efforts on 3D <phrase>concealment</phrase> strategies. Because of their <phrase>psycho</phrase>-<phrase>visual</phrase> characteristics, <phrase>stereoscopic</phrase> images have to fulfill a very <phrase>high</phrase> quality demand. We propose an <phrase>algorithm</phrase> that makes use of the redundancies between two views of a <phrase>stereo image pair</phrase>. In many cases erroneous block bursts occur and can be highly disturbing, thus we will mainly concentrate on these errors. In addition, we focused on the <phrase>quality assessment</phrase> of several <phrase>error concealment</phrase> strategies. Beside the <phrase>objective evaluation</phrase> measures, we carried out a <phrase>subjective quality</phrase> <phrase>test</phrase> following the DSCQS methodology as proposed by <phrase>MPEG</phrase>. The <phrase>results</phrase> of this <phrase>test</phrase> demonstrate the efficiency of our approach.
<phrase>Fast</phrase> <phrase>Landmark-Based</phrase> Registration via <phrase>Deterministic</phrase> and <phrase>Efficient</phrase> Processing, Some <phrase>Preliminary Results</phrase>.
Texture at the <phrase>Terminator</phrase>.
Using 3D-<phrase>Bresenham</phrase> for <phrase>Resampling</phrase> <phrase>Structured Grids</phrase>.
<phrase>Structured grids</phrase> and some of their applications in <phrase>natural sciences</phrase> are discussed. The problem of their visualization and <phrase>quantitative</phrase> evaluation is considered and possible ways for itssolution sketched. <phrase>Resampling</phrase> a <phrase>structured grid</phrase> onto a regular one is such a possible <phrase>solution</phrase> offering the additional benefit of enabling <phrase>quantitative</phrase> evaluations, too. This <phrase>resampling</phrase> is achieved by a preliminary tetrahedronization of the <phrase>structured grid</phrase>(<phrase>s</phrase>)and a subsequent <phrase>digitalization</phrase> of the constituent tetrahedrons using an adaptation of the 3D-<phrase>Bresenham</phrase> <phrase>algorithm</phrase>. <phrase>Advantages and disadvantages</phrase> of this approach as compared to other possible schemes are discussed. An implementation based on our <phrase>open source</phrase> f3d-<phrase>file format</phrase> for storage and transmission of <phrase>volumetric data</phrase> is presented, and <phrase>results</phrase> from <phrase>applying</phrase> it to <phrase>real-world data</phrase> shown.
<phrase>Interactive Walkthroughs</phrase> using "<phrase>Morphable</phrase> 3D-<phrase>Mosaics</phrase>".
This <phrase>paper</phrase> presents <phrase>a hybrid</phrase> (<phrase>geometry</phrase>- & <phrase>image-based</phrase>) technique suitable for providing <phrase>interactive walkthroughs</phrase> of large, complex <phrase>outdoor</phrase> scenes. Motion is <phrase>restricted</phrase> along a smooth predefined path and the input to the system is a <phrase>sparse</phrase> set of <phrase>stereoscopic</phrase> views at certain points (key-positions) along that path (one view per position). An <phrase>approximate</phrase> <phrase>local</phrase> 3D <phrase>model</phrase> is constructed from each view, capable of capturing <phrase>photometric</phrase> and <phrase>geometric</phrase> properties of the scene only locally. Then during the rendering process, a <phrase>continuous</phrase> <phrase>morphing</phrase> (both <phrase>photometric</phrase> & <phrase>geometric</phrase>) <phrase>takes place</phrase> between successive <phrase>local</phrase> 3D models, using what we call a "<phrase>morphable</phrase> 3D-<phrase>model</phrase>". The <phrase>morphing</phrase> proceeds in a <phrase>physically-valid</phrase> way. For this reason, a <phrase>wide-baseline image matching</phrase> technique is proposed, handling cases where the <phrase>wide baseline</phrase> between the two images is mainly due to a <phrase>looming</phrase> of the <phrase>camera</phrase>. Our system can be extended in the event of multiple <phrase>stereoscopic</phrase> views (and therefore multiple <phrase>local</phrase> models) per key-position of the path (related by a <phrase>camera</phrase> rotation). In that case one <phrase>local</phrase> 3D-<phrase>mosaic</phrase> (per key-position) is constructed comprising all <phrase>local</phrase> 3D models therein and a "<phrase>morphable</phrase> 3D-<phrase>mosaic</phrase>" is used during the rendering process. A <phrase>partial-differential equation</phrase> is adopted to handle the problem of <phrase>geometric</phrase> consistency of each 3D-<phrase>mosaic</phrase>.
<phrase>Color</phrase>, <phrase>Fusion</phrase>, and <phrase>Stereopsis</phrase>.
A <phrase>Graph Cut based</phrase> <phrase>Adaptive</phrase> <phrase>Structured Light</phrase> Approach for <phrase>Real-Time</phrase> <phrase>Range</phrase> Acquisition.
This <phrase>paper</phrase> describes a new <phrase>algorithm</phrase> that yields <phrase>dense</phrase> <phrase>range</phrase> <phrase>maps</phrase> in real-time.Reconstruction are based on a <phrase>single</phrase> frame <phrase>structured light</phrase> illumination.On-the-<phrase>fly</phrase> adaptation of the <phrase>projection</phrase> pattern renders the system more <phrase>robust</phrase> against scene variability. A <phrase>continuous</phrase> <phrase>trade</phrase> off between speed and quality is made. The <phrase>correspondence</phrase> problem is solved by using <phrase>geometric</phrase> pattern coding in combination with <phrase>sparse</phrase> <phrase>color</phrase> coding. Only <phrase>local</phrase> <phrase>spatial</phrase> and <phrase>temporal continuity</phrase> are assumed. This allows to construct a <phrase>neighbor relationship</phrase> within every frame and to <phrase>track</phrase> correspondences over time.All cues are integrated in one consistent labeling.This is achieved by <phrase>reformulating</phrase> the problem as a <phrase>graph</phrase> cut.Every <phrase>cue</phrase> is <phrase>weighted</phrase> based on its <phrase>average</phrase> consistency with the result within a small time window.Integration and <phrase>weighting</phrase> of <phrase>additional cues</phrase> is straightforward. The correctness of the <phrase>range</phrase> <phrase>maps</phrase> is not guaranteed, but an estimation of the uncertainty is provided for each part of the reconstruction.Our <phrase>prototype</phrase> is implemented using unmodified <phrase>consumer</phrase> hardware only.Frame rates vary between 10 and 25fps dependent on <phrase>scene complexity</phrase>.
3D Volume Extraction and <phrase>Mesh Generation</phrase> Using <phrase>Energy Minimization</phrase> Techniques.
<phrase>Multi-Spectral</phrase> <phrase>Stereo</phrase> <phrase>Image Matching</phrase> using <phrase>Mutual Information</phrase>.
<phrase>Mutual information</phrase> (<phrase>MI</phrase>) has <phrase>shown promise</phrase> as an effective <phrase>stereo</phrase> matching measure for images affected by <phrase>radiometric</phrase> <phrase>distortion</phrase>. This is due to the robustness of <phrase>MI</phrase> against changes in illumination. However, <phrase>MI-based</phrase> approaches are particularly prone to the generation of <phrase>false matches</phrase> due to the small <phrase>statistical power</phrase> of the matching <phrase>windows</phrase>. Consequently, most previous <phrase>MI</phrase> approaches utilise large matching <phrase>windows</phrase> which smooth the estimated <phrase>disparity field</phrase>. This <phrase>paper</phrase> proposes extensions to <phrase>MI-based</phrase> <phrase>stereo</phrase> matching in <phrase>order</phrase> to increase the robustness of the <phrase>algorithm</phrase>. <phrase>Firstly</phrase>, <phrase>prior probabilities</phrase> are incorporated into the <phrase>MI</phrase> measure in <phrase>order</phrase> to <phrase>considerably increase</phrase> the <phrase>statistical power</phrase> of the matching <phrase>windows</phrase>. These <phrase>prior probabilities</phrase>, which are calculated from the <phrase>global</phrase> <phrase>joint</phrase> <phrase>histogram</phrase> between the <phrase>stereo</phrase> pair, are tuned to a <phrase>two level</phrase> <phrase>hierarchical</phrase> approach. A 2D match surface, in which the <phrase>match score</phrase> is computed for every possible combination of template and matching window, is also utilised. This enforces <phrase>left-right</phrase> consistency and <phrase>uniqueness</phrase> constraints. These additions to <phrase>MI-based</phrase> <phrase>stereo</phrase> matching <phrase>significantly enhance</phrase> the <phrase>algorithm's ability</phrase> to detect <phrase>correct matches</phrase> while decreasing computation time and <phrase>improving</phrase> the accuracy. <phrase>Results</phrase> show that the <phrase>MI</phrase> measure does not perform quite as well for standard <phrase>stereo</phrase> pairs when compared to traditional <phrase>area</phrase>-based metrics. However, the <phrase>MI</phrase> approach is far <phrase>superior</phrase> when matching across multi-<phrase>spectra</phrase> <phrase>stereo</phrase> pairs.
3D <phrase>Object Modelling</phrase> in <phrase>Mobile Robot</phrase> Environment Using <phrase>B-Spline</phrase> Surfaces.
<phrase>Automated</phrase> <phrase>Multi-view</phrase> 3D <phrase>Image Acquisition</phrase> in <phrase>Human Genome</phrase> <phrase>Research</phrase>.
<phrase>Pictorial</phrase> Techniques and <phrase>Intrinsic</phrase> Images.
<phrase>High</phrase>-Resolution Cytometry Network <phrase>Project</phrase>: Towards <phrase>Remote</phrase> a <phrase>d</phrase> Distributed Acquisition, Processing and <phrase>Visualisation</phrase> of 3D <phrase>Image Data</phrase> in <phrase>Human Genome</phrase> <phrase>Research</phrase>.
Towards <phrase>Automatic</phrase> Modeling of Monuments and <phrase>Towers</phrase>.
<phrase>Feature Based</phrase> Registration of <phrase>Range</phrase> Images for Mapping of <phrase>Natural Outdoor</phrase> <phrase>Feature Based</phrase> Registration of <phrase>Range</phrase> Images for Mapping of <phrase>Natural Outdoor</phrase>.
Challenges related to <phrase>viewpoint</phrase> registration in <phrase>rough</phrase> <phrase>forest</phrase> <phrase>terrain</phrase> can be quite different compared to those faced in <phrase>structured environments</phrase>. Manoeuvring the <phrase>sensor</phrase> between measurement positions introduces large error into the <phrase>a priori</phrase> estimates of the registration coordinates. As a consequence, <phrase>locally optimal</phrase> <phrase>registration methods</phrase> may not work properly. Moreover, due to the <phrase>clutter</phrase>, the <phrase>scene contents</phrase> can change substantially even due to a relative small displacement of the <phrase>sensor</phrase>. Often, the <phrase>sensor</phrase> has to be moved to the other side of the <phrase>target</phrase> object, such as a <phrase>group</phrase> of <phrase>trees</phrase>, to get a good coverage of its <phrase>geometry</phrase>. In both cases, overlap between the two 3D <phrase>data</phrase> sets will be <phrase>minimal</phrase> ruling out conventional <phrase>registration methods</phrase>. In this <phrase>paper</phrase>, a <phrase>feature-based</phrase> method for registering 3D <phrase>range</phrase> scans for mapping <phrase>natural outdoor</phrase> environments is proposed. The <phrase>method utilizes</phrase> <phrase>cylindrical</phrase>, <phrase>rotation symmetric</phrase> <phrase>features extracted</phrase> from the 3D <phrase>measurement data</phrase> for <phrase>viewpoint</phrase> registration. The method is tested on real <phrase>range</phrase> images.
<phrase>Multiresolution</phrase> Distance <phrase>Volumes</phrase> for <phrase>Progressive</phrase> Surface Compression.
<phrase>Progressive</phrase> Compression of <phrase>Volumetric</phrase> <phrase>Subdivision Meshes</phrase>.
We present a <phrase>progressive compression</phrase> technique for <phrase>volumetric</phrase> <phrase>subdivision meshes</phrase> based on the <phrase>slow growing</phrase> <phrase>refinement</phrase> <phrase>algorithm</phrase>. The system is comprised of a <phrase>wavelet transform</phrase> followed by a <phrase>progressive</phrase> encoding of the resulting <phrase>wavelet</phrase> coefficients. We compare the efficiency of two <phrase>wavelet</phrase> transforms. The first transform is based on the <phrase>smoothing</phrase> rules used in the <phrase>slow growing</phrase> subdivision technique. The second transform is a <phrase>generalization</phrase> of lifted linear <phrase>B-spline wavelets</phrase> to the same <phrase>multi-tier</phrase> <phrase>refinement</phrase> structure. <phrase>Direct</phrase> <phrase>coupling</phrase> with a <phrase>hierarchical</phrase> coder produces <phrase>progressive</phrase> <phrase>bit</phrase> streams. <phrase>Rate distortion</phrase> metrics are evaluated for both <phrase>wavelet</phrase> transforms. We tested the practical performance of the scheme on <phrase>synthetic data</phrase> as well as <phrase>data</phrase> from <phrase>laser</phrase> <phrase>indirect</phrase>-drive <phrase>fusion</phrase> simulations with <phrase>multiple fields</phrase> per vertex. Both <phrase>wavelet</phrase> transforms result in <phrase>high</phrase> quality <phrase>trade</phrase> off curves and produce qualitatively good coarse representations.
<phrase>Robust</phrase> identification and matching of <phrase>fiducial points</phrase> for the <phrase>reconstruction</phrase> of 3D <phrase>human</phrase> faces from <phrase>raw</phrase> <phrase>video</phrase> sequences.
Effects of <phrase>Joystick</phrase> Mapping and <phrase>Field-of-View</phrase> on <phrase>Human</phrase> Performance in <phrase>Virtual</phrase> <phrase>Walkthroughs</phrase>.
Applications of 3D <phrase>Medical Imaging</phrase> in <phrase>Orthopaedic</phrase> <phrase>Surgery</phrase>: <phrase>Introducing</phrase> the <phrase>Hip</phrase>-<phrase>Op</phrase> System.
A <phrase>Real-time</phrase> Realization of <phrase>Geometrical</phrase> Valid <phrase>View Synthesis</phrase> for <phrase>Tele-conferencing</phrase> with <phrase>Viewpoint</phrase> Adaptation.
<phrase>Reconstruction</phrase> of <phrase>Euclidean</phrase> Planes from Voxels.
In this <phrase>paper</phrase>, we aim to formulate the recognition of a planes from a <phrase>discrete point</phrase> set as a <phrase>nonlinear</phrase> <phrase>optimization problem</phrase>, and we prove a <phrase>uniqueness</phrase> theorem for the <phrase>solution</phrase> of this problem. We deal with the <phrase>supercover</phrase> <phrase>model</phrase> in a space for the expression of <phrase>discrete planes</phrase>. The <phrase>algorithm</phrase> achieves <phrase>invertible</phrase> <phrase>data</phrase> compression of <phrase>digital</phrase> objects, since the <phrase>algorithm</phrase> transforms a collection voxels to a collection of <phrase>plane parameters</phrase>, which classify the voxels.
Thickness <phrase>Histogram</phrase> and Statistical <phrase>Harmonic</phrase> Representation for 3D <phrase>Model</phrase> Retrieval.
<phrase>Similarity measuring</phrase> is a key problem for 3D <phrase>model</phrase> retrieval. In this <phrase>paper</phrase>, we propose a novel <phrase>shape descriptor</phrase> "Thickness <phrase>Histogram</phrase>" (<phrase>TH</phrase>) by uniformly <phrase>estimating</phrase> thickness of a <phrase>model</phrase> using <phrase>statistical methods</phrase>. It is <phrase>translation</phrase> and <phrase>rotation-invariant</phrase>, <phrase>discriminative</phrase> to different shapes, and very <phrase>efficient</phrase> to compute with the <phrase>Shape Distribution</phrase> (<phrase>SD</phrase>) proposed by Osada etc. For <phrase>high</phrase> performance of the retrieval, we propose a <phrase>robust</phrase> method for <phrase>translating</phrase> the <phrase>directional</phrase> form of the <phrase>statistical distribution</phrase> to the <phrase>harmonic</phrase> representation. By summing up energies at different <phrase>frequencies</phrase>, a matrix <phrase>shape signature</phrase> is formed to provide an exhaustive characterization of 3D <phrase>geometry</phrase>. Experiments show that the performance of the statistical <phrase>harmonic</phrase> representation is among the <phrase>top</phrase> ones of existing <phrase>shape descriptors</phrase>.
<phrase>Motion-induced</phrase> <phrase>error correction</phrase> in <phrase>ultrasound imaging</phrase>.
3D <phrase>Image Sensing</phrase> for <phrase>Bit</phrase> Plane Method of <phrase>Progressive</phrase> Transmission.
<phrase>Image Compression</phrase> has received a <phrase>lot</phrase> of interest over the years. Almost all the <phrase>compression algorithms</phrase> and standards, discussed in <phrase>literature</phrase>, <phrase>gather statistics</phrase> and compress on the complete image and compresses to suit various requirements such as <phrase>lossy</phrase> / <phrase>lossless</phrase>, baseline/<phrase>progressive</phrase>, <phrase>spatial</phrase>, <phrase>region</phrase> on interest. <phrase>Natural images</phrase> such as <phrase>gray scale images</phrase> and <phrase>color images</phrase> are best compressed in the <phrase>existing literature</phrase> based on the <phrase>local</phrase> and <phrase>global</phrase> properties such as attributes of constituent <phrase>pixels</phrase> of the given image. In this <phrase>paper</phrase>, it is proposed to quantize the amplitudes of <phrase>pixel</phrase> values to form a number of <phrase>bit</phrase> planes and these <phrase>bit</phrase> planes are transmitted in either <phrase>lossy</phrase>, <phrase>lossless</phrase>, <phrase>progressive</phrase> manner. <phrase>Bit</phrase> plane formation is attempted from the image <phrase>acquiring</phrase> stage to compress and then to transmission stage. <phrase>Results</phrase> obtained are promising and give <phrase>rise</phrase> to new method or <phrase>ideology</phrase> in <phrase>image sensing</phrase>, <phrase>acquiring</phrase>, storage and transmission.
Small <phrase>CPU</phrase> Times and <phrase>Fast</phrase> <phrase>Interactivity</phrase> in <phrase>Sonar</phrase> Seabottom Surveys.
<phrase>Sonar</phrase> <phrase>profiling</phrase> of the seabottom provide 3D <phrase>data</phrase> sets that can <phrase>cover</phrase> huge survey areas with many gaps. This <phrase>paper</phrase> describes a <phrase>multiresolution</phrase> framework or <phrase>visualization pipeline</phrase> that is being optimized for dealing with such <phrase>data</phrase>, <phrase>taking into account</phrase> both the <phrase>CPU</phrase> time and the <phrase>user interactivity</phrase>. This <phrase>paper</phrase> describes the techniques employed: (a) the <phrase>construction</phrase> of a <phrase>quadtree</phrase> that allows to eliminate gaps by <phrase>interpolating</phrase> available 3D <phrase>data</phrase>, (<phrase>b</phrase>) a first but coarse visualization at a <phrase>high</phrase> <phrase>tree</phrase> level in <phrase>order</phrase> to rapidly change or adjust the <phrase>region</phrase> of interest, and (<phrase>c</phrase>) a very <phrase>efficient</phrase> <phrase>triangulation</phrase> (mesh reduction) that allows for <phrase>a fast</phrase> <phrase>interactivity</phrase> even at the highest detail level. By using one <phrase>single</phrase> <phrase>octree</phrase>, all processing can be combined because (1) gaps can be filled by <phrase>interpolation</phrase> since they are smaller at higher <phrase>tree</phrase> levels, and (2) <phrase>connected components</phrase> can be projected down the <phrase>tree</phrase> and refined using the <phrase>data</phrase> available there. As a result, <phrase>huge data sets</phrase> can be visualized in near <phrase>realtime</phrase> on normally-sized discrete <phrase>grids</phrase> using shading <phrase>instead</phrase> of <phrase>wire</phrase>-frames, and this enables <phrase>a fast</phrase> searching for objects in the seabottom. Real <phrase>CPU</phrase> times are presented for a real <phrase>sonar</phrase> <phrase>data</phrase> set which is visualized at a <phrase>low resolution</phrase>, showing the overall shape of the seabottom, and at a <phrase>high</phrase> resolution, showing a (semi-)<phrase>buried</phrase> pipeline. In <phrase>order</phrase> to detect an object at such a <phrase>high</phrase> resolution additional techniques are applied to the <phrase>data</phrase>: (a) an interslice <phrase>interpolation</phrase> in <phrase>order</phrase> to <phrase>cope</phrase> with the increased <phrase>data sparseness</phrase> and (<phrase>b</phrase>) a maximum-homogeneity filtering in <phrase>order</phrase> to <phrase>cope</phrase> with the decreased <phrase>signal-to-noise-ratio</phrase>. After the extraction of the pipeline a thinning technique is applied in <phrase>order</phrase> to be able to quantify its length.
<phrase>Visualizing</phrase> <phrase>I/O</phrase> Predictability.
3D <phrase>Performance Capture</phrase> for <phrase>Facial Animation</phrase>.
This <phrase>paper</phrase> describes how a <phrase>photogrammetry</phrase> based 3D capture system can be used as an <phrase>input device</phrase> for <phrase>animation</phrase>. The 3D <phrase>Dynamic</phrase> Capture System is used to capture the motion of a <phrase>human</phrase> face which is extracted from a <phrase>sequence</phrase> of 3D models captured at <phrase>TV</phrase> <phrase>frame rate</phrase>. Initially the positions of a set of landmarks on the face are extracted. These landmarks are then used to provide <phrase>motion data</phrase> in two different ways. First, a <phrase>high level</phrase> description of the movements are extracted, and these can be used as input to a <phrase>procedural</phrase> <phrase>animation</phrase> package (i.e. CreaToon). Second the landmarks can be used as registration points for a <phrase>conformation</phrase> process where the <phrase>model</phrase> to be <phrase>animated</phrase> is <phrase>modified</phrase> to match the captured <phrase>model</phrase>. This approach gives a new <phrase>sequence</phrase> of models which have the structure of the drawn <phrase>model</phrase> but the movement of the captured <phrase>sequence</phrase>.
On Robustness and <phrase>Localization Accuracy</phrase> of <phrase>Optical Flow</phrase> Computation from <phrase>Color</phrase> Imagery.
Accurate and <phrase>efficient</phrase> <phrase>optical flow</phrase> estimation is a <phrase>major</phrase> step in many <phrase>computational vision</phrase> problems, including tracking and 2-<phrase>D</phrase>/3-<phrase>D</phrase> mapping applications. Processing of <phrase>grayscale</phrase> images has been the dominant approach, with only a few <phrase>studies investigating</phrase> selected aspects in the use of <phrase>color</phrase> imagery. In a <phrase>physics-based</phrase> analysis to study the impact of the spectral-dependent medium <phrase>attenuation</phrase> on the <phrase>color</phrase> channels, we have shown merit in the use of <phrase>color</phrase> cues in the computation of <phrase>optical flow</phrase> for <phrase>underwater</phrase> imagery-the primary <phrase>motivation</phrase> of the investigation [<phrase>Robust</phrase> <phrase>optical flow</phrase> estimation using <phrase>underwater</phrase> <phrase>color images</phrase>]. Comparisons among various <phrase>color</phrase> representations and traditional intensity component on the <phrase>optical flow</phrase> computation are given, suggesting that the <phrase>HSV</phrase> representation could be the most suitable. For both <phrase>underwater</phrase> and <phrase>terrestrial</phrase> imagery, even where <phrase>data</phrase> in the 3 <phrase>color</phrase> channels are <phrase>highly correlated</phrase>, one expects <phrase>multiple constraints</phrase> from <phrase>color</phrase> channels to give <phrase>increased robustness</phrase> due to the <phrase>independent</phrase> <phrase>channel</phrase> noises. <phrase>Results</phrase> of experiments are given to demonstrate <phrase>improved localization</phrase> and accuracy.
<phrase>Data-Driven</phrase> Approaches to <phrase>Digital</phrase> <phrase>Human</phrase> Modeling.
<phrase>Data-driven</phrase> approach is an appealing way to depict people in a <phrase>virtual world</phrase>. The captured shape and <phrase>movement data</phrase> from real people are structured and combined to reproduce or create new samples in an intuitive and <phrase>controllable</phrase> way. We focus on the <phrase>body shape</phrase> modeling and elucidate the issues related to <phrase>data</phrase>-driven methods. The difficulty of adopting <phrase>data-driven</phrase> approach for <phrase>human body shape</phrase> modeling is due in part to the <phrase>intrinsic</phrase> <phrase>articulated structure</phrase> of the body. Since such <phrase>internal structure</phrase> is not measured with most of existing <phrase>capture devices</phrase> available today, it has to be calculated through estimation. We develop a framework for collecting and <phrase>managing</phrase> <phrase>range scan data</phrase> that automatically estimates this structure from user-<phrase>tagged</phrase> landmarks. By <phrase>framing</phrase> the captured and <phrase>structurally</phrase> <phrase>annotated data</phrase> so that statistic <phrase>implicit</phrase> is exploited for <phrase>synthesizing</phrase> new <phrase>body shapes</phrase>, our technique support time-saving generation of animatable body models with <phrase>high</phrase> realism.
<phrase>Spacetime</phrase>-<phrase>Coherent</phrase> <phrase>Geometry</phrase> <phrase>Reconstruction</phrase> from <phrase>Multiple Video Streams</phrase>.
By <phrase>reconstructing</phrase> <phrase>time-varying</phrase> <phrase>geometry</phrase> one frame at a time, one ignores the continuity of <phrase>natural motion</phrase>, wasting useful <phrase>information</phrase> about the underlying <phrase>video</phrase>-<phrase>image formation</phrase> process and <phrase>taking into account</phrase> temporally <phrase>discontinuous</phrase> <phrase>reconstruction</phrase> <phrase>results</phrase>. In 4D <phrase>spacetime</phrase>, the surface of a <phrase>dynamic</phrase> object describes a <phrase>continuous</phrase> 3D <phrase>hyper</phrase>-surface. This <phrase>hyper</phrase>-surface can be <phrase>implicitly defined</phrase> as the <phrase>minimum</phrase> of an <phrase>energy</phrase> <phrase>functional</phrase> designed to optimize <phrase>photo</phrase>-consistency. Based on an <phrase>Euler-Lagrange</phrase> <phrase>reformulation</phrase> of the problem, we find this <phrase>hyper</phrase>-surface from a handful of <phrase>synchronized video</phrase> recordings. The resulting <phrase>object geometry</phrase> varies smoothly over time, and intermittently <phrase>invisible</phrase> <phrase>object regions</phrase> are correctly interpolated from previously and/or future frames.
3WPS : A 3D <phrase>Web-based</phrase> Process <phrase>Visualization Framework</phrase>.
A <phrase>Gesture Recognition</phrase> System Using 3D <phrase>Data</phrase>.
<phrase>Concentric</phrase> <phrase>Strips</phrase>: <phrase>Algorithms</phrase> and <phrase>Architecture</phrase> for the <phrase>Compression/Decompression</phrase> of <phrase>Triangle</phrase> Meshes.
Description of Simple Method in 3D <phrase>Reconstruction</phrase> in <phrase>Medical Imaging</phrase>.
Encoding <phrase>Volumetric</phrase> <phrase>Grids</phrase> For Streaming <phrase>Isosurface</phrase> Extraction.
Gridded <phrase>volumetric data</phrase> sets representing <phrase>simulation</phrase> or <phrase>tomography</phrase> output are commonly visualized by displaying a triangulated <phrase>isosurface</phrase> for a particular isovalue. When the <phrase>grid</phrase> is stored in a standard format, the entire volume must be loaded from disk, even <phrase>though</phrase> only a fraction of the <phrase>grid</phrase> cells may intersect the <phrase>isosurface</phrase>. We propose a compressed on-disk representation for regular volume <phrase>grids</phrase> that allows streaming, <phrase>I/O</phrase>-<phrase>efficient</phrase>, out-of-core <phrase>isosurface</phrase> extraction. <phrase>Unlike previous methods</phrase>, we provide a guaranteed bound on the ratio between the number of cells loaded and number of cells intersecting the <phrase>isosurface</phrase> that applies for any isovalue. As <phrase>grid</phrase> cells are decompressed, we immediately extract vertices and <phrase>triangles</phrase> of the <phrase>isosurface</phrase>. Our output is a <phrase>coherent</phrase> streaming mesh, which facilitates <phrase>subsequent processing</phrase>, including on-the-<phrase>fly</phrase> <phrase>simplification</phrase> and compression.
<phrase>Object Shape</phrase> Modelling from <phrase>Multiple Range Images</phrase> by Matching <phrase>Signed Distance</phrase> Fields.
Filling the <phrase>Signed Distance</phrase> Field by <phrase>Fitting</phrase> <phrase>Local</phrase> <phrase>Quadrics</phrase>.
We propose a method of filling unmeasured regions of <phrase>shape models</phrase> integrated from multiple measurements of <phrase>surface shapes</phrase>. We use the <phrase>signed distance</phrase> field (<phrase>SDF</phrase>) as <phrase>shape representation</phrase> that contains <phrase>information</phrase> of the <phrase>surface normal</phrase> along with the <phrase>signed</phrase> distance at the <phrase>closest point</phrase> on the surface from the <phrase>sampling</phrase> point. We solve this problem by iteratively <phrase>fitting</phrase> <phrase>quadratic function</phrase> to generate smoothly connected <phrase>SDF</phrase>. We analyzed the relationship between the <phrase>quadratic</phrase> coefficients and the <phrase>surface curvature</phrase>, and by using the coefficients, we evenly propagated the <phrase>SDF</phrase> so that it satisfies the constraints of the field. The <phrase>proposed method</phrase> was tested on <phrase>synthetic data</phrase> and <phrase>real data</phrase> that was generated by <phrase>integrating multiple</phrase> <phrase>range</phrase> images.
Generation, Visualization, and <phrase>Editing</phrase> of 3D <phrase>Video</phrase>.
<phrase>Effectivity</phrase> of <phrase>Spherical</phrase> <phrase>Object Reconstruction</phrase> Using <phrase>Star</phrase> -Shaped <phrase>Simplex</phrase> Meshes.
<phrase>High</phrase>-Resolution Cytometry Network <phrase>Project</phrase>: <phrase>Client/Server</phrase> System for 3D <phrase>Optical Microscope</phrase> <phrase>Data</phrase> Storage and Analysis.
If several <phrase>laboratories</phrase> work in the same field and need to cooperate, it is necessary to exchange and mutually compare their computer <phrase>results</phrase>. The <phrase>quick</phrase> way to solve this problem is to <phrase>unite</phrase> their <phrase>file formats</phrase> (if it is practicable) or to install new <phrase>software</phrase> systems, which are <phrase>data</phrase> or <phrase>file format</phrase> compatible. A much better <phrase>solution</phrase> is to use only one common system. This <phrase>article describes</phrase> the <phrase>architecture</phrase> of a new <phrase>client-server</phrase> system, which offers possibilities of effective <phrase>cooperation</phrase> for <phrase>laboratories</phrase> doing the <phrase>research</phrase> in the field of the <phrase>spatial</phrase> <phrase>organization</phrase> of <phrase>human genome</phrase>. However, the <phrase>system design</phrase> is determined mainly by <phrase>optical microscopy</phrase> principles and therefore the system can easily be <phrase>modified</phrase> for use in other applications or environments. The most pressing problem during the <phrase>system design</phrase> was how to share and process large 3D <phrase>image data</phrase> in <phrase>client-server architecture</phrase>.
A <phrase>Model</phrase> (In)Validation Approach to <phrase>Gait</phrase> Recognition.
Edge-Constrained <phrase>Marching</phrase> <phrase>Triangles</phrase>.
<phrase>Enhanced</phrase> <phrase>Surface Reconstruction</phrase> from <phrase>Wide Baseline</phrase> Images.
This <phrase>paper</phrase> deals with the problem of <phrase>dense</phrase> matching from <phrase>stereo</phrase> images under <phrase>wide baseline</phrase> conditions. By considering the <phrase>characteristic properties</phrase> of <phrase>widely separated views</phrase>, we propose an extension to a <phrase>recently</phrase> published <phrase>algorithm</phrase> for detailed <phrase>reconstruction</phrase> of <phrase>continuous</phrase> surfaces. The <phrase>algorithm</phrase> compensates for the occurrent <phrase>affine</phrase> <phrase>distortion</phrase> between the views to allow <phrase>low level</phrase> <phrase>intensity based</phrase> comparison necessary for <phrase>dense</phrase> matching. The matching itself is performed by <phrase>an enhanced</phrase> <phrase>region</phrase> <phrase>rowing</phrase> based <phrase>affine</phrase> <phrase>propagation method</phrase> that takes surface <phrase>distortion</phrase> into account to handle complex <phrase>piecewise-smooth</phrase> surfaces. It is <phrase>experimentally shown</phrase> that this new method can achieve smooth and accurate <phrase>reconstruction</phrase> from <phrase>wide baseline</phrase> images of both <phrase>indoor and outdoor scenes</phrase>. To quantify the <phrase>reconstruction</phrase> <phrase>results</phrase> we have created <phrase>realistic synthetic</phrase> datasets with <phrase>ground truth</phrase>. These datasets form the core of a future <phrase>testbed</phrase> for comparison of different <phrase>wide baseline</phrase> <phrase>surface reconstruction</phrase> techniques. In the current study, <phrase>results</phrase> on the <phrase>synthetic images</phrase> are compared to the <phrase>ground truth</phrase> to measure the accuracy of our method.
An Easy <phrase>Viewer</phrase> for Out-of-Core Visualization of Huge <phrase>Point-Sampled</phrase> Models.
In this <phrase>paper</phrase>, we propose a <phrase>viewer</phrase> for huge <phrase>point-sampled</phrase> models by <phrase>combining</phrase> out-of-<phrase>core technologies</phrase> with <phrase>view-dependent</phrase> <phrase>level-of-detail</phrase> (<phrase>LOD</phrase>) control. This <phrase>viewer</phrase> is designed on the basis of a <phrase>multiresolution</phrase> <phrase>data structure</phrase> we have developed for <phrase>gaze</phrase>-<phrase>guided</phrase> visualization and transmission of 3D <phrase>point sets</phrase>. In <phrase>order</phrase> to reduce <phrase>memory</phrase> loads for huge <phrase>point sets</phrase> on <phrase>general</phrase> <phrase>PC</phrase> platforms, we introduce a <phrase>partition</phrase>-based out-of-core strategy to balance usage of main and <phrase>external memories</phrase>. At first, the <phrase>data</phrase> surface is <phrase>partitioned</phrase> into <phrase>small blocks</phrase> and points in each block are reorganized into error-controlled LODs by <phrase>hierarchical clustering</phrase> and <phrase>LOD</phrase> <phrase>organization</phrase>. In the <phrase>interactive rendering</phrase> process, a <phrase>data</phrase> <phrase>block scheduling</phrase> <phrase>algorithm</phrase> is used to realize the <phrase>view-dependent</phrase> <phrase>paging</phrase>. <phrase>Experimental</phrase> <phrase>results</phrase> show that the <phrase>viewer</phrase> can perform <phrase>interactive visualization</phrase> of huge point models on <phrase>commodity</phrase> graphics platforms with ease.
<phrase>Direct</phrase> and <phrase>Robust</phrase> <phrase>Voxelization</phrase> and Polygonization of <phrase>Free</phrase>-Form <phrase>CSG</phrase> <phrase>Solids</phrase>.
<phrase>Network-based</phrase> raditional <phrase>Japanese</phrase> <phrase>Crafting</phrase> Presentation System Using Agent and <phrase>Virtual Reality</phrase> Technologies.
<phrase>Network-based</phrase> raditional <phrase>Japanese</phrase> <phrase>Crafting</phrase> Presentation System Using Agent and <phrase>Virtual Reality</phrase> echnologies.
3D objects visualization for <phrase>remote</phrase> interactive <phrase>medical</phrase> applications.
<phrase>Adaptive</phrase> <phrase>Space Carving</phrase>.
In this work, we present <phrase>an adaptive</phrase> <phrase>space carving</phrase> method for <phrase>scene reconstruction</phrase> from a set of images obtained from <phrase>low cost</phrase> calibrated webcams. Our method uses a combination of <phrase>silhouette</phrase> and <phrase>photometric</phrase> <phrase>information</phrase> to efficiently carve the shape of the observed scene out of a <phrase>volumetric</phrase> space represented by an <phrase>octree</phrase> <phrase>data structure</phrase>. In this method different resolutions are considered both in <phrase>object space</phrase> and in <phrase>image space</phrase>. This <phrase>led</phrase> us to adopt a strategy in which the <phrase>information</phrase> used by the <phrase>photo</phrase>-consistency <phrase>test</phrase> is registered in scene space by <phrase>projective</phrase> <phrase>texture mapping</phrase>. Another <phrase>important question</phrase> addressed in this work is the <phrase>high</phrase> level of noise present in <phrase>low cost</phrase> webcams. To deal with this problem we devised a statistical <phrase>photo</phrase>-consistency <phrase>test</phrase> that uses <phrase>statistical estimators</phrase> for the noise introduced by the sensors of the cameras.
<phrase>Dense</phrase> <phrase>Multiple View Stereo</phrase> with <phrase>General</phrase> <phrase>Camera</phrase> Placement using <phrase>Tensor Voting</phrase>.
We present a <phrase>computational framework</phrase> for the inference of <phrase>dense</phrase> descriptions from <phrase>multiple view stereo</phrase> with <phrase>general</phrase> <phrase>camera</phrase> placement. Thus far <phrase>research</phrase> on <phrase>dense</phrase> <phrase>multiple view stereo</phrase> has evolved along three axes: computation of scene approximations in the form of <phrase>visual hulls</phrase>; <phrase>merging</phrase> of <phrase>depth maps</phrase> derived from simple configurations, such as <phrase>binocular</phrase> or <phrase>trinocular</phrase>; and <phrase>multiple view stereo</phrase> with <phrase>restricted</phrase> <phrase>camera</phrase> placement. These approaches are either <phrase>sub-optimal</phrase>, since they do not maximize the use of available <phrase>information</phrase>, or cannot be applied to <phrase>general</phrase> <phrase>camera</phrase> configurations. Our approach does not involve <phrase>binocular</phrase> processing other than the detection of <phrase>tentative</phrase> <phrase>pixel</phrase> correspondences. We require <phrase>calibration</phrase> <phrase>information</phrase> for all cameras and that there exist <phrase>camera</phrase> pairs which enable <phrase>automatic</phrase> <phrase>pixel</phrase> matching. The inference of scene surfaces is based on the premise that correct <phrase>pixel</phrase> correspondences, reconstructed in 3-<phrase>D</phrase>, form salient, <phrase>coherent</phrase> surfaces, while wrong correspondences form less <phrase>coherent</phrase> structures. The <phrase>tensor voting</phrase> framework is suitable for this task since it can process the <phrase>very large</phrase> datasets we generate with reasonable <phrase>computational complexity</phrase>. We show <phrase>results</phrase> on <phrase>real images</phrase> that present <phrase>numerous challenges</phrase>.
<phrase>Fast</phrase> 3D <phrase>Model</phrase> Acquisition from <phrase>Stereo</phrase> Images.
<phrase>Bayesian</phrase> <phrase>Surface Reconstruction</phrase>.
In this <phrase>paper</phrase> we illustrate <phrase>an innovative</phrase> method which estimates the surfaces -modelled as <phrase>polygonal meshes</phrase>-<phrase>bounding</phrase> objects present in a scene, viewed by arbitrarily placed cameras. We present a Montecarlo <phrase>based iterative</phrase> approach which, at every step, increases its <phrase>knowledge</phrase> about the scene <phrase>sampling</phrase> the unknown volume around the <phrase>current estimation</phrase>. Then, the samples which mostly appear to be consistent with the measurements are used to extend the mesh representing the surface. The <phrase>reconstruction</phrase> is <phrase>regularized</phrase> <phrase>applying</phrase> a <phrase>filter -based</phrase> on a <phrase>dynamic</phrase> system- to the mesh. This operation will preserve the <phrase>high</phrase> <phrase>curvature</phrase> areas of the surface, while <phrase>smoothing</phrase> away the noise in the estimation.
A Non <phrase>Causal</phrase> <phrase>Bayesian</phrase> Framework for <phrase>Object Tracking</phrase> and <phrase>Occlusion Handling</phrase> for the <phrase>Synthesis</phrase> of <phrase>Stereoscopic</phrase> <phrase>Video</phrase>.
This <phrase>paper</phrase> presents a framework for the <phrase>synthesis</phrase> of <phrase>stereoscopic</phrase> <phrase>video</phrase> using as input only a monoscopic <phrase>image sequence</phrase>. Initially, <phrase>bi-directional</phrase> 2D <phrase>motion estimation</phrase> is performed, which is followed by <phrase>an efficient</phrase> method for the <phrase>reliable</phrase> tracking of <phrase>object contours</phrase>. Rigid 3D motion and structure is recovered utilizing <phrase>extended Kalman filtering</phrase>. <phrase>Finally</phrase>, occlusions are dealt with a novel <phrase>Bayesian</phrase> framework, which exploits future <phrase>information</phrase> to correctly reconstruct <phrase>occluded areas</phrase>. <phrase>Experimental evaluation</phrase> shows that the <phrase>layered</phrase> object <phrase>scene representation</phrase>, combined with the proposed methods for <phrase>object tracking</phrase> throughout the <phrase>sequence</phrase> and <phrase>occlusion handling</phrase>, yields very <phrase>accurate results</phrase>.
<phrase>Exploring</phrase> Boundary Concavities in <phrase>Active</phrase> Contours and Surfaces.
<phrase>Active</phrase> contours and surfaces are <phrase>deformable models</phrase> used for 2D and 3D <phrase>image segmentation</phrase>. These models <phrase>generally lack</phrase> of convergence into boundary concavities, when <phrase>segmenting</phrase> highly concave objects. In this <phrase>paper</phrase>, we propose a method for <phrase>exploring</phrase> concavities, applicable on discrete <phrase>active</phrase> contours and surfaces deformed thanks to the <phrase>greedy algorithm</phrase>, which minimizes the <phrase>energy</phrase> <phrase>functional</phrase>. As a basis of this method, we introduce the <phrase>gradient</phrase> line <phrase>energy</phrase> (GLE), which goal is to make discrete parts of the surface coincide with boundaries, and the <phrase>exploration</phrase> force, computed from this <phrase>energy</phrase>, driving the surface into the object concavities. Our method lies on a <phrase>general</phrase> framework, enabling application on discrete 2D contours and 3D meshes with easy adaptation between both models.
<phrase>Segmenting</phrase> Correlation <phrase>Stereo</phrase> <phrase>Range</phrase> Images using <phrase>Surface Elements</phrase>.
This <phrase>paper</phrase> describes methods for <phrase>segmenting</phrase> <phrase>planar</phrase> surfaces from noisy 3D <phrase>data</phrase> obtained from correlation <phrase>stereo</phrase> vision. We make use of <phrase>local</phrase> <phrase>planar surface</phrase> elements called patchlets. Patchlets have 3D position, orientation and size parameters. As well, they have <phrase>positional</phrase> <phrase>confidence measures</phrase> based on the <phrase>stereo</phrase> <phrase>sensor</phrase> <phrase>model</phrase>. Patchlet orientations (i.e., <phrase>surface normals</phrase>) provide important additional dimensionality that reduces the ambiguity of segmentation-by-<phrase>clustering</phrase>. Patchlet size allows the use of continuity or coverage constraints when <phrase>segmenting</phrase> <phrase>bounded</phrase> surfaces from <phrase>depth images</phrase>. We use a <phrase>region</phrase>-growing approach to identify the number of surfaces that exist in a <phrase>stereo</phrase> image and obtain an <phrase>initial estimate</phrase> of the <phrase>surface parameters</phrase>. We refine segmentation using a <phrase>maximum likelihood</phrase> <phrase>clustering</phrase> approach that is <phrase>optimised</phrase> with <phrase>Expectation-Maximisation</phrase>. <phrase>Confidence measures</phrase> on the patchlet parameters allow proper <phrase>weighting</phrase> of patchlet contributions to the <phrase>solution</phrase>. We provide <phrase>experimental</phrase> <phrase>results</phrase> of the segmentation on complex <phrase>outdoor</phrase> scenes.
<phrase>Viewpoint</phrase> Consistent <phrase>Texture Synthesis</phrase>.
The purpose of this work is to synthesize textures of <phrase>rough</phrase>, <phrase>real world</phrase> surfaces under <phrase>freely chosen</phrase> viewing and <phrase>illumination directions</phrase>. Moreover, such textures are <phrase>produced</phrase> for <phrase>continuously changing</phrase> directions in such a way that the different textures are <phrase>mutually consistent</phrase>, i.e. emulate the same piece of surface. This is necessary for 3D <phrase>animation</phrase>. It is assumed that the mesostructure (<phrase>small-scale</phrase>) <phrase>geometry</phrase> of a surface is not known, and that the only input consists of a set of images, taken under different viewing and <phrase>illumination directions</phrase>. These are automatically aligned to build an appropriate <phrase>Bidirectional Texture Function</phrase> (<phrase>BTF</phrase>). Directly <phrase>extending</phrase> 2D <phrase>synthesis</phrase> methods for <phrase>pixels</phrase> to complete <phrase>BTF</phrase> columns has drawbacks which are exposed, and a <phrase>superior</phrase> <phrase>sequential</phrase> but <phrase>highly parallelizable</phrase> <phrase>algorithm</phrase> is proposed. Examples demonstrate the quality of the <phrase>results</phrase>.
A Hierarchy of Cameras for 3D <phrase>Photography</phrase>.
The <phrase>view-independent</phrase> visualization of 3D scenes is most often based on rendering accurate 3D models or utilizes <phrase>image-based rendering</phrase> techniques. To compute the 3D structure of a scene from a moving <phrase>vision sensor</phrase> or to use <phrase>image-based</phrase> rendering approaches, we need to be able to estimate the motion of the <phrase>sensor</phrase> from the recorded <phrase>image information</phrase> with <phrase>high</phrase> accuracy, a problem that has been well-studied. In this work, we investigate the relationship between <phrase>camera</phrase> <phrase>design</phrase> and our ability to perform accurate 3D <phrase>photography</phrase>, by <phrase>examining</phrase> the influence of <phrase>camera</phrase> <phrase>design</phrase> on the estimation of the motion and structure of a scene from <phrase>video</phrase> <phrase>data</phrase>. By relating the differential structure of the <phrase>time varying</phrase> <phrase>plenoptic function</phrase> to different known and new <phrase>camera</phrase> designs, we can establish a hierarchy of cameras based upon the stability and complexity of the computations necessary to estimate <phrase>structure and motion</phrase>. At the <phrase>low end</phrase> of this hierarchy is the standard <phrase>planar</phrase> <phrase>pinhole camera</phrase> for which the <phrase>structure from motion</phrase> problem is <phrase>non-linear</phrase> and <phrase>ill-posed</phrase>. At the <phrase>high</phrase> end is a <phrase>camera</phrase>, which we call the full <phrase>field of view</phrase> polydioptric <phrase>camera</phrase>, for which the <phrase>motion estimation</phrase> problem can be <phrase>solved independently</phrase> of the depth of the scene which leads to <phrase>fast</phrase> and <phrase>robust</phrase> <phrase>algorithms</phrase> for 3D <phrase>Photography</phrase>. In between are <phrase>multiple view</phrase> cameras with a large <phrase>field of view</phrase> which we have built, as well as <phrase>omni-directional</phrase> sensors.
<phrase>Automatic</phrase> <phrase>Passive</phrase> Recovery of 3D from Images and <phrase>Video</phrase>.
This <phrase>paper</phrase> gives a <phrase>summary</phrase> of <phrase>automatic</phrase> <phrase>passive</phrase> <phrase>reconstruction</phrase> of 3D scenes from images and <phrase>video</phrase>. Features are tracked between the images. Relative <phrase>camera</phrase> poses are then estimated based on the feature tracks. Both the <phrase>feature tracking</phrase> and the <phrase>robust</phrase> method used to estimate the <phrase>camera</phrase> poses has <phrase>recently</phrase> been shown to provide <phrase>robust</phrase> <phrase>real-time</phrase> performance. Given the <phrase>camera</phrase> poses, a more elaborate method is used to derive <phrase>dense</phrase> <phrase>textured surfaces</phrase>. The <phrase>dense</phrase> <phrase>reconstruction</phrase> method was originally part of the authors <phrase>thesis</phrase> [<phrase>Automatic</phrase> <phrase>Dense</phrase> <phrase>Reconstruction</phrase> from <phrase>Uncalibrated Video Sequences</phrase>]. It first computesdepth <phrase>maps</phrase> using <phrase>graph cuts</phrase>, <phrase>optimizing</phrase> a <phrase>Bayesian</phrase> formulation. The <phrase>graph cut</phrase> operation is used to <phrase>let</phrase> <phrase>depth map</phrase> hypotheses from various sources compete in <phrase>order</phrase> to optimize the <phrase>cost function</phrase>. The <phrase>hypothesis</phrase> generators used are <phrase>feature based</phrase> <phrase>surface triangulation</phrase>, <phrase>plane fitting</phrase> and <phrase>multi-hypothesis</phrase> <phrase>multi-scale</phrase> <phrase>patch-based</phrase> <phrase>stereo</phrase>. The requirements for a <phrase>cost function</phrase> to fit into the <phrase>graph cut</phrase> framework were already given in [<phrase>Automatic</phrase> <phrase>Dense</phrase> <phrase>Reconstruction</phrase> from <phrase>Uncalibrated Video Sequences</phrase>], along with a procedure for <phrase>constructing</phrase> the <phrase>graph</phrase> weights corresponding to any <phrase>cost function</phrase> that satisfies the requirements. <phrase>Depth maps</phrase> from many different viewpoints are then robustly fused to give a consistent <phrase>global</phrase> result using a process called <phrase>median</phrase> <phrase>fusion</phrase>. The robustness of the <phrase>median</phrase> <phrase>fusion</phrase> is important. It departs from the too <phrase>common practice</phrase> of <phrase>fusing</phrase> <phrase>results</phrase> by either using the <phrase>union</phrase> of <phrase>free</phrase>-space constraints as the resulting <phrase>free</phrase>-space, or the <phrase>union</phrase> of all predicted surfaces as the resulting surfaces, which is tremendously <phrase>error-prone</phrase>, since it essentially corresponds to taking either the <phrase>minimum</phrase> or maximum of the individual <phrase>results</phrase>.
Heterogeneous <phrase>Deformation Model</phrase> for 3D Shape and <phrase>Motion Recovery</phrase> from <phrase>Multi-Viewpoint</phrase> Images.
This <phrase>paper</phrase> presents a framework for <phrase>dynamic</phrase> 3D shape and <phrase>motion reconstruction</phrase> from <phrase>multi-viewpoint</phrase> images using a <phrase>deformable mesh</phrase> <phrase>model</phrase>. By deforming a mesh at a frame to that at the <phrase>next</phrase> frame, we can obtain both 3D shape and motion of the object simultaneously. The deformation process of our mesh <phrase>model</phrase> is heterogeneous. Each vertex changes its deformation process according to its 1) <phrase>photometric</phrase> <phrase>property</phrase> (i.e., if it has prominent texture or not), and 2) <phrase>physical property</phrase> (i.e., if it is an element of rigid part of the object or not). This heterogeneous <phrase>deformation model</phrase> enables us to reconstruct the object which consists of different kinds of materials or parts with different <phrase>motion models</phrase>, e.g., rigidly acting <phrase>body parts</phrase> and deforming <phrase>soft</phrase> clothes or its skins, by a <phrase>single</phrase> and <phrase>unified</phrase> <phrase>computational framework</phrase>.
The Influence of Shape on <phrase>Image Correspondence</phrase>.
We examine the implications of shape on the process of <phrase>finding</phrase> <phrase>dense correspondence</phrase> and <phrase>half-occlusions</phrase> for a <phrase>stereo</phrase> pair of images. The desired <phrase>property</phrase> of the <phrase>depth map</phrase> is that it should be a <phrase>piecewise</phrase> <phrase>continuous function</phrase> which is consistent with the images and which has the <phrase>minimum</phrase> number of discontinuities. To zeroeth <phrase>order</phrase>, <phrase>piecewise</phrase> continuity becomes <phrase>piecewise</phrase> <phrase>constancy</phrase>. Using this approximation, we first discuss an approach for dealing with such a <phrase>fronto-parallel</phrase> shapeless world, and the problems involved therein. We then introduce <phrase>horizontal and vertical</phrase> <phrase>slant</phrase> to create a <phrase>first order</phrase> approximation to <phrase>piecewise</phrase> continuity. We highlight the fact that a horizontally slanted surface (<phrase>ie</phrase>. having depth variation in the direction of the <phrase>separation</phrase> of the two cameras) will appear horizontally stretched in one image as compared to the other image. Thus, while corresponding two images, N <phrase>pixels</phrase> on a scanline in one image may correspond to a different number of <phrase>pixels</phrase> <phrase>M</phrase> in the other image, which has consequences with regard to <phrase>sampling</phrase> and <phrase>occlusion detection</phrase>. We also discuss the asymmetry between <phrase>vertical and horizontal</phrase> <phrase>slant</phrase>, and the central role of non-<phrase>horizontal</phrase> edges in the context of <phrase>vertical</phrase> <phrase>slant</phrase>. Using experiments, we discuss cases where <phrase>existing algorithms</phrase> fail, and how the <phrase>incorporation</phrase> of new constraints provides correct <phrase>results</phrase>.
Registration of <phrase>Range</phrase> Images that Preserves <phrase>Local Surface</phrase> Structures and <phrase>Color</phrase>.
We propose an <phrase>ICP</phrase>-<phrase>based registration</phrase> method for <phrase>range</phrase> images that preserves fundamental features, i.e., <phrase>local</phrase> structures and <phrase>color</phrase>, of <phrase>object surfaces</phrase>. The method employs <phrase>local</phrase> surfaces as an attribute for establishing correspondences between <phrase>range</phrase> images where <phrase>local</phrase> surfaces are evaluated geometrically and photometrically. In <phrase>estimating</phrase> correspondences between <phrase>range</phrase> images, our method evaluates consistency of shape patterns and <phrase>chromaticity</phrase> of <phrase>local</phrase> surfaces together. In <phrase>estimating</phrase> <phrase>transformation parameters</phrase> relating the coordinates between different <phrase>range</phrase> images, on the other hand, our method evaluates <phrase>skewness</phrase> and <phrase>chromaticity</phrase> of correspondences. These two kinds of evaluation enhances accuracy of the estimation and <phrase>results</phrase> in preserving <phrase>local</phrase> structures and <phrase>color</phrase> of <phrase>object surfaces</phrase>.
<phrase>Construction</phrase> of <phrase>Animal</phrase> Models and <phrase>Motion Synthesis</phrase> in 3D <phrase>Virtual</phrase> Environments using <phrase>Image Sequences</phrase>.
In this <phrase>paper</phrase>, we describe a system that can build 3D <phrase>animal</phrase> models and synthesize animations in 3D <phrase>virtual</phrase> environments. The <phrase>model</phrase> is constructed by 2D <phrase>images captured</phrase> by <phrase>specific views</phrase>. The <phrase>animation</phrase> is synthesised by using <phrase>physical motion</phrase> models of the <phrase>animal</phrase> and tracking <phrase>data</phrase> from <phrase>image sequences</phrase>. <phrase>Finally</phrase>, the user selects some points of the 3D world and a smooth and <phrase>safe</phrase> <phrase>motion path</phrase>, which <phrase>passes</phrase> by these points, is created. The main assumption of the 3D modelling is that the <phrase>animal</phrase> could be <phrase>divided into</phrase> parts whose normal sections are ellipses. Joints and angles between <phrase>skeleton</phrase> points are used in <phrase>order</phrase> to decrease models complexity. Using the above methodology, a <phrase>snake</phrase>, a <phrase>lizard</phrase> and a <phrase>goat</phrase> are reconstructed.
The <phrase>Virtual</phrase> Boutique: a Synergic Approach to <phrase>Virtualization</phrase>, <phrase>Content-based</phrase> <phrase>Management</phrase> of 3D <phrase>Information</phrase>, 3D <phrase>Data Mining</phrase> an <phrase>Virtual Reality</phrase> for <phrase>E-commerce</phrase>.
Specularity <phrase>Elimination</phrase> in <phrase>Range</phrase> Sensing for Accurate 3D Modeling of <phrase>Specular</phrase> Objects.
We present a novel <phrase>range</phrase> sensing method that is capable of <phrase>constructing</phrase> accurate 3Dmodels of <phrase>specular</phrase> objects. Our <phrase>method utilizes</phrase> a new <phrase>range</phrase> <phrase>imaging</phrase> concept called multi-<phrase>peak</phrase> <phrase>range</phrase> <phrase>imaging</phrase>, which accounts for the effects of mutual <phrase>reflections</phrase>. False measurements generated by mutual <phrase>reflections</phrase> are then eliminated by <phrase>applying</phrase> a series of constraint <phrase>tests</phrase> based on <phrase>local</phrase> <phrase>smoothness</phrase>, <phrase>global</phrase> coordinate consistency and <phrase>visibility</phrase> consistency. We show the usefulness of our method by <phrase>applying</phrase> the method to three <phrase>real objects</phrase> with <phrase>specular</phrase> surfaces. The <phrase>ground truth data</phrase> for those three objects were also acquired in <phrase>order</phrase> to evaluate the <phrase>elimination</phrase> of false measurements and to justify the selection of the parameters in the constraint <phrase>tests</phrase>. <phrase>Experimental</phrase> <phrase>results</phrase> indicate that our method <phrase>significantly improves</phrase> upon the <phrase>traditional methods</phrase> for <phrase>constructing</phrase> <phrase>reliable</phrase> 3D models of <phrase>specular</phrase> objects with <phrase>complex shapes</phrase>.
3D Mesh <phrase>Wavelet</phrase> Coding Using <phrase>Efficient</phrase> <phrase>Model</phrase>-based <phrase>Bit</phrase> Allocation.
3D <phrase>Non-Linear</phrase> <phrase>Invisible</phrase> <phrase>Boundary Detection</phrase> Filters.
The <phrase>human</phrase> vision system can discriminate regions which differ up to the <phrase>second order statistics</phrase> only. A <phrase>lot</phrase> of <phrase>malignant</phrase> tumours have boundaries which are not visible to the <phrase>human eye</phrase>. We present an <phrase>algorithm</phrase> designed to reveal "<phrase>hidden</phrase>" boundaries in <phrase>grey level images</phrase>, by <phrase>computing</phrase> gradients in <phrase>higher order statistics</phrase> of the <phrase>data</phrase>. We demonstrate it by <phrase>applying</phrase> it to the identification of possible "<phrase>hidden</phrase>" boundaries of gliomas as manifest themselves in <phrase>MRI</phrase> 3D scans.
<phrase>Surface Segmentation</phrase> Using <phrase>Geodesic</phrase> Centroidal Tesselation.
In this <phrase>paper</phrase>, we solve the problem of mesh <phrase>partition</phrase> using <phrase>intrinsic</phrase> computations on the 3D surface. The key concept is the notion of centroidal tesselation that is widely used in an eucidan settings. Using the <phrase>Fast</phrase> <phrase>Marching</phrase> <phrase>algorithm</phrase>, we are able to <phrase>recast</phrase> this <phrase>powerful tool</phrase> in the <phrase>language</phrase> of <phrase>mesh processing</phrase>. This method naturally fits into a framework for 3D <phrase>geometry</phrase> modelling and processing that uses only <phrase>fast</phrase> <phrase>geodesic</phrase> computations. With the use of <phrase>classical</phrase> <phrase>geodesic</phrase>-based <phrase>building</phrase> blocks, we are able to take into account any available <phrase>information</phrase> or requirement such as a 2D texture or the <phrase>curvature</phrase> of the surface.
Detection and Compensation of <phrase>Image Sequence</phrase> <phrase>Jitter</phrase> Due to an Unstable <phrase>CCD Camera</phrase> for <phrase>Video</phrase> Tracking of a <phrase>Moving Target</phrase>.
<phrase>Nowadays</phrase> <phrase>image motion</phrase> analysis is considered as a significant subject in <phrase>image processing</phrase> and according to its characteristics is <phrase>divided into</phrase> different categories. This <phrase>paper</phrase> focuses on <phrase>camera</phrase> <phrase>jitter</phrase> as <phrase>fast</phrase> translations in <phrase>image sequence</phrase> due to an unstable platform. Our studies have <phrase>led</phrase> to do <phrase>correlation matching</phrase> [Motion <phrase>Displacement Estimation</phrase> Using an <phrase>Affine</phrase> Modelfor <phrase>Image Matching</phrase>] between well featured templates[<phrase>Edge Detection</phrase> using <phrase>KL</phrase> Transform, <phrase>Extracting</phrase> Good Features for <phrase>Motion Estimation</phrase>] of <phrase>successive frames</phrase> to prevent <phrase>aperture</phrase> problems and thus have good estimation of the translations. But <phrase>camera</phrase> <phrase>vibration</phrase> may also suffer from <phrase>rotation and scaling</phrase> as <phrase>nonlinear</phrase> motions [Detection of <phrase>Non-Uniform</phrase> Motion in <phrase>Image Sequences</phrase> using a <phrase>Reduced Order</phrase> <phrase>Likelihood Ratio Test</phrase>] that may defect thematching process. Therefore mapping of 3D <phrase>image points</phrase> into <phrase>camera image</phrase> plane has been investigated to trace the effects of these <phrase>nonlinear</phrase> parameters in 2D <phrase>motion equations</phrase> [<phrase>Image Based</phrase> <phrase>Measurement Systems</phrase>]. Now by <phrase>approximating</phrase> these equations for minute rotation and <phrase>bounded</phrase> scaling between frame <phrase>i</phrase> and <phrase>i</phrase>+1, the set of <phrase>motion equations</phrase> with four unknowns (rotation, scaling, <phrase>horizontal /vertical</phrase> translations) could be solved just by <phrase>LSE</phrase> [<phrase>Kalman Filtering</phrase>, Theory and Practice using <phrase>MATLAB</phrase>] method for a unique and optimized response. After all when you apply the estimated displacements on each frame for compensation, an <phrase>stabilized</phrase> <phrase>sequence</phrase> will conclude.
Surface <phrase>Illuminance</phrase> Flow.
We introduce the concept of "surface <phrase>illuminance</phrase> flow" in two steps.First we reiterate the notion of the "<phrase>light</phrase> <phrase>vector</phrase>", then we proceed to decompose the <phrase>light</phrase> <phrase>vector</phrase> into a scalar "normal <phrase>illuminance</phrase>" and a <phrase>vector</phrase> "surface <phrase>illuminance</phrase> flow".The scalar normal <phrase>illuminance</phrase> generates the familiar <phrase>illuminance</phrase> pattern that is often known as the "shading".The <phrase>vector</phrase> surface <phrase>illuminance</phrase> flow is irrelevant for <phrase>smooth surfaces</phrase> (which probably explains why it is <phrase>conventionally</phrase> ignored) but it generates the texture due to surface mesorelief.We show how observation of the <phrase>illuminance</phrase> induced texture leads to <phrase>robust</phrase> inferences of the surface <phrase>illuminance flow</phrase> direction <phrase>modulo</phrase> <phrase>180°</phrase>. This makes surface <phrase>illuminance</phrase> flow a <phrase>property</phrase> that is <phrase>observable</phrase> in natural scenes.Muchl <phrase>ike</phrase> <phrase>optical flow</phrase>, the surface <phrase>illuminance</phrase> flow is largely due to a <phrase>global</phrase> <phrase>property</phrase> that exists <phrase>independent</phrase> of <phrase>local</phrase> structure, namely the direction of the <phrase>general</phrase> <phrase>illuminating</phrase> <phrase>beam</phrase> (<phrase>sunlight</phrase> or <phrase>light</phrase> from the overcast <phrase>sky</phrase> in a typical outdoors scene).However, due to the fact that there exists "true <phrase>screening</phrase>" in <phrase>radiometry</phrase> (thus removing any hope for a "<phrase>field theory</phrase>" of <phrase>radiometry</phrase>) the <phrase>local</phrase> <phrase>scene structure</phrase> has an influence on the <phrase>local</phrase> <phrase>light</phrase> field.Such "<phrase>vignetting</phrase>" is a main cause of the complexity of <phrase>radiometry</phrase>, the other cause being the ever present multiple scatterings.This complicates <phrase>matters</phrase> but also introduces additional sources of information.We illustrate instances of the observation of <phrase>illuminance</phrase> flow in scenes.We also present a <phrase>data</phrase> base of roughly <phrase>spherical</phrase> objects, <phrase>illuminated</phrase> in a number of standard ways that we have used to study <phrase>illuminance</phrase> flow over actual <phrase>rough</phrase> objects.
<phrase>Interactive Modeling</phrase> from <phrase>Dense</phrase> <phrase>Color</phrase> and <phrase>Sparse</phrase> Depth.
We present <phrase>research</phrase> in <phrase>scene modeling</phrase>. The task is to build <phrase>digital</phrase> models of <phrase>natural scenes</phrase> that support interactive, <phrase>photorealistic</phrase> rendering. <phrase>Scene modeling</phrase> is the bottleneck in many <phrase>computer graphics</phrase> applications, notably <phrase>virtual</phrase> training, <phrase>geometric</phrase> modeling for <phrase>physical simulation</phrase>, <phrase>cultural heritage preservation</phrase>, <phrase>internet marketing</phrase>, and <phrase>gaming</phrase>. Capturing <phrase>complex scenes</phrase> with current modeling <phrase>technology</phrase> is slow, difficult, and expensive. We describe <phrase>an interactive</phrase> modeling system that has the potential to solve these problems.
Comparison of 3D <phrase>Measurement Techniques</phrase> in <phrase>Cultural Heritage</phrase> Application: User <phrase>Point of View</phrase>.
3D <phrase>Model</phrase> Retrieval Based on 2D <phrase>Slice</phrase> <phrase>Similarity Measurements</phrase>.
<phrase>Volume Rendering</phrase> on the <phrase>Internet</phrase>.
<phrase>Surface Normals</phrase> and Height from <phrase>Non-Lambertian</phrase> <phrase>Image Data</phrase>.
It is well known that many surfaces exhibit <phrase>reflectance</phrase> that is not well modelled by <phrase>Lambert's law</phrase>. This is the case not only for surfaces that are <phrase>rough</phrase> or <phrase>shiny</phrase>, but also those that are matte and composed of materials that are <phrase>particle</phrase> <phrase>suspensions</phrase>. As a result, standard <phrase>Lambertian</phrase> shape-from-shadingmethods can not be <phrase>applied directly</phrase> to the analysis of <phrase>rough</phrase> and <phrase>shiny surfaces</phrase>. In <phrase>order</phrase> to overcome this difficulty, in this <phrase>paper</phrase>, weconsider how to reconstruct the <phrase>Lambertian</phrase> component for <phrase>rough</phrase> and <phrase>shiny</phrase> surfaceswhen the object is <phrase>illuminated</phrase> in the <phrase>viewing direction</phrase>. To do this we make use of the <phrase>diffuse reflectance</phrase> models described by Oren and Nayar, and by Wolff. Our experiments with <phrase>synthetic and real-world</phrase> <phrase>data</phrase> reveal the effectiveness of the <phrase>correction method</phrase>, leading to improved <phrase>surface normal</phrase> and <phrase>height recovery</phrase>.
Testing <phrase>Reflectance</phrase> Models Against <phrase>Radiance</phrase> <phrase>Data</phrase>.
This <phrase>paper</phrase> describes <phrase>an empirical investigation</phrase> of departures from <phrase>Lambert's law</phrase> for <phrase>rough</phrase> and <phrase>shiny surfaces</phrase>. We commence by using a <phrase>recently</phrase> reported method to recover estimates ofthe <phrase>surface radiance</phrase> <phrase>function</phrase> for objects <phrase>illuminated</phrase> in the <phrase>viewer</phrase> direction. This method is <phrase>non-parametric</phrase>, and offers the advantage that it is simple to use since it does not require detailed <phrase>camera calibration</phrase>. We compare the <phrase>radiance</phrase> <phrase>data</phrase> with a number of <phrase>phenomenological</phrase> and <phrase>physics</phrase>-basedreflectance models. The models studied include those of Oren-Nayar, Wolff and different variants of the <phrase>Beckmann model</phrase>. The <phrase>main conclusion</phrase> of the study is that among these models the <phrase>best fit</phrase> to the <phrase>empirical data</phrase> is found to be the Wolff <phrase>model</phrase> for smooth objects and the <phrase>modified</phrase> <phrase>Beckmann model</phrase> for <phrase>rough</phrase> objects.
<phrase>A Unified</phrase> Approach for <phrase>Motion Analysis</phrase> and <phrase>View Synthesis</phrase>.
<phrase>Image based</phrase> rendering (<phrase>IBR</phrase>) consists of several steps: (<phrase>i</phrase>) <phrase>Calibration</phrase> (or <phrase>ego-motion</phrase> computation) of all <phrase>input images</phrase>. (<phrase>ii</phrase>) <phrase>Determination</phrase> of regions in the <phrase>input images</phrase> used to synthesize the new view. (<phrase>iii</phrase>) <phrase>Interpolating</phrase> the new view from the selected areas of the <phrase>input images</phrase>. We propose <phrase>a unified</phrase> representation for all these aspects of <phrase>IBR</phrase> using the <phrase>Space-Time</phrase> (<phrase>x-y</phrase>-<phrase>t</phrase>) volume. The presented approach is very <phrase>robust</phrase>, and allows to use <phrase>IBR</phrase> in <phrase>general</phrase> conditions even with a <phrase>hand-held camera</phrase>. To take <phrase>care</phrase> of (<phrase>i</phrase>), the <phrase>Space-Time</phrase> volume is constructed by placing frames at locations along the time <phrase>axis</phrase> so that <phrase>image features</phrase> create <phrase>straight lines</phrase> in the <phrase>EPI</phrase> (<phrase>epipolar plane</phrase> images). Different slices of the <phrase>Space-Time</phrase> volume are used to produce new views, taking <phrase>care</phrase> of (<phrase>ii</phrase>). Step (<phrase>iii</phrase>) is done by <phrase>interpolating</phrase> between image samples using the <phrase>feature lines</phrase> in the <phrase>EPI</phrase> images. <phrase>IBR</phrase> Examples are shown for various cases: sequences taken from a driving <phrase>car</phrase>, from a <phrase>hand held camera</phrase>, or when using a <phrase>tripod</phrase>.
A Surface Partitioning <phrase>Spectrum</phrase> (<phrase>SPS</phrase>) for Retrieval and <phrase>Indexing</phrase> of 3D <phrase>CAD</phrase> Models.
<phrase>Manual indexing</phrase> of <phrase>large databases</phrase> of <phrase>geometric information</phrase> is costly and often impracticable. Because of this <phrase>research</phrase> into retrieval and <phrase>indexing</phrase> schemes has focused on the development of various 3D to 2D mappings that characterise a shape as a <phrase>histogram</phrase> with a small number of parameters. Many methods of <phrase>generating</phrase> such 2D <phrase>signatures</phrase> (i.e. histograms) have been proposed, generally based on <phrase>geometric</phrase> measures of say <phrase>curvature</phrase> or distance. However these <phrase>geometric</phrase> <phrase>signatures</phrase> lack <phrase>information</phrase> about <phrase>topology</phrase> and tend to become indistinct as the complexity of the shape increases. This <phrase>paper</phrase> describes a new method for <phrase>characterising</phrase> both the <phrase>geometry</phrase> and <phrase>topology</phrase> of shapes in a <phrase>single</phrase> 2D <phrase>graph</phrase>, the Surface Partitioning <phrase>Spectrum</phrase> (<phrase>SPS</phrase>). We evaluate the effectiveness of using the <phrase>SPS</phrase> with a <phrase>Neural Network</phrase> to assess the similarity of shapes within a <phrase>test</phrase> set.
Visualization of <phrase>Arbitrary-Shaped</phrase> 3D Scenes on <phrase>Depth-Limited</phrase> 3D Displays.
We propose a depth scaling method that enables visualization of <phrase>arbitrary-shaped</phrase> 3D scenes on 3D displays.Most current 3D displays have a depth limitation, while the scene to be displayed has not.The trivial solutions as clipping or <phrase>linear scaling</phrase> of the scene's 3D <phrase>bounding box</phrase> suffer from non-<phrase>optimal</phrase> utilization of the display's capabilities. Our approach uses <phrase>spatially adaptive</phrase> depth scaling that maximizes the <phrase>perceptual</phrase> 3D effect.From the original <phrase>scene geometry</phrase>, the <phrase>topology</phrase> and <phrase>local</phrase> <phrase>depth ordering</phrase> among objects are preserved, while depth <phrase>linearity</phrase> is disregarded. The scaling method applies to nearly all 3D displays, such as <phrase>glasses</phrase>-based, <phrase>head</phrase>-tracked, <phrase>multi-view</phrase>, <phrase>holographic</phrase> and <phrase>volumetric</phrase> 3D displays.Subjective <phrase>tests</phrase> with the <phrase>Dynamic</phrase> <phrase>Dimension</phrase> display system show that our method <phrase>significantly increases</phrase> the <phrase>perceptual</phrase> 3D effect.
ATTEST: <phrase>Advanced</phrase> <phrase>Three-dimensional</phrase> <phrase>Television</phrase> System Technologies.
Accurate and <phrase>robust</phrase> marker <phrase>localization algorithm</phrase> for <phrase>camera calibration</phrase>.
Empirical <phrase>Calibration</phrase> Method for Adding <phrase>Colour</phrase> to <phrase>Range</phrase> Images.
<phrase>Estimating</phrase> the <phrase>Surface Radiance</phrase> <phrase>Function</phrase> from <phrase>Single</phrase> Images.
This <phrase>paper</phrase> describes a simple method for <phrase>estimating</phrase> the <phrase>surface radiance</phrase> <phrase>function</phrase> from <phrase>single</phrase> images of <phrase>smooth surfaces</phrase> made of materials whose <phrase>reflectance</phrase> <phrase>function</phrase> is <phrase>isotropic</phrase> and <phrase>monotonic</phrase>. The method makes <phrase>implicit</phrase> use of the <phrase>Gauss</phrase> <phrase>map</phrase> between the surface and a <phrase>unit sphere</phrase>. We assume that the material <phrase>brightness</phrase> is <phrase>monotonic</phrase> with respect to the angle between the <phrase>illuminant</phrase> direction and the <phrase>surface normal</phrase>. Under conditions in which the <phrase>light</phrase> source and the <phrase>viewer</phrase> directions are identical, we show how a <phrase>tabular</phrase> representation of the <phrase>surface radiance</phrase> <phrase>function</phrase> can be estimated using the <phrase>cumulative</phrase> distribution of <phrase>image gradients</phrase>. Using this <phrase>tabular</phrase> representation of the <phrase>radiance</phrase> <phrase>function</phrase>, surfaces may be rendered under varying <phrase>light</phrase> source direction by <phrase>rotating</phrase> the corresponding <phrase>reflectance</phrase> <phrase>map</phrase> on the <phrase>Gauss</phrase> <phrase>sphere</phrase> about the <phrase>specular</phrase> <phrase>spike</phrase> direction. We present a sensitivity study on <phrase>synthetic and real-world</phrase> imagery. We also present two applications which make use of the estimated <phrase>radiance</phrase> <phrase>function</phrase>. The first of these illustrates how the <phrase>radiance</phrase> <phrase>function</phrase> estimates can be used to render objects when the <phrase>light</phrase> and <phrase>viewer</phrase> directions are <phrase>no longer</phrase> coincident. The second application involves <phrase>applying</phrase> corrected <phrase>Lambertian</phrase> <phrase>radiance</phrase> to <phrase>rough</phrase> and <phrase>shiny surfaces</phrase>.
<phrase>Surface Height</phrase> Recovery Using <phrase>Heat Flow</phrase> and <phrase>Manifold</phrase> <phrase>Embedding</phrase>.
This <phrase>paper</phrase> makes two contributions to the problem of <phrase>shape-from-shading</phrase>. First, we develop a new method for <phrase>surface normal</phrase> recovery. We pose the problem as that of solving the <phrase>steady state</phrase> <phrase>heat equation</phrase> subject to the <phrase>hard constraint</phrase> that <phrase>Lambert's law</phrase> is satisfied. According to this <phrase>picture</phrase>, the <phrase>surface normals</phrase> are found by taking the <phrase>gradient</phrase> of a <phrase>scalar field</phrase>. The <phrase>heat equation</phrase> for the <phrase>scalar field</phrase> can be solved using simple <phrase>finite difference</phrase> methods and leads to an <phrase>iterative</phrase> procedure for <phrase>surface normal</phrase> estimation. The second contribution is to show how <phrase>surface height</phrase> recovery from the <phrase>field of surface normals</phrase> can be posed as one of <phrase>low dimensional embedding</phrase>. We experiment with the resulting method on a <phrase>variety</phrase> of <phrase>real-world</phrase> <phrase>image data</phrase>, where it produces qualitatively good <phrase>reconstructed surfaces</phrase>.
<phrase>Audio effects</phrase> to enhance <phrase>spatial</phrase> informition displays.
<phrase>Estimating</phrase> Curvatures and Their Derivatives on <phrase>Triangle</phrase> Meshes.
The computation of <phrase>curvature</phrase> and other <phrase>differential properties</phrase> of surfaces is essential formany techniques in analysis and rendering. We present a <phrase>finite-differences</phrase> approach for <phrase>estimating</phrase> curvatures on <phrase>irregular</phrase> <phrase>triangle</phrase> meshes that may be thought of as an extension of a common method for <phrase>estimating</phrase> per-<phrase>vertex normals</phrase>. The technique is <phrase>efficient</phrase> in space and time, and <phrase>results</phrase> in <phrase>significantly fewer</phrase> <phrase>outlier</phrase> estimates while more broadly offering accuracy comparable to <phrase>existing methods</phrase>. It generalizes naturally to <phrase>computing</phrase> derivatives of <phrase>curvature</phrase> and <phrase>higher-order</phrase> surface <phrase>differentials</phrase>.
<phrase>Colon</phrase> Centreline Calculation for <phrase>CT</phrase> Colonography using <phrase>Optimised</phrase> 3D <phrase>Topological</phrase> Thinning.
<phrase>Octree</phrase> approximation and <phrase>compression methods</phrase>.
Modeling of <phrase>Free</phrase>-Form Surfaces and <phrase>Shape From Shading</phrase>.
Modeling a <phrase>free</phrase>-form 3D-surface from a <phrase>single</phrase> view has been a widely pursued problem. The <phrase>existing schemes</phrase> are either <phrase>fully-automatic</phrase> shape-from-<phrase>X</phrase> techniques or involve <phrase>adept</phrase> interaction from the user but little or no <phrase>geometric</phrase> (<phrase>photometric</phrase>) basis. We propose a novel scheme of <phrase>interactive modeling</phrase> of <phrase>free</phrase>-form <phrase>lambertian</phrase> surfaces where the <phrase>solution</phrase> obtained is consistent with the <phrase>Shape from Shading</phrase> <phrase>model</phrase>. To this end, a <phrase>reinforcement learning</phrase> based scheme has been adopted which allows <phrase>user intervention</phrase> at any stage of the <phrase>algorithm</phrase> to guide the <phrase>SFS</phrase> <phrase>solution</phrase> to a <phrase>global minimum</phrase>.
<phrase>Automatic</phrase> Extraction of <phrase>Planar</phrase> Projections from <phrase>Panoramic</phrase> <phrase>Range</phrase> Images.
This <phrase>paper</phrase> presents a <phrase>segmentation technique</phrase> to decompose automatically a <phrase>panoramic</phrase> <phrase>range</phrase> image into a set of <phrase>planar</phrase> projections. It consists of three stages. <phrase>Firstly</phrase>, two <phrase>orthogonal</phrase> <phrase>surface orientation</phrase> histograms are generated. <phrase>Secondly</phrase>, from these histograms the <phrase>major</phrase> surfaces' orientations are extracted. <phrase>Finally</phrase>, a <phrase>histogram</phrase> of distances is computed for each one of these orientations; it will be used to define the position of the <phrase>projection</phrase> planes as well as the corresponding clipping planes. The original <phrase>panoramic</phrase> <phrase>range</phrase> image is <phrase>divided into</phrase> as many <phrase>planar</phrase> projections as main directions in the <phrase>orientation histograms</phrase> are extracted. This technique can be used with both <phrase>indoor and outdoor scenes</phrase>. <phrase>Experimental</phrase> result with a <phrase>panoramic</phrase> <phrase>range</phrase> image is presented.
<phrase>Surface Model</phrase> Generation from <phrase>Range</phrase> Images of <phrase>Industrial</phrase> Environments.
This <phrase>paper</phrase> presents an <phrase>hybrid</phrase> <phrase>segmentation technique</phrase> that combines both the speed of an <phrase>edge based</phrase> approach with the robustness of a <phrase>surface based</phrase> approach. It consists of three stages. In the first stage a <phrase>scan line</phrase> approximation process extracts the edges contained into the given <phrase>range</phrase> image. These edges are later on used to define the positions of <phrase>seed</phrase> points. Through the second stage a two steps <phrase>region</phrase> growing technique is applied. First a 2D growing process enlarges the original <phrase>seed</phrase> points <phrase>generating</phrase> bigger regions. <phrase>Next</phrase>, each <phrase>region</phrase> is fitted to a plane and a <phrase>cylinder</phrase>. The one that <phrase>best fit</phrase> the given points is selected to represent that <phrase>region</phrase> and used during the 3D growing stage. The 3D growing stage is carried out <phrase>taking into account</phrase> the <phrase>approximation error</phrase> from <phrase>candidate points</phrase> to be added to the fitted surface. In this way, each surface is grown until no points can be added according to a <phrase>user defined</phrase> threshold. <phrase>Finally</phrase>, in the third stage, a <phrase>post-processing</phrase> <phrase>algorithm</phrase> merges neighbour regions that belong to the same surface. <phrase>Experimental</phrase> <phrase>results</phrase> by using <phrase>industrial</phrase> environments are presented.
<phrase>Unsupervised</phrase> <phrase>Motion Classification</phrase> by Means of <phrase>Efficient</phrase> <phrase>Feature Selection</phrase> and Tracking.
This <phrase>paper</phrase> presents <phrase>an efficient</phrase> technique for <phrase>human motion</phrase> recognition; in particular, it is focused on labeling a movement as a <phrase>walking</phrase> or running displacement, which are the most frequent type of <phrase>locomotion</phrase>. The proposed technique consists of two stages and is based on the study of <phrase>feature points</phrase>' trajectories. The first stage detects <phrase>peaks</phrase> and valleys of points' trajectories, which are used on the second stage to <phrase>discern</phrase> whether the movement corresponds to a <phrase>walking</phrase> or a running displacement. <phrase>Prior knowledge</phrase> of <phrase>human body</phrase> <phrase>kinematics</phrase> structure together with the corresponding <phrase>motion model</phrase> are the basis for the <phrase>motion recognition</phrase>. <phrase>Experimental</phrase> <phrase>results</phrase> with different <phrase>video</phrase> sequences are presented.
Modeling <phrase>closed surfaces</phrase> in a <phrase>multi-resolution</phrase> <phrase>fashion</phrase>.
Compression of Isosurfaces for Structured <phrase>Volumes</phrase> with <phrase>Context Modelling</phrase>.
<phrase>Second Order</phrase> <phrase>Local</phrase> Analysis for 3D <phrase>Reconstruction</phrase> of <phrase>Specular</phrase> Surfaces.
Implementation of a <phrase>Shadow</phrase> <phrase>Carving</phrase> System for <phrase>Shape Capture</phrase>.
3D <phrase>Reality</phrase> Modelling: <phrase>Photo</phrase>-Realistic 3D Models of <phrase>Real World</phrase> Scenes.
A Formulation of Boundary <phrase>Mesh Segmentation</phrase>.
We present a formulation of boundary <phrase>mesh segmentation</phrase> as an <phrase>optimization problem</phrase>. Previous segmentation solutions are classified according to the different segmentation goals, the <phrase>optimization criteria</phrase> and the various <phrase>algorithmic</phrase> techniques used. We identify two primarily distinct types of <phrase>mesh segmentation</phrase>, namely partssegmentation and patch segmentation. We also define <phrase>generic</phrase> <phrase>algorithms</phrase> for the <phrase>major</phrase> techniques used for segmentation.
Extraction and Description of 3D (Articulated) <phrase>Moving Objects</phrase>.
<phrase>Pyramid</phrase> Coordinates for <phrase>Morphing</phrase> and Deformation.
Many <phrase>model</phrase> <phrase>editing</phrase> operations, such as <phrase>morphing</phrase>, <phrase>blending</phrase>, and <phrase>shape deformation</phrase>, require the ability to interactively transform the surface of a <phrase>model</phrase> in response to some <phrase>control mechanism</phrase>. For most <phrase>computer graphics</phrase> applications, it is important to preserve the <phrase>local</phrase> shape properties of input models during <phrase>editing</phrase> operations. Our work introduces the first, to our <phrase>knowledge</phrase>, <phrase>mesh editing</phrase> technique that explicitly preserves <phrase>local</phrase> shape properties. The method is based on a <phrase>local shape</phrase> representation, which we refer to as <phrase>pyramid</phrase> coordinates. The <phrase>pyramid</phrase> coordinates capture the <phrase>local</phrase> shape of the mesh around each vertex and help maintain this shape under various <phrase>editing</phrase> operations. They are based on a set of angles and lengths relating a vertex to its <phrase>immediate neighbors</phrase>. This representation is invariant under <phrase>rigid transformations</phrase>. Using <phrase>pyramid</phrase> coordinates, we introduce a new technique for <phrase>mesh deformation</phrase> and <phrase>morphing</phrase> based on a small number of <phrase>user-specified</phrase> control vertices. Our <phrase>algorithm</phrase> generate <phrase>natural looking</phrase> deformations and <phrase>morphing</phrase> sequences in seconds with <phrase>minimal</phrase> <phrase>user interaction</phrase>.
<phrase>Unifying</phrase> Measured Point Sequences of <phrase>Deforming Objects</phrase>.
<phrase>Recent progress</phrase> in <phrase>digitizing</phrase> technologies is making it possible to capture the 3D shapes of <phrase>moving objects</phrase>. To <phrase>efficiently utilize</phrase> <phrase>time series</phrase> records of <phrase>spatial data</phrase>, the <phrase>information</phrase> must be <phrase>unified</phrase> to yield <phrase>coherent</phrase> deforming models. This <phrase>paper</phrase> presents a <phrase>general</phrase> method that unifies <phrase>unregistered</phrase> 3D point sequences to generate <phrase>deforming mesh</phrase> models. The method does not assume any specific <phrase>kinematic</phrase> structure, and is applicable to any digitizer. The method first polygonizes the <phrase>initial points</phrase> and then deforms meshes to <phrase>best fit</phrase> the subsequent <phrase>data</phrase> points while <phrase>minimizing</phrase> the <phrase>deformation energy</phrase>. Experiments are conducted on real <phrase>measured data</phrase> and <phrase>CG</phrase> <phrase>data</phrase>, and successful <phrase>results</phrase> are obtained. As an application of the method, we examine <phrase>data compression</phrase> and achieve a 380 fold reduction rate for a <phrase>measured data</phrase> <phrase>sequence</phrase>.
<phrase>Surface Reconstruction</phrase> from <phrase>Multiple Views</phrase> using <phrase>Rational B-Splines</phrase> and <phrase>Knot Insertion</phrase>.
<phrase>Efficient</phrase> <phrase>algorithm</phrase> for the computation of 3D <phrase>Fourier</phrase> descriptors.
<phrase>Visual-Hull Reconstruction</phrase> from <phrase>Uncalibrated</phrase> and <phrase>Unsynchronized</phrase> <phrase>Video</phrase> Streams.
We present an approach for <phrase>automatic</phrase> <phrase>reconstruction</phrase> of a <phrase>dynamic</phrase> event using multiple <phrase>video</phrase> cameras <phrase>recording</phrase> from different viewpoints. Those cameras do not need to be calibrated or even synchronized. Our approach recovers all the necessary <phrase>information</phrase> by <phrase>analyzing</phrase> the motion of the silhouettes in the <phrase>multiple video streams</phrase>. The first step consists of <phrase>computing</phrase> the <phrase>calibration</phrase> and synchronization for pairs of cameras. We compute the temporal offset and <phrase>epipolar geometry</phrase> using <phrase>an efficient</phrase> <phrase>RANSAC-based</phrase> <phrase>algorithm</phrase> to search for the epipoles as well as for robustness. In the <phrase>next</phrase> stage the <phrase>calibration</phrase> and synchronization for the complete <phrase>camera</phrase> network is recovered and then refined through <phrase>maximum likelihood estimation</phrase>. <phrase>Finally</phrase>, a <phrase>visual</phrase>-<phrase>hull</phrase> <phrase>algorithm</phrase> is used to the recover the <phrase>dynamic</phrase> shape of the observed object. For <phrase>unsynchronized</phrase> <phrase>video</phrase> streams silhouettes are interpolated to deal with <phrase>subframe</phrase> temporal offsets. We demonstrate the validity of our approach by obtaining the <phrase>calibration</phrase>, synchronization and 3D <phrase>reconstruction</phrase> of a moving person from a set of 4 minute videos recorded from 4 <phrase>widely separated</phrase> <phrase>video</phrase> cameras.
<phrase>Image-Based</phrase> <phrase>Photo</phrase> <phrase>Hulls</phrase>.
Facial <phrase>View Synthesis</phrase> from a <phrase>Single</phrase> Image using <phrase>Shape from Shading</phrase>.
We present a facial <phrase>view synthesis</phrase> technique based on explicit shape and <phrase>reflectance</phrase> <phrase>information</phrase> extracted from a <phrase>single</phrase> image. The technique combines an <phrase>image based</phrase> <phrase>reflectance estimation</phrase> process with a novel method of <phrase>interpolating</phrase> between <phrase>needle-maps</phrase> recovered using <phrase>shape from shading</phrase>. This allows images of a face to be synthesised under novel lighting, pose and <phrase>skin</phrase> <phrase>reflectance</phrase> given only one example image. We exploit <phrase>facial symmetry</phrase> by reflecting the <phrase>needle-map</phrase> of a <phrase>rotated</phrase> face to yield the <phrase>needle-map</phrase> of the face <phrase>rotated</phrase> in the <phrase>opposite direction</phrase>. This provides two <phrase>needle-maps</phrase> between which <phrase>interpolation</phrase> can be performed.
A <phrase>Variational</phrase> Analysis of Shape from Specularities using <phrase>Sparse Data</phrase>.
Looking around in our <phrase>every day</phrase> environment, many of the encountered objects are <phrase>specular</phrase> to some <phrase>degree</phrase>. Actively using this fact when <phrase>reconstructing</phrase> objects from <phrase>image sequences</phrase> is the scope of the shape from specularities problem. One reason why this problem is important is that standard <phrase>structure from motion</phrase> techniques fail when the <phrase>object surfaces</phrase> are <phrase>specular</phrase>. Here this problem is addressed by <phrase>estimating</phrase> <phrase>surface shape</phrase> using <phrase>information</phrase> from the <phrase>specular reflections</phrase>. A <phrase>specular reflection</phrase> gives constraints on the <phrase>surface normal</phrase>. The approach taken in this <phrase>paper</phrase> <phrase>differs significantly</phrase> from many earlier shape from specularities methods since the normal <phrase>data</phrase> used is <phrase>sparse</phrase>. The <phrase>main contribution</phrase> of this <phrase>paper</phrase> is to give a <phrase>solid foundation</phrase> for shape from specularities problems. Estimation of <phrase>surface shape</phrase> using <phrase>reflections</phrase> is formulated as a <phrase>variational</phrase> problem and the surface is <phrase>represented implicitly</phrase> using <phrase>a level</phrase> set formulation. A <phrase>functional</phrase> <phrase>incorporating</phrase> all surface constraints is proposed and the corresponding <phrase>level set</phrase> motion <phrase>PDE</phrase> is explicitly derived. This motion is then <phrase>proven</phrase> to minimize the <phrase>functional</phrase>. As a part of this <phrase>functional</phrase> a <phrase>variational</phrase> approach to normal alignment is proposed and analyzed. Also novel methods for <phrase>implicit surface</phrase> <phrase>interpolation</phrase> to <phrase>sparse</phrase> <phrase>point sets</phrase> are presented together with a <phrase>variational</phrase> analysis. Experiments on both real and <phrase>synthetic data</phrase> support the <phrase>proposed method</phrase>.
<phrase>Surface Reconstruction</phrase> from the <phrase>Projection</phrase> of Points, Curves and Contours.
In this <phrase>paper</phrase> the problem of <phrase>building</phrase> and <phrase>reconstructing</phrase> <phrase>geometrical</phrase> <phrase>surface models</phrase> from multiple <phrase>calibrated images</phrase> is considered. We build an appropriate statistical 3D <phrase>model</phrase> from the images alone and show how this <phrase>a priori</phrase> <phrase>model</phrase> can be used to automatically reconstruct new instances of the <phrase>object category</phrase> from one or several images. The <phrase>surface reconstruction</phrase> method is based on <phrase>a level</phrase> set representation and one of the main novel contributions <phrase>lie</phrase> within the <phrase>level set</phrase> framework. Standard methods use either <phrase>image-correlation</phrase> or <phrase>point correspondences</phrase> to achieve this goal. We show how this framework can be extended to incorporate image curves and <phrase>apparent contours</phrase> (i.e. the projections of silhouettes). In <phrase>order</phrase> to automatically obtain <phrase>feature correspondences</phrase>, we use a <phrase>statistical shape</phrase> modelfor the <phrase>object category</phrase> of interest. The <phrase>model</phrase> is based on the <phrase>Active Shape Model</phrase> using <phrase>Probabilistic</phrase> <phrase>PCA</phrase>. The scheme is applied to build and automatically reconstruct 3D <phrase>surface models</phrase> of faces. The resulting system is demonstrated on a <phrase>database</phrase> of real <phrase>face images</phrase>.
Browsing 3-<phrase>D</phrase> spaces with 3-<phrase>D</phrase> vision: <phrase>body-driven</phrase> <phrase>navigation</phrase> through the <phrase>Internet</phrase> <phrase>city</phrase>.
f3d - A <phrase>File Format</phrase> and Tools for Storage and Manipulation of <phrase>Volumetric Data</phrase> Sets.
<phrase>Efficient</phrase> <phrase>Model</phrase> Creation of Large Structures based on <phrase>Range</phrase> Segmentation.
This <phrase>paper</phrase> describes <phrase>an efficient</phrase> 3D <phrase>modeling method</phrase> from 3D <phrase>range</phrase> <phrase>data</phrase>-sets that is utilizing <phrase>range</phrase> <phrase>data</phrase> segmentation. Our <phrase>algorithm</phrase> starts with a set of <phrase>unregistered</phrase> 3D <phrase>range</phrase> scans of a <phrase>large scale</phrase> scene. The scans are being <phrase>pre-processed</phrase> for <phrase>noise removal</phrase> and <phrase>hole</phrase> filling. The <phrase>next</phrase> step is <phrase>range</phrase> segmentation and the extraction of <phrase>planar</phrase> and <phrase>linear features</phrase>. These features are utilized for the <phrase>automatic</phrase> registration of the <phrase>range</phrase> scans into a common frame of reference [<phrase>Automated</phrase> <phrase>feature-based</phrase> <phrase>range</phrase> registration of <phrase>urban</phrase> scenes of <phrase>large scale</phrase>]. A <phrase>volumetric</phrase>-<phrase>based algorithm</phrase> is used for the <phrase>construction</phrase> of a <phrase>coherent</phrase> 3D mesh that encloses all <phrase>range</phrase> scans. <phrase>Finally</phrase>, the original segmented scans are used in <phrase>order</phrase> to simplify the constructed mesh. The mesh can now be represented as a set of <phrase>planar</phrase> regions at areas of <phrase>low complexity</phrase> and as a set of <phrase>dense</phrase> mesh <phrase>triangular elements</phrase> at areas of <phrase>high</phrase> complexity. This is achieved by <phrase>computing</phrase> the overlaps of the original segmented <phrase>planar</phrase> areas on the generated 3D mesh. The example of the <phrase>construction</phrase> of the 3D <phrase>model</phrase> of a <phrase>building</phrase> in the <phrase>NYC</phrase> <phrase>area</phrase> is presented.
<phrase>PDE</phrase>-<phrase>based Multi</phrase>-view <phrase>Depth Estimation</phrase>.
<phrase>Triangle Mesh</phrase>-Based <phrase>Surface Modeling</phrase> Using <phrase>Adaptive Smoothing</phrase> and <phrase>Implicit Surface</phrase> Texture <phrase>Integration</phrase>.
<phrase>Image Matching</phrase> based on <phrase>Co</phrase>-<phrase>Motion Statistics</phrase>.
This <phrase>paper</phrase> presents a method for matching <phrase>partially overlapping</phrase> <phrase>image-pairs</phrase> where the object of interest is in motion, even if the motion is <phrase>discontinuous</phrase> and in an <phrase>unstructured environment</phrase>. In a typical <phrase>outdoor</phrase> <phrase>multi-camera surveillance</phrase> system, an observed object as seen by separate cameras may appear very different, due to the <phrase>variable</phrase> influence of factors such as <phrase>lighting conditions</phrase> and <phrase>camera</phrase> angles. Thus <phrase>static features</phrase> such as <phrase>object color</phrase>, shape, and contours cannot be used for <phrase>image matching</phrase>. In this <phrase>paper</phrase> a different method is proposed for matching <phrase>partially overlapping</phrase> <phrase>images captured</phrase> by such cameras. The matching is achieved by calculation of <phrase>co</phrase>-<phrase>motion statistics</phrase>, followed by detection and rejection of points outside the <phrase>overlap area</phrase> and a <phrase>nonlinear optimization</phrase> process. The <phrase>robust</phrase> <phrase>algorithm</phrase> we describe finds <phrase>point correspondences</phrase> in two images without searching for any structures and without the need for tracking <phrase>continuous</phrase> motion. Trials using statistical <phrase>motion-based</phrase> image cross-registration, a <phrase>robust</phrase> <phrase>rejection algorithm</phrase>, and <phrase>automatic</phrase> 3D <phrase>image-transformation</phrase> and <phrase>camera calibration</phrase> on <phrase>real-life</phrase> <phrase>outdoor</phrase> images have demonstrated the feasibility of this approach.
<phrase>Robust</phrase> 3D Segmentation for <phrase>Underwater Acoustic</phrase> Images.
In this <phrase>paper</phrase>, a new technique for 3D <phrase>acoustic</phrase> <phrase>image segmentation</phrase> and modelling is proposed. Especially, in the <phrase>underwater</phrase> environment, in which <phrase>optical sensors</phrase> suffer from <phrase>visibility</phrase> problems, the <phrase>acoustical</phrase> devices may provide <phrase>efficient</phrase> solutions, but, on the other hand, <phrase>acoustic</phrase> <phrase>image interpretation</phrase> is surely more difficult for a <phrase>human</phrase> operator. The proposed application involves the use of an <phrase>acoustic</phrase> <phrase>camera</phrase> which directly acquires images structured as a set of 3D points. Due to the noisy <phrase>nature</phrase> of this type of <phrase>data</phrase>, the segmentation problem becomes more challenging and the standard <phrase>algorithms</phrase> for <phrase>range</phrase> <phrase>image segmentation</phrase> are likely to fail. The <phrase>proposed method</phrase> is based on a <phrase>simplified</phrase> version of the so called recover and select <phrase>paradigm</phrase> in which the <phrase>seed</phrase> areas, from which the segmentation starts, are generated by adopting a <phrase>robust</phrase> approach based on the <phrase>RANSAC</phrase> (<phrase>RANdom</phrase> Sample And <phrase>Consensus</phrase>) <phrase>algorithm</phrase>. <phrase>Superquadric</phrase> primitives are directly recovered from <phrase>raw data</phrase> without any <phrase>pre-segmentation</phrase> processing. <phrase>Experimental</phrase> trials using both synthetic and real <phrase>acoustical</phrase> images confirm the goodness of the method, and a large robustness of the resulting <phrase>segmented images</phrase>, associated to a relatively low <phrase>computational load</phrase>.
A <phrase>Tensor Voting</phrase> Approach for the <phrase>Hierarchical</phrase> Segmentation of 3-<phrase>D</phrase> <phrase>Acoustic</phrase> Images.
Advances in Mesh <phrase>Signal Processing</phrase> and <phrase>Geometry</phrase> Compression.
3D <phrase>image sequence</phrase> acquisition for <phrase>TV</phrase> & <phrase>film</phrase> <phrase>production</phrase>.
<phrase>Panoramic Image</phrase> Transform of <phrase>Omnidirectional</phrase> Images Using <phrase>Discrete Geometry</phrase> Techniques.
This <phrase>paper</phrase> proposes an <phrase>omnidirectional</phrase>-to-<phrase>panoramic image</phrase> transform with <phrase>high</phrase> accuracy using <phrase>PDE</phrase>-based <phrase>resampling</phrase> models. For the application of <phrase>computer-vision</phrase> techniques to <phrase>omnidirectional</phrase> images, the transformation of <phrase>omnidirectional</phrase> images to <phrase>uniform</phrase>-resolution <phrase>quadric</phrase>-surface images is needed in the two reasons. First, an <phrase>omni-directional</phrase> image does not have a <phrase>uniform</phrase> resolution. Second, the development of the <phrase>computer-vision</phrase>-<phrase>based techniques</phrase> on the <phrase>quadric</phrase> surface is mathematically accurate compared with the development of the techniques on the <phrase>omnidirectional</phrase> image directly. Therefore, our aim is to generate <phrase>uniform</phrase>-resolution <phrase>panoramic images</phrase> on <phrase>cylindrical</phrase> surface from <phrase>nonuniform</phrase>-resolution <phrase>omnidirectional</phrase> images. The <phrase>uniform</phrase>-resolution <phrase>panoramic images</phrase> allow us to reconstruct 3D objects and scenes from <phrase>omnidirectional</phrase> images robustly. Our <phrase>panoramic</phrase> transformation selects the <phrase>uniform</phrase> resolution <phrase>pixels</phrase> on <phrase>omnidirectional</phrase> images employing the <phrase>geometrical</phrase> configuration of cameras in the estimation and <phrase>resampling</phrase> process. Therefore, our method is mathematically accurate <phrase>comparing</phrase> to the traditional <phrase>panoramic</phrase> transformation using <phrase>point-to-point</phrase> correspondences with the geometries of cameras and the <phrase>cubic</phrase> <phrase>convolution</phrase>.
<phrase>Generalized</phrase> <phrase>RANSAC</phrase> Framework for <phrase>Relaxed</phrase> <phrase>Correspondence</phrase> Problems.
<phrase>Finding</phrase> correspondences between two (widely) <phrase>separated views</phrase> is essential for several <phrase>computer vision</phrase> tasks, such as <phrase>structure and motion</phrase> estimation and <phrase>object recognition</phrase>. In the <phrase>wide-baseline</phrase> matching using scale and/or <phrase>affine invariant</phrase> features the search for correspondences typically proceeds in two stages. In the first stage a putative set of correspondences is obtained based on distances between <phrase>feature descriptors</phrase>. In the second stage the matches are refined by imposing <phrase>global</phrase> <phrase>geometric</phrase> constraints by means of <phrase>robust</phrase> estimation of the <phrase>epipolar geometry</phrase> and the incorrect matches are rejected as <phrase>outliers</phrase>. For a feature in one view, usually only one "best" feature (the <phrase>nearest neighbor</phrase>) in the other view is chosen as corresponding feature, despite the fact that several match candidates exist. In this <phrase>paper</phrase>, we will consider <phrase>multiple candidate</phrase> matches for each feature, and integrate this choice with the <phrase>robust</phrase> estimation stage, thus avoiding the early commitment to the "best" one. This yields a <phrase>generalized</phrase> <phrase>RANSAC</phrase> framework for <phrase>identifying</phrase> the true correspondences among sets of matches. We examine the effectiveness of different <phrase>sampling</phrase> strategies for sets of correspondences and <phrase>test</phrase> the approach extensively using real examples of hard <phrase>correspondence</phrase> problems caused by a large motion between views and/or ambiguities due to repetitive scene structures.
<phrase>Exploitation</phrase> of 3D Images for <phrase>Face Authentication</phrase> Under <phrase>Pose and Illumination</phrase> Variations.
An <phrase>appearance-based face</phrase> <phrase>authentication</phrase> system <phrase>integrating</phrase> 2D <phrase>color</phrase> or <phrase>intensity images</phrase> and 3D <phrase>data</phrase> is presented in this <phrase>paper</phrase>. The proposed system is based on a <phrase>low-cost</phrase> 3D and <phrase>color</phrase> <phrase>sensor</phrase>, capable of <phrase>synchronous</phrase> <phrase>real-time</phrase> acquisition of 3D images and associated <phrase>color images</phrase>. Novel <phrase>algorithms</phrase> are proposed that exploit <phrase>depth information</phrase> and <phrase>prior knowledge</phrase> of <phrase>face geometry</phrase> and <phrase>symmetry</phrase> to achieve <phrase>robust</phrase> <phrase>face detection</phrase>, localization and <phrase>authentication</phrase> under conditions of <phrase>background clutter</phrase>, occlusion, <phrase>face pose</phrase> alteration and harsh illumination. A method for the <phrase>enrichment</phrase> of <phrase>face databases</phrase> with <phrase>synthetically generated</phrase> views depicting variations in <phrase>pose and illumination</phrase> is proposed to <phrase>cope</phrase> with <phrase>head</phrase> rotations and <phrase>illumination variations</phrase>, avoiding a cumbersome enrolment process. The performance of the proposed <phrase>authentication</phrase> scheme is tested thoroughly on a <phrase>face database</phrase> of 1500 images, recorded with the 3D acquisition system. <phrase>Experimental</phrase> <phrase>results</phrase> demonstrate <phrase>significant gains</phrase> resulting from the combined use of depth and <phrase>color</phrase> or intensity <phrase>information</phrase>, in comparison to the use of 2D images alone.
<phrase>Archiving</phrase> 3D <phrase>Cultural</phrase> Objects with <phrase>Surface Point</phrase>-<phrase>Wise</phrase> <phrase>Database</phrase> <phrase>Information</phrase>.
<phrase>A Unified</phrase> Representation for Interactive 3D Modeling.
Interactive 3D modeling is the process of <phrase>building</phrase> a 3D <phrase>model</phrase> of an object or a scene in <phrase>real-time</phrase> while the 3D (<phrase>range</phrase>) <phrase>data</phrase> is acquired. This is possible only if the <phrase>computational complexity</phrase> of all involved <phrase>algorithms</phrase> is linear with respect to the amount of <phrase>data</phrase>. We propose a new framework for 3D modeling where a complete modeling chain meets with this requirement. The framework is based on the use of <phrase>vector fields</phrase> as an <phrase>implicit surface</phrase> representation. Each modeling step, registration, <phrase>surface reconstruction</phrase>, <phrase>geometric</phrase> <phrase>fusion</phrase>, compression and visualization is solved and explained using the <phrase>vector fields</phrase> without anyintermediate representations. The proposed framework allows <phrase>model</phrase> <phrase>reconstruction</phrase> from any type of 3D <phrase>data</phrase>, <phrase>surface patches</phrase>, curves, unorganized sets of points or a combination of these.
A <phrase>Volumetric</phrase> Approach for Interactive 3D Modeling.
<phrase>Range</phrase> <phrase>image registration</phrase> and <phrase>surface reconstruction</phrase> have been traditionally considered as two <phrase>independent</phrase> processes where the latter relies on the <phrase>results</phrase> of the former. This <phrase>paper</phrase> presents a new approach to <phrase>surface recovery</phrase> from <phrase>range</phrase> images where the two processes are <phrase>unified</phrase> and performed in a common <phrase>volumetric</phrase> representation. While the reconstructed surface is described in its <phrase>implicit</phrase> form as a <phrase>signed distance</phrase> field within a volume, registration <phrase>information</phrase> for matching <phrase>partial</phrase> surfaces is encoded in the same volume as the <phrase>gradient</phrase> of the <phrase>distance field</phrase>. This allows <phrase>coupling</phrase> of both <phrase>reconstruction</phrase> and registration and leads to an <phrase>algorithm</phrase> whose complexity is linear with respect to the number of images and the number of measured 3D points. The <phrase>close integration</phrase> and <phrase>performance gain</phrase> improve <phrase>interactivity</phrase> in the process of modeling from <phrase>range image</phrase> acquisition to <phrase>surface reconstruction</phrase>. The distances computed in the direction of filtered normals improve robustness while preserving the <phrase>sharp</phrase> details of the initial <phrase>range</phrase> images. It is shown that the integrated <phrase>algorithm</phrase> is tolerant to initial <phrase>registration errors</phrase> as well as to <phrase>measurement errors</phrase>. The <phrase>paper</phrase> describes the representation and formalizes the approach. <phrase>Experimental</phrase> <phrase>results</phrase> demonstrate <phrase>performance advantages</phrase> and tolerance to aforementioned types of errors.
A <phrase>Closed-Form</phrase> <phrase>Solution</phrase> for a Two-View <phrase>Self-Calibration</phrase> Problem under <phrase>Fixation</phrase>.
It is well known that the <phrase>epipolar geometry</phrase> between two <phrase>uncalibrated</phrase> <phrase>perspective</phrase> views is completely encapsulated in the <phrase>fundamental matrix</phrase>. Since the <phrase>fundamental matrix</phrase> has seven <phrase>degrees of freedom</phrase> (<phrase>DOF</phrase>), <phrase>self-calibration</phrase> is possible if at most seven of the <phrase>intrinsic</phrase> or <phrase>extrinsic camera parameters</phrase> are unknown by <phrase>extracting</phrase> them from the <phrase>fundamental matrix</phrase>. This <phrase>paper</phrase> presents a linear <phrase>algorithm</phrase> for <phrase>self-calibrating</phrase> a <phrase>perspective</phrase> <phrase>camera</phrase> which undergoes <phrase>fixation</phrase>, that is, a special motion in which the camera's <phrase>optical axis</phrase> is confined in a plane. Since this <phrase>fixation</phrase> has four <phrase>degrees of freedom</phrase>, which is one smaller than that of <phrase>general</phrase> motion, we can extract at most three <phrase>intrinsic</phrase> parameters from the <phrase>fundamental matrix</phrase>. We here assume that the <phrase>focal length</phrase> (1 <phrase>DOF</phrase>) and the <phrase>principal point</phrase> (2 <phrase>DOF</phrase>) are unknown but fixed for two views. It will be shown that these three parameters are obtained from the <phrase>fundamental matrix</phrase> in an analytical <phrase>fashion</phrase> and a <phrase>closed-form</phrase> <phrase>solution</phrase> is derived. We also characterize all the <phrase>degenerate</phrase> motions under which there exists an <phrase>infinite set</phrase> of solutions.
<phrase>Long</phrase>-<phrase>range</phrase> <phrase>high</phrase>-performance <phrase>time-of-flight</phrase>-based 3D <phrase>imaging</phrase> sensors.
3-Dimensional <phrase>Object Modeling</phrase> with <phrase>Mesh Simplification</phrase> Based Resolution Adjustment.
A 3-Dimensional (3-<phrase>D</phrase>) <phrase>object modeling</phrase> technique with <phrase>mesh simplification</phrase> and <phrase>refinement</phrase> based resolution adjustment is proposed in this <phrase>paper</phrase>. <phrase>Polygonal models</phrase> which are <phrase>widely utilized</phrase> in the modeling of 3-<phrase>D</phrase> objects are taken as basis, making use of the <phrase>polygonal</phrase> structure and <phrase>vertex coordinates</phrase> for the display of 3-<phrase>D</phrase> models. The amount of <phrase>polygons</phrase> and vertices of a <phrase>model</phrase> is <phrase>proportional</phrase> to the resolution as well as <phrase>data</phrase> quantity. In other words the resolution and <phrase>data</phrase> increases with the number of <phrase>polygons</phrase>. In this <phrase>paper</phrase>, it is proposed to utilize resolution, and <phrase>hence</phrase> <phrase>data</phrase> amount, <phrase>adjustable</phrase> 3-<phrase>D</phrase> modeling so that <phrase>model</phrase> resolution and transmitted <phrase>data</phrase> amount can be <phrase>regulated</phrase> according to access constraints.
<phrase>Active</phrase> <phrase>Polygon</phrase> for <phrase>Object Tracking</phrase>.
<phrase>A Practical Approach</phrase> for 3D <phrase>Model</phrase> <phrase>Indexing</phrase> by <phrase>combining</phrase> <phrase>Local</phrase> and <phrase>Global</phrase> Invariants.
<phrase>Protein folding</phrase> using <phrase>inter-residue</phrase> contacts.
Analysis of <phrase>Three-Dimensional</phrase> Motion of an Object Using a Fixed <phrase>Monocular</phrase> <phrase>Camera</phrase> .
The <phrase>research</phrase> on analysis of <phrase>three-dimensional</phrase> motion by using a <phrase>monocular</phrase> <phrase>camera</phrase> <phrase>instead</phrase> of a <phrase>stereo camera</phrase> has important applications for making the <phrase>microscopes</phrase> used in <phrase>microbiology</phrase> or <phrase>constructing</phrase> the <phrase>autonomous robots</phrase> used in various fields of <phrase>industry</phrase>. In this <phrase>paper</phrase>, we propose a fixed <phrase>monocular</phrase> <phrase>camera</phrase> whose focus changed cyclically to recognize <phrase>three-dimensional</phrase> <phrase>absolute</phrase> motion of a <phrase>rigid object</phrase>.
3D Interactive, On-site Visualization of <phrase>Ancient</phrase> <phrase>Olympia</phrase>.
<phrase>Design</phrase> of a <phrase>Service-Based</phrase> Framework for <phrase>Generic</phrase> 3D <phrase>Information Visualization</phrase>.
<phrase>Posture</phrase> Recognition <phrase>nd</phrase> Segmentation from 3D <phrase>Human Body</phrase> Scans.
<phrase>Fan</phrase>-Meshes: A <phrase>Geometric</phrase> Primitive for <phrase>Point-Based</phrase> Description of 3D Models and Scenes.
We propose a new <phrase>data structure</phrase>, called <phrase>Fan</phrase>-Meshes (<phrase>FM</phrase>), for <phrase>reconstructing</phrase> 3D models and scenes represented by <phrase>dense</phrase> scanning <phrase>point clouds</phrase>. It is a <phrase>local</phrase> <phrase>piecewise</phrase> <phrase>linear approximation</phrase> to the <phrase>data</phrase> <phrase>geometry</phrase>, and can serve as primitives in <phrase>reconstruction</phrase> with a good balance between <phrase>computational loads</phrase> and <phrase>reconstruction</phrase> quality. In our <phrase>algorithm</phrase>, <phrase>local</phrase> remeshing is performed in <phrase>preprocessing</phrase> to obtain regular <phrase>FMs</phrase>, and a three-level-<phrase>point data</phrase> structure called <phrase>Triangle</phrase> Selection Record (<phrase>TSR</phrase>) is then used to reduce redundancies in the <phrase>raw data</phrase> and overlapping in the original <phrase>FMs</phrase>. Furthermore, to apply the method to <phrase>raw</phrase> 3D scanning <phrase>data</phrase>, we use a <phrase>smoothing</phrase> operator to the <phrase>point cloud</phrase> in <phrase>order</phrase> to eliminate some <phrase>sensor</phrase> noises. <phrase>Experimental</phrase> <phrase>results</phrase> demonstrate that our scheme is effective even for <phrase>large-scale</phrase> scenes with <phrase>real data</phrase>.
<phrase>Uncalibrated</phrase> <phrase>Narrow Baseline</phrase> <phrase>Augmented Reality</phrase>.
A <phrase>Surface Evolution</phrase> Approach <phrase>o</phrase> <phrase>Probabilistic</phrase> <phrase>Space Carving</phrase>.
<phrase>Reconstruction</phrase> of <phrase>Three Dimensional</phrase> Models from <phrase>Real Images</phrase>.
<phrase>Speech-Driven</phrase> <phrase>Face Synthesis</phrase> from 3D <phrase>Video</phrase>.
This <phrase>paper</phrase> presents a framework for <phrase>speech-driven</phrase> <phrase>synthesis</phrase> of real faces from a corpus of 3D <phrase>video</phrase> of a person speaking.Video-rate capture of <phrase>dynamic</phrase> 3D <phrase>face shape</phrase> and <phrase>colour</phrase> appearance provides the basis for a <phrase>visual</phrase> <phrase>speech synthesis</phrase> model.A <phrase>displacement map</phrase> representation combines <phrase>face shape</phrase> and <phrase>colour</phrase> into a 3D video.This representation is used to efficiently register and integrate shape and <phrase>colour information</phrase> captured from multiple views.To allow <phrase>visual</phrase> <phrase>speech synthesis</phrase> viseme primitives are identified from the corpus using <phrase>automatic speech recognition</phrase>. A novel <phrase>non-rigid</phrase> <phrase>alignment algorithm</phrase> is introduced to estimate <phrase>dense correspondence</phrase> between 3D <phrase>face shape</phrase> and appearance for different visemes.The registered <phrase>displacement map</phrase> representation together with a novel <phrase>optical flow</phrase> <phrase>optimisation</phrase> using both shape and <phrase>colour</phrase>, enables accurate and <phrase>efficient</phrase> <phrase>non-rigid</phrase> alignment.Face <phrase>synthesis</phrase> from speech is performed by <phrase>concatenation</phrase> of the corresponding viseme <phrase>sequence</phrase> using the <phrase>non-rigid</phrase> <phrase>correspondence</phrase> to reproduce both 3D <phrase>face shape</phrase> and <phrase>colour</phrase> appearance. <phrase>Concatenative synthesis</phrase> reproduces both viseme timing and <phrase>co</phrase>-articulation.Face capture and <phrase>synthesis</phrase> has been performed for a <phrase>database</phrase> of 51 people.Results demonstrate <phrase>synthesis</phrase> of 3D <phrase>visual speech</phrase> <phrase>animation</phrase> with a quality comparable to the <phrase>captured video</phrase> of a person.
<phrase>Multi-Camera</phrase> <phrase>Reconstruction</phrase> based on <phrase>Surface Normal</phrase> Estimation and Best <phrase>Viewpoint</phrase> Selection.
In this <phrase>paper</phrase>, we present a new <phrase>algorithm</phrase> for <phrase>reconstructing</phrase> an environment from images recorded by <phrase>multiple calibrated cameras</phrase>. <phrase>Multiple camera</phrase> systems <phrase>challenge</phrase> traditional <phrase>stereo</phrase> <phrase>algorithms</phrase> in many issues including <phrase>view registration</phrase>, selection of commonly visible image parts for matching, and the fact that surfaces are imaged differently from different viewpoints and poses. On the other hand, <phrase>multiple cameras</phrase> have the advantage of revealing surfaces at <phrase>occluding contours</phrase> and covering <phrase>wide areas</phrase>. The presented <phrase>algorithm</phrase> makes no assumption on <phrase>camera</phrase> loci and outputs an <phrase>occupancy</phrase> <phrase>voxel</phrase> <phrase>grid</phrase>, with occupied voxels being accompanied by a <phrase>surface normal</phrase>. It is <phrase>correlation-based</phrase>, however, outperforms the conventional <phrase>correlation-based</phrase> approach in <phrase>reconstruction</phrase> quality. It is <phrase>highly parallelizable</phrase>, and <phrase>most importantly</phrase>, is <phrase>robust</phrase> against artifacts due to <phrase>camera registration</phrase> errors that are typically encountered when using <phrase>multiple cameras</phrase>.
<phrase>Rapid</phrase> <phrase>Shape Acquisition</phrase> Using <phrase>Color</phrase> <phrase>Structured Light</phrase> and <phrase>Multi-pass</phrase> <phrase>Dynamic Programming</phrase>.
The Meaning and Limitations of <phrase>Protein Structure</phrase> Alignments.
<phrase>Mosaic</phrase> <phrase>Construction</phrase> from a <phrase>Sparse</phrase> Set of Views.
<phrase>Focal Region</phrase>-<phrase>Guided</phrase> <phrase>Feature-Based</phrase> <phrase>Volume Rendering</phrase>.
3D Modelling and Visualization of the <phrase>Human</phrase> <phrase>Lung</phrase>.
A method for modelling and <phrase>visualizing</phrase> <phrase>human</phrase> <phrase>lungs</phrase> using <phrase>knowledge</phrase> of <phrase>lung</phrase> <phrase>anatomy</phrase> and <phrase>High Resolution CT</phrase> (<phrase>HRCT</phrase>) images is presented. The <phrase>model</phrase> consists of a <phrase>symbolic</phrase> description of <phrase>lung</phrase> <phrase>anatomy</phrase> and a 3D <phrase>atlas</phrase>. The 3D <phrase>atlas</phrase> is constructed using <phrase>HRCT</phrase> <phrase>volume data</phrase>. A few <phrase>anatomical</phrase> landmarks are determined and are used to divide the <phrase>lungs</phrase> into <phrase>anatomically</phrase> and diagnostically important regions. The landmarks and the <phrase>lung</phrase> regions enable accurate mapping of the <phrase>model</phrase> to <phrase>patient data</phrase> and enable the system to deal with image and <phrase>human</phrase> variability. The <phrase>model</phrase> can be displayed as a set of <phrase>labelled</phrase> <phrase>axial</phrase> slices and as a 3D <phrase>model</phrase> of the <phrase>lungs</phrase>. The 3D visualization enables rotation and viewing of <phrase>lung</phrase> structures, lungfeatures and <phrase>lung</phrase> regions from different angles.
<phrase>Hue</phrase> Flows and <phrase>Scene Structure</phrase>.
<phrase>Geometry</phrase> of <phrase>Contour</phrase>-based <phrase>Correspondence</phrase> for <phrase>Stereo</phrase>.
<phrase>Hierarchical</phrase> Representation of <phrase>Virtual</phrase> Cities for <phrase>Progressive</phrase> Transmission over Networks.
Interactive <phrase>network-based</phrase> <phrase>navigation</phrase> over large <phrase>urban</phrase> environments raises <phrase>difficult problems</phrase> due to the size and complexity of these scenes. In this <phrase>paper</phrase>, we present a clientserver system allowing <phrase>navigation</phrase> over 3D cities in <phrase>real time</phrase>. Due to a novel <phrase>progressive</phrase> and <phrase>hierarchical</phrase> representation of 3D models of densely built <phrase>urban areas</phrase>, only perceptible details for all the regions visible from a given <phrase>viewpoint</phrase> are progressively streamed to <phrase>visualisation</phrase> clients. Furthermore, <phrase>efficient</phrase> coding methods are used to compress the representation <phrase>data</phrase> allowing <phrase>quick start</phrase>-up of the <phrase>interactive visualisation</phrase> with a <phrase>highly-detailed</phrase> <phrase>model</phrase>. This is achieved through a set of dedicated <phrase>algorithms</phrase> allowing a <phrase>very large</phrase> <phrase>city</phrase> <phrase>model</phrase> to be structured into a <phrase>multi-resolution</phrase> representation. The method efficiently exploits the fact that most <phrase>automated</phrase> <phrase>modelling techniques</phrase> of <phrase>urban</phrase> scenes provides 2D<phrase>\frac</phrase>{1} {2} models (<phrase>building footprint</phrase>, height, <phrase>altitude</phrase>, ...). So as to efficiently and faithfully <phrase>model</phrase> <phrase>complex buildings</phrase>, a <phrase>procedural</phrase> representation for roofs and <phrase>facades</phrase> is proposed. <phrase>Finally</phrase>, we present an <phrase>MPEG4</phrase> compatible implementation based on the <phrase>introduction</phrase> of new <phrase>node types</phrase> with the associated <phrase>bitstream</phrase>.
<phrase>Image Guided</phrase> <phrase>Geometry</phrase> Inference.
We introduce a new method for <phrase>filling holes</phrase> in <phrase>geometry</phrase> obtained from 3D <phrase>range</phrase> scanners. Our method makes use of 2D images of the areas where <phrase>geometric data</phrase> is missing. The 2D images guide the filling using the relationship between the images and <phrase>geometry</phrase> learned from the existing 3D <phrase>scanned data</phrase>. Our method builds on <phrase>existing techniques</phrase> for using scanned <phrase>geometry</phrase> and for <phrase>estimating</phrase> shape from <phrase>shaded images</phrase>. Rather than <phrase>creating</phrase> plausibly filled holes, we attempt to <phrase>approximate</phrase> the missing <phrase>geometry</phrase>. We present <phrase>results</phrase> for <phrase>scanned data</phrase> from both <phrase>triangulation</phrase> and <phrase>time-of-flight</phrase> scanners for various types of materials. To quantitatively validate our <phrase>proposed method</phrase>, we also compare the filled areas with <phrase>ground-truth data</phrase>.
Scanline Optimization for <phrase>Stereo</phrase> on <phrase>Graphics Hardware</phrase>.
In this work we propose a scanline <phrase>optimization procedure</phrase> for computational <phrase>stereo</phrase> using a linear <phrase>smoothness</phrase> <phrase>cost model</phrase> performed by <phrase>programmable graphics hardware</phrase>. The <phrase>main idea</phrase> for <phrase>an efficient</phrase> implementation of this <phrase>dynamic programming</phrase> approach is a <phrase>recursive</phrase> scheme to calculate the <phrase>min</phrase>-<phrase>convolution</phrase> in a manner suitable for the <phrase>parallel</phrase> <phrase>stream</phrase> <phrase>computation model</phrase> of <phrase>graphics processing units</phrase>. Since many <phrase>image similarity</phrase> functions can be efficiently calculated by <phrase>modern graphics hardware</phrase>, it is reasonable to address the final disparity extraction by <phrase>graphics processors</phrase> as well. Our timing <phrase>results</phrase> indicate that the proposed approach is beneficial for larger <phrase>image resolutions</phrase> and disparity <phrase>ranges</phrase> in particular.
A <phrase>Robust</phrase> <phrase>Correlation Measure</phrase> for <phrase>Correspondence</phrase> Estimation.
A <phrase>median</phrase> correlation for the estimation of corresponding points in <phrase>stereovision</phrase> is proposed. It is based on the <phrase>normalised</phrase> <phrase>correlation coefficient</phrase> using the <phrase>median</phrase> <phrase>instead</phrase> of the mean. Its performance appears to be <phrase>superior</phrase> than conventional correlation specially in <phrase>depth discontinuities</phrase> image areas. This <phrase>conclusion</phrase> is derived from <phrase>an empirical evaluation</phrase> in which the proposed correlation is compared with the <phrase>normalised</phrase> <phrase>correlation coefficient</phrase> and the <phrase>sum</phrase> of <phrase>absolute difference</phrase>. The <phrase>results</phrase> show that the <phrase>median</phrase> correlation produces <phrase>higher scores</phrase> and <phrase>lower</phrase> <phrase>estimation errors</phrase>.
<phrase>Scale Selection</phrase> for the Analysis of <phrase>Point-Sampled</phrase> Curves.
An important task in the analysis and <phrase>reconstruction</phrase> of <phrase>curvilinear</phrase> structures from unorganized 3-<phrase>D</phrase> <phrase>point samples</phrase> is the estimation of <phrase>tangent</phrase> <phrase>information</phrase> at each <phrase>data</phrase> point. Its <phrase>main challenges</phrase> are in (1) the selection of an appropriate scale of analysis to accommodate noise, <phrase>density</phrase> variation and <phrase>sparsity</phrase> in the <phrase>data</phrase>, and in (2) the formulation of a <phrase>model</phrase> and associated <phrase>objective function</phrase> that correctly expresses their effects. We pose this problem as one of <phrase>estimating</phrase> the <phrase>neighborhood</phrase> size for which the <phrase>principal eigenvector</phrase> of the <phrase>data</phrase> <phrase>scatter</phrase> matrix is best aligned with the true <phrase>tangent</phrase> of the curve, in a <phrase>probabilistic</phrase> sense. We analyze the <phrase>perturbation</phrase> on the direction of the <phrase>eigenvector</phrase> due to <phrase>finite samples</phrase> and noise using the expected <phrase>statistics</phrase> of the <phrase>scatter</phrase> matrix estimators, and employ a simple <phrase>iterative</phrase> procedure to choose the <phrase>optimal</phrase> <phrase>neighborhood</phrase> size. Experiments on synthetic and <phrase>real data</phrase> validate the behavior predicted by the <phrase>model</phrase>, and show <phrase>competitive performance</phrase> and improved stability over leading <phrase>polynomial-fitting</phrase> alternatives that require a preset scale.
3D <phrase>Reconstruction</phrase> of <phrase>Natural Scenes</phrase> with View-<phrase>Adaptive</phrase> <phrase>Multi-Texturing</phrase>.
We present a 3D <phrase>reconstruction</phrase> and modeling system that operates on a number of <phrase>input photographs</phrase> that show a <phrase>natural scene</phrase>. Approaches from <phrase>computer graphics</phrase> and <phrase>image processing</phrase> are combined and performance is shown via experiments. Furthermore, <phrase>reconstruction</phrase> quality is analyzed w.r.t. the number and distribution of textures, used for <phrase>reconstruction</phrase>. The <phrase>reconstruction</phrase> pipeline starts with <phrase>image acquisition</phrase>, which consists of a number of photographs of the scene that are sequentially taken at different positions. Since the photographs are not acquired concurrently, they are influenced by different <phrase>illumination conditions</phrase> that we mandate to be preserved in the final 3D representation. In the second step, <phrase>object segmentation</phrase> is applied and <phrase>camera calibration</phrase> provided. This allows the application of <phrase>shape-from-silhouette</phrase> approaches, namely a <phrase>hierarchical</phrase> <phrase>voxel</phrase> approach, where different resolution layers are organized within an <phrase>octree</phrase> structure. For <phrase>applying</phrase> <phrase>texture mapping</phrase>, the <phrase>voxel</phrase> <phrase>model</phrase> is transformed into a <phrase>wireframe</phrase>, which provides <phrase>smoothing</phrase> of the <phrase>object's surface</phrase> and also reduces the number of surface primitives. <phrase>Finally</phrase>, a <phrase>subset</phrase> of <phrase>original images</phrase> is <phrase>mapped onto</phrase> the 3D <phrase>geometry</phrase> to provide <phrase>texture information</phrase>. Here, view-<phrase>adaptive</phrase> <phrase>multi-texturing</phrase> is used to preserve <phrase>natural illumination</phrase>. <phrase>Intermediate views</phrase> are interpolated automatically using <phrase>adaptive</phrase> <phrase>real-time</phrase> weight calculations for original textures.
<phrase>Efficient</phrase> Constraint Evaluation <phrase>Algorithms</phrase> for <phrase>Hierarchical</phrase> <phrase>Next-Best-View</phrase> <phrase>Planning</phrase>.
We <phrase>recently</phrase> proposed a new and <phrase>efficient</phrase> <phrase>next</phrase>-best-view <phrase>algorithm</phrase> for 3D <phrase>reconstruction</phrase> of <phrase>indoor</phrase> scenes using <phrase>active</phrase> <phrase>range</phrase> sensing. We overcome the computation difficulty of <phrase>evaluating</phrase> the view metric <phrase>function</phrase> by using <phrase>an adaptive</phrase> <phrase>hierarchical</phrase> approach to exploit the various <phrase>spatial</phrase> coherences inherent in the acquisition constraints and <phrase>quality requirements</phrase>. The <phrase>impressive speedups</phrase> have allowed our NBV <phrase>algorithm</phrase> to become the first to be able to exhaustively evaluate a large set of 3D views with respect to a large set of surfaces, and to include many practical acquisition constraints and <phrase>quality requirements</phrase>. The success of the <phrase>algorithm</phrase> is greatly dependent on the implementation efficiency of the constraint and <phrase>quality evaluations</phrase>. In this <phrase>paper</phrase>, we describe the <phrase>algorithmic</phrase> details of the <phrase>hierarchical</phrase> view evaluation, and present <phrase>efficient algorithms</phrase> that evaluate sensing constraints and surface <phrase>sampling</phrase> densities between a view volume and a <phrase>surface patch</phrase> <phrase>instead</phrase> of simply between a <phrase>single view</phrase> point and a <phrase>surface point</phrase>. The presentation here provides examples for the <phrase>design</phrase> of <phrase>efficient algorithms</phrase> for new sensing constraints.
3D <phrase>Face Recognition</phrase> with <phrase>Region</phrase> <phrase>Committee</phrase> <phrase>Voting</phrase>.
In this <phrase>paper</phrase>, we introduce a new system for <phrase>face recognition</phrase> by matching 3D <phrase>face shape</phrase>. This <phrase>algorithm</phrase> selects <phrase>multiple regions</phrase> of the face for matching in an attempt to reduce the effects caused by variations in expression between <phrase>gallery and probe</phrase> images. <phrase>Experimental</phrase> <phrase>results</phrase> are reported using the <phrase>Face Recognition Grand Challenge</phrase> v2.0 <phrase>data</phrase> set. Our <phrase>results</phrase> demonstrate <phrase>improved performance</phrase> relative to those of four <phrase>previous papers</phrase> using this same <phrase>data</phrase> set.
Towards <phrase>On-Line</phrase> <phrase>Digital</phrase> <phrase>Doubles</phrase>.
We present a <phrase>modular</phrase> system for <phrase>real-time</phrase> 3D-scanning of <phrase>human</phrase> bodies under motion. The <phrase>high</phrase>-resolution shape and <phrase>colour</phrase> appearance is captured by several scanning units positioned around the object of interest. Each of these units performs a <phrase>foreground-background segmentation</phrase> and computes a valid <phrase>depth-range</phrase> for the spatially neighbouring units. Multiple depth-<phrase>ranges</phrase> are combined in a <phrase>visual</phrase> <phrase>hull</phrase> representation, which limits the <phrase>search-range</phrase> for the 3D-<phrase>reconstruction</phrase>. <phrase>Depth-estimation</phrase> is based on a <phrase>hierarchical</phrase> mult-<phrase>view-stereo</phrase> <phrase>plane sweep</phrase> approach. Robustness and accuracy is increased by <phrase>incorporating</phrase> imperceptible <phrase>infrared</phrase> illumination as well as adding <phrase>local</phrase> <phrase>pixel</phrase> <phrase>gradient</phrase> <phrase>information</phrase>. All parts of the <phrase>processing pipeline</phrase>, involving <phrase>camera</phrase> <phrase>color</phrase> conversions, segmentation, <phrase>depth-range</phrase> computation, <phrase>visual</phrase>-<phrase>hull</phrase> generation, <phrase>lossless image compression</phrase>, network transfer of the <phrase>infrared</phrase> and <phrase>colour</phrase> images, and the <phrase>plane sweep algorithm</phrase>, are implemented on the <phrase>GPU</phrase> and <phrase>highly optimized</phrase> for speed, allowing scanning times of less than 40ms <phrase>per frame</phrase>. <phrase>Experimental</phrase> <phrase>results</phrase> demonstrate the applicability of our system to the creation of <phrase>high</phrase>-<phrase>density</phrase> <phrase>on-line</phrase> <phrase>digital</phrase> <phrase>doubles</phrase>.
<phrase>High</phrase>-Quality <phrase>Real-Time</phrase> <phrase>Stereo</phrase> Using <phrase>Adaptive</phrase> <phrase>Cost Aggregation</phrase> and <phrase>Dynamic Programming</phrase>.
We present a <phrase>stereo</phrase> <phrase>algorithm</phrase> that <phrase>achieves high</phrase> quality <phrase>results</phrase> while maintaining <phrase>real-time</phrase> performance. The <phrase>key idea</phrase> is simple: we introduce <phrase>an adaptive</phrase> aggregation step in a <phrase>dynamic-programming</phrase> (<phrase>DP</phrase>) <phrase>stereo</phrase> framework. The <phrase>per-pixel</phrase> matching cost is aggregated in the <phrase>vertical</phrase> direction only. Compared to traditional <phrase>DP</phrase>, our approach reduces the typical "<phrase>streaking</phrase>" artifacts without the penalty of blurry <phrase>object boundaries</phrase>. Evaluation using the benchmark <phrase>Middlebury</phrase> <phrase>stereo</phrase> <phrase>database</phrase> shows that our approach is among the best (ranked first in the new evaluation system) for <phrase>DP</phrase>-<phrase>based approaches</phrase>. The <phrase>performance gain</phrase> mainly comes from a <phrase>computationally expensive</phrase> <phrase>weighting</phrase> scheme based on <phrase>color</phrase> and distance <phrase>proximity</phrase>. We utilize the <phrase>vector processing</phrase> capability and parallelism in <phrase>commodity graphics hardware</phrase> to <phrase>speed up</phrase> this process over two <phrase>orders of magnitude</phrase>. Over <phrase>50 million</phrase> disparity evaluations per second (<phrase>MDE</phrase>/<phrase>s</phrase>)1 are achieved in our current implementation.
A <phrase>Spatio-Temporal Modeling</phrase> Method for <phrase>Shape Representation</phrase>.
The <phrase>spherical harmonic</phrase> (SPHARM) description is a powerful <phrase>surface modeling</phrase> technique that can <phrase>model</phrase> <phrase>arbitrarily shaped</phrase> but <phrase>simply connected</phrase> <phrase>three dimensional</phrase> (3D) objects. Because SPHARM based 3D models can derive <phrase>functional</phrase> <phrase>information</phrase> analysis and classify different pathological symptoms, it has been used in many applications in <phrase>biomedical image</phrase> <phrase>computing</phrase>. There is an urgent requirement for <phrase>efficient</phrase> <phrase>spatio-temporal</phrase> <phrase>shape modeling</phrase> to represent the <phrase>dynamic</phrase> <phrase>anatomical structures</phrase> in many applications (e.g., <phrase>medical</phrase> <phrase>image analysis</phrase>, <phrase>geospatial information</phrase> systems). In this <phrase>paper</phrase> we propose a novel real <phrase>spherical harmonics</phrase> based <phrase>spatio-temporal</phrase> <phrase>shape modeling</phrase> method to efficiently and flexibly represent the shapes <phrase>sequence</phrase> of <phrase>anatomical structures</phrase> in <phrase>medical</phrase> images. Our <phrase>method works</phrase> well on the <phrase>simply connected</phrase> 3D objects and the effectiveness of our approach is demonstrated through theoretic and <phrase>experimental</phrase> <phrase>exploration</phrase> of a set of <phrase>medical</phrase> image applications. Furthermore, an <phrase>evaluation criterion</phrase> for <phrase>spatio-temporal</phrase> <phrase>shape modeling</phrase> efficiency is proposed and the <phrase>comparison results</phrase> showed the good performance of our method.
<phrase>Efficient</phrase>, Precise, and Accurate Utilization of the <phrase>Uniqueness</phrase> Constraint in <phrase>Multi-View Stereo</phrase>.
In this <phrase>paper</phrase>, the <phrase>depth cue</phrase> due to the assumption of texture <phrase>uniqueness</phrase> is reviewed. The <phrase>spatial</phrase> direction over which a <phrase>similarity measure</phrase> is optimized, in <phrase>order</phrase> to establish a <phrase>stereo correspondence</phrase>, is considered and methods to increase the precision and accuracy of <phrase>stereo</phrase> reconstructions are presented. <phrase>An efficient</phrase> implementation of the above methods is offered, based on optimizations that evaluate potential correspondences hierarchically, in the <phrase>spatial</phrase> and <phrase>angular</phrase> dimensions. Furthermore, the <phrase>expansion</phrase> of the above techniques in a <phrase>multi-view</phrase> framework where <phrase>calibration</phrase> errors cause the misregistration of individually obtained reconstructions are considered, and a treatment of the <phrase>data</phrase> is proposed for the <phrase>elimination</phrase> of duplicate reconstructions of a <phrase>single</phrase> <phrase>surface point</phrase>. <phrase>Finally</phrase>, a processing step is proposed for the increase of <phrase>reconstruction</phrase> precision and <phrase>post-processing</phrase> of the <phrase>final result</phrase>. The above contributions are integrated in a <phrase>generic</phrase> and parallelizable implementation of the <phrase>uniqueness</phrase> constraint to observe speedup and increase in the fidelity of <phrase>surface reconstruction</phrase>.
Orientation of Fragments of Rotationally <phrase>Symmetrical</phrase> 3D-Shapes for <phrase>Archaeological</phrase> Documentation.
Motivated by the requirements of modern <phrase>archaeologists</phrase>, we are <phrase>developing</phrase> a documentation system based on <phrase>structured light</phrase> for acquisition of ceramics. Fragments of ceramics are <phrase>daily</phrase> finds at excavations and important for <phrase>archaeological</phrase> <phrase>research</phrase>, because their shape leads to <phrase>information</phrase> about <phrase>ancient</phrase> cultures. The shapes used for documentation are called profile lines and estimated by a <phrase>vertical</phrase> <phrase>cross-section</phrase> of <phrase>orientated</phrase> fragments. As ceramics have been <phrase>produced</phrase> using <phrase>rotational</phrase> plates for several thousands of years, the <phrase>rotational</phrase> <phrase>axis</phrase> can be used for orientation. Therefore we <phrase>conducted experiments</phrase> using <phrase>existing methods</phrase> for estimation of the <phrase>rotational</phrase> <phrase>axis</phrase>. The drawbacks of these methods are the requirement of either complete objects or <phrase>industrialized</phrase> quality of <phrase>symmetry</phrase>. Therefore we show a new method using <phrase>circle</phrase> templates, which has been inspired by the manual method of <phrase>archaeologists</phrase>. In this work we present <phrase>results</phrase> using previous and related work in comparison with the estimation of the <phrase>rotational</phrase> <phrase>axis</phrase> using <phrase>circle</phrase> templates. The <phrase>results</phrase> of the presented methods are shown for <phrase>synthetic data</phrase>, well-known fragments and <phrase>real data</phrase> acquired at an <phrase>archaeological</phrase> <phrase>excavation</phrase>. <phrase>Finally</phrase> a <phrase>conclusion</phrase> and an <phrase>outlook</phrase> is given.
<phrase>Point Containment</phrase> in Discrete <phrase>Arbitrary Dimension</phrase>.
The <phrase>point containment</phrase> predicate which specifies if a point is part of a <phrase>mathematically defined</phrase> shape is one of the most <phrase>elementary</phrase> operations in <phrase>computer graphics</phrase> and is a natural way to perform the many <phrase>raster</phrase> calculations. It plays an essential role in several important processes such as filling, stroking, <phrase>anti-aliasing</phrase>, <phrase>geometric</phrase> modeling and <phrase>volume rendering</phrase>. This <phrase>paper</phrase> presents a <phrase>generalized</phrase> <phrase>point containment</phrase> <phrase>algorithm</phrase> for <phrase>arbitrary dimension</phrase> <phrase>discrete objects</phrase> whose <phrase>main characteristics</phrase> are <phrase>low complexity</phrase>, simple <phrase>data structures</phrase> and suitability for <phrase>hardware implementation</phrase>.
VisTRE: A <phrase>Visualization Tool</phrase> to Evaluate Errors in <phrase>Terrain</phrase> Representation.
New <phrase>data</phrase> sources and sensors bring new possibilities for <phrase>terrain</phrase> representations, and new types of characteristic errors. We develop a system to visualize and compare <phrase>terrain</phrase> representations and the errors they produce.
<phrase>Exploiting</phrase> 3D <phrase>Spatial</phrase> Continuity for <phrase>Robust</phrase> <phrase>Automatic</phrase> <phrase>Horizon</phrase> Matching across Faults.
<phrase>Oil and gas exploration</phrase> decisions are made based on inferences obtained from <phrase>seismic data</phrase> interpretation. The interpretation task is getting very <phrase>time-consuming</phrase> as <phrase>seismic data</phrase> sets become larger. <phrase>Image processing</phrase> tools such as <phrase>auto</phrase>-trackers assist manual interpretation of <phrase>horizons</phrase>-visible boundaries between certain <phrase>sediment</phrase> layers in <phrase>seismic data</phrase>. <phrase>Auto</phrase>-trackers assume <phrase>data</phrase> continuities; therefore, their <phrase>assistance</phrase> is very limited in areas of discontinuities such as faults. In this <phrase>paper</phrase>, we present a method for <phrase>automatic</phrase> <phrase>horizon</phrase> matching across faults based on <phrase>a Bayesian approach</phrase>. A <phrase>stochastic</phrase> matching <phrase>model</phrase> which integrates 3d <phrase>spatial information</phrase> of <phrase>seismic data</phrase> and prior <phrase>geological</phrase> <phrase>knowledge</phrase> is introduced. The <phrase>optimal</phrase> matching <phrase>solution</phrase> is found by <phrase>MAP</phrase> estimate of this <phrase>model</phrase>. A <phrase>simulated annealing</phrase> with <phrase>reversible jump Markov Chain Monte Carlo</phrase> <phrase>algorithm</phrase> is employed to sample from <phrase>a-posteriori</phrase> distribution. The <phrase>model</phrase> was applied to real 3d <phrase>seismic data</phrase>, and has shown to produce geologically acceptable <phrase>horizons</phrase> <phrase>matchings</phrase>.
A <phrase>Range</phrase> <phrase>Camera</phrase> Collecting <phrase>Multi-Spectral</phrase> Texture for <phrase>Architecture</phrase> Applications.
This work proposes a system for the <phrase>automatic</phrase> <phrase>construction</phrase> of <phrase>multi-spectral</phrase> 3D models of <phrase>architecture</phrase>. Besides the specific application which concerns the <phrase>interactive visualization</phrase> and the <phrase>restoration</phrase> of <phrase>historical</phrase> buildings, the interest of the proposed techniques lays in the <phrase>multi-spectral</phrase> <phrase>nature</phrase> of the textures which allow rendering with <phrase>faithful</phrase> colors and in the automatism of 3D <phrase>model</phrase> <phrase>construction</phrase>. The proposed system is an effective tool for producing 3D content amenable to a great number of applications.
<phrase>Qualitative</phrase> Characterization of <phrase>Deforming Surfaces</phrase>.
This <phrase>paper</phrase> extends the idea of <phrase>classification schemes</phrase> for static <phrase>surface curvature</phrase> into the <phrase>temporal domain</phrase>. We seek to identify regions in sequences of <phrase>depth data</phrase> that exhibit variations in <phrase>shape change</phrase>, and to characterise the <phrase>nature</phrase> of the deformation. From <phrase>observing</phrase> the change in principle curvatures we show how it is possible to decouple the type of change into one of fifteen classes, and also reveal the extent of alteration. <phrase>Results</phrase> are presented for synthetic and <phrase>real data</phrase> sequences, with additional alignment performed to accommodate <phrase>global</phrase> motion. This technique <phrase>shows promise</phrase> in <phrase>analysing</phrase> <phrase>data</phrase> from <phrase>video</phrase>-rate <phrase>range</phrase> sensors, with <phrase>potential applications</phrase> in <phrase>biometric</phrase> and <phrase>psychological</phrase> analysis of the face and other <phrase>deformable objects</phrase>.
Constraint <phrase>Integration</phrase> for <phrase>Multiview</phrase> <phrase>Pose Estimation</phrase> of Humans with <phrase>Self-Occlusions</phrase>.
Detection of <phrase>articulated objects</phrase> such as humans is an important task in <phrase>computer vision</phrase>. We present a system that incorporates a <phrase>variety</phrase> of constraints in <phrase>a unified</phrase> <phrase>multi-view</phrase> framework to <phrase>automatically detect</phrase> humans in possibly <phrase>crowded scenes</phrase>. These constraints include the <phrase>kinematic</phrase> constraints, the occlusion of one part by another and the <phrase>high</phrase> correlation between the appearance of parts such as the two <phrase>arms</phrase>. The <phrase>graphical</phrase> structure (non-<phrase>tree</phrase>) obtained is optimized in a <phrase>nonparametric belief propagation</phrase> framework using prior <phrase>based search</phrase>.
<phrase>Structured Light</phrase> Based <phrase>Reconstruction</phrase> under <phrase>Local</phrase> <phrase>Spatial Coherence</phrase> Assumption.
3D scanning techniques based on <phrase>structured light</phrase> usually achieve robustness against <phrase>outliers</phrase> by performing <phrase>multiple projections</phrase> to simplify <phrase>correspondence</phrase>. However, for cases such as <phrase>dynamic</phrase> scenes, the number of frames captured from a certain view must be kept as low as possible, which makes it difficult to reconstruct <phrase>complex scenes</phrase> with <phrase>high</phrase> <phrase>frequency</phrase> shapes and inappropriate <phrase>reflection</phrase> properties. To tackle this problem, we present a novel set of <phrase>color</phrase> <phrase>stripe</phrase> patterns and a <phrase>robust</phrase> <phrase>correspondence</phrase> <phrase>algorithm</phrase> that assume <phrase>local</phrase> <phrase>spatial coherence</phrase> in the captured <phrase>data</phrase>. This assumption allows us to <phrase>design</phrase> our <phrase>stripe</phrase> sequences with <phrase>globally unique</phrase> <phrase>neighborhood</phrase> properties to effectively avoid wrong correspondences. The concept of <phrase>local</phrase> <phrase>spatial coherence</phrase> is further exploited to make the ensuing <phrase>surface reconstruction</phrase> practically insensitive to noise, <phrase>outliers</phrase>, and <phrase>anisotropic</phrase> <phrase>sampling</phrase> <phrase>density</phrase>. Thus, the recovery of a <phrase>topologically</phrase> consistent <phrase>manifold</phrase> surface can be drastically <phrase>simplified</phrase>. We have successfully generated <phrase>high</phrase> quality meshes of various <phrase>colored</phrase> objects using a <phrase>minimalistic</phrase> <phrase>projector-camera system</phrase>. In particular, the full <phrase>sampling</phrase> capabilities of our devices can be exhausted by taking only three shots.
Recognition of <phrase>Free</phrase>-Form Objects in <phrase>Complex Scenes</phrase> Using DGI-<phrase>BS</phrase> Models.
<phrase>Object recognition</phrase> in 3D scenes with occlusion means <phrase>identifying</phrase> an incomplete and unknown object, which is arbitrarily posed, in an <phrase>object database</phrase>. This hard <phrase>computer vision</phrase> problem is solved in this <phrase>paper</phrase> through a new 3D <phrase>shape representation</phrase> called Depth <phrase>Gradient</phrase> <phrase>Image Based</phrase> on <phrase>Silhouette</phrase> (DGI-<phrase>BS</phrase>). DGI-<phrase>BS</phrase> can be used to obtain a complete <phrase>model</phrase> as well as a <phrase>partial</phrase> <phrase>model</phrase> of an object. This <phrase>property</phrase> allows us to use it in <phrase>complex scenes</phrase> where incomplete surfaces of objects are available. The complete DGI-<phrase>BS</phrase> version synthesizes surface <phrase>information</phrase> (through <phrase>depth image</phrase>) and <phrase>shape information</phrase> (through <phrase>contour</phrase>) of the whole object in a <phrase>single</phrase> image smaller than 1 <phrase>mega pixel</phrase>. <phrase>Object recognition</phrase> is carried out by means of a simple <phrase>matching algorithm</phrase> in the DGI-<phrase>BS</phrase> space which yields a <phrase>correspondence</phrase> <phrase>point-to-point</phrase> between scene and <phrase>model</phrase>. This method has been <phrase>successfully tested</phrase> in <phrase>real scenes</phrase> with no special restrictions using <phrase>range</phrase> sensors.
<phrase>Visual</phrase> <phrase>Hull</phrase> <phrase>Construction</phrase> in the Presence of <phrase>Partial</phrase> Occlusion.
In this <phrase>paper</phrase>, we propose a <phrase>visual</phrase> <phrase>hull</phrase> <phrase>algorithm</phrase>, which guarantees a correct <phrase>construction</phrase> even in the presence of <phrase>partial</phrase> occlusion, while "correct" here means that the real shape is <phrase>located inside</phrase> the <phrase>visual</phrase> <phrase>hull</phrase>. The <phrase>algorithm</phrase> is based on a new idea of the "extended <phrase>silhouette</phrase>", which requires the <phrase>silhouette</phrase> from <phrase>background subtraction</phrase> and the "occlusion mask" of the same view. In <phrase>order</phrase> to prepare the occlusion mask, we also propose a novel concept of "effective boundary" of <phrase>moving foreground objects</phrase> in a <phrase>video</phrase> obtained from a <phrase>static camera</phrase>. The <phrase>accumulation</phrase> of the effective boundary through time automatically gives <phrase>robust</phrase> occluder boundaries. We <phrase>theoretically prove</phrase> that our <phrase>algorithm</phrase> deterministically computes the tightest, correct <phrase>visual</phrase> <phrase>hull</phrase> in the presence of occlusion. Both synthetic and real examples are given as a <phrase>demonstration</phrase> of the correctness of the <phrase>algorithm</phrase>. <phrase>Finally</phrase> we analyze that this new <phrase>algorithm</phrase> is still within the time complexity of the traditional method.
<phrase>Aerial LiDAR Data</phrase> <phrase>Classification Using Support Vector Machines</phrase> (<phrase>SVM</phrase>).
We classify 3D <phrase>aerial</phrase> <phrase>LiDAR</phrase> scattered height <phrase>data</phrase> into buildings, <phrase>trees</phrase>, roads, and <phrase>grass</phrase> using the <phrase>Support Vector Machine</phrase> (<phrase>SVM</phrase>) <phrase>algorithm</phrase>. To do so we use five features: height, height variation, <phrase>normal variation</phrase>, <phrase>LiDAR</phrase> return intensity, and <phrase>image intensity</phrase>. We also use only <phrase>LiDAR</phrase>-derived features to organize the <phrase>data</phrase> into three classes (the <phrase>road</phrase> and <phrase>grass</phrase> classes are merged). We have implemented and experimented with several variations of the <phrase>SVM</phrase> <phrase>algorithm</phrase> with <phrase>soft</phrase>-margin classification to allow for the noise in the <phrase>data</phrase>. We have applied our <phrase>results</phrase> to classify <phrase>aerial LiDAR data</phrase> collected over approximately 8 square <phrase>miles</phrase>. We visualize the <phrase>classification results</phrase> along with the associated confidence using a variation of the <phrase>SVM</phrase> <phrase>algorithm</phrase> producing <phrase>probabilistic</phrase> classifications. We observe that the <phrase>results</phrase> are <phrase>stable</phrase> and <phrase>robust</phrase>. We compare the <phrase>results</phrase> against the <phrase>ground truth</phrase> and obtain higher than 90% accuracy and convincing <phrase>visual</phrase> <phrase>results</phrase>.
Resolution <phrase>Scalable Coding</phrase> and <phrase>Region</phrase> of Interest Access with <phrase>Three-Dimensional</phrase> SBHP <phrase>Algorithm</phrase>.
<phrase>A low-complexity</phrase> <phrase>three-dimensional</phrase> <phrase>image compression</phrase> <phrase>algorithm</phrase> based on <phrase>wavelet</phrase> transforms and <phrase>set-partitioning</phrase> strategy is presented. The <phrase>Subband</phrase> Block <phrase>Hierarchial</phrase> Partitioning (SBHP) <phrase>algorithm</phrase> is <phrase>modified</phrase> and extended to three dimensions, and applied to every code block independently. The resultant <phrase>algorithm</phrase>, 3D-SBHP, efficiently encodes 3D <phrase>image data</phrase> by the <phrase>exploitation</phrase> of the dependencies in all dimensions, while enabling <phrase>progressive</phrase> <phrase>SNR</phrase> and resolution <phrase>decompression</phrase> and <phrase>Region</phrase>-of-Interest (<phrase>ROI</phrase>) access from the same <phrase>bit</phrase> <phrase>stream</phrase>. The code-<phrase>block selection</phrase> method by which <phrase>random access</phrase> decoding can be achieved is outlined.The resolution scalable and <phrase>random access</phrase> performances are <phrase>empirically investigated</phrase>. The <phrase>results</phrase> show 3D-SBHP is a good candidate to compress 3D <phrase>image data</phrase> sets for <phrase>multimedia</phrase> applications.
<phrase>Estimating</phrase> <phrase>a-priori</phrase> Unknown 3D <phrase>Axially Symmetric</phrase> Surfaces from <phrase>Noisy Measurements</phrase> of Their Fragments.
In this <phrase>paper</phrase>, we present a <phrase>computationally efficient</phrase> technique for solving the <phrase>difficult problem</phrase> of <phrase>estimating</phrase> the <phrase>global</phrase> shape of a <phrase>ceramic</phrase> <phrase>pot</phrase> from measurements of its fragments. Each unknown <phrase>pot</phrase> is modeled as a surface of <phrase>revolution</phrase>, i.e., a 3D line-- the <phrase>central axis</phrase> of the <phrase>pot</phrase> -- and a 2D <phrase>profile curve</phrase> with respect to that <phrase>axis</phrase>. For each fragment, a <phrase>probabilistic</phrase> distribution is estimated which models both the <phrase>geometric</phrase> shape of the fragment and the variability of the estimated fragment shape. Estimation of the <phrase>global</phrase> <phrase>pot</phrase> shape is then a <phrase>Maximum Likelihood Estimation</phrase> (<phrase>MLE</phrase>) problem where we seek the values of the <phrase>Euclidean</phrase> <phrase>transformation parameters</phrase> that maximize the <phrase>joint</phrase> <phrase>probability</phrase> of the matched fragments' <phrase>axis</phrase>/profile-curvemodels (which includes the additional constraint that the matched fragments must share a common <phrase>central axis</phrase>). This is a new type of curve-analysis problem and our <phrase>solution</phrase> is a new and effective approach applicable for <phrase>generic</phrase> constrained 2D <phrase>curve alignment</phrase> and for modeling of 3D <phrase>axially-symmetric</phrase> surfaces and for <phrase>comparing</phrase> <phrase>geometric</phrase> models which may correspond over a <phrase>subset</phrase> of the complete <phrase>model</phrase>.
On 3D Retrieval from Photos.
In this <phrase>paper</phrase>, we propose a method for 3D-<phrase>model</phrase> retrieval from one or more photos. This method provides an "<phrase>optimal</phrase>" selection of 2D views to represent a 3D-<phrase>model</phrase>, and a <phrase>probabilistic</phrase> <phrase>Bayesian</phrase> method for 3D-<phrase>model</phrase> retrieval from realistic photos and sketches using these views. The characteristic <phrase>view selection</phrase> <phrase>algorithm</phrase> is based on <phrase>an adaptive</phrase> <phrase>clustering algorithm</phrase> and uses <phrase>statistical model</phrase> distribution scores to select the <phrase>optimal</phrase> number of views. We also introduce <phrase>a Bayesian approach</phrase> to score the <phrase>probability</phrase> of <phrase>correspondence</phrase> between the queries and the 3D-models. We present our <phrase>results</phrase> on the <phrase>Princeton</phrase> 3D Shape <phrase>Benchmark database</phrase> (1814 3D-models) and 50 photos (real photographs, sketches, synthesised images). A practical <phrase>on-line</phrase> 3D-<phrase>model</phrase> <phrase>retrieval system</phrase> based on our approach is available on the <phrase>web</phrase> to <phrase>asset</phrase> our <phrase>results</phrase> [1].
The <phrase>Reverse</phrase> <phrase>Projection</phrase> Correlation Principle for <phrase>Depth from Defocus</phrase>.
In this <phrase>paper</phrase>, we address the problem of <phrase>finding</phrase> <phrase>depth from defocus</phrase> in a fundamentally new way. Most <phrase>previous methods</phrase> have used an <phrase>approximate</phrase> <phrase>model</phrase> in which blurring is <phrase>shift invariant</phrase> and <phrase>pixel</phrase> <phrase>area</phrase> is negligible. Our <phrase>model</phrase> avoids these assumptions. We consider the <phrase>area</phrase> in the scene whose <phrase>radiance</phrase> is recorded by a <phrase>pixel</phrase> on the <phrase>sensor</phrase>, and relate the size and shape of that <phrase>area</phrase> to the scene's position with respect to the plane of focus. This is the notion of <phrase>reverse</phrase> <phrase>projection</phrase>, which allows us to illustrate that, when out of focus, <phrase>neighboring pixels</phrase> will record <phrase>light</phrase> from <phrase>overlapping regions</phrase> in the scene. This overlap <phrase>results</phrase> in a measurable change in the correlation between the <phrase>pixels</phrase>' <phrase>intensity values</phrase>. We demonstrate that this relationship can be characterized in such a way as to recover depth from <phrase>defocused images</phrase>. <phrase>Experimental</phrase> <phrase>results</phrase> show the ability of this relationship to <phrase>accurately predict</phrase> depth from correlation measurements.
<phrase>Direct</phrase> and <phrase>Indirect</phrase> 3-<phrase>D</phrase> <phrase>Reconstruction</phrase> from Opti-<phrase>Acoustic</phrase> <phrase>Stereo</phrase> <phrase>Imaging</phrase>.
Utilization of an <phrase>acoustic</phrase> <phrase>camera</phrase> for <phrase>range</phrase> measurements is a significant advantage for 3-<phrase>D</phrase> <phrase>shape recovery</phrase> of <phrase>underwater</phrase> targets by opti-<phrase>acoustic</phrase> <phrase>stereo</phrase> <phrase>imaging</phrase>, where the associated <phrase>epipolar geometry</phrase> of <phrase>visual</phrase> and <phrase>acoustic</phrase> <phrase>image correspondences</phrase> is described in terms of <phrase>conic sections</phrase> and <phrase>trigonometric functions</phrase>. In this <phrase>paper</phrase>, we propose and analyze a number of methods based on <phrase>direct</phrase> and <phrase>indirect</phrase> approaches that <phrase>provide insight</phrase> on the merits of the new <phrase>imaging</phrase> and 3-<phrase>D</phrase> <phrase>object reconstruction</phrase> <phrase>paradigm</phrase>. We have devised certain <phrase>indirect</phrase> methods, built on a <phrase>regularization</phrase> formulation, to first compute from noisy correspondences <phrase>maximum likelihood</phrase> estimates that satisfy the <phrase>epipolar geometry</phrase>. The 3-<phrase>D</phrase> <phrase>target</phrase> points can then be determined from a number of <phrase>closed-form</phrase> solutions applied to these <phrase>ML</phrase> estimates. An <phrase>alternative</phrase> <phrase>direct</phrase> approach is also presented for 3-<phrase>D</phrase> reocnstruction directly from noisy correspondences. Computer simulations verify consistency between the analytical and <phrase>experimental</phrase> <phrase>reconstruction</phrase> <phrase>SNRs</phrase> -- the criterion applied in <phrase>performance assessment</phrase> of these various solutions.
<phrase>Automatic</phrase> Registration of <phrase>Multiple Range Images</phrase> by the <phrase>Local</phrase> <phrase>Log-Polar</phrase> <phrase>Range</phrase> Images.
We propose a method for <phrase>automatic</phrase> registration of <phrase>multiple range images</phrase> by matching <phrase>invariant feature</phrase> vectors generated from the <phrase>local</phrase> <phrase>log-polar</phrase> <phrase>range</phrase> images. <phrase>Point pairs</phrase> are corresponded by <phrase>finding</phrase> the <phrase>nearest neighbor</phrase> of <phrase>invariant feature</phrase> vectors. The <phrase>correspondence</phrase> is validated, and the pairwise transformations between the <phrase>input range</phrase> images are determined by using the <phrase>RANSAC algorithm</phrase>. The registration of all <phrase>input range</phrase> images are determined by <phrase>constructing</phrase> the view <phrase>tree</phrase> of the <phrase>input range</phrase> images. The registration result of the <phrase>proposed method</phrase> is used as the initial value of a <phrase>fine registration</phrase> methods for <phrase>object shape</phrase> modeling.
A <phrase>Modular</phrase> Scheme for 2D/3D Conversion of <phrase>TV</phrase> <phrase>Broadcast</phrase>.
The 3D <phrase>reconstruction</phrase> from 2D <phrase>broadcast</phrase> <phrase>video</phrase> is a <phrase>challenging problem</phrase> with many <phrase>potential applications</phrase>, such as 3DTV, <phrase>free-viewpoint video</phrase> or <phrase>augmented reality</phrase>. In this <phrase>paper</phrase>, a <phrase>modular</phrase> system capable of efficiently <phrase>reconstructing</phrase> 3D scenes from <phrase>broadcast</phrase> <phrase>video</phrase> is proposed. The system consists of four constitutive modules: tracking and segmentation, <phrase>self-calibration</phrase>, <phrase>sparse</phrase> <phrase>reconstruction</phrase> and, <phrase>finally</phrase>, <phrase>dense</phrase> <phrase>reconstruction</phrase>. This <phrase>paper</phrase> also introduces some novel approaches for <phrase>moving object</phrase> segmentation and <phrase>sparse</phrase> and <phrase>dense</phrase> <phrase>reconstruction</phrase> problems. According to the simulations for both synthetic and <phrase>real data</phrase>, the system achieves a <phrase>promising performance</phrase> for typical <phrase>TV</phrase> content, indicating that it is a significant step towards the 3D <phrase>reconstruction</phrase> of scenes from <phrase>broadcast</phrase> <phrase>video</phrase>.
<phrase>Fast</phrase> and <phrase>Efficient</phrase> <phrase>Dense</phrase> <phrase>Variational</phrase> <phrase>Stereo</phrase> on <phrase>GPU</phrase>.
Thanks to their <phrase>high</phrase> performance and programmability, the latest <phrase>graphics cards</phrase> can now be used for scientific purpose. They are indeed very <phrase>efficient parallel</phrase> <phrase>Single Instruction Multiple Data</phrase> (<phrase>SIMD</phrase>) machines. This new trend is called <phrase>General</phrase> Purpose computation on <phrase>Graphics Processing Unit</phrase> (<phrase>GPGPU</phrase> [4]). Regarding the <phrase>stereo</phrase> problem, <phrase>variational</phrase> methods based on <phrase>deformable models</phrase> provide <phrase>dense</phrase>, smooth and <phrase>accurate results</phrase>. Nevertheless, they prove to be <phrase>slower than</phrase> usual disparity-<phrase>based approaches</phrase>. In this <phrase>paper</phrase>, we present a <phrase>dense</phrase> <phrase>stereo</phrase> <phrase>algorithm</phrase>, <phrase>handling occlusions</phrase>, using three cameras as inputs and entirely implemented on a <phrase>Graphics Processing Unit</phrase> (<phrase>GPU</phrase>). <phrase>Experimental</phrase> speedups prove that our approach is <phrase>efficient</phrase> and perfectly adapted to the <phrase>GPU</phrase>, leading to nearly <phrase>video</phrase> <phrase>frame rate</phrase> <phrase>reconstruction</phrase>.
<phrase>Automatic</phrase> 3D <phrase>Face Detection</phrase>, Normalization and Recognition.
A <phrase>fully automatic</phrase> 3D <phrase>face recognition</phrase> <phrase>algorithm</phrase> is presented. Several novelties are introduced to make the recognition <phrase>robust</phrase> to <phrase>facial expressions</phrase> and <phrase>efficient</phrase>. These novelties include: (1) <phrase>Automatic</phrase> 3D <phrase>face detection</phrase> by <phrase>detecting</phrase> the <phrase>nose</phrase>; (2) <phrase>Automatic</phrase> <phrase>pose correction</phrase> and normalization of the 3D face as well as its corresponding 2D face using the <phrase>Hotelling</phrase> Transform; (3) A <phrase>Spherical</phrase> <phrase>Face Representation</phrase> and its use as a rejection classifier to quickly reject a <phrase>large number</phrase> of <phrase>candidate faces</phrase> for <phrase>efficient</phrase> recognition; and (4) Robustness to <phrase>facial expressions</phrase> by <phrase>automatically segmenting</phrase> the face into expression sensitive and insensitive regions. <phrase>Experiments performed</phrase> on the <phrase>FRGC</phrase> Ver 2.0 dataset (9,500 2D/3D faces) show that our <phrase>algorithm outperforms</phrase> existing 3D <phrase>recognition algorithms</phrase>. We achieved verification rates of 99.47% and 94.09% at 0.001 FAR and identification rates of 98.03% and 89.25% for probes with neutral and non-<phrase>neutral expression</phrase> respectively.
<phrase>Extracting</phrase> 3D <phrase>Shape Features</phrase> in <phrase>Discrete Scale-Space</phrase>.
3D <phrase>shape features</phrase> are inherently <phrase>scale-dependent</phrase>. For instance, on a 3D <phrase>model</phrase> of a <phrase>human</phrase> body, the <phrase>top</phrase> of the <phrase>head</phrase> and a <phrase>fingertip</phrase> can both be detected as <phrase>corner</phrase> points, however, at entirely different scales. In this <phrase>paper</phrase>, we present a method for <phrase>extracting</phrase> and <phrase>integrating</phrase> 3D <phrase>shape features</phrase> in the <phrase>discrete scale-space</phrase> of a <phrase>triangular mesh</phrase> <phrase>model</phrase>. We first parameterize the surface of the mesh <phrase>model</phrase> on a 2D plane and then construct a <phrase>dense</phrase> <phrase>surface normal</phrase> <phrase>map</phrase>. In <phrase>general</phrase>, the <phrase>parametrization</phrase> is not <phrase>isometric</phrase>. To account for this, we compute the relative <phrase>stretch</phrase> of the original <phrase>edge lengths</phrase>. <phrase>Next</phrase>, we compute a <phrase>dense</phrase> <phrase>distortion</phrase> <phrase>map</phrase> which is used to <phrase>approximate</phrase> the <phrase>geodesic</phrase> distances on the <phrase>normal map</phrase>. Then, we construct a <phrase>discrete scale-space</phrase> of the original 3D shape by successively convolving the <phrase>normal map</phrase> with <phrase>distortion</phrase>-<phrase>adapted Gaussian</phrase> kernels of increasing <phrase>standard deviation</phrase>. We derive <phrase>corner</phrase> and <phrase>edge detectors</phrase> to extract 3D features at each scale in the <phrase>discrete scale-space</phrase>. Furthermore, we show how to combine the detector responses from different scales to form <phrase>a unified</phrase> representation of the 3D features.
<phrase>Philips</phrase> 3D Solutions: From <phrase>Content Creation</phrase> to Visualization.
<phrase>Philips</phrase> is <phrase>realizing</phrase> an <phrase>end-to-end</phrase> 3D display <phrase>solution</phrase> from 3D <phrase>content creation</phrase> to visualization. This development fits in our <phrase>long</phrase>-standing tradition of <phrase>combining</phrase> expertise in <phrase>video processing</phrase> with our strength in display development to create the most exciting and best <phrase>viewing experience</phrase>. <phrase>Philips</phrase> developed several <phrase>high</phrase>-quality 3D displays, ranging in resolution, <phrase>viewing angle</phrase>, depth experience, and sizes from 4" to 40" and up. <phrase>Backwards compatibility</phrase> with 2D content is enabled via <phrase>signal-processing</phrase> or <phrase>opto-electronic</phrase> 3D & 2D <phrase>dual</phrase> mode displays. <phrase>Content creation</phrase> and conversion methods are provided, which are a key factor for the success of 3D displays. <phrase>Fully automatic</phrase> conversion from monoscopic 2D content into 3D enables the <phrase>re</phrase>-use of all existing 2D <phrase>video</phrase> material. Further methods enable 3D <phrase>animation</phrase>/<phrase>design</phrase>, 2D to 3D conversion in <phrase>post-production</phrase> and <phrase>live</phrase> capture of new 3D content. Our efforts in <phrase>MPEG</phrase> <phrase>standardization</phrase> towards the "2D-plus-depth" format for 3D <phrase>video</phrase> enables a flexible interface between the <phrase>variety</phrase> in 3D <phrase>content creation</phrase> methods and the <phrase>range</phrase> in 3D displays. Furthermore, the 3D format is compatible with existing 2D content, standards and <phrase>infrastructure</phrase>. Currently, <phrase>Philips</phrase> offers several commercial 3D <phrase>products</phrase> for <phrase>professional</phrase> use such as <phrase>digital signage</phrase>, and progress is being made towards <phrase>consumer</phrase> <phrase>products</phrase> such as 3DTV.
<phrase>Gaze</phrase> Tracking by Using <phrase>Factorized</phrase> Likelihoods <phrase>Particle</phrase> Filtering and <phrase>Stereo</phrase> Vision.
This <phrase>paper</phrase> describes a <phrase>non-intrusive</phrase> method to estimate the <phrase>gaze</phrase> direction of a person by using <phrase>stereo</phrase> cameras. First, <phrase>facial features</phrase> are tracked with an adapted <phrase>particle filtering</phrase> <phrase>algorithm</phrase> using <phrase>factorized</phrase> likelihoods to estimate the 3D <phrase>head</phrase> pose. <phrase>Next</phrase> the 3D <phrase>gaze</phrase> <phrase>vector</phrase> is calculated by <phrase>estimating</phrase> the eyeball <phrase>center</phrase> and the <phrase>cornea</phrase> <phrase>center</phrase> of both <phrase>eyes</phrase>. For the intended application of <phrase>visual perception</phrase> <phrase>research</phrase>, we also propose a new screen <phrase>registration scheme</phrase> to <phrase>accurately locate</phrase> a <phrase>planar</phrase> screen in <phrase>world coordinates</phrase> within 2 <phrase>mm</phrase> error. We combine the 3D screen location with the 3D <phrase>gaze</phrase> vectors from both <phrase>eyes</phrase> to establish a point of focus on the screen. The <phrase>experimental</phrase> <phrase>results</phrase> indicate that an <phrase>average</phrase> error of the <phrase>gaze</phrase> direction of about 4.6± can be achieved and an <phrase>average</phrase> error of about 4 <phrase>mm</phrase> for the focus <phrase>point location</phrase> at a <phrase>viewing distance</phrase> of 50 <phrase>cm</phrase>.
Invariant <phrase>High</phrase> Level <phrase>Reeb Graphs</phrase> of 3D <phrase>Polygonal Meshes</phrase>.
Many applications in <phrase>computer graphics</phrase> need <phrase>high</phrase> level <phrase>shape descriptions</phrase>, in <phrase>order</phrase> to benefit from a <phrase>global</phrase> <phrase>understanding</phrase> of shapes. <phrase>Topological</phrase> approaches enable pertinent surface <phrase>decompositions</phrase>, providing <phrase>structural</phrase> descriptions of 3D <phrase>polygonal meshes</phrase>; but in practice, their use raises several difficulties. In this <phrase>paper</phrase>, we present a novel method for the <phrase>construction</phrase> of invariant <phrase>high</phrase> level <phrase>Reeb graphs</phrase>, <phrase>topological</phrase> entities that give a good <phrase>overview</phrase> of the shape structure. With this aim, we propose an accurate and straightforward <phrase>feature point extraction</phrase> <phrase>algorithm</phrase> for the computation of an invariant and meaningful <phrase>quotient</phrase> <phrase>function</phrase>. Moreover, we propose a new <phrase>graph</phrase> <phrase>construction</phrase> <phrase>algorithm</phrase>, based on an analysis of the connectivity evolutions of discrete <phrase>level lines</phrase>. This <phrase>algorithm</phrase> brings a <phrase>practical solution</phrase> for the suppression of non-significant <phrase>critical points</phrase> over <phrase>piecewise</phrase> <phrase>continuous</phrase> functions, providing meaningful <phrase>Reeb graphs</phrase>. Presented method gives <phrase>accurate results</phrase>, with satisfactory <phrase>execution times</phrase> and without <phrase>input parameter</phrase>. The <phrase>geometrical</phrase> <phrase>invariance</phrase> of resulting <phrase>graphs</phrase> and their robustness to variation in <phrase>model</phrase> pose and mesh <phrase>sampling</phrase> make them good candidates for several applications, like <phrase>shape deformation</phrase> (experimented in this <phrase>paper</phrase>), recognition, compression, <phrase>indexing</phrase>, etc.
<phrase>Recovering</phrase> Illumination and Texture Using Ratio Images.
In this <phrase>paper</phrase> we consider the problem of <phrase>factoring</phrase> illumination and texture from a pair of images of a diffuse object of known <phrase>geometry</phrase>. This <phrase>problem arises</phrase> frequently in 3D <phrase>photography</phrase> applications that use images to acquire <phrase>photometric</phrase> properties of a scanned object. Our approach uses the ratio of the images and the <phrase>geometry</phrase> <phrase>information</phrase> to compute the relative incident <phrase>irradiance</phrase> of one image with respect to the other. After the <phrase>irradiance</phrase> <phrase>maps</phrase> are recovered, we build a <phrase>spatially varying</phrase> <phrase>albedo</phrase> <phrase>map</phrase>, which can then be used to render the object under different <phrase>illumination conditions</phrase>. We present two <phrase>algorithms</phrase>, one for <phrase>point-light source</phrase> illumination, and another one based on <phrase>spherical harmonics</phrase> for more <phrase>general</phrase> <phrase>illumination conditions</phrase>.
A 3D <phrase>Outdoor</phrase> Scene <phrase>Scanner</phrase> Based on a <phrase>Night-Vision</phrase> <phrase>Range</phrase>-<phrase>Gated</phrase> <phrase>Active</phrase> <phrase>Imaging</phrase> System.
We present a 3D <phrase>outdoor</phrase> scene <phrase>scanner</phrase> for the acquisition of kilometers-<phrase>deep</phrase> scenes in <phrase>night</phrase> conditions. Its <phrase>imaging</phrase> system is based on a <phrase>compact</phrase> and <phrase>low-cost</phrase> <phrase>pulsed</phrase> <phrase>laser</phrase> illuminator and a <phrase>light</phrase>-<phrase>intensifier</phrase> equipped <phrase>CCD camera</phrase>. By precisely <phrase>synchronizing</phrase> both the illuminator and the <phrase>camera</phrase> shutter, it is possible to acquire "slices" of the scene at specific known distances. We show that even with large <phrase>laser</phrase> pulses and without <phrase>megahertz</phrase>-capable <phrase>electronics</phrase>, the third <phrase>dimension</phrase> can be recovered for the whole <phrase>range</phrase> of the scene by processing only two <phrase>images acquired</phrase> in specific conditions. As the <phrase>pixel</phrase> intensities of the images <phrase>produced</phrase> by <phrase>active</phrase> <phrase>imaging</phrase> systems vary with the square of the <phrase>range</phrase>, and due to the limited dynamics of <phrase>image sensors</phrase>, scanning <phrase>long</phrase>-<phrase>range</phrase> scenes with shorter "slices" allows the <phrase>camera</phrase> gain to be adjusted with respect to the <phrase>range</phrase> and the accuracy to be <phrase>enhanced</phrase>. The <phrase>imaging</phrase> system as well as the different <phrase>image processing</phrase> steps are detailed in this <phrase>paper</phrase> and an example of typical <phrase>results</phrase> is given.
<phrase>Deformable Mesh</phrase> <phrase>Model</phrase> for Complex <phrase>Multi-Object</phrase> 3D <phrase>Motion Estimation</phrase> from <phrase>Multi-Viewpoint</phrase> <phrase>Video</phrase>.
We propose a new <phrase>algorithm</phrase> using <phrase>deformable mesh</phrase> <phrase>model</phrase> for complex 3D <phrase>motion estimation</phrase> of <phrase>multiple objects</phrase> from <phrase>multi-viewpoint</phrase> <phrase>video</phrase>. In this <phrase>paper</phrase>, we define "<phrase>complex motion</phrase>" as motion which includes <phrase>global</phrase> change of the <phrase>object shape</phrase> <phrase>topology</phrase>. In <phrase>complex motion</phrase>, a part of the object may <phrase>touch</phrase> the other parts. To manage this effect, we introduce (1) "<phrase>repulsive</phrase> force" into <phrase>deformable mesh</phrase> <phrase>model</phrase> for simple <phrase>motion estimation</phrase> which integrates texture and <phrase>silhouette</phrase> <phrase>information</phrase> into <phrase>unified</phrase> computation scheme, and (2) <phrase>efficient</phrase> <phrase>collision detection</phrase> <phrase>algorithm</phrase> for <phrase>deformable mesh</phrase> <phrase>model</phrase>. Our <phrase>deformable mesh</phrase> <phrase>model</phrase> with <phrase>repulsive</phrase> force keeps <phrase>hidden</phrase>, collided surfaces to be touched each other, and gives <phrase>dense</phrase>, <phrase>non-rigid</phrase> complex 3D motion of the object. Some <phrase>experimental</phrase> <phrase>results</phrase> show that our <phrase>deformation model</phrase> can estimate motions of <phrase>multiple objects</phrase> and the object's motion with <phrase>time-varying</phrase> <phrase>global</phrase> <phrase>topology</phrase>, and gives <phrase>topologically</phrase>-consistent <phrase>mesh models</phrase> which can be compressed efficiently by conventional <phrase>inter-frame</phrase> 3D <phrase>data compression</phrase> <phrase>algorithms</phrase> and be used for 3D <phrase>motion analysis</phrase>.
<phrase>Computing</phrase> the <phrase>Camera Motion</phrase> Direction from Many Images.
We analyze the problem of <phrase>estimating</phrase> a camera's <phrase>motion direction</phrase> from a calibrated multi-<phrase>image sequence</phrase>. We assume that the <phrase>camera</phrase> moves roughly along a line and that its <phrase>velocity</phrase> and orientation are unknown and can vary over time. For <phrase>infinitesimal</phrase> <phrase>camera</phrase> motion (<phrase>multiple flows</phrase> rather than <phrase>multiple images</phrase>), we give a <phrase>closed-form expression</phrase> for the result of <phrase>minimizing</phrase> the true <phrase>least-squares</phrase> error over all variables but the camera's <phrase>motion direction</phrase>. Our result includes the <phrase>rigidity</phrase> constraint that the scene stays fixed over time. For finite motion, we present a <phrase>noniterative</phrase> <phrase>algorithm</phrase> that approximates the <phrase>exact</phrase> multi-image coplanarity error to better than a percent. Also, we define a new error contribution that incorporates the <phrase>rigidity</phrase> constraint and is analogous to the <phrase>rigidity</phrase> component of the error for <phrase>infinitesimal</phrase> motion. By adding this to the coplanarity error, we obtain a <phrase>noniterative</phrase> <phrase>algorithm</phrase> that approximates the complete finite motion <phrase>least-squares</phrase> error--including <phrase>rigidity</phrase>--as a <phrase>function</phrase> just of the <phrase>translation</phrase> direction.
<phrase>Minimum Spanning Tree</phrase> <phrase>Pose Estimation</phrase>.
The <phrase>extrinsic camera parameters</phrase> from <phrase>video</phrase> <phrase>stream</phrase> images can be <phrase>accurately estimated</phrase> by tracking features through the <phrase>image sequence</phrase> and using these features to compute <phrase>parameter estimates</phrase>. The poses for <phrase>long</phrase> <phrase>video</phrase> sequences have been estimated in this manner. However, the poses of <phrase>large sets</phrase> of still images cannot be estimated using the same strategy because <phrase>wide-baseline</phrase> correspondences are not as <phrase>robust</phrase> as <phrase>narrow-baseline</phrase> feature tracks. Moreover, <phrase>video</phrase> <phrase>pose estimation</phrase> requires a linear or hierarchically-<phrase>linear ordering</phrase> on the images to be calibrated, <phrase>reducing</phrase> the image matches to the neighboring <phrase>video</phrase> frames. We propose a novel <phrase>generalization</phrase> to the <phrase>linear ordering</phrase> requirement of <phrase>video</phrase> <phrase>pose estimation</phrase> by <phrase>computing</phrase> the <phrase>Minimum Spanning Tree</phrase> of the <phrase>camera</phrase> <phrase>adjacency graph</phrase> and using the <phrase>tree</phrase> hierarchy to determine the <phrase>calibration</phrase> <phrase>order</phrase> for a set of <phrase>input images</phrase>. We validate the pose accuracy using an <phrase>error metric</phrase> that is <phrase>functionally independent</phrase> of the <phrase>estimation process</phrase>. Because we do not rely on <phrase>feature tracking</phrase> for <phrase>generating</phrase> <phrase>feature correspondences</phrase>, our method can use internally calibrated wide- or <phrase>narrow-baseline</phrase> images as input, and can estimate the <phrase>camera</phrase> poses from <phrase>multiple video streams</phrase> without special <phrase>pre-processing</phrase> to concatenate the streams.
<phrase>Multiview</phrase> 3D Tracking with an Incrementally Constructed 3D <phrase>Model</phrase>.
We propose a <phrase>multiview</phrase> <phrase>tracking method</phrase> for <phrase>rigid objects</phrase>. Assuming that a part of the object is visible in at least two cameras, a <phrase>partial</phrase> 3D <phrase>model</phrase> is reconstructed in terms of a collection of small 3D <phrase>planar</phrase> patches of <phrase>arbitrary topology</phrase>. The 3D representation, recovered <phrase>fully automatically</phrase>, allows to formulate tracking as <phrase>gradient</phrase> minimization in pose (<phrase>translation</phrase>, rotation) space. As the object moves, the 3D <phrase>model</phrase> is <phrase>incrementally updated</phrase>. A <phrase>virtuous</phrase> <phrase>circle</phrase> emerges: tracking enables composition of the <phrase>partial</phrase> 3D <phrase>model</phrase>; the 3D <phrase>model</phrase> facilitates and robustifies the <phrase>multi-view</phrase> tracking. We <phrase>demonstrate experimentally</phrase> that the <phrase>interleaved</phrase> <phrase>track</phrase>-and-reconstruct approach successfully tracks a <phrase>360 degrees</phrase> turn-around and a <phrase>wide range</phrase> of motions. <phrase>Monocular</phrase> tracking is also possible after the <phrase>model</phrase> is constructed. Using more cameras, however, <phrase>significantly increases</phrase> stability in critical poses and moves. We demonstrate how to exploit the 3D <phrase>model</phrase> to increases stability in the presence of uneven and/or changing illumination.
<phrase>Hemispherical</phrase> <phrase>Harmonic</phrase> Surface Description and Applications to <phrase>Medical</phrase> <phrase>Image Analysis</phrase>.
The use of surface <phrase>harmonics</phrase> for <phrase>rigid and nonrigid</phrase> <phrase>shape description</phrase> is well known. In this <phrase>paper</phrase> we define a set of complete <phrase>hemispherical</phrase> <phrase>harmonic</phrase> <phrase>basis functions</phrase> on a hemisphere domain and propose a novel <phrase>parametric shape</phrase> description method to efficiently and flexibly represent the surfaces of <phrase>anatomical structures</phrase> in <phrase>medical</phrase> images. As the first application of <phrase>hemispherical</phrase> <phrase>harmonic</phrase> theory in <phrase>shape description</phrase>, our technique differs from the previous surface <phrase>harmonics</phrase> <phrase>shape descriptors</phrase>, all of which <phrase>don't</phrase> work efficiently on the hemisphere-like objects that often exist in <phrase>medical</phrase> <phrase>anatomical structures</phrase> (e.g., <phrase>ventricles</phrase>, atriums, etc.). We demonstrate the effectiveness of our approach through theoretic and <phrase>experimental</phrase> <phrase>exploration</phrase> of a set of <phrase>medical</phrase> image applications. Furthermore, an <phrase>evaluation criterion</phrase> for <phrase>surface modeling</phrase> efficiency is described and the <phrase>comparison results</phrase> demonstrated that our <phrase>method outperformed</phrase> the <phrase>previous approaches</phrase> using <phrase>spherical harmonic</phrase> models.
<phrase>Belief Propagation</phrase> for <phrase>Panorama</phrase> Generation.
We present an <phrase>algorithm</phrase> for <phrase>generating</phrase> <phrase>panoramic images</phrase> of <phrase>complex scenes</phrase> from a <phrase>multi-sensor</phrase> <phrase>camera</phrase>. We further present a <phrase>programmable graphics hardware</phrase> implementation to process the <phrase>large data sets</phrase> more quickly. Because the sensors do not share the same <phrase>center</phrase> of <phrase>projection</phrase>, <phrase>nearby objects</phrase> may not be <phrase>properly aligned</phrase>, <phrase>creating</phrase> a <phrase>ghosting</phrase> or echoing effect in the generated <phrase>panorama</phrase>, unless correct <phrase>depth information</phrase> is taken into account. Taking a <phrase>cue</phrase> from the similar problem of <phrase>dense</phrase> <phrase>stereo</phrase>, we <phrase>approximate</phrase> our scene with a <phrase>Markov random field</phrase> and use <phrase>belief propagation</phrase> to estimate the maximum <phrase>a posteriori</phrase> <phrase>panoramic</phrase> image for that scene.
<phrase>Reflectance</phrase> Modeling for <phrase>Layered</phrase> Dielectrics with <phrase>Rough Surface</phrase> Boundaries.
A new <phrase>model</phrase> for the <phrase>scattering</phrase> of <phrase>light</phrase> from <phrase>layered</phrase> dielectrics with <phrase>rough surface</phrase> boundaries is introduced. The <phrase>model</phrase> contains a <phrase>surface scattering</phrase> component together with a <phrase>subsurface scattering</phrase> component. The former component corresponds to the <phrase>roughness</phrase> on the <phrase>upper</phrase> surface boundary and is modeled using the <phrase>modified</phrase> <phrase>Beckmann model</phrase>. The latter component accounts for both <phrase>refraction</phrase> due to <phrase>Fresnel</phrase> transmission through the layer and <phrase>rough</phrase> <phrase>scattering</phrase> at the <phrase>lower</phrase> layer boundary. By allowing <phrase>independent</phrase> <phrase>roughness</phrase> parameters for each surface boundary we can <phrase>achieve excellent</phrase> fits of the <phrase>model</phrase> to the measured <phrase>BRDF</phrase> <phrase>data</phrase>. Using a well known method of testing <phrase>reflectance</phrase> models, we experiment with <phrase>BRDF</phrase> <phrase>data</phrase> from <phrase>skin</phrase> surface samples (<phrase>human</phrase> volunteers) and show that the new <phrase>model</phrase> outperforms <phrase>alternative</phrase> variants of the <phrase>Beckmann model</phrase> and the Lafortune <phrase>et al</phrase>. <phrase>reflectance</phrase> <phrase>model</phrase>. As an application in <phrase>computer graphics</phrase>, we also show that <phrase>realistic images</phrase> of 3D surfaces can be generated using the new <phrase>model</phrase>, by setting the values of its <phrase>physical parameters</phrase>.
<phrase>Multi-View</phrase> <phrase>Multi-Exposure</phrase> <phrase>Stereo</phrase>.
<phrase>Multi-view</phrase> <phrase>stereo</phrase> <phrase>algorithms</phrase> typically rely on same-exposure images as inputs due to the <phrase>brightness constancy</phrase> assumption. While <phrase>state</phrase>-of-the-<phrase>art</phrase> depth <phrase>results</phrase> are excellent, they do not produce <phrase>high</phrase>-<phrase>dynamic range</phrase> textures required for <phrase>high</phrase>-quality <phrase>view reconstruction</phrase>. In this <phrase>paper</phrase>, we propose a technique that adapts <phrase>multi-view stereo</phrase> for different exposure inputs to simultaneously recover <phrase>reliable</phrase> <phrase>dense</phrase> depth and <phrase>high</phrase> <phrase>dynamic range</phrase> textures. In our technique, we use an exposure-invariant similarity statistic to establish correspondences, through which we <phrase>robustly extract</phrase> the <phrase>camera</phrase> <phrase>radiometric</phrase> <phrase>response function</phrase> and the image exposures. This enables us to then convert all images to <phrase>radiance</phrase> space and selectively use the <phrase>radiance</phrase> <phrase>data</phrase> for <phrase>dense</phrase> depth and <phrase>high</phrase> <phrase>dynamic range</phrase> texture recovery. We show <phrase>results</phrase> for synthetic and <phrase>real scenes</phrase>.
<phrase>Synthesis</phrase> of 3D <phrase>Model</phrase> of a <phrase>Magnetic</phrase> Field-Influenced Body from a <phrase>Single</phrase> Image.
A method for recovery of a 3D <phrase>model</phrase> of a <phrase>planet</phrase>-sized <phrase>cloud</phrase>-like structure that is in motion and deforming but approximately <phrase>governed by</phrase> <phrase>magnetic field</phrase> properties is described. The method allows recovery of the <phrase>model</phrase> from a <phrase>single</phrase> <phrase>intensity image</phrase> in which the structure's <phrase>silhouette</phrase> can be observed. The method exploits <phrase>envelope</phrase> theory and a <phrase>magnetic field</phrase> <phrase>model</phrase>. Given one <phrase>intensity image</phrase> and the segmented <phrase>silhouette</phrase> in the image, the method proceeds without <phrase>human</phrase> intervention to produce the 3D <phrase>model</phrase>. In addition to allowing 3D <phrase>model</phrase> <phrase>synthesis</phrase>, the method's capability to yield a very <phrase>compact</phrase> description offers further utility. Application of the method to <phrase>real-world data</phrase> is also demonstrated.
A <phrase>Factorization Based</phrase> <phrase>Self-Calibration</phrase> for <phrase>Radially Symmetric</phrase> Cameras.
The <phrase>paper</phrase> proposes a novel approach for <phrase>planar</phrase> <phrase>self-calibration</phrase> of <phrase>radially symmetric</phrase> cameras. We <phrase>model</phrase> these <phrase>camera</phrase> images using notions of <phrase>distortion</phrase> <phrase>center</phrase> and <phrase>concentric</phrase> <phrase>distortion</phrase> circles around it. The <phrase>rays</phrase> corresponding to <phrase>pixels</phrase> lying on a <phrase>single</phrase> <phrase>distortion</phrase> <phrase>circle</phrase> form a right <phrase>circular cone</phrase>. Each of these cones is associated with two unknowns; optical <phrase>center</phrase> and <phrase>focal length</phrase> (<phrase>opening</phrase> angle). In the central case, we consider all <phrase>distortion</phrase> circles to have the same optical <phrase>center</phrase>, whereas in the non-central case they have different optical <phrase>centers</phrase> lying on the same <phrase>optical axis</phrase>. Based on this <phrase>model</phrase> we provide a <phrase>factorization based</phrase> <phrase>self-calibration</phrase> <phrase>algorithm</phrase> for <phrase>planar</phrase> scenes from <phrase>dense</phrase> image matches. Our formulation provides a rich set of constraints to validate the correctness of the <phrase>distortion</phrase> <phrase>center</phrase>. We also propose possible extensions of this <phrase>algorithm</phrase> in terms of non-<phrase>planar</phrase> scenes, non-unit <phrase>aspect ratio</phrase> and <phrase>multi-view</phrase> constraints. <phrase>Experimental</phrase> <phrase>results</phrase> are shown.
3D <phrase>Content-Based Search</phrase> Based on 3D <phrase>Krawtchouk Moments</phrase>.
In this <phrase>paper</phrase> a novel method for 3D <phrase>content-based</phrase> search and retrieval is proposed. <phrase>Guided</phrase> by the imperative need for a <phrase>reliable</phrase> 3D <phrase>content based search</phrase> tool and the very <phrase>interesting results</phrase> of <phrase>research</phrase> work done in the past on the performance of <phrase>Krawtchouk moments</phrase> and <phrase>Krawtchouk</phrase> <phrase>moment invariants</phrase> in <phrase>image processing</phrase>, <phrase>Weighted</phrase> 3D <phrase>Krawtchouk moments</phrase> are introduced for <phrase>efficient</phrase> 3D analysis which are suitable for <phrase>content-based</phrase> search and retrieval applications. The <phrase>proposed method</phrase> was tested on <phrase>Princeton</phrase> Shape Benchmark. Experiments have shown that the <phrase>proposed method</phrase> is <phrase>superior</phrase> in terms of <phrase>precision-recall</phrase> <phrase>comparing</phrase> with other well-known methods reported in the <phrase>literature</phrase>.
A <phrase>CSC</phrase> <phrase>Based Classification</phrase> Method for <phrase>CT</phrase> <phrase>Bone</phrase> Images.
The <phrase>CSC</phrase> (<phrase>color</phrase> structure code) is a <phrase>robust</phrase> and <phrase>fast</phrase> <phrase>two dimensional</phrase> <phrase>segmentation method</phrase> which has been already <phrase>generalized</phrase> to <phrase>three dimensional</phrase> images. As the <phrase>CSC</phrase> does not need any <phrase>prior knowledge</phrase> it can be used for different applications. In this <phrase>paper</phrase> we focus on the segmentation of <phrase>bones</phrase> from <phrase>Computer Tomography</phrase> <phrase>data</phrase> (<phrase>CT</phrase>) with the <phrase>CSC</phrase>. In the <phrase>postprocessing</phrase> step <phrase>CSC</phrase> segments will be classified according to their <phrase>average</phrase> hounsfield value. The classification is <phrase>steered</phrase> by some <phrase>application specific</phrase> <phrase>topological</phrase> rules.
<phrase>Illumination Insensitive</phrase> <phrase>Model</phrase>-Based 3D <phrase>Object Tracking</phrase> and Texture <phrase>Refinement</phrase>.
A common approach to <phrase>model</phrase>-based tracking is to use a <phrase>model</phrase> of the object to predict what will be observed, and then to compare that with real observations. For methods that make use of the object's <phrase>photometric</phrase> properties (appearance) in their measurements, illumination inconsistencies between the modeled and actual scene can cause tracking problems. In this <phrase>paper</phrase> we address one case: <phrase>model</phrase>-based tracking of <phrase>Lambertian</phrase> objects under <phrase>directional</phrase> <phrase>light</phrase> sources. We present an <phrase>iterative optimization</phrase> method that uses a <phrase>Kalman filter</phrase> to simultaneously refine estimates of the <phrase>object motion</phrase>, the illumination, and the <phrase>model</phrase> texture. We <phrase>model</phrase> the illumination <phrase>variance</phrase> between the real and predicted observation using the intensity ratios of corresponding <phrase>surface points</phrase>, which we then use to make <phrase>model-based</phrase> image predictions consistent with the real lighting. To demonstrate the effectiveness of our method we present <phrase>experimental</phrase> <phrase>results</phrase> using both synthetic (controlled) and <phrase>real image sequences</phrase>.
<phrase>Object Centered</phrase> <phrase>Stereo</phrase>: <phrase>Displacement Map</phrase> Estimation Using Texture and Shading.
We consider the problem of <phrase>recovering</phrase> 3D surface displacements using both shading and <phrase>multi-view</phrase> <phrase>stereo</phrase> cues. In contrast to traditional disparity or <phrase>depth map</phrase> representations, the <phrase>object centered</phrase> <phrase>displacement map</phrase> representation enables the recovery of complete 3D objects while also ensuring the <phrase>reconstruction</phrase> is not <phrase>biased</phrase> towards a particular image. Although <phrase>displacement mapping</phrase> requires a base surface, this <phrase>base mesh</phrase> is <phrase>easily obtained</phrase> using traditional <phrase>computer vision</phrase> techniques (e.g., <phrase>shape-from-silhouette</phrase> or <phrase>structure-from-motion</phrase>). Our method exploits shading variation due to <phrase>object rotation</phrase> relative to the <phrase>light</phrase> source, allowing the recovery of displacements in both textured and textureless regions in a common framework. In particular, shading cues are integrated into a <phrase>multi-view stereo</phrase> <phrase>photo</phrase>-consistency <phrase>function</phrase> through the <phrase>surface normals</phrase> that are implied by the <phrase>displacement map</phrase>. The <phrase>analytic</phrase> <phrase>gradient</phrase> of this <phrase>photo</phrase>-consistency <phrase>function</phrase> is used to drive a <phrase>multiresolution</phrase> <phrase>conjugate gradient</phrase> optimization. We demonstrate the <phrase>geometric</phrase> quality of the reconstructed displacements on several example objects including a <phrase>human</phrase> face.
<phrase>Flatness</phrase> and Orientation Signature for Modeling and Matching 3D Objects.
This <phrase>paper</phrase> proposes a new technique for modeling and matching <phrase>three-dimensional</phrase> <phrase>rigid objects</phrase> by encoding the fluctuation of the surface and the variation of its normal around an oriented point on the surface as the surface expands. The surface of the object is encoded into two <phrase>two-dimensional</phrase> curves as the surface signature on each point, and then the collection of the <phrase>signatures</phrase> are used to <phrase>model</phrase> and match the object. The <phrase>signatures</phrase> <phrase>implicitly encode</phrase> the <phrase>curvature</phrase> and <phrase>symmetry</phrase> of the surface around an oriented point. This <phrase>modeling technique</phrase> is <phrase>robust</phrase> to scale, orientation, noise, patch resolution, occlusion, and cluttering.
<phrase>Large-Scale</phrase> Modeling of <phrase>Parametric</phrase> Surfaces Using <phrase>Spherical Harmonics</phrase>.
We present an approach for <phrase>large-scale</phrase> modeling of <phrase>parametric</phrase> surfaces using <phrase>spherical harmonics</phrase> (SHs). A standard <phrase>least square fitting</phrase> (<phrase>LSF</phrase>) method for <phrase>SH</phrase> <phrase>expansion</phrase> is not scalable and cannot accurately <phrase>model</phrase> large 3D surfaces. We propose an <phrase>iterative</phrase> <phrase>residual</phrase> <phrase>fitting</phrase> (<phrase>IRF</phrase>) <phrase>algorithm</phrase>, and demonstrate its effectiveness and <phrase>scalability</phrase> in <phrase>creating</phrase> accurate <phrase>SH</phrase> models for large 3D surfaces. These <phrase>large-scale</phrase> and accurate <phrase>parametric</phrase> models can be used in many applications in <phrase>computer vision</phrase>, graphics, and <phrase>biomedical imaging</phrase>. As a simple extension of <phrase>LSF</phrase>, <phrase>IRF</phrase> is very <phrase>easy to implement</phrase> and requires few machine resources.
<phrase>Graph Cut</phrase> Based <phrase>Multiple View</phrase> Segmentation for 3D <phrase>Reconstruction</phrase>.
In this <phrase>paper</phrase> we propose a novel framework for efficiently <phrase>extracting</phrase> <phrase>foreground objects</phrase> in so called shortbaseline <phrase>image sequences</phrase>. We apply the obtained segmentation to improve subsequent 3D <phrase>reconstruction</phrase> <phrase>results</phrase>. Essentially, our framework combines a <phrase>graph cut based</phrase> <phrase>optimization algorithm</phrase> with an <phrase>intuitive user interface</phrase>. At first a meanshift <phrase>segmentation algorithm</phrase> <phrase>partitions</phrase> each image of the <phrase>sequence</phrase> into a certain number of regions. Additionally we provide <phrase>an intelligent</phrase> <phrase>graphical user interface</phrase> for easy specification of foreground as well as <phrase>background regions</phrase> across all images of the <phrase>sequence</phrase>. Within the <phrase>graph cut optimization</phrase> <phrase>algorithm</phrase> we define new <phrase>energy</phrase> terms to increase the robustness and to keep the segmentation of the <phrase>foreground object</phrase> <phrase>coherent</phrase> across all images of the <phrase>sequence</phrase>. <phrase>Finally</phrase>, a refined <phrase>graph cut</phrase> segmentation and several adjustment operations allow an accurate and effective <phrase>foreground extraction</phrase>. The obtained <phrase>results</phrase> are demonstrated on several <phrase>real world data sets</phrase>.
<phrase>Depth Images</phrase>: Representations and <phrase>Real-Time Rendering</phrase>.
<phrase>Depth Images</phrase> are viable representations that can be computed from the <phrase>real world</phrase> using cameras and/or other scanning devices. The <phrase>depth map</phrase> provides 2<phrase>\frac</phrase>{1}{2}<phrase>D</phrase> structure of the scene. A set of <phrase>Depth Images</phrase> can provide <phrase>hole</phrase>-<phrase>free</phrase> rendering of the scene. <phrase>Multiple views</phrase> need to <phrase>blended</phrase> to provide smooth <phrase>hole</phrase>-<phrase>free</phrase> rendering, however. Such a representation of the scene is bulky and needs good <phrase>algorithms</phrase> for <phrase>real-time rendering</phrase> and <phrase>efficient</phrase> representation. In this <phrase>paper</phrase>, we present a discussion on the <phrase>Depth Image</phrase> representation and provide a <phrase>GPU-based</phrase> <phrase>algorithm</phrase> that can render large models represented using <phrase>DIs</phrase> in <phrase>real time</phrase>. We then present a <phrase>proxy-based</phrase> <phrase>compression scheme</phrase> for <phrase>Depth Images</phrase> and provide <phrase>results</phrase> for the same. <phrase>Results</phrase> are shown on <phrase>synthetic scenes</phrase> under different conditions and on some scenes generated from images. Lastly, we initiate discussion on varying <phrase>quality levels</phrase> in <phrase>IBR</phrase> and show a way to create representations using <phrase>DIs</phrase> with different <phrase>trade</phrase>-offs between <phrase>model</phrase> size and <phrase>rendering quality</phrase>. This enables the use of this representation for a <phrase>variety</phrase> of rendering situations.
How Far Can We <phrase>Go</phrase> with <phrase>Local</phrase> Optimization in <phrase>Real-Time</phrase> <phrase>Stereo</phrase> Matching.
Applications such as <phrase>robot</phrase> <phrase>navigation</phrase> and <phrase>augmented reality</phrase> require <phrase>high</phrase>-accuracy <phrase>dense disparity maps</phrase> in <phrase>real-time</phrase> and <phrase>online</phrase>. Due to time constraint, most <phrase>real-time</phrase> <phrase>stereo</phrase> applications rely on <phrase>local</phrase> <phrase>winner</phrase>-take-all optimization in the <phrase>disparity computation</phrase> process. These <phrase>local</phrase> approaches are generally outperformed by offline <phrase>global optimization</phrase> <phrase>based algorithms</phrase>. However, <phrase>recent research</phrase> shows that, through <phrase>carefully selecting</phrase> and <phrase>aggregating</phrase> the matching costs of <phrase>neighboring pixels</phrase>, the <phrase>disparity maps</phrase> <phrase>produced</phrase> by a <phrase>local</phrase> approach can be more accurate than those generated by many <phrase>global optimization</phrase> techniques. We are therefore motivated to investigate whether these <phrase>cost aggregation</phrase> approaches can be adopted in <phrase>real-time</phrase> <phrase>stereo</phrase> applications and, if so, how well they perform under the <phrase>real-time</phrase> constraint. The evaluation is conducted on a <phrase>real-time</phrase> <phrase>stereo</phrase> platform, which utilizes the <phrase>processing power</phrase> of <phrase>programmable graphics hardware</phrase>. Several recent <phrase>cost aggregation</phrase> approaches are also implemented and optimized for <phrase>graphics hardware</phrase> so that <phrase>real-time</phrase> speed can be achieved. The performances of these aggregation approaches in terms of both <phrase>processing speed</phrase> and <phrase>result quality</phrase> are reported.
<phrase>A Bayesian Approach</phrase> to <phrase>Building Footprint</phrase> Extraction from <phrase>Aerial LIDAR Data</phrase>.
<phrase>Building footprints</phrase> have been shown to be extremely useful in <phrase>urban planning</phrase>, <phrase>infrastructure</phrase> development, and <phrase>roof</phrase> modeling. <phrase>Current methods</phrase> for <phrase>creating</phrase> these <phrase>footprints</phrase> are often highly manual and rely largely on <phrase>architectural</phrase> <phrase>blueprints</phrase> or skilled modelers. In this work we will use <phrase>aerial LIDAR data</phrase> to generate <phrase>building footprints</phrase> automatically. Existing <phrase>automatic</phrase> methods have been mostly unsuccessful due to large amounts of noise around <phrase>building</phrase> edges. We present a novel <phrase>Bayesian</phrase> technique for <phrase>automatically constructing</phrase> <phrase>building footprints</phrase> from a <phrase>pre-classified</phrase> <phrase>LIDAR</phrase> <phrase>point cloud</phrase>. Our <phrase>algorithm</phrase> first computes a boundederror <phrase>approximate</phrase> <phrase>building footprint</phrase> using an application of the <phrase>shortest path</phrase> <phrase>algorithm</phrase>. We then determine the <phrase>most probable</phrase> <phrase>building footprint</phrase> by <phrase>maximizing</phrase> the <phrase>posterior probability</phrase> using <phrase>linear optimization</phrase> and <phrase>simulated annealing</phrase> techniques. We have applied our <phrase>algorithm</phrase> to more than 300 buildings in our <phrase>data</phrase> set and observe that we obtain accurate <phrase>building footprints</phrase> compared to the <phrase>ground truth</phrase>. Our <phrase>algorithm</phrase> is <phrase>automatic</phrase> and can be applied to other <phrase>man</phrase>-made shapes such as roads and <phrase>telecommunication</phrase> lines with <phrase>minor modifications</phrase>.
A System for <phrase>Reconstructing</phrase> Integrated <phrase>Texture Maps</phrase> for Large Structures.
We consider the problem of <phrase>creating</phrase> integrated <phrase>texture maps</phrase> of large structures scanned with a <phrase>time-of-flight</phrase> <phrase>laser scanner</phrase> and imaged with a <phrase>digital camera</phrase>. The <phrase>key issue</phrase> in <phrase>creating</phrase> integrated textures is <phrase>correcting</phrase> for the <phrase>spatially varying</phrase> illumination across the structure. In most cases, the illumination cannot be controlled, and <phrase>dense</phrase> <phrase>spatial</phrase> estimates of illumination are not possible. We present a system for processing multiple <phrase>color images</phrase> into <phrase>an integrated</phrase> texture that makes use of the <phrase>laser scanner</phrase> return intensity and the captured <phrase>geometry</phrase>, together with <phrase>color</phrase> <phrase>balancing</phrase> and mapping of illumination-corrected images onto the <phrase>target</phrase> <phrase>geometry</phrase> after filtering into two <phrase>spatial frequency</phrase> bands.
<phrase>Motion Editing</phrase> in 3D <phrase>Video</phrase> <phrase>Database</phrase>.
As the <phrase>next</phrase> generation of <phrase>media</phrase>, 3D <phrase>video</phrase> is attracting <phrase>increased attention</phrase>. 3D <phrase>video</phrase> is a <phrase>sequence</phrase> of <phrase>three dimensional</phrase> <phrase>mesh models</phrase>, captured and generated for a real <phrase>dynamic</phrase> object. In this <phrase>paper</phrase>, we present a simple framework of <phrase>motion editing</phrase> in 3D <phrase>video</phrase> <phrase>database</phrase> to <phrase>re</phrase>-use 3D <phrase>video</phrase> <phrase>data</phrase>. Our system is composed of two modules. In the first module, a motion <phrase>database</phrase> is automatically set up from original 3D <phrase>video</phrase> sequences <phrase>off-line</phrase> by <phrase>analyzing</phrase> the <phrase>feature vectors</phrase> of each frame. It is observed that our original 3D <phrase>video</phrase> sequences have a <phrase>two-level</phrase> <phrase>temporal structure</phrase>. A <phrase>fine-to-coarse</phrase> method is proposed to extract such a structure. 3D <phrase>video</phrase> is segmented into the fine-level structure by a three <phrase>reference frame</phrase> strategy and then is <phrase>clustered</phrase> into the <phrase>coarse-level</phrase> structure. In the second module, users can synthesize the motions to edit a new 3D <phrase>video</phrase> <phrase>sequence</phrase> <phrase>online</phrase>. A <phrase>cost function</phrase> is optimized to <phrase>transit</phrase> between two motions with the users' requirements. All the <phrase>algorithms</phrase> in the system are based on the analysis in <phrase>feature vector</phrase> space and the edited 3D <phrase>video</phrase> <phrase>sequence</phrase> is played using <phrase>OpenGL</phrase>.
The ASDMCon <phrase>Project</phrase>: The <phrase>Challenge</phrase> of <phrase>Detecting</phrase> Defects on <phrase>Construction</phrase> Sites.
Techniques for <phrase>three dimensional</phrase> (3D) <phrase>imaging</phrase> and analysis of as-built conditions of buildings are <phrase>gaining acceptance</phrase> in the <phrase>Architecture</phrase>, <phrase>Engineering</phrase>, and <phrase>Construction</phrase> (<phrase>AEC</phrase>) <phrase>community</phrase>. <phrase>Early detection</phrase> of defects on <phrase>construction</phrase> sites is one domain where these techniques have the potential to revolutionize an <phrase>industry</phrase>, since <phrase>construction</phrase> defects can consume a significant portion of a project's budget. The ASDMCon <phrase>project</phrase> is <phrase>developing</phrase> methods to aid site managers in <phrase>detecting</phrase> and <phrase>managing</phrase> <phrase>construction</phrase> defects using 3D <phrase>imaging</phrase> and other <phrase>advanced</phrase> <phrase>sensor</phrase> technologies. This <phrase>paper</phrase> presents <phrase>an overview</phrase> of the <phrase>project</phrase>, its 4D <phrase>visualization environment</phrase>, and the 3D segmentation and recognition strategies that are being employed to automate <phrase>defect detection</phrase>.
<phrase>High</phrase>-Performance <phrase>Multi-View Reconstruction</phrase>.
We present <phrase>a high performance</phrase> <phrase>reconstruction</phrase> approach, which generates true 3D models from <phrase>multiple views</phrase> with known <phrase>camera</phrase> parameters. The complete pipeline from <phrase>depth map</phrase> generation over <phrase>depth image</phrase> <phrase>integration</phrase> to the final 3D <phrase>model</phrase> visualization is performed on <phrase>programmable graphics processing units</phrase> (<phrase>GPUs</phrase>). The proposed pipeline is suitable for <phrase>long</phrase> <phrase>image sequences</phrase> and uses a <phrase>plane-sweep</phrase> <phrase>depth estimation</phrase> procedure optionally employing <phrase>robust</phrase> <phrase>image similarity</phrase> functions to generate a set of <phrase>depth images</phrase>. The subsequent <phrase>volumetric</phrase> <phrase>fusion</phrase> step combines these <phrase>depth maps</phrase> into an impicit <phrase>surface representation</phrase> of the final <phrase>model</phrase>, which can be directly displayed using <phrase>GPU</phrase>-based <phrase>raycasting</phrase> methods. Depending on the number of input views and the desired resolution of the final <phrase>model</phrase> the <phrase>computing</phrase> times <phrase>range</phrase> from several seconds to a few minutes. The quality of the obtained models is illustrated with <phrase>real-world</phrase> datasets.
<phrase>Multiple Camera</phrase> <phrase>Calibration</phrase> Using <phrase>Robust</phrase> <phrase>Perspective</phrase> Factorization.
In this <phrase>paper</phrase> we address the problem of <phrase>recovering</phrase> <phrase>structure and motion</phrase> from a <phrase>large number</phrase> of intrinsically calibrated <phrase>perspective</phrase> cameras. We describe a method that combines (1) <phrase>weak-perspective</phrase> <phrase>reconstruction</phrase> in the presence of noisy and <phrase>missing data</phrase> and (2) an <phrase>algorithm</phrase> that updates <phrase>weak-perspective</phrase> <phrase>reconstruction</phrase> to <phrase>perspective</phrase> <phrase>reconstruction</phrase> by incrementally <phrase>estimating</phrase> the <phrase>projective</phrase> depths. The method also solves for the <phrase>reversal</phrase> ambiguity associated with <phrase>affine</phrase> factorization techniques. The method has been <phrase>successfully applied</phrase> to the problem of <phrase>calibrating</phrase> the external parameters (<phrase>position and orientation</phrase>) of several <phrase>multiple-camera</phrase> setups. <phrase>Results</phrase> obtained with synthetic and <phrase>experimental</phrase> <phrase>data</phrase> <phrase>compare favourably</phrase> with <phrase>results</phrase> obtained with <phrase>nonlinear</phrase> minimization such as <phrase>bundle adjustment</phrase>.
Angle <phrase>Independent</phrase> <phrase>Bundle Adjustment</phrase> <phrase>Refinement</phrase>.
Obtaining a <phrase>digital</phrase> <phrase>model</phrase> of a <phrase>real-world</phrase> 3D scene is a <phrase>challenging task</phrase> pursued by <phrase>computer vision</phrase> and <phrase>computer graphics</phrase>. Given an initial <phrase>approximate</phrase> 3D <phrase>model</phrase>, a popular <phrase>refinement</phrase> process is to perform a <phrase>bundle adjustment</phrase> of the estimated <phrase>camera</phrase> position, <phrase>camera</phrase> orientation, and <phrase>scene points</phrase>. Unfortunately, simultaneously solving for both <phrase>camera</phrase> position and <phrase>camera</phrase> orientation is an <phrase>ill-conditioned</phrase> problem. To address this issue, we propose <phrase>an improved</phrase>, <phrase>camera</phrase>-orientation <phrase>independent</phrase> <phrase>cost function</phrase> that can be used <phrase>instead</phrase> of the standard <phrase>bundle adjustment</phrase> <phrase>cost function</phrase>. This yields a new <phrase>bundle adjustment</phrase> formulation which exhibits noticeably better numerical behavior, but at the expense of an increased <phrase>computational cost</phrase>. We alleviate the <phrase>additional cost</phrase> by automatically partitioning the dataset into <phrase>smaller subsets</phrase>. <phrase>Minimizing</phrase> our <phrase>cost function</phrase> for these subsets still achieves significant <phrase>error reduction</phrase> over standard <phrase>bundle adjustment</phrase>. We <phrase>empirically demonstrate</phrase> our formulation using several different size models and <phrase>image sequences</phrase>.
<phrase>Image Based</phrase> Localization in <phrase>Urban</phrase> Environments.
